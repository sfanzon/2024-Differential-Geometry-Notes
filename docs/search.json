[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Differential Geometry",
    "section": "",
    "text": "Welcome\nThese are the Lecture Notes of Differential Geometry 661955 for 2024/25 at the University of Hull. I will use this material during lectures. If you have any question or find any typo, please email me at\nUp to date information about the course, Tutorials and Homework will be published on the University of Hull Canvas Website",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#digital-notes",
    "href": "index.html#digital-notes",
    "title": "Differential Geometry",
    "section": "Digital Notes",
    "text": "Digital Notes\nFeatures of these digital notes:\n\nNavigation bar is available on the left\nA search function is available on the top-right\nYou can toggle dark mode on the top-right\nA pdf version of these notes is available to download on the top-right",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#readings",
    "href": "index.html#readings",
    "title": "Differential Geometry",
    "section": "Readings",
    "text": "Readings\nWe will study curves and surfaces in \\(\\mathbb{R}^3\\), as well as some general topology. The main textbooks are:\n\nPressley (Pressley 2010) for differential geometry,\nManetti (Manetti 2023) for general topology.\n\nOther good readings are the books by do Carmo (do Carmo 2017) and Abate, Tovena (Abate, Marco and Tovena, Francesca 2011). I will assume some knowledge from Analysis and Linear Algebra. A good place to revise these topics are the books by Zorich (Zorich 2015, 2016).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#visualization",
    "href": "index.html#visualization",
    "title": "Differential Geometry",
    "section": "Visualization",
    "text": "Visualization\nIt is important to visualize the geometrical objects and concepts we are going to talk about in this course. I will show basic Python code to plot curves and surfaces. This part of the course is not required for the final examination. If you want to have fun plotting with Pyhton, I recommend installation through Anaconda or Miniconda. The actual coding can then be done through Jupyter Notebook. Good references for scientific Python programming are (Johansson 2019; Kong, Qingkai, Siauw, Timmy, and Bayen, Alexandre 2020).\nIf you do not want to mess around with Python, you can still visualize pretty much everything we will do in this course using the excellent online 3D grapher tool CalcPlot3D. To understand how it works, please refer to the help manual or to the short video introduction. Another nice tool is Desmos.\n\n\n\n\n\n\nImportant\n\n\n\nYou are not expected to purchase any of the above books. These lecture notes will cover 100% of the topics you are expected to known in order to excel in the Homework and Final Exam.\n\n\n\n\n\n\nAbate, Marco, and Tovena, Francesca. 2011. Curves and Surfaces. Springer.\n\n\ndo Carmo, Manfredo P. 2017. Differential Geometry of Curves and Surfaces. Second Edition. Dover Books on Mathematics.\n\n\nJohansson, Robert. 2019. Numerical Python. Scientific Computing and Data Science Applications with Numpy, SciPy and Matplotlib. Second Edition. Apress.\n\n\nKong, Qingkai, Siauw, Timmy, and Bayen, Alexandre. 2020. Python Programming and Numerical Methods. Academic Press.\n\n\nManetti, Marco. 2023. Topology. Second Edition. Springer.\n\n\nPressley, Andrew. 2010. Elementary Differential Geometry. Second Edition. Springer.\n\n\nZorich, Vladimir A. 2015. Mathematical Analysis I. Second Edition. Springer.\n\n\n———. 2016. Mathematical Analysis II. Second Edition. Springer.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "sections/chap_1.html",
    "href": "sections/chap_1.html",
    "title": "1  Curves",
    "section": "",
    "text": "1.1 Parametrized curves\nRather than Cartesian equations, a more useful way of thinking about curves is viewing them as the path traced out by a moving point. If \\(\\pmb{\\gamma}(t)\\) represents the position a point in \\(\\mathbb{R}^n\\) at time \\(t\\), the whole curve can be identified by the function \\[\n\\pmb{\\gamma} \\ \\colon \\mathbb{R} \\to \\mathbb{R}^n \\,, \\,\\,\\, \\pmb{\\gamma} = \\pmb{\\gamma}(t) \\,.\n\\]\nThis motivates the following definition of parametrized curve, which will be our main definition of curve.\nA few remarks:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#parametrized-curves",
    "href": "sections/chap_1.html#parametrized-curves",
    "title": "1  Curves",
    "section": "",
    "text": "Definition 1: Parametrized curveA parametrized curve in \\(\\mathbb{R}^n\\) is a function \\[\n\\pmb{\\gamma} \\ \\colon  (a,b) \\to \\mathbb{R}^n \\,.\n\\]\nwhere\n\\[\n- \\infty \\leq a &lt; b \\leq \\infty \\,.\n\\]\n\n\n\n\nThe symbol \\((a,b)\\) denotes an open interval \\[\n(a,b) = \\{ t \\in \\mathbb{R} \\ \\colon \\ a &lt; t &lt; b \\}\\,.\n\\]\nThe requirement that \\[\n-\\infty \\leq a &lt; b \\leq \\infty\n\\] means that the interval \\((a,b)\\) is possibly unbounded.\nFor each \\(t \\in (a,b)\\) the quantity \\(\\pmb{\\gamma}(t)\\) is a vector in \\(\\mathbb{R}^n\\).\nThe components of \\(\\pmb{\\gamma}(t)\\) are denoted by \\[\n\\pmb{\\gamma}(t) = ( \\gamma_1(t), \\ldots, \\gamma_n(t) ) \\,,\n\\] where the components are functions \\[\n\\gamma_i \\ \\colon (a,b) \\to \\mathbb{R} \\,,\n\\] for all \\(i = 1, \\ldots, n\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#parametrizing-cartesian-curves",
    "href": "sections/chap_1.html#parametrizing-cartesian-curves",
    "title": "1  Curves",
    "section": "1.2 Parametrizing Cartesian curves",
    "text": "1.2 Parametrizing Cartesian curves\nAt the start we said that examples of curves in \\(\\mathbb{R}^2\\) were the straight line, the hyperbole and the circle, with equations \\[\ny = 2x + 1\\,, \\quad y = e^x  \\,, \\quad  x^2 + y^2 = 1 \\,.\n\\] We saw that these can be represented by Cartesian equations \\[\nf(x,y) = c\n\\] for some function \\(f \\ \\colon \\mathbb{R}^2 \\to \\mathbb{R}\\) and value \\(c \\in \\mathbb{R}\\). Curves that can be represented in this way are called level curves. Let us give a precise definition.\n\nDefinition 2: Level curveA level curve in \\(\\mathbb{R}^n\\) is a set \\(C \\subset \\mathbb{R}^n\\) which can be described as \\[\nC= \\{  (x_1,\\ldots,x_n) \\in \\mathbb{R}^n \\ \\colon \\ f(x_1,\\ldots,x_n) = c   \\}\n\\] for some given function \\[\nf \\ \\colon \\mathbb{R}^n \\to \\mathbb{R}\n\\] and value \\[\nc \\in \\mathbb{R} \\,.\n\\]\n\n\nWe now want to represent level curves by means of parametrizations.\n\nDefinition 3Suppose given a level curve \\(C \\subset \\mathbb{R}^n\\). We say that a curve \\[\n\\pmb{\\gamma} \\ \\colon (a,b) \\to \\mathbb{R}^n\n\\] parametrizes \\(C\\) if \\[\nC = \\{ (\\gamma_1(t), \\ldots, \\gamma_n(t) ) \\ \\colon \\ t \\in (a,b)   \\} \\,.\n\\]\n\n\n\nQuestionCan we represent the level curves we saw above by means of a parametrization \\(\\pmb{\\gamma}\\)?\n\n\nThe answer is YES, as shown in the following examples.\n\nExample 4: Parametrizing the straight lineThe straight line \\[\ny = 2x + 1\n\\]\nis a level curve with \\[\nC = \\{ (x,y) \\in \\mathbb{R}^2 \\ \\colon \\  f(x,y) = c  \\} \\,,\n\\] where \\[\nf(x,y) := y -2x \\,, \\quad c :=1 \\,.\n\\]\nHow do we represent \\(C\\) as a parametrized curve \\(\\pmb{\\gamma}\\)? We know that the curve is 2D, therefore we need to find a function \\[\n\\pmb{\\gamma} \\ \\colon  (a,b) \\to \\mathbb{R}^2\n\\] with componenets \\[\n\\pmb{\\gamma}(t) = (\\gamma_1(t),\\gamma_2(t)) \\, .\n\\] The curve \\({\\pmb{\\gamma}}\\) needs to be chosen so that it parametrizes the set \\(C\\), in the sense that \\[\nC = \\{ (\\gamma_1(t), \\gamma_2(t)) \\ \\colon \\ t \\in (a,b)  \\} \\,.\n\\tag{1.1}\\] Thus we need to have \\[\n(x,y) = (\\gamma_1,\\gamma_2) \\,.\n\\tag{1.2}\\] How do we define such \\(\\pmb{\\gamma}\\)? Note that the points \\((x,y)\\) in \\(C\\) satisfy \\[\n(x,y) \\in C \\iff  y = 2x +1 \\,.\n\\] Therefore, using (1.2), we have that \\[\n\\gamma_1 = x \\,, \\quad \\gamma_2 = y = 2x + 1\n\\] from which we deduce that \\(\\pmb{\\gamma}\\) must satisfy \\[\n\\gamma_2(t) = 2 \\gamma_1(t) + 1\n\\tag{1.3}\\] for all \\(t \\in (a,b)\\). We can then choose \\[\n\\gamma_1(t) := t \\,,\n\\] and from (1.3) we deduce that \\[\n\\gamma_2 (t) = 2 t + 1 \\,.\n\\] This choice of \\(\\pmb{\\gamma}\\) works: \\[\\begin{align}\nC & = \\{ (x,2x+1) \\ \\colon \\ x \\in \\mathbb{R}  \\} \\\\\n  & = \\{ (t,2t+1) \\ \\colon \\ - \\infty &lt; t &lt; \\infty  \\} \\\\\n  & = \\{ (\\gamma_1(t),\\gamma_2(t)) \\ \\colon \\ - \\infty &lt; t &lt; \\infty  \\} \\,,\n\\end{align}\\] where in the second line we just swapped the symbol \\(x\\) with the symbol \\(t\\). In this case we have to choose the time interval as \\[\n(a,b) = (-\\infty,\\infty) \\,.\n\\] In this way \\(\\pmb{\\gamma}\\) satisfies (1.1) and we have successfully parametrized the straight line \\(C\\).\n\n\n\nRemark 5: Parametrization is not uniqueLet us consider again the straight line \\[\nC = \\{ (x,y) \\in \\mathbb{R}^2 \\ \\colon \\  2x+1 = y \\} \\,.\n\\] We saw that \\(\\pmb{\\gamma} \\colon (-\\infty,\\infty) \\to \\mathbb{R}^2\\) defined by \\[\n\\pmb{\\gamma}(t):=(t,2t+1)\n\\] is a parametrization of \\(C\\). But of course any \\(\\pmb{\\gamma}\\) satisfying \\[\n\\gamma_2(t) = 2 \\gamma_1(t) + 1\n\\] would yield a parametrization of \\(C\\). For example one could choose \\[\n\\gamma_1 (t) = 2t \\,, \\quad \\gamma_2(t) = 2 \\gamma_1(t) + 1 = 4t + 1 \\,.\n\\] In general, any time rescaling would work: the curve \\(\\pmb{\\gamma}\\) defined by \\[\n\\gamma_1 (t) = nt \\,, \\quad \\gamma_2(t) = 2 \\gamma_1(t) + 1 = 2nt + 1  \n\\] parametrizes \\(C\\) for all \\(n \\in \\mathbb{N}\\). Hence there are infinitely many parametrizations of \\(C\\).\n\n\n\nExample 6: Parametrizing the circle\nThe circle \\(C\\) is described by all the points \\((x,y) \\in \\mathbb{R}^2\\) such that \\[\nx^2 + y^2 = 1\\,.\n\\] Therefore if we want to find a curve \\[\n\\pmb{\\gamma} = (\\gamma_1,\\gamma_2)\n\\] which parametrizes \\(C\\), this has to satisfy \\[\n\\gamma_1 (t)^2 + \\gamma_2(t)^2 = 1\n\\tag{1.4}\\] for all \\(t \\in (a,b)\\).\nHow to find such curve? We could proceed as in the previous example, and set \\[\n\\gamma_1(t):=t \\,.\n\\] Then (1.4) implies \\[\n\\gamma_2 (t) = \\sqrt{1-t^2}\\,,\n\\] from which we also deduce that \\[\n- 1 \\leq t \\leq 1\n\\] are the only admissible values of \\(t\\). However this curve does not represent the full circle \\(C\\), but only the upper half, as seen in the plot below.\nSimlarly, another solution to (1.4) would be \\(\\pmb{\\gamma}\\) with \\[\n\\gamma_1(t)=t \\,, \\quad \\gamma_2 (t) = - \\sqrt{1-t^2}\\,,\n\\] for \\(t \\in [-1,1]\\). However this choice does not parametrize the full circle \\(C\\) either, but only the bottom half, as seen in the plot below.\nHow to represent the whole circle? Recall the trigonometric identity \\[\n\\cos(t)^2 + \\sin(t)^2 = 1\n\\] for all \\(t \\in \\mathbb{R}\\). This suggests to choose \\(\\pmb{\\gamma}\\) as \\[\n\\gamma_1(t):=\\cos(t)\\,, \\quad \\gamma_2(t):=\\sin(t)\n\\] for \\(t \\in [0,2\\pi)\\). This way \\(\\pmb{\\gamma}\\) satisfies (1.4), and actually parametrizes \\(C\\), as shown below.\nNote the following:\n\nIf we had chosen \\(t \\in [0,4\\pi]\\) then \\(\\pmb{\\gamma}\\) would have covered \\(C\\) twice.\nIf we had chosen \\(t \\in [0,\\pi]\\), then \\(\\pmb{\\gamma}\\) would have covered the upper semi-circle\nIf we had chosen \\(t \\in [\\pi,2\\pi]\\), then \\(\\pmb{\\gamma}\\) would have covered the lower semi-circle\nSimilarly, we can choose \\(t \\in [\\pi/6, \\pi /2]\\) to cover just a portion of \\(C\\), as shown below.\n\n\n\n\n\n\n\n\nUpper semi-circle\n\n\n\n\n\n\n\n\n\nLower semi-circle\n\n\n\n\n\n\n\n\n\nLower semi-circle\n\n\n\n\n\n\n\n\n\nPlotting a portion of \\(C\\)\n\n\n\n\nFinally we are also able to give a mathematical description of the 3D Helix.\n\nExample 7: Parametrizing the helixThe Helix plotted above can be parametrized by \\[\n\\pmb{\\gamma} \\ \\colon (-\\infty,\\infty) \\to \\mathbb{R}^3\n\\] defined by \\[\n\\gamma_1(t) = \\cos(t)\\,, \\,\\,\n\\gamma_2(t) = \\sin(t)\\,, \\,\\,\n\\gamma_3(t) = t \\,.\n\\] The above equations are in line with our intuition: the helix can be drawn by tracing a circle while at the same time lifting the pencil.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#smooth-curves",
    "href": "sections/chap_1.html#smooth-curves",
    "title": "1  Curves",
    "section": "1.3 Smooth curves",
    "text": "1.3 Smooth curves\nLet us recall the definition of parametrized curve.\n\nDefinition 8: Parametrized curveA parametrized curve in \\(\\mathbb{R}^n\\) is a function \\[\n{\\pmb{\\gamma}}\\ \\colon  (a,b) \\to \\mathbb{R}^n \\,.\n\\] where\n\\[\n(a,b) = \\{ t \\in \\mathbb{R}\\ \\colon \\ a &lt; t &lt; b \\} \\,,\n\\] with \\[\n- \\infty \\leq a &lt; b \\leq \\infty \\,.\n\\] The components of \\({\\pmb{\\gamma}}(t) \\in \\mathbb{R}^n\\) are denoted by \\[\n{\\pmb{\\gamma}}(t) = ( \\gamma_1(t), \\ldots, \\gamma_n(t) ) \\,,\n\\] where the components are functions \\[\n\\gamma_i \\ \\colon (a,b) \\to \\mathbb{R}\\,,\n\\] for all \\(i = 1, \\ldots, n\\).\n\n\nAs we already mentioned, the aim of the course is to study curves by differentiating them. Let us see what that means for curves.\n\nDefinition 9: Smooth functionsA scalar function \\(f \\ \\colon (a,b) \\to \\mathbb{R}\\) is called smooth if the derivative \\[\n\\frac{d^n f}{dt^n}\n\\] exists for all \\(n \\geq 1\\) and \\(t \\in (a,b)\\).\n\n\nWe will denote the first and second derivatives of \\(f\\) as follows: \\[\n\\dot f :=  \\frac{d f}{dt} \\,, \\quad  \\ddot f := \\frac{d^2 f}{dt^2} \\,.\n\\]\n\nExample 10The function \\(f(x)=x^4\\) is smooth, with \\[\\begin{align*}\n& \\frac{d f}{dt}  = 4x^3 ,\\,\\, \\frac{d^2 f}{dt^2}  = 12 x^2 \\,, \\\\\n& \\frac{d^3 f}{dt^3}  = 24 x ,\\,\\, \\frac{d^4 f}{dt^4} = 24  \\,, \\\\\n& \\frac{d^n f}{dt^n}  = 0  \\, \\text{ for all } \\, n \\geq 5  \\,.\n\\end{align*}\\] Other examples smooth functions are polynomials, as well as \\[\nf(t) = \\cos(t) , \\,\\, f(t) = \\sin(t) \\,, \\,\\, f(t) = e^t \\,.\n\\]\n\n\n\nDefinition 11Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) with \\[\n{\\pmb{\\gamma}}(t) = ( {\\pmb{\\gamma}}_1(t), \\ldots, {\\pmb{\\gamma}}_n(t) )\n\\] be a parametrized curve. We say that \\({\\pmb{\\gamma}}\\) is smooth if the components \\[\n{\\pmb{\\gamma}}_i \\ \\colon (a,b) \\to \\mathbb{R}\n\\] are smooth for all \\(i=1,\\ldots,n\\). The derivatives of \\({\\pmb{\\gamma}}\\) are \\[\n\\frac{d^k{\\pmb{\\gamma}}}{dt^k}  := \\left(  \\frac{d^k\\gamma_1}{dt^k} , \\ldots, \\frac{d^k\\gamma_n}{dt^k} \\right)  \n\\] for all \\(k \\in \\mathbb{N}\\). As a shorthand, we will denote the first derivative of \\({\\pmb{\\gamma}}\\) as \\[\n\\dot{{\\pmb{\\gamma}}}:= \\frac{d{\\pmb{\\gamma}}}{dt} = \\left(  \\frac{d\\gamma_1}{dt} , \\ldots, \\frac{d\\gamma_n}{dt} \\right)  \n\\] and the second by \\[\n\\ddot{{\\pmb{\\gamma}}}:= \\frac{d^2{\\pmb{\\gamma}}}{dt^2} = \\left(  \\frac{d^2\\gamma_1}{dt^2} , \\ldots, \\frac{d^2\\gamma_n}{dt^2} \\right)   \\,.\n\\]\n\n\nIn Figure 1.1 we skectch a smooth and a non-smooth curve. Notice that the curve on the right is smooth, except for the point \\(x\\).\n\n\n\n\n\n\nFigure 1.1: Example of smooth and non-smooth curves\n\n\n\nWe will work under the following assumption.\n\nAssumptionAll the parametrized curves in this lecture notes are assumed to be smooth.\n\n\n\nExample 12The circle \\[\n{\\pmb{\\gamma}}(t) = (\\cos(t),\\sin(t))\n\\] is a smooth parametrized curve, since both \\(\\cos(t)\\) and \\(\\sin(t)\\) are smooth functions. We have \\[\n\\dot{{\\pmb{\\gamma}}}= (-\\sin(t),\\cos(t)) \\,.\n\\] For example the derivative of \\({\\pmb{\\gamma}}\\) at the point \\((0,1)\\) is given by \\[\n\\dot{{\\pmb{\\gamma}}}( \\pi/2) = (-\\sin(\\pi/2),\\cos(\\pi/2)) = (-1,0) \\,.\n\\] The plot of the circle and the derivative vector at \\((-1,0)\\) can be seen in Figure 1.2.\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Plot of Circle and Tangent Vector at \\((0,1)\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#tangent-vectors",
    "href": "sections/chap_1.html#tangent-vectors",
    "title": "1  Curves",
    "section": "1.4 Tangent vectors",
    "text": "1.4 Tangent vectors\nLooking at Figure 1.2, it seems like the vector \\[\n\\dot{{\\pmb{\\gamma}}}(\\pi/2) = (-1,0)\n\\] is tangent to the circle at the point \\[\n{\\pmb{\\gamma}}(\\pi/2) = (0,1) \\,.\n\\] Is this a coincidence? Not that all. Let us look at the definition of derivative at a point: \\[\n\\dot{{\\pmb{\\gamma}}}(t) := \\lim_{\\delta \\to 0} \\frac{{\\pmb{\\gamma}}(t + \\delta) - {\\pmb{\\gamma}}(t)}{\\delta} \\,.\n\\] If we just look at the quantity \\[\n\\frac{{\\pmb{\\gamma}}(t + \\delta) - {\\pmb{\\gamma}}(t)}{\\delta}\n\\] for non-negative \\(\\delta\\), we see that this vector is parallel to the chord joining \\({\\pmb{\\gamma}}(t)\\) to \\({\\pmb{\\gamma}}(t + \\delta)\\), as shown in Figure 1.3 below. As \\(\\delta \\to 0\\), the length of the chord tends to zero. However the direction of the chord becomes parallel to that of the tangent vector of the curve \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\). Since \\[\n\\frac{{\\pmb{\\gamma}}(t + \\delta) - {\\pmb{\\gamma}}(t)}{\\delta}  \\to \\dot{{\\pmb{\\gamma}}}(t)\n\\] as \\(\\delta \\to 0\\), we see that \\(\\dot{{\\pmb{\\gamma}}}(t)\\) is parallel to the tangent of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\), as showin in Figure 1.3.\n\n\n\n\n\n\nFigure 1.3: Approximating the tangent vector\n\n\n\nThe above remark motivates the following definition.\n\nDefinition 13: Tangent vectorLet \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a parametrized curve. The tangent vector to \\({\\pmb{\\gamma}}\\) at the point \\({\\pmb{\\gamma}}(t)\\) is defined as \\[\n\\tau:= \\dot{{\\pmb{\\gamma}}}(t) \\,.\n\\]\n\n\n\nExample 14: Tangent vector to helixThe helix is described by the parametric curve \\[\n{\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^3\n\\] with \\[\n{\\pmb{\\gamma}}_1(t) = \\cos (t)\\, ,  \\,\\,\n{\\pmb{\\gamma}}_2(t) = \\sin (t)\\, ,  \\,\\,\n{\\pmb{\\gamma}}_3(t) = t .\n\\] This is plotted in Figure 1.4 below. The tangent vector at point \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\dot{{\\pmb{\\gamma}}}(t) = ( -\\sin(t), \\cos(t) , 1) \\,.\n\\] For example in Figure 1.4 we plot the tangent vector at time \\(t = \\pi/2\\), that is, \\[\n\\dot{{\\pmb{\\gamma}}}(\\pi/2) = (-1,0,\\pi/2) \\,.\n\\] The above looks very similar to the tangent vector to the circle. Except that there is a \\(z\\) component, and that component is constant and equal to \\(1\\). Intuitively this means that the helix is lifting from the plane \\(xy\\) with constant speed with respect to the \\(z\\)-axis. We will soon give a name to this concept.\n\n\n\n\n\n\n\n\n\n\nFigure 1.4: Plot of Helix with tangent vector\n\n\n\n\n\n\nRemark 15: Avoiding potential ambiguitiesSometimes it will happen that a curve self intersects, meaning that there are two time instants \\(t_1\\) and \\(t_2\\) and a point \\(p \\in \\mathbb{R}^n\\) such that \\[\np = {\\pmb{\\gamma}}(t_1) = {\\pmb{\\gamma}}(t_2)\\,.\n\\] In this case there is ambiguity in talking about the tangent vector at the point \\(p\\): in principle there are two tangent vectors \\(\\dot{{\\pmb{\\gamma}}}(t_1)\\) and \\(\\dot{{\\pmb{\\gamma}}}(t_2)\\), and it could happen that \\[\n\\dot{{\\pmb{\\gamma}}}(t_1) \\neq  \\dot{{\\pmb{\\gamma}}}(t_1)\\,.\n\\] Thus the concept of tangent at \\(p\\) is not well-defined. We need then to be more precise and talk about tangent at a certain time-step \\(t\\), rather than at some point \\(p\\). We however do not amend Definition 13, but you should keep this potential ambiguity in mind.\n\n\n\nExample 16: The Lemniscate, a self intersecting curveFor example consider \\({\\pmb{\\gamma}}\\ \\colon [0,2\\pi] \\to \\mathbb{R}^2\\) defined as \\[\n{\\pmb{\\gamma}}_1(t) = \\sin (t)\\, ,  \\,\\,\n{\\pmb{\\gamma}}_2(t) = \\sin (t) \\cos(t) \\, .\n\\] Such curve is called Lemniscate, see Wikipedia page, and is plotted in Figure 1.5 below. The orgin \\((0,0)\\) is a point of self-intersection, meaning that \\[\n{\\pmb{\\gamma}}(0) = {\\pmb{\\gamma}}(\\pi) = (0,0) \\,.\n\\] The tangent vector at point \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (\\cos(t), \\cos^2(t) - \\sin^2(t) )\n\\] and therefore we have two tangents at \\((0,0)\\), that is, \\[\n\\tau_1 = \\dot{{\\pmb{\\gamma}}}(0) = (1,1) \\,, \\,\\,\n\\tau_2 = \\dot{{\\pmb{\\gamma}}}(\\pi) = (-1,1) \\,.\n\\]\n\n\n\n\n\n\n\n\n\n\nFigure 1.5: The Lemniscate curve",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#length-of-curves",
    "href": "sections/chap_1.html#length-of-curves",
    "title": "1  Curves",
    "section": "1.5 Length of curves",
    "text": "1.5 Length of curves\nFor a vector \\(v \\in \\mathbb{R}^n\\) with components \\[\nv=(v_1,\\ldots,v_n),\n\\] its length is defined by \\[\n\\left\\| v \\right\\|:= \\sqrt{\\sum_{i=1}^n v_i^2 } \\,.\n\\] The above is just an extension of the Pythagoras theorem to \\(\\mathbb{R}^n\\), and the length of \\(v\\) is computed from the origin.\n\n\n\nInterpretation of \\(\\left\\| v \\right\\|\\) in \\(\\mathbb{R}^2\\)\n\n\nIf we have a second vector \\(u \\in \\mathbb{R}^n\\), then the quantity \\[\n\\left\\| u-v \\right\\|:= \\sqrt{\\sum_{i=1}^n (u_i-v_i)^2 }\n\\] measures the length of the difference between \\(u\\) and \\(v\\).\n\n\n\nInterpretation of \\(\\left\\| u-v \\right\\|\\) in \\(\\mathbb{R}^2\\)\n\n\nWe would like to define the concept of length of a curve. Intuitively, one could proceed by approximation as in the figure below.\n\n\n\nApproximating the length of \\({\\pmb{\\gamma}}\\)\n\n\nIn formulae, this means choosing some time instants \\[\nt_0, \\ldots, t_m \\in (a,b) \\,.\n\\] The length of the segment connecting \\({\\pmb{\\gamma}}(t_{i-1})\\) to \\({\\pmb{\\gamma}}(t_i)\\) is given by \\[\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| \\,.\n\\] Thus \\[\nL({\\pmb{\\gamma}}) \\approx \\sum_{i=1}^m \\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| \\,.  \n\\tag{1.5}\\] Intuitively, if we increase the number of points \\(t_i\\), the quantity on the RHS of (1.5) should approximate \\(L({\\pmb{\\gamma}})\\) better and better. Let us make this precise.\n\nDefinition 17: PartitionLet \\((a,b)\\) be an interval. A partition \\(\\mathcal{P}\\) of \\([a,b]\\) is a vector of time instants \\[\n\\mathcal{P} = (t_0,\\ldots, t_k) \\in [a,b]^{m+1}\n\\] with \\[\nt_0 = a &lt; t_1 &lt; \\ldots &lt; t_{m-1} &lt; t_m = b \\,.\n\\] If \\(\\mathcal{P}\\) is a partition of \\([a,b]\\), we define its maximum length as \\[\n\\left\\| \\mathcal{P} \\right\\| := \\max_{1 \\leq i \\leq m} |t_{i} - t_{i-1}| \\,.\n\\]\n\n\nNote that \\(\\left\\| \\mathcal{P} \\right\\|\\) measures how fine the partition \\(\\mathcal{P}\\) is.\n\nDefinition 18: Length of approximating polygonal curveSuppose \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\) is a parametrized curve and \\(\\mathcal{P}\\) a partition of \\([a,b]\\). We define the length of the polygonal curve connecting the points \\[\n{\\pmb{\\gamma}}(t_0)\\,, \\,\\, {\\pmb{\\gamma}}(t_1) \\,,  \\,\\, \\ldots, \\,\\, {\\pmb{\\gamma}}(t_m)\n\\] as \\[\nL({\\pmb{\\gamma}}, \\mathcal{P}) := \\sum_{i=1}^m \\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| \\,.\n\\]\n\n\nIf \\(\\left\\| \\mathcal{P} \\right\\|\\) becomes smaller and smaller, that is, the partition \\(\\mathcal{P}\\) is finer and finer, it is reasonable to say that \\[\nL({\\pmb{\\gamma}}, \\mathcal{P})\n\\] is approximating the length of \\({\\pmb{\\gamma}}\\). We take this as definition of length.\n\nDefinition 19: Rectifiable curve and lengthSuppose \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\) is a parametrized curve. We say that \\({\\pmb{\\gamma}}\\) is rectifiable if the limit \\[\nL({\\pmb{\\gamma}}) = \\lim_{ \\left\\| P \\right\\| \\to 0}   \\ L({\\pmb{\\gamma}},\\mathcal{P})\n\\] exists finite. In such case we call \\(L({\\pmb{\\gamma}})\\) the length of \\({\\pmb{\\gamma}}\\).\n\n\nThis definition definitely corresponds to our geometrical intuition of length of a curve.\n\nQuestion 20How do we use such definition in practice to compute the length of a given curve \\({\\pmb{\\gamma}}\\)?\n\n\nThankfully, when \\({\\pmb{\\gamma}}\\) is smooth, the length \\(L({\\pmb{\\gamma}})\\) can be characterized in terms of \\(\\dot{{\\pmb{\\gamma}}}\\). Indeed, when \\(\\delta\\) is small, then the quantity \\[\n\\left\\| {\\pmb{\\gamma}}(t + \\delta) - {\\pmb{\\gamma}}(t) \\right\\|\n\\] is approximating the length of \\({\\pmb{\\gamma}}\\) between \\({\\pmb{\\gamma}}(t)\\) and \\({\\pmb{\\gamma}}(t + \\delta)\\). Multiplying and dividing by \\(\\delta\\) we obtain \\[\n\\frac{\\left\\| {\\pmb{\\gamma}}(t + \\delta) - {\\pmb{\\gamma}}(t) \\right\\|}{\\delta} \\, \\delta\n\\] which for small \\(\\delta\\) is close to \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\,\\delta \\,.\n\\] We can now divide the time interval \\((a,b)\\) in steps \\(t_0, \\ldots, t_m\\) with \\(|t_{i}-t_{i-1}| &lt; \\delta\\) and obtain \\[\\begin{align*}\n\\left\\| {\\pmb{\\gamma}}(t_{i}) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| & = \\frac{\\left\\| {\\pmb{\\gamma}}(t_{i}) - {\\pmb{\\gamma}}(t_{i-1}) \\right\\|}{ |t_{i}-t_{i-1}| } |t_{i}-t_{i-1}| \\\\\n& \\approx \\left\\|  \\dot{{\\pmb{\\gamma}}}(t_i) \\right\\| \\delta\n\\end{align*}\\] since \\(\\delta\\) is small. Therefore \\[\nL({\\pmb{\\gamma}}) \\approx \\sum_{i=1}^m  \\left\\| {\\pmb{\\gamma}}(t_{i}) - {\\pmb{\\gamma}}(t_{i-1}) \\right\\|\n\\approx \\sum_{i=1}^m   \\left\\| \\dot{{\\pmb{\\gamma}}}(t_i) \\right\\| \\,\\delta \\,.\n\\] The RHS is a Riemann sum, therefore \\[\n  L({\\pmb{\\gamma}}) \\approx \\int_a^b  \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt \\,.\n\\]\nThe above argument can be made rigorous, as we see in the next theorem.\n\n\n\nApproximating \\(L({\\pmb{\\gamma}})\\) via \\(\\dot{{\\pmb{\\gamma}}}\\)\n\n\n\nTheorem 21: Characterizing the length of \\({\\pmb{\\gamma}}\\)Assume \\({\\pmb{\\gamma}}\\ \\colon [a,b] \\to \\mathbb{R}^n\\) is a parametrized curve, with \\([a,b]\\) bounded. Then \\({\\pmb{\\gamma}}\\) is rectifiable and \\[\nL({\\pmb{\\gamma}}) = \\int_a^b  \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt \\,.\n\\tag{1.6}\\]\n\n\n\nProofStep 1. The integral in (1.6) is bounded.\nSince \\({\\pmb{\\gamma}}\\) is smooth, in particular \\(\\dot{{\\pmb{\\gamma}}}\\) is continuous. Since \\([a,b]\\) is bounded, then \\(\\dot{{\\pmb{\\gamma}}}\\) is bounded, that is \\[\n\\sup_{t \\in [a,b]} \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\leq C\n\\] for some constant \\(C \\geq 0\\). Therefore \\[\n\\int_a^b  \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt \\leq C (b-a) &lt; \\infty \\,.\n\\]\nStep 2. Writing (1.6) as limit.\nRecalling that \\[\nL({\\pmb{\\gamma}}) = \\lim_{\\left\\| \\mathcal{P} \\right\\| \\to 0} \\ L({\\pmb{\\gamma}},\\mathcal{P}) \\,,\n\\] whenever the limit is finite, in order to show (1.6) we then need to prove \\[\nL({\\pmb{\\gamma}},\\mathcal{P}) \\to \\int_a^b  \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt\n\\] as \\(\\left\\| \\mathcal{P} \\right\\| \\to 0\\). Showing the above means proving that: for every \\(\\varepsilon&gt; 0\\) there exists a \\(\\delta &gt; 0\\) such that, if \\(\\mathcal{P}\\) is a partition of \\([a,b]\\) such that \\(\\left\\|  \\mathcal{P}  \\right\\|&lt;\\delta\\), then \\[\n\\left|    \\int_a^b  \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt -  L({\\pmb{\\gamma}}, \\mathcal{P} )        \\right| &lt; \\varepsilon\\,.\n\\tag{1.7}\\]\nStep 3. First estimate in (1.7).\nThis first estimate is easy, and only relies on the Fundamental Theorem of Calculus. To be more precise, we will show that each polygonal has shorter length than \\(\\int_{a}^b \\left\\|    \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt\\). To this end, take an arbitrary partition \\(\\mathcal{P} = (t_0, \\ldots, t_m)\\) of \\([a,b]\\). Then for each \\(i = 1,\\ldots,m\\) we have \\[\n\\left\\|   {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| = \\left\\|   \\int_{t_{i-1}}^{t_i}  \\dot{{\\pmb{\\gamma}}}(t)\\, dt  \\right\\| \\leq   \\int_{t_{i-1}}^{t_i}\\left\\|    \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt   \n\\] where we used the Fundamental Theorem of calculus, and usual integral properties. Therefore by definition \\[\\begin{align*}\nL({\\pmb{\\gamma}},\\mathcal{P} ) & = \\sum_{i=1}^m  \\left\\|   {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| \\\\\n& \\leq \\sum_{i=1}^m  \\int_{t_{i-1}}^{t_i} \\left\\|    \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt \\\\\n& = \\int_{a}^b \\left\\|    \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt \\,.\n\\end{align*}\\] We have then shown \\[\nL({\\pmb{\\gamma}}, \\mathcal{P}) \\leq \\int_{a}^b \\left\\|    \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt\n\\tag{1.8}\\] for all partitions \\(\\mathcal{P}\\).\nStep 4. Second estimate in (1.7).\nThe second estimate is more delicate. We need to carefully construct a polygonal so that its length is close to \\(\\int_a^b \\left\\|  \\dot{{\\pmb{\\gamma}}} \\right\\| \\,dt\\). This will be possible by uniform continuity of \\(\\dot{{\\pmb{\\gamma}}}\\). Indeed, note that \\(\\dot{{\\pmb{\\gamma}}}\\) is continuous on the compact set \\([a,b]\\). Therefore it is uniformly continuous by the Heine-Borel Theorem. Fix \\(\\varepsilon&gt;0\\). By uniform continuity of \\(\\dot{{\\pmb{\\gamma}}}\\) there exists \\(\\delta &gt;0\\) such that \\[\n|t-s| &lt; \\delta \\implies \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)-\\dot{{\\pmb{\\gamma}}}(s)  \\right\\| &lt; \\frac{ \\varepsilon}{b-a} \\,.\n\\tag{1.9}\\] for all \\(t,s \\in [a,b]\\). Let \\(\\mathcal{P} = (t_0, \\ldots, t_m)\\) be a partition of \\([a,b]\\) with \\(\\left\\| \\mathcal{P} \\right\\| &lt; \\delta\\). Recall that \\[\n\\left\\| \\mathcal{P} \\right\\| = \\max_{i=1,\\ldots ,m} |t_i - t_{i-1}| \\,.\n\\] Therefore the condition \\(\\left\\| \\mathcal{P} \\right\\| &lt; \\delta\\) implies \\[\n|t_i - t_{i-1}| &lt; \\delta\n\\tag{1.10}\\] for each \\(i = 1, \\ldots, m\\). For all \\(i = 1, \\ldots, m\\) and \\(s \\in [t_{i-1},t_i]\\) we have \\[\\begin{align*}\n{\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1}) & = \\int_{t_{i-1}}^{ t_i }  \\dot{{\\pmb{\\gamma}}}(t)\\, dt \\\\\n                      & =  \\int_{t_{i-1}}^{ t_i } \\dot{{\\pmb{\\gamma}}}(s) +  (\\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s))    \\, dt \\\\\n                      & = ( t_i - t_{i-1} ) \\dot{{\\pmb{\\gamma}}}(s) + \\int_{t_{i-1}}^{ t_i }   (\\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s))    \\, dt\n\\end{align*}\\] Therefore \\[\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\|  = \\left\\|  ( t_i - t_{i-1} ) \\dot{{\\pmb{\\gamma}}}(s) +\n\\int_{t_{i-1}}^{ t_i }   (\\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s))    \\, dt  \\right\\|\n\\tag{1.11}\\] We can now use the reverse triangle inequality \\[\n| \\| x\\| - \\left\\| y \\right\\|| \\leq \\left\\| x-y \\right\\|\\,,\n\\] for all \\(x,y \\in \\mathbb{R}^n\\), which implies \\[\n\\left\\| x+y \\right\\|  = \\left\\| x - (-y) \\right\\| \\geq \\| x \\| - \\left\\| y \\right\\|\n\\] for all \\(x,y \\in \\mathbb{R}^n\\). Applying the above to (1.11) we get \\[\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\|  \\geq\n( t_i - t_{i-1} ) \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| -\n\\left\\|  \\int_{t_{i-1}}^{ t_i }   (\\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s))    \\, dt  \\right\\|\n\\tag{1.12}\\] By standard properties of integral we also have \\[\n\\left\\|  \\int_{t_{i-1}}^{ t_i }   (\\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s))    \\, dt  \\right\\|\n\\leq\n\\int_{t_{i-1}}^{ t_i }   \\left\\| \\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s) \\right\\|    \\, dt\\,,\n\\] so that (1.12) implies \\[\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| \\geq ( t_i - t_{i-1} ) \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\|   - \\int_{t_{i-1}}^{ t_i }   \\left\\| \\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s) \\right\\|    \\, dt\\,.\n\\tag{1.13}\\] Since \\(t,s \\in [t_{i-1},t_i]\\), then \\[\n|t-s| \\leq | t_{i} - t_{i-1} |   &lt;  \\delta\n\\] where the last inequality follows by (1.10). Thus by uniform continuity (1.9) we get \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s)  \\right\\| &lt; \\frac{\\varepsilon}{b-a} \\,.\n\\] We can therefore further estimate (1.13) and obtain \\[\\begin{align*}\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| & \\geq ( t_i - t_{i-1} ) \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\|   - \\int_{t_{i-1}}^{ t_i }   \\left\\| \\dot{{\\pmb{\\gamma}}}(t) - \\dot{{\\pmb{\\gamma}}}(s) \\right\\|    \\, dt \\\\\n& \\geq  ( t_i - t_{i-1} ) \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| -  ( t_i - t_{i-1} ) \\frac{\\varepsilon}{b-a}    \\, dt \\,.\n\\end{align*}\\] Dividing the above by \\(t_i - t_{i-1}\\) we get \\[\n\\frac{ \\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\| }{ t_i - t_{i-1}  } \\geq\n\\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| - \\frac{\\varepsilon}{b-a}  \\,.\n\\] Integrating the above over \\(s\\) in the interval \\([t_{i-1}, t_i ]\\) we get \\[\n\\left\\|  {\\pmb{\\gamma}}(t_i) - {\\pmb{\\gamma}}(t_{i-1})  \\right\\|  \\geq \\int_{t_{i-1}}^{ t_i } \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| \\, ds  - \\frac{\\varepsilon}{b-a} (t_i - t_{i-1}) \\,.\n\\] Summing over \\(i=1,\\ldots,m\\) we get \\[\nL(\\mathcal{P},{\\pmb{\\gamma}}) \\geq \\int_{a}^b \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| \\, ds - \\varepsilon\n\\tag{1.14}\\] since \\[\n\\sum_{i=1}^m (t_i - t_{i-1}) = t_m - t_0 = b - a \\,.\n\\]\nConclusion.\nPutting together (1.8) and (1.14) we get \\[\n\\int_{a}^b \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| \\, ds - \\varepsilon\\leq L(\\mathcal{P},{\\pmb{\\gamma}})\n\\leq  \\int_{a}^b \\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| \\, ds\n\\] which implies (1.7), concluding the proof.\n\n\nThanks to the above theorem we have now a way to compute \\(L({\\pmb{\\gamma}})\\). Let us check that we have given a meaningful definition of length by computing \\(L({\\pmb{\\gamma}})\\) on known examples.\n\nExample 22: Length of CircleThe circle of radius \\(R\\) is parametrized by \\({\\pmb{\\gamma}}\\ \\colon [0,2\\pi] \\to \\mathbb{R}^2\\) defined by \\[\n{\\pmb{\\gamma}}(t) = (R\\cos(t), R\\sin(t)) \\,.\n\\] Then \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (-R\\sin(t), R\\cos(t))\n\\] and \\[\\begin{align*}\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| & = \\sqrt{ {\\dot\\gamma}_1^2(t) +   {\\dot \\gamma}_2^2(t)      } \\\\\n                & = R \\sqrt{ \\sin^2(t) + \\cos^2 (t)} = R\\,.\n\\end{align*}\\] Therefore \\[\nL({\\pmb{\\gamma}}) = \\int_{0}^{2\\pi}  \\left\\|   \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt = \\int_0^{2\\pi} R \\, dt = 2 \\pi R\n\\] as expected.\n\n\n\nExample 23: Length of helixLet us consider one full turn of the Helix of radius \\(R\\) and rise \\(H\\). This is parametrized by \\[\n{\\pmb{\\gamma}}(t) = (R\\cos(t), R\\sin(t) ,Ht)\n\\] for \\(t \\in [0,2\\pi]\\). Then \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (-R\\sin(t), R\\cos(t) , H) \\,,\n\\] and \\[\\begin{align*}\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)   \\right\\| & = \\sqrt{  {\\dot{\\gamma}}_1^2 + {\\dot{\\gamma}}_2^2 + {\\dot{\\gamma}}_3^2 } \\\\\n                    & = \\sqrt{ R^2\\sin^2(t) + R^2\\cos^2(t) + H^2 } = \\sqrt{R^2 + H^2} \\,.\n\\end{align*}\\] Therefore \\[\nL({\\pmb{\\gamma}}) = \\int_0^{2\\pi} \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\, dt = 2 \\pi \\sqrt{R^2 + H^2} \\,.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#arc-length",
    "href": "sections/chap_1.html#arc-length",
    "title": "1  Curves",
    "section": "1.6 Arc-length",
    "text": "1.6 Arc-length\nWe have just shown in Theorem 21 that the length of a regular curve \\({\\pmb{\\gamma}}\\ \\colon [a,b] \\to \\mathbb{R}^n\\) with \\([a,b]\\) bounded is given by \\[\nL({\\pmb{\\gamma}}) = \\int_a^b \\left\\|  \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\,dt \\,.\n\\] Using this formula, we introduce the notion of length of a portion of \\({\\pmb{\\gamma}}\\).\n\nDefinition 24: Arc-lengthLet \\({\\pmb{\\gamma}}\\, \\colon (a,b) \\to \\mathbb{R}^n\\) be a curve, with \\((a,b)\\) possibly unbounded. We define the arc-length of \\({\\pmb{\\gamma}}\\) starting at the point \\({\\pmb{\\gamma}}(t_0)\\) as the function \\(s \\colon \\mathbb{R}\\to \\mathbb{R}\\) defined by \\[\ns(t) := \\int_{t_0}^t  \\left\\|   \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\|\\, d\\tau \\,.\n\\]\n\n\n\n\n\nArc-length of \\({\\pmb{\\gamma}}\\) starting at \\({\\pmb{\\gamma}}(t_0)\\)\n\n\n\nRemark 25\nA few remarks:\n\nArc-length is well-defined\n\nIndeed, \\({\\pmb{\\gamma}}\\) is smooth, and so \\(\\dot{{\\pmb{\\gamma}}}\\) is continuous. WLOG assume \\(t \\geq t_0\\). Then \\[\ns(t) = \\int_{t_0}^t  \\left\\|   \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\|\\, d\\tau \\leq (t-t_0) \\max_{ \\tau \\in [t_0,t] } \\left\\| \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| &lt; \\infty \\,.\n\\]\n\nWe always have \\[\ns(t_0)=0\\,.\n\\]\nWe have \\[\nt &gt; t_0   \\implies  s(t) \\geq 0\n\\] and \\[\nt &lt; t_0   \\implies  s(t) \\leq 0 \\,.\n\\]\nChoosing a different starting point changes the arc-length by a constant:\n\nFor example define \\(\\tilde{s}\\) as the arc-length starting from \\(\\tilde{t}_0\\) \\[\n\\tilde{s}(t) := \\int_{\\tilde{t}_0}^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau  \\,.\n\\] Then by the properties of integral \\[\\begin{align*}\ns(t) & = \\int_{t_0}^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau \\\\\n& = \\int_{t_0}^{\\tilde{t}_0} \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau +\n\\int_{\\tilde{t}_0}^{t} \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau \\\\\n& = \\int_{t_0}^{\\tilde{t}_0} \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau + \\tilde{s}(t) \\,.\n\\end{align*}\\] Hence \\[\ns = c + \\tilde{s}\n\\] with \\[\nc := \\int_{t_0}^{\\tilde{t}_0} \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau \\,.\n\\] Note that \\(c\\) is the arc-length of \\({\\pmb{\\gamma}}\\) between the starting points \\({\\pmb{\\gamma}}(t_0)\\) and \\({\\pmb{\\gamma}}(\\tilde{t}_0)\\).\n\nThe arc-length is a differentiable function, with \\[\n\\dot s(t) = \\frac{d}{dt} \\int_{t_0}^t \\left\\| \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| \\, d\\tau =\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\,.\n\\]\n\nSince \\(\\dot{{\\pmb{\\gamma}}}\\) is continuous, the above follows by the Fundamental Theorem of Calculus.\n\n\n\n\n\nExample 26: CircleThe circle of radius \\(R\\) is parametrized by \\({\\pmb{\\gamma}}\\ \\colon [0,2\\pi] \\to \\mathbb{R}^2\\) defined by \\[\n{\\pmb{\\gamma}}(t) = (R\\cos(t), R\\sin(t)) \\,.\n\\] Then \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (-R\\sin(t), R\\cos(t)) \\,, \\quad \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| = R \\,.\n\\] Therefore, for any fixed \\(t_0 \\in [0,2\\pi]\\) we have \\[\ns(t) = \\int_{t_0}^{t}  \\left\\|   \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| \\, d\\tau = \\int_{t_0}^{t} R \\, d\\tau = (t - t_0)  R \\,.\n\\] In particular we see that \\(\\dot s = R\\) is constant.\n\n\n\nExample 27: Logarithmic spiralThe Logarithmic spiral is defined by \\({\\pmb{\\gamma}}\\ \\colon [0,2\\pi] \\to \\mathbb{R}^2\\) with \\[\n{\\pmb{\\gamma}}(t) = (e^{kt} \\cos(t), e^{kt} \\sin(t)) \\,,\n\\] where \\(k \\in \\mathbb{R}\\), \\(k \\neq 0\\), is called the growth factor. Then \\[\n{\\dot \\gamma}_1(t) = e^{kt} ( k \\cos(t) - \\sin(t) )\n\\] \\[\n{\\dot \\gamma}_2(t) = e^{kt} ( k \\sin(t) + \\cos(t) )\n\\] and so, after some calculations, \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2   =  {\\dot{\\gamma}}_1^2 + {\\dot{\\gamma}}_2^2 = (k^2 + 1) e^{2kt} \\,.\n\\] The arc-length starting from \\(t_0\\) is \\[\\begin{align*}\ns(t) & = \\int_{t_0}^t \\left\\| \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| \\, d \\tau \\\\\n     & = \\sqrt{k^2 + 1} \\int_{t_0}^t e^{k \\tau} \\, d \\tau  \\\\\n     & = \\frac{\\sqrt{k^2 + 1}}{k} ( e^{kt} - e^{k t_0} ) \\,.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\nFigure 1.6: Plot of Logarithmic Spiral with \\(k=0.1\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#scalar-product-in-mathbbrn",
    "href": "sections/chap_1.html#scalar-product-in-mathbbrn",
    "title": "1  Curves",
    "section": "1.7 Scalar product in \\(\\mathbb{R}^n\\)",
    "text": "1.7 Scalar product in \\(\\mathbb{R}^n\\)\nLet us start by defining the scalar product in \\(\\mathbb{R}^2\\).\n\nDefinition 28: Scalar product in \\(\\mathbb{R}^2\\)Let \\(u, v \\in \\mathbb{R}^2\\) and denote by \\(\\theta \\in [0,\\pi]\\) the angle formed by \\(u\\) and \\(v\\). The scalar product between \\(u\\) and \\(v\\) is defined by \\[\nu \\cdot v := |u| |v| \\cos(\\theta) \\,.\n\\]\n\n\n\n\n\nVectors \\(u\\) and \\(v\\) in \\(\\mathbb{R}^2\\) forming angle \\(\\theta\\)\n\n\n\nRemark 29The scalar product is maximized for \\(\\theta = 0\\), for which we have \\[\nu \\cdot v = |u| |v| \\cos(\\theta) =  |u| |v| \\,.\n\\] It is instead minimized for \\(\\theta = \\pi\\), for which \\[\nu \\cdot v = |u| |v| \\cos(\\theta) =  -|u| |v| \\,.\n\\]\n\n\n\nDefinition 30: Orthogonal vectorsLet \\(u, v \\in \\mathbb{R}^2\\). If \\[\nu \\cdot v = 0\n\\] we say that \\(u\\) and \\(v\\) are orthogonal.\n\n\n\nProposition 31: Bilinearity and symmetry of scalar product\nLet \\(u, v, w \\in \\mathbb{R}^2\\) and \\(\\lambda \\in \\mathbb{R}\\). Then\n\nSymmetry: \\(u \\cdot v = v \\cdot u\\)\nBilinearity: It holds \\[\n\\lambda (u \\cdot v) = (\\lambda u) \\cdot v = u \\cdot (\\lambda v) \\,,\n\\] \\[\nu \\cdot (v + w) = u \\cdot v  + u \\cdot w \\,.\n\\]\n\n\n\nWe leave the proof to the reader. The above proposition is saying that the scalar product is bilinear and symmetric.\n\nProposition 32: Scalar products written wrt euclidean coordinatesDenote by \\[\ne_1 = (1,0) \\,, \\quad e_2 = (0,1)\n\\] the euclidean basis of \\(\\mathbb{R}^2\\). Let \\(u,v \\in \\mathbb{R}^2\\) and denote by \\[\nu = (u_1,u_2) = u_1 e_1 + u_2 e_2\n\\] \\[\nv = (v_1,v_2) = v_1 e_1 + v_2 e_2\n\\] their coordinates with respect to \\(e_1,e_2\\). Then \\[\nu \\cdot v = u_1v_2 + u_2 v_2 \\,.\n\\]\n\n\n\nProofNote that \\[\ne_1 \\cdot e_1 = 1 \\,, \\quad e_2 \\cdot e_2 = 1 \\,, \\quad\ne_1 \\cdot e_2 = e_2 \\cdot e_1 = 0 \\,.\n\\] Using the bilinearity of scalar product we have \\[\\begin{align*}\nu \\cdot v & = (u_1 e_1 + u_2 e_2) \\cdot (v_1 e_1 + v_2 e_2) \\\\\n          & = u_1 v_1 e_1 \\cdot e_1 +  u_1 v_2 e_1 \\cdot e_2 +\n              u_2 v_1 e_2 \\cdot e_1 + u_2 v_2  e_2 \\cdot e_2 \\\\\n          & = u_1 v_1  + u_2 v_2 \\,.\n\\end{align*}\\]\n\n\nThe above proposition provides a way to generalize of the scalar product to \\(\\mathbb{R}^n\\)..\n\nDefinition 33: Scalar product in \\(\\mathbb{R}^n\\)Let \\(u,v \\in \\mathbb{R}^n\\) and denote their coordinates by \\[\nu = (u_1, \\ldots, u_n) \\,, \\quad\nu = (v_1, \\ldots, v_n) \\,.\n\\] We define the scalar product between \\(u\\) and \\(v\\) by \\[\nu \\cdot v := \\sum_{i=1}^n u_i v_i \\,.\n\\]\n\n\nWith the above definition we still have that the scalar product is bilinear and symmetric, as detailed in the following proposition:\n\nProposition 34: Bilinearity and symmetry of scalar product in \\(\\mathbb{R}^n\\)\nLet \\(u, v, w \\in \\mathbb{R}^n\\) and \\(\\lambda \\in \\mathbb{R}\\). Then\n\nSymmetry: \\(u \\cdot v = v \\cdot u\\)\nBilinearity: It holds \\[\n\\lambda (u \\cdot v) = (\\lambda u) \\cdot v = u \\cdot (\\lambda v) \\,,\n\\] \\[\nu \\cdot (v + w) = u \\cdot v  + u \\cdot w \\,.\n\\]\n\n\n\nThe proof of the above proposition is an easy check, and is left to the reader for exercise.\n\nDefinition 35Let \\(u,v \\in \\mathbb{R}^n\\). We say that \\(u\\) and \\(v\\) are orthogonal if \\[\nu \\cdot v = 0 \\,.\n\\]\n\n\n\nProposition 36: Differentiating scalar productLet \\({\\pmb{\\gamma}}, {\\pmb{\\eta}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be parametrized curves. Then the scalar map \\[\n{\\pmb{\\gamma}}\\cdot {\\pmb{\\eta}}\\ \\colon (a,b) \\to \\mathbb{R}\n\\] is smooth, and \\[\n\\frac{d}{dt} ({\\pmb{\\gamma}}\\cdot {\\pmb{\\eta}})  = \\dot{{\\pmb{\\gamma}}}\\cdot {\\pmb{\\eta}}+ {\\pmb{\\gamma}}\\cdot \\dot{{\\pmb{\\eta}}}\n\\] for all \\(t \\in (a,b)\\).\n\n\n\nProofDenote by \\[\n{\\pmb{\\gamma}}= ({\\pmb{\\gamma}}_1 ,\\ldots , {\\pmb{\\gamma}}_n) \\,, \\quad {\\pmb{\\eta}}= (\\eta_1, \\ldots , \\eta_n)\n\\] the coordinates of \\({\\pmb{\\gamma}}\\) and \\({\\pmb{\\eta}}\\). Clearly the map \\[\nt \\mapsto {\\pmb{\\gamma}}\\cdot {\\pmb{\\eta}}= \\sum_{i=1}^n {\\pmb{\\gamma}}_i \\eta_i\n\\] is smooth, being sum and product of smooth functions.\nConcerning the formula, by definition of scalar product and linearity of the derivative we have \\[\\begin{align*}\n\\frac{d}{dt} ({\\pmb{\\gamma}}\\cdot {\\pmb{\\eta}}) & = \\frac{d}{dt} \\left( \\sum_{i=1}^n {\\pmb{\\gamma}}_i \\eta_i \\right) \\\\\n& = \\sum_{i=1}^n \\frac{d}{dt} ( {\\pmb{\\gamma}}_i \\eta_i ) \\\\\n& = \\sum_{i=1}^n  {\\dot\\gamma}_i \\eta_i + \\dot{\\gamma}_i {\\dot \\eta}_i \\\\\n& = \\dot{{\\pmb{\\gamma}}}\\cdot {\\pmb{\\eta}}+ {\\pmb{\\gamma}}\\cdot \\dot{{\\pmb{\\eta}}} \\,,\n\\end{align*}\\] where in the second to last equality we used the product rule of differentiation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#speed-of-a-curve",
    "href": "sections/chap_1.html#speed-of-a-curve",
    "title": "1  Curves",
    "section": "1.8 Speed of a curve",
    "text": "1.8 Speed of a curve\nGiven a curve \\({\\pmb{\\gamma}}\\) we defined the tangent vector at \\({\\pmb{\\gamma}}(t)\\) to be \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\,.\n\\] The tangent vector measures the change of direction of the curve. Therefore the magnitude of \\(\\dot{{\\pmb{\\gamma}}}\\) can be interpreted as the speed of the curve.\n\nDefinition 37Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a curve. We define the speed of \\({\\pmb{\\gamma}}\\) at the point \\({\\pmb{\\gamma}}(t)\\) by \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\,.\n\\] We say that \\({\\pmb{\\gamma}}\\) is a unit-speed curve if \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|  = 1 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\nRemark 38The derivative of the arc-length \\(s\\) gives the speed of \\({\\pmb{\\gamma}}\\): \\[\ns(t) := \\int_{t_0}^t \\left\\|   \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau  \\,\\, \\implies \\,\\,\n\\dot s(t) = \\left\\|   \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\,.\n\\]\n\n\nThe reason why we introduce unit speed curves is because they make calculations easy. This is essentially because of the next proposition.\n\nProposition 39Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a unit speed curve. Then \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0\n\\] for all \\(t \\in (a,b)\\).\n\n\n\nProofLet us consider the identity \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t) = \\sum_{i=1}^n {\\dot{{\\pmb{\\gamma}}}}_i^2(t) = \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2 \\,.\n\\tag{1.15}\\] Since \\({\\pmb{\\gamma}}\\) is unit speed we have \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2 = 1 \\quad \\forall \\, t \\in (a,b) \\,.\n\\] and therefore \\[\n\\frac{d}{dt} \\left( \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2 \\right) = 0  \\quad \\forall \\, t \\in (a,b) \\,.\n\\tag{1.16}\\] We can differentiate the LHS of (1.15) to get \\[\n\\frac{d}{dt} (\\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}) = \\ddot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}\n+  \\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 2 \\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}\\,.\n\\tag{1.17}\\] where we used Proposition 36 and symmetry of the scalar product. Differentiating (1.15) and using (1.16)-(1.17) we conclude \\[\n2 \\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0 \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\nRemark 40Proposition 39 is saying that if \\({\\pmb{\\gamma}}\\) is unit speed, then its tangent vector \\(\\dot{{\\pmb{\\gamma}}}\\) is always orthogonal to the second derivative \\(\\ddot{{\\pmb{\\gamma}}}\\). This will be very useful in the future.\n\n\n\n\n\nIf \\({\\pmb{\\gamma}}\\) is unit speed then \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\ddot{{\\pmb{\\gamma}}}\\) are orthogonal",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#reparametrization",
    "href": "sections/chap_1.html#reparametrization",
    "title": "1  Curves",
    "section": "1.9 Reparametrization",
    "text": "1.9 Reparametrization\nAs we have observed in the Examples of Chapter 1, there is in general no unique way to parametrize a curve. However we would like to understand when two parametrizations are related. In other words, we want to clarify the concept of equivalence of two parametrizations.\n\nDefinition 41: Diffeomorphism\nLet \\(\\phi\\ \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\). We say that \\(\\phi\\) is a diffeomorphism if the following conditions are satisfied:\n\n\\(\\phi\\) is invertible, with inverse \\(\\phi^{-1} \\ \\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\\). Thus \\[\n\\phi^{-1} \\circ \\phi=   \\phi\\circ \\phi^{-1} = \\mathop{\\mathrm{Id}}\\,,\n\\] where \\(\\mathop{\\mathrm{Id}}\\colon \\mathbb{R}\\to \\mathbb{R}\\) is the identity map on \\(\\mathbb{R}\\), that is, \\[\n\\mathop{\\mathrm{Id}}(t) = t \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\]\n\\(\\phi\\) is smooth,\n\\(\\phi^{-1}\\) is smooth.\n\n\n\n\nDefinition 42: ReparametrizationLet \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a parametrized curve. A reparametrization of \\({\\pmb{\\gamma}}\\) is another parametrized curve \\(\\tilde{{\\pmb{\\gamma}}} \\ \\colon (\\tilde{a},\\tilde{b}) \\to \\mathbb{R}^n\\) such that \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) = {\\pmb{\\gamma}}(\\phi(t)) \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b})\\,,\n\\tag{1.18}\\] where \\[\n\\phi\\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\n\\] is a diffeomerphism. We call both \\(\\phi\\) and \\(\\phi^{-1}\\) reparametrization maps.\n\n\n\nRemark 43A comment about the above definition. Given a parametrized curve \\({\\pmb{\\gamma}}\\), this identifies a 1D shape \\(\\Gamma \\subset \\mathbb{R}^n\\). A reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) is just an equivalent way to describe \\(\\Gamma\\). For \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) to be reparametrizations of each other, there must exist a smooth rule \\(\\phi\\) to switch from one to another, according to formula (1.18)\n\n\n\n\n\nSketch of 1D shaper parametrized by \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\)\n\n\n\nExample 44: Change of orientationThe map \\(\\phi\\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\\) defined by \\[\n\\phi(t) := - t\n\\] is a diffeomoprhism. The inverse of \\(\\phi\\) is given by \\({\\phi}^{-1} \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\) defined by \\[\n{\\phi}^{-1} (t) = - t \\,.\n\\] Note that \\(\\phi\\) can be used to reverse the orientation of a curve.\n\n\n\nExample 45: Reversing orientation of circleConsider the unit circle parametrized as usual by \\({\\pmb{\\gamma}}\\ \\colon [0,2\\pi] \\to \\mathbb{R}^2\\) defined as \\[\n{\\pmb{\\gamma}}(t) := (\\cos (t), \\sin(t)) \\,.\n\\] To reverse the orientation we can reparametrize \\({\\pmb{\\gamma}}\\) by using the diffeomorphism \\[\n\\phi(t):= - t \\,.\n\\] This way we obtain \\(\\tilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\phi\\ \\colon [0,2\\pi] \\to [0, 2\\pi]\\), \\[\\begin{align*}\n\\tilde{{\\pmb{\\gamma}}}(t) & = {\\pmb{\\gamma}}(\\phi(t)) \\\\\n              & = (\\cos(-t),\\sin(-t)) \\\\\n              & = (\\cos(t),-\\sin(t)) \\,,\n\\end{align*}\\] where in the last identity we used the properties of \\(\\cos\\) and \\(\\sin\\). Notice that in this way, for example, \\[\n{\\pmb{\\gamma}}(\\pi/2) = (0,1) \\,, \\quad {\\pmb{\\gamma}}(\\pi/2) = (0,-1) \\,.\n\\]\n\n\n\n\n\nUnit circle with usual parametrization \\({\\pmb{\\gamma}}\\), and with reversed orientation \\(\\widetilde{{\\pmb{\\gamma}}}\\)\n\n\n\nExample 46: Change of speed\nLet \\(k &gt; 0\\). The map \\(\\phi\\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\\) defined by \\[\n\\phi(t) := kt\n\\] is a diffeomoprhism. The inverse of \\(\\phi\\) is given by \\({\\phi}^{-1} \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\) defined by \\[\n{\\phi}^{-1} (t) = \\frac{t}{k} \\,.\n\\] Note that \\(\\phi\\) can be used to change the speed of a curve:\n\nIf \\(k &gt; 1\\) the speed increases ,\nIf \\(0 &lt; k &lt; 1\\) the speed decreases.\n\n\n\n\nExample 47: Doubling the speed of Lemniscate\nRecall the Lemniscate \\[\n{\\pmb{\\gamma}}(t): = (\\sin(t), \\sin(t)\\cos(t) ) \\,, \\quad t \\in [0,2\\pi] \\,.\n\\] We can double the speed of the Lemniscate by using the Using the diffeomorphism \\[\n\\phi(t):=2t \\,.\n\\] This way we obtain \\(\\tilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\phi\\ \\colon [0,\\pi] \\to [0, 2\\pi]\\) with \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) = {\\pmb{\\gamma}}(\\phi(t)) = (\\sin(2t), \\sin(2t)\\cos(2t)) \\,.\n\\] In this case we have that \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = 2 \\dot{{\\pmb{\\gamma}}}(\\phi(t)) \\,.\n\\]\n\nThe above follows by chain rule. Indeed, \\(\\dot{\\phi} = 2\\), so that \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}= \\frac{d}{dt} \\left(  {\\pmb{\\gamma}}(\\phi(t))  \\right)  = \\dot{\\phi}(t) \\dot{{\\pmb{\\gamma}}}(\\phi(t)) = 2 \\dot{{\\pmb{\\gamma}}}(\\phi(t))\\,.\n\\]\n\n\n\n\n\n\nLemniscate curve \\({\\pmb{\\gamma}}\\) and Lemniscate at double speed \\(\\widetilde{{\\pmb{\\gamma}}}\\)\n\n\n\nImportantThe main reason we are interested in reparametrizations is because we want to parametrize curves by arc-lenght: This means that, for a curve \\({\\pmb{\\gamma}}\\), we want to find a reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) such that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed: \\[\n\\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}} \\right\\| = 1 \\,, \\quad  \\forall t \\in (a,b) \\,.\n\\] We will see that this is not always possible.\n\n\n\nDefinition 48: Regular points\nLet \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a parametrized curve. We say that:\n\n\\({\\pmb{\\gamma}}(t_0)\\) is a regular point if \\[\n\\dot{{\\pmb{\\gamma}}}(t_0) \\neq 0 \\,.\n\\]\nA point \\({\\pmb{\\gamma}}(t_0)\\) is singular if it is not regular.\nThe curve \\({\\pmb{\\gamma}}\\) is regular if every point of \\({\\pmb{\\gamma}}\\) is regular, that is, \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\nNote that when \\(\\dot{{\\pmb{\\gamma}}}(t_0) = 0\\), this means the curve is stopping at time \\(t_0\\). Before making an example, let us prove a useful lemma about diffeomorphisms.\n\nLemma 49Let \\(\\phi\\ \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\) be a diffeomorphism. Then \\[\n\\dot{\\phi} (t) \\neq 0 \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\nProofWe know that \\(\\phi\\) is smooth with smooth inverse \\[\n\\psi := \\phi^{-1} \\ \\colon (\\tilde{a},\\tilde{b}) \\to (a,b) \\,.\n\\] In particular it holds \\[\n\\psi (\\phi(t)) = t \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] We can differentiate both sides of the above expression to get \\[\n\\frac{d}{dt} \\left( \\psi (\\phi(t))  \\right) = 1 \\,.\n\\tag{1.19}\\] We can differentiate the LHS by chain rule \\[\n\\frac{d}{dt} \\left( \\psi (\\phi(t))  \\right) = \\dot\\psi (\\phi(t)) \\, \\dot\\phi(t) \\,.\n\\] From (1.19) we then get \\[\n\\dot\\psi (\\phi(t)) \\, \\dot\\phi(t) = 1 \\, , \\quad \\forall \\, t \\in (a,b) \\,.\n\\] Since on the LHS we have a product, this means that none of the LHS terms vanishes, so that \\[\n\\dot\\phi(t) \\neq  0 \\, , \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\nExample 50: A curve with one singular point\nConsider the parabola \\[\n\\Gamma := \\{ (x,y) \\in \\mathbb{R}^2 \\, \\colon \\,  y=x^2 , \\, -1 \\leq x \\leq 1\\} \\,.\n\\] This can be parametrized in two ways by \\({\\pmb{\\gamma}}, {\\pmb{\\eta}}\\ \\colon [-1,1] \\to \\mathbb{R}^2\\) defined as \\[\n{\\pmb{\\gamma}}(t) = (t,t^2) \\,, \\quad\n{\\pmb{\\eta}}(t) = (t^3, t^6) \\,.\n\\] We will see that the above parametrizations are not equivalent. This is intuitively clear, since the change of variables map should be \\[\n\\phi(t) = t^3 \\,.\n\\] This is smooth and invertible, with inverse \\[\n\\phi^{-1}(t) = \\sqrt[3]{x} \\,.\n\\] However \\(\\phi^{-1}\\) is not smooth at \\(t=0\\), and thus \\(\\phi\\) is not a diffeomorphism. Alternatively we could have just noticed that \\[\n\\dot \\phi(t) = 3t^2 \\quad \\implies \\quad \\dot\\phi(0) = 0 \\,,\n\\] and therefore \\(\\phi\\) cannot be a diffeomorphism due to Lemma 49.\nLet us look at the derivatives: \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (1,2t) \\,, \\quad \\dot{{\\pmb{\\eta}}} (t)= (3t^2,6t^5) \\,.\n\\] We notice a difference:\n\n\\({\\pmb{\\gamma}}\\) is a regular parametrization,\n\\({\\pmb{\\eta}}(t)\\) is regular only for \\(t \\neq 0\\).\n\nIndeed if we animate the plots of the above parametrizations, we see that:\n\nThe point \\({\\pmb{\\gamma}}(t)\\) moves with constant horizontal speed\nThe point \\({\\pmb{\\eta}}(t)\\) is decelerating for \\(t &lt; 0\\), it stops at \\(t = 0\\), and then accelerates again for \\(t&gt;0\\).\n\n\n\n\n\n\nLeft: Animation of \\({\\pmb{\\gamma}}\\). Right: Animation of \\({\\pmb{\\eta}}\\)\n\n\n\nProposition 51: Regularity is invariant for reparametrizationLet \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a parametrized curve and suppose that \\({\\pmb{\\gamma}}\\) is regular, that is, \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\neq 0 \\,, \\quad  \\forall \\, t \\in (a,b) \\,.\n\\] Then every reparametrization of \\({\\pmb{\\gamma}}\\) is also regular.\n\n\n\nProofLet \\(\\widetilde{{\\pmb{\\gamma}}}\\ \\colon (\\tilde{a},\\tilde{b}) \\to \\mathbb{R}^n\\) be a reparametrization of \\({\\pmb{\\gamma}}\\). Then there exist \\(\\phi\\ \\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\\) diffeomorphism such that \\[\n\\tilde {\\pmb{\\gamma}}(t) = {\\pmb{\\gamma}}(\\phi(t)) \\,, \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b}) \\,.\n\\] By the chain rule we have \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\frac{d}{dt}  \\left(  {\\pmb{\\gamma}}(\\phi(t))  \\right) = \\dot{{\\pmb{\\gamma}}}(\\phi(t)) \\dot\\phi(t) \\,.\n\\] Therefore \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\neq 0 \\quad \\iff \\quad \\dot{{\\pmb{\\gamma}}}(\\phi(t)) \\dot\\phi(t)  \\neq 0 \\,.\n\\tag{1.20}\\] But we are assuming that \\({\\pmb{\\gamma}}\\) is regular, so that \\[\n\\dot{{\\pmb{\\gamma}}}(\\phi(t)) \\neq 0 \\,, \\quad \\forall\\, t \\in (\\tilde{a},\\tilde{b}) \\,.\n\\] Thus (1.20) is equivalent to \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\neq 0 \\quad \\iff \\quad  \\dot\\phi(t)  \\neq 0 \\,.\n\\tag{1.21}\\] Since \\(\\phi\\) is a diffeomorphism, by Lemma 49 we have that \\[\n\\dot \\phi(t) \\neq 0 \\,, \\quad \\forall\\, t \\in (\\tilde{a},\\tilde{b})  \\,.\n\\] By (1.21) we conclude that \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\neq  0 \\, , \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b}) \\,,\n\\] proving that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is regular.\n\n\n\nExample 52Let us go back to the parabola \\[\n\\Gamma := \\{ (x,y) \\in \\mathbb{R}^2 \\, \\colon \\,  y=x^2 , \\, -1 \\leq x \\leq 1\\} \\,,\n\\] with the two parametrizations \\({\\pmb{\\gamma}}, {\\pmb{\\eta}}\\ \\colon [-1,1] \\to \\mathbb{R}^2\\) with \\[\n{\\pmb{\\gamma}}(t) = (t,t^2) \\,, \\quad\n{\\pmb{\\eta}}(t) = (t^3, t^6) \\,.\n\\] We have that \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (1,2t) \\,, \\quad \\dot{{\\pmb{\\eta}}} (t)= (3t^2,6t^5) \\,.\n\\] Therefore\n\n\\({\\pmb{\\gamma}}\\) is a regular parametrization,\n\\({\\pmb{\\eta}}(t)\\) is regular only for \\(t \\neq 0\\).\n\nProposition 51 implies that \\({\\pmb{\\eta}}\\) is NOT a reparametrization of \\({\\pmb{\\gamma}}\\).\n\n\n\nDefinition 53: Unit speed reparametrizationLet \\({\\pmb{\\gamma}}\\) be a parametrized curve. A unit speed reparametrization of \\({\\pmb{\\gamma}}\\) is a reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) such that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed.\n\n\nThe next theorem states that a curve is regular if and only if it has a unit speed reparametrization. For the proof, it is crucial to recall the definition of arc-length of a curve \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\), which is given by \\[\ns(t):=\\int_{t_0}^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau \\,,\n\\] for some arbitrary \\(t_0 \\in (a,b)\\) fixed. Indeed, we will see that for \\(\\phi\\) regular the unit speed parametrization map can be taken as \\[\n\\phi= s^{-1} \\,.\n\\]\n\nTheorem 54: Existence of unit speed reparametrization\nLet \\({\\pmb{\\gamma}}\\) be a parametrized curve. They are equivalent:\n\n\\({\\pmb{\\gamma}}\\) is regular,\n\\({\\pmb{\\gamma}}\\) has a unit speed reparametrization.\n\n\n\n\nProofStep 1. Direct implication.\nAssume \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) is regular, that is, \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b)\\,.\n\\] Let \\(s \\ \\colon (a,b) \\to \\mathbb{R}\\) be the arc-length of \\({\\pmb{\\gamma}}\\) starting at any point \\(t_0 \\in (a,b)\\). By the Fundamental Theorem of Calculus we have \\[\n\\dot s (t) = \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|  \n\\tag{1.22}\\] so that \\[\n\\dot s (t) &gt; 0 \\,, \\quad \\forall \\, t \\in (a,b)\\,.\n\\] Since \\(s\\) is a scalar function, the above condition and the Inverse Function Theorem guarantee the existsence of a smooth inverse \\[\ns^{-1} \\ \\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\n\\] for some \\(\\tilde{\\alpha}&lt; \\tilde{\\beta}\\). Define the reparametrization map \\(\\phi\\) as \\[\n\\phi:= s^{-1}\n\\] and the corresponding reparametrization of \\({\\pmb{\\gamma}}\\) given by the curve \\[\n\\widetilde{{\\pmb{\\gamma}}}\\ \\colon  (\\tilde{a},\\tilde{b}) \\to \\mathbb{R}^n \\,, \\quad\n\\widetilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\phi\\,.\n\\] We claim that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed. Indeed, by definition \\[\n\\widetilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\phi\\quad \\implies \\quad {\\pmb{\\gamma}}= \\widetilde{{\\pmb{\\gamma}}}\\circ \\phi^{-1} = \\widetilde{{\\pmb{\\gamma}}}\\circ s \\,,\n\\] or in other words \\[\n{\\pmb{\\gamma}}(t) = \\widetilde{{\\pmb{\\gamma}}}(s(t)) \\,, \\quad \\forall t \\in (a,b) \\,.\n\\] Differentiating the above expression and using the chain rule we get \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(s(t)) \\, \\dot s(t) =  \\dot{\\widetilde{{\\pmb{\\gamma}}}}(s(t)) \\, \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|  \n\\] where in the last equality we used (1.22). Taking the absolute value of the above yileds \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|   = \\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(s(t)) \\right\\| \\, \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\,.  \n\\tag{1.23}\\] Since \\({\\pmb{\\gamma}}\\) is regular, we have \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b)\\,.\n\\] Therefore we can divide (1.23) by \\(\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|\\) and obtain \\[\n\\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(s(t)) \\right\\| = 1  \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] By invertibility of \\(s\\), the above holds if and only if \\[\n\\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\| = 1  \\,, \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b}) \\,,\n\\] showing that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is a unit speed reparametrization of \\({\\pmb{\\gamma}}\\).\nStep 2. Reverse implication.\nSuppose there exists a unit speed reparametrization of \\({\\pmb{\\gamma}}\\) denoted by \\[\n\\widetilde{{\\pmb{\\gamma}}}\\ \\colon (\\tilde{a},\\tilde{b})  \\to \\mathbb{R}^n \\,, \\quad \\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\\circ \\phi\n\\] for some reparametrization map \\(\\phi\\ \\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\\). Differentiating \\(\\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\\circ \\phi\\) and using the chain rule we get \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\dot{{\\pmb{\\gamma}}}(\\phi(t)) \\, \\dot{\\phi} (t) \\,.\n\\] Taking the norm \\[\n\\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\| = \\left\\| \\dot{{\\pmb{\\gamma}}}(\\phi(t))  \\right\\| \\, |\\dot{\\phi} (t)| \\,.\n\\] Since \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed we obtain \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(\\phi(t))  \\right\\| \\, |\\dot \\phi(t)| = 1 \\,, \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b}) \\,.\n\\tag{1.24}\\] Since \\(\\phi\\) is a diffeomorphism from \\((\\tilde{a},\\tilde{b})\\) into \\((a,b)\\), Lemma 49 guarantees that \\[\n\\dot{\\phi} (t)  \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] In particular (1.24) implies \\[\n\\dot{{\\pmb{\\gamma}}}(\\phi(t))  \\neq 0 \\,, \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b}) \\,.\n\\] As \\(\\phi\\) is invertible, we also have \\[\n\\dot{{\\pmb{\\gamma}}}(t)  \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,,\n\\] proving that \\({\\pmb{\\gamma}}\\) is regular.\n\n\nThe proof of Theorem 54 told us that, if \\({\\pmb{\\gamma}}\\) is regular, then \\[\n\\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\\circ s^{-1}\n\\] is a unit speed reparametrization of \\({\\pmb{\\gamma}}\\). In the next proposition we show that the arc-length \\(s\\) is essentially the only unit-speed reparametrization of a regular curve.\n\nProposition 55: Arc-length and unit speed reparametrization\nLet \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a regular curve. Let \\(\\widetilde{{\\pmb{\\gamma}}}\\ \\colon (\\tilde{a},\\tilde{b}) \\to \\mathbb{R}^n\\) be reparametrization of \\({\\pmb{\\gamma}}\\), so that \\[\n{\\pmb{\\gamma}}(t) = \\widetilde{{\\pmb{\\gamma}}}( \\phi(t) )  , \\quad \\forall \\, t \\in (a,b)\\,.\n\\] for some diffeomorphism \\(\\phi\\ \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\). Denote by \\[\ns(t):= \\int_{t_0}^t  \\left\\| \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| \\, d \\tau \\,, \\quad t \\in (a,b)\n\\] the arc-length of \\({\\pmb{\\gamma}}\\) starting at any point \\(t_0 \\in (a,b)\\). We have:\n\nIf \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed, then there exists \\(c \\in \\mathbb{R}\\) such that \\[\n\\phi(t) = \\pm s(t) + c   \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\tag{1.25}\\]\nIf \\(\\phi\\) is given by (1.25) for some \\(c \\in \\mathbb{R}\\), then \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed.\n\n\n\n\nProofStep 1. First Point.\nFirst note that a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) of \\({\\pmb{\\gamma}}\\) exists by Theorem 54, since \\({\\pmb{\\gamma}}\\) is assumed to be regular. Thus assume \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed reparametrization of \\({\\pmb{\\gamma}}\\). By differentiating both sides of \\[\n{\\pmb{\\gamma}}(t) = \\widetilde{{\\pmb{\\gamma}}}( \\phi(t) )  , \\quad \\forall \\, t \\in (a,b)\\,,\n\\] we obtain \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\frac{d}{dt} \\widetilde{{\\pmb{\\gamma}}}( \\phi(t) ) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(\\phi(t)) \\, \\dot\\phi(t)  \\,.\n\\] Taking the norms we then have \\[\\begin{align*}\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| & = \\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}}(\\phi(t)) \\, \\dot\\phi(t)  \\right\\| \\\\\n                    & = \\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}}(\\phi(t))  \\right\\| \\, | \\dot\\phi(t) | \\\\\n                    & = | \\dot\\phi(t) | \\,,\n\\end{align*}\\] where in the last equality we used that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed, and so \\[\n\\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}} \\right\\| \\equiv 1 \\,.\n\\] To summarize, so far we have proven that \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|  = | \\dot\\phi(t) | \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] Therefore \\[\ns(t) = \\int_{t_0}^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(\\tau)  \\right\\| \\, d\\tau =  \\int_{t_0}^t | \\dot \\phi(\\tau) | \\, d\\tau \\,.\n\\] By the Fundamental Theorem of Calculus we get \\[\n\\dot s(t) = |\\dot \\phi(t) |\n\\] and therefore \\[\n\\phi= \\pm s + c\n\\] for some \\(c \\in \\mathbb{R}\\), concluding the proof.\nStep 2. Second Point.\nSuppose that \\[\n\\phi:= \\pm s + c\n\\] for some \\(c \\in \\mathbb{R}\\), so that \\(\\phi \\ \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\). We have \\[\n\\dot\\phi(t) =  \\pm \\dot s (t) = \\pm \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\neq 0  \n\\tag{1.26}\\] where the last term is non-zero since \\({\\pmb{\\gamma}}\\) is regular. Therefore, due to the Inverse Function Theorem, \\(\\phi\\) is invertible with smooth inverse. This proves that \\(\\widetilde{{\\pmb{\\gamma}}}\\) defined by \\[\n\\widetilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\psi  \\,, \\quad \\psi := \\phi^{-1} \\,,\n\\] is a reparametrization of \\({\\pmb{\\gamma}}\\). In particular \\[\n{\\pmb{\\gamma}}= \\widetilde{{\\pmb{\\gamma}}}\\circ \\phi\\,.\n\\] Differentiating the above, and recalling (1.26), we get \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\phi(t) ) \\, \\dot\\phi(t) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\phi(t) ) \\,\\left( \\pm \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\right) \\,.\n\\] Taking the absolute value of the above yields \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| = \\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\phi(t) ) \\right\\|  \\, \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\,.\n\\] Since \\({\\pmb{\\gamma}}\\) is regular we can divide by \\(\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|\\) to get \\[\n\\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\phi(t) ) \\right\\|  = 1 \\, \\quad \\forall \\, t \\in (a,b)  \\, .\n\\] Since \\(\\phi\\) is invertible, the above is equivalent to \\[\n\\left\\|  \\dot{\\widetilde{{\\pmb{\\gamma}}}}( t ) \\right\\|  = 1 \\, \\quad \\forall \\, t \\in (\\tilde{a},\\tilde{b})  \\, ,\n\\] proving that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is a unit speed reparametrization.\n\n\n\nRemark 56Let \\({\\pmb{\\gamma}}\\) be regular. The above proposition tells us that they are equivalent:\n\nComputing a unit speed reparametrization of \\({\\pmb{\\gamma}}\\),\nComputing \\(s\\) the arc-length of \\({\\pmb{\\gamma}}\\).\n\nIn some cases however, unit speed reparametrization and arc-length are impossible to characterize in terms of elementary functions, even for very simple curves.\n\n\n\nExample 57: Twisted cubicDefine the twisted cubic \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^3\\) by \\[\n{\\pmb{\\gamma}}(t) = (t,t^2,t^3)\\,.\n\\] Therefore \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (1,2t,3t^2)\\,,\n\\] so that \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\neq 0 \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,,\n\\] meaning that \\({\\pmb{\\gamma}}\\) is regular. In particular we have \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| = \\sqrt{  1 + 4t^2 + 9t^4 }\n\\] so that the arc-length of \\({\\pmb{\\gamma}}\\) is \\[\ns(t) = \\int_{t_0}^t  \\sqrt{  1 + 4\\tau^2 + 9\\tau^4 }\\, d\\tau \\,.\n\\] Since \\({\\pmb{\\gamma}}\\) is regular, by Proposition 55 we know that \\({\\pmb{\\gamma}}\\) admits a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) such that \\[\n{\\pmb{\\gamma}}=  \\widetilde{{\\pmb{\\gamma}}}\\circ \\phi\n\\] with the diffeomorphism \\(\\phi\\) given by \\[\n\\phi(t) = \\pm s(t) + c = \\pm \\int_{t_0}^t  \\sqrt{  1 + 4\\tau^2 + 9\\tau^4 }\\, d\\tau + c\n\\] for some \\(c \\in \\mathbb{R}\\). It can be shown that the above integral does not have a closed form in terms of elementary functions. Therefore the unit speed parametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) cannot be computed explicitly.\n\n\n\n\n\n\n\nPlot of Twisted Cubic for t between -2 and 2",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_1.html#closed-curves",
    "href": "sections/chap_1.html#closed-curves",
    "title": "1  Curves",
    "section": "1.10 Closed curves",
    "text": "1.10 Closed curves\nSo far we have seen examples of:\n\nCurves which are infinite, or unbounded. This is for example the parabola \\[\n{\\pmb{\\gamma}}(t) := (t,t^2) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,,\n\\]\nCurves which are finite and have end-points, such as the semi-circle \\[\n{\\pmb{\\gamma}}(t) := (\\cos(t),\\sin(t)) \\,, \\quad \\forall \\, t \\in [0,\\pi] \\,,\n\\]\nCurves which form loops, such as the circle \\[\n{\\pmb{\\gamma}}(t) := (\\cos(t),\\sin(t)) \\,, \\quad \\forall \\, t \\in [0,2\\pi] \\,.\n\\]\n\nHowever there are examples of curves which are in between the above types.\n\nExample 58\nFor example consider the curve \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^2\\) \\[\n{\\pmb{\\gamma}}(t) := (t^2-1, t^3 -t) \\,\\quad  \\forall \\, t \\in \\mathbb{R}\\,.\n\\] This curve has two main properties:\n\n\\({\\pmb{\\gamma}}\\) is unbounded: If define \\(\\widetilde{{\\pmb{\\gamma}}}\\) as the restriction of \\({\\pmb{\\gamma}}\\) to the time interval \\([1,\\infty)\\), then \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unbounded. A point which starts at \\({\\pmb{\\gamma}}(1) = (0,0)\\) goes towards infinity.\n\\({\\pmb{\\gamma}}\\) contains a loop: If we define \\(\\widetilde{{\\pmb{\\gamma}}}\\) as the restriction of \\({\\pmb{\\gamma}}\\) to the time interval \\([-1,1]\\), then \\(\\widetilde{{\\pmb{\\gamma}}}\\) is a closed loop starting at \\({\\pmb{\\gamma}}(-1) = (0,0)\\) and returnning at \\({\\pmb{\\gamma}}(1) = (0,0)\\).\n\n\n\n\n\n\nAnimated plot of curve \\({\\pmb{\\gamma}}(t) = (t^2-1, t^3-1)\\) for \\(t \\in [-2,2]\\)\n\n\nThe aim of this section is to make precise the concept of looping curve. To do that, we need to define periodic curves.\n\nDefinition 59: Periodic curveLet \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^n\\) be a parametrized curve, and let \\(T \\in \\mathbb{R}\\). We say that \\({\\pmb{\\gamma}}\\) is T-periodic if \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\gamma}}(t+T) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\]\n\n\nNote that every curve is \\(0\\)-periodic. Therefore to define a closed curve we need to rule out this case.\n\nDefinition 60: Closed curve\nLet \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^n\\) be a parametrized curve. We say that \\({\\pmb{\\gamma}}\\) is closed if:\n\n\\({\\pmb{\\gamma}}\\) is not constant,\n\\({\\pmb{\\gamma}}\\) is T-periodic for some \\(T \\neq 0\\).\n\n\n\n\nRemark 61\nWe have the following basic facts:\n\nIf \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic, then a point moving around \\({\\pmb{\\gamma}}\\) returns to its starting point after time \\(T\\).\n\nThis is exactly the definition of \\(T\\)-periodicity. Indeed let \\(p = {\\pmb{\\gamma}}(a)\\) be the point in question, then \\[\n{\\pmb{\\gamma}}(a + T) = {\\pmb{\\gamma}}(a) = p\n\\] by periodicity. Thus \\({\\pmb{\\gamma}}\\) returns to \\(p\\) after time \\(T\\).\n\nIf \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic, then \\({\\pmb{\\gamma}}\\) is determined by its restriction to any interval of length \\(|T|\\).\nConversely, suppose that \\({\\pmb{\\gamma}}\\ \\colon [a,b] \\to \\mathbb{R}^n\\) satisfies \\[\n{\\pmb{\\gamma}}(a) = {\\pmb{\\gamma}}(b) \\,, \\quad \\frac{d^k {\\pmb{\\gamma}}}{dt^k} (a) =\\frac{d^k {\\pmb{\\gamma}}}{dt^k}  (b)  \n\\] for all \\(k \\in \\mathbb{N}\\). Set \\[\nT:=b-a \\,.\n\\] Then \\({\\pmb{\\gamma}}\\) can be extended to a \\(T\\)-periodic curve \\(\\widetilde{{\\pmb{\\gamma}}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^n\\) defined by \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) := {\\pmb{\\gamma}}(\\tilde{t}) \\,, \\quad  \\tilde{t}:= t - \\biggl\\lfloor \\frac{t-a}{b-a}  \\biggr\\rfloor (b-a)  \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\] The above means that \\(\\widetilde{{\\pmb{\\gamma}}}(t)\\) is defined by \\({\\pmb{\\gamma}}(\\tilde{t})\\) where \\(\\tilde{t}\\) is the unique point in \\([a,b]\\) such that \\[\nt = \\tilde{t} + k(b-a)\n\\] with \\(k \\in \\mathbb{Z}\\) defined by \\[\nk := \\biggl\\lfloor \\frac{t-a}{b-a}  \\biggr\\rfloor \\,,\n\\] see figure below. In this way \\(\\widetilde{{\\pmb{\\gamma}}}\\) is \\(T\\)-periodic.\nIf \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic, then it is also \\((-T)\\)-periodic.\n\nBecause if \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic then \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\gamma}}((t - T) + T ) = {\\pmb{\\gamma}}(t - T)\n\\] where in the first equality we used the trivial identity \\(t = (t-T) + T\\), while in the second equality we used \\(T\\)-periodicity of \\({\\pmb{\\gamma}}\\).\n\nIf \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic for some \\(T \\neq 0\\), then it is \\(T\\)-periodic for some \\(T&gt;0\\).\n\nThis is an immediate consequence of Point 4.\n\nIf \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic the \\({\\pmb{\\gamma}}\\) is \\((kT)\\)-periodic, for all \\(k \\in \\mathbb{Z}\\).\n\nBy point 4 we can assume WLOG that \\(k \\geq 0\\). We proceed by induction:\n\nThe statement is true for \\(k=1\\), since \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic.\nAssume now that \\({\\pmb{\\gamma}}\\) is \\(kT\\)-periodic. Then \\[\\begin{align*}\n{\\pmb{\\gamma}}(t + (k+1) T) & = {\\pmb{\\gamma}}( (t+T)  + kT ) & \\\\\n& = {\\pmb{\\gamma}}(t + T)   &  \\mbox{(by $kT$-periodicity)} \\\\  \n& = {\\pmb{\\gamma}}(t)   &  \\mbox{(by $T$-periodicity)}\n\\end{align*}\\] showing that \\({\\pmb{\\gamma}}\\) is \\((k+1)T\\)-periodic.\n\n\n\nBy induction we conclude that \\({\\pmb{\\gamma}}\\) is \\((kT)\\)-periodic for all \\(k \\in \\mathbb{N}\\).\n\nIf \\({\\pmb{\\gamma}}\\) is \\(T_1\\)-periodic and \\(T_2\\)-periodic then \\({\\pmb{\\gamma}}\\) is \\((k_1T_1 + k_2 T_2)\\)-periodic, for all \\(k_1, k_2 \\in \\mathbb{Z}\\).\n\nBy Point 6 we know that \\({\\pmb{\\gamma}}\\) is \\(k_1T_1\\)-periodic and \\(k_2T_2\\)-periodic. Set \\(T:=k_1T_1 + k_2T_2\\). We have \\[\\begin{align*}\n{\\pmb{\\gamma}}(t + T) & = {\\pmb{\\gamma}}( (t+ k_1T_1)  + k_2T_2 ) & \\\\\n& = {\\pmb{\\gamma}}(t + k_1T_1)  &  \\mbox{(by $k_2T_2$-periodicity)} \\\\  \n& = {\\pmb{\\gamma}}(t)  &  \\mbox{(by $k_1T_1$-periodicity)}\n\\end{align*}\\] showing that \\({\\pmb{\\gamma}}\\) is \\((k_1T_1 + k_2 T_2)\\)-periodic.\n\n\n\n\n\n\n\nThe points \\(t \\in \\mathbb{R}\\) and \\(\\tilde{t} \\in [a,b]\\) from Point 3 in Remark 61. In this skecth \\(t = \\tilde{t} + 3 T\\), with \\(T = b-a\\).\n\n\n\nDefinition 62Let \\({\\pmb{\\gamma}}\\) be a closed curve. The period of \\({\\pmb{\\gamma}}\\) is the smallest \\(T&gt;0\\) such that \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic, that is \\[\n\\mbox{Period of ${\\pmb{\\gamma}}$} := \\min \\{ T \\, \\colon \\, T &gt; 0 \\,, \\,\\, {\\pmb{\\gamma}}\\, \\mbox{ is T-periodic}    \\} \\,.\n\\]\n\n\nWe need to show that the above definition is well-posed, i.e., that there exists such smallest \\(T&gt;0\\).\n\nProposition 63Let \\({\\pmb{\\gamma}}\\) be a closed curve. Then there exists a smallest \\(T&gt;0\\) such that \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic. In other words, the set \\[\nS := \\{ T  \\, \\colon \\, T &gt; 0 \\,, \\,\\, {\\pmb{\\gamma}}\\, \\mbox{ is T-periodic} \\} \\,.\n\\] admits positive minumum \\[\nP = \\min S \\,, \\quad P &gt; 0 \\,.\n\\]\n\n\n\nProofWe make 2 observations about the set \\(S\\):\n\nSince \\({\\pmb{\\gamma}}\\) is closed, we have that \\({\\pmb{\\gamma}}\\) is \\(T\\)-periodic for some \\(T \\neq 0\\). By Remark 61 Point 5, we know that \\(T\\) can be chosen such that \\(T&gt;0\\). Therefore \\[\nS \\neq \\emptyset \\,.\n\\]\n\\(S\\) is bounded below by \\(0\\). This is by definition of \\(S\\).\n\nThus, by the Axiom of Completeness of the Real Numbers, the set \\(S\\) admits an infimum \\[\nP = \\inf S \\,.\n\\] The proof is concluded if we show that:\nClaim. We have \\[\nP = \\min S  \\,.\n\\] This is equivalent to saying that \\[\nP \\in S \\,.\n\\]\nProof of claim.\nTo see that \\(P \\in S\\) we need to show that\n\n\\({\\pmb{\\gamma}}\\) is \\(P\\)-periodic,\n\\(P&gt;0\\).\n\nSince \\(P\\) is the infimum of \\(S\\), there exists an infimizing sequence \\(\\{T_n\\}_{n \\in \\mathbb{N}} \\subset S\\) such that \\[\nT_n \\to P \\,.\n\\] WLOG we can choose \\(T_n\\) decreasing, that is, such that \\[\nT_1 &gt; T_2 &gt; \\ldots &gt; T_n &gt; \\ldots &gt; 0 \\,.\n\\]\nProof of Point 1. As \\(T_n \\in S\\), we have that \\({\\pmb{\\gamma}}\\) is \\(T_n\\)-periodic. Then \\[\n{\\pmb{\\gamma}}(t + T_n) = {\\pmb{\\gamma}}(t) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,,  \\,\\, n \\in \\mathbb{N}\\,.\n\\] Since \\(T_n \\to P\\), we can take the limit as \\(n \\to \\infty\\) and use the continuity of \\({\\pmb{\\gamma}}\\) to obtain \\[\n{\\pmb{\\gamma}}(t) = \\lim_{n \\to \\infty} \\ {\\pmb{\\gamma}}(t + T_n) = {\\pmb{\\gamma}}(t + P) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,,\n\\] showing that \\({\\pmb{\\gamma}}\\) is \\(P\\)-periodic.\nProof of Point 2. Suppose by contradiction that \\[\nP = 0 \\,.\n\\] Fix \\(t \\in \\mathbb{R}\\). Since \\(T_n &gt; 0\\), we can find unique \\[\nt_n \\in [0,T_n] \\,, \\quad k_n \\in \\mathbb{Z}\\,,\n\\] such that \\[\nt = t_n + k_n T_n \\,,\n\\] as shown in the figure below. Indeed, it is sufficient to define \\[\nk_n := \\biggl\\lfloor \\frac{t}{T_n}  \\biggr\\rfloor \\in \\mathbb{Z}\\,, \\quad t_n := t - k_n T_n \\,.\n\\] Since \\(T_n \\in S\\), we know that \\({\\pmb{\\gamma}}\\) is \\(T_n\\)-periodic. Remark 61 Point 6 implies that \\({\\pmb{\\gamma}}\\) is also \\(k_nT_n\\)-periodic, since \\(k_n \\in \\mathbb{Z}\\). Thus \\[\\begin{align*}\n{\\pmb{\\gamma}}(t) & = {\\pmb{\\gamma}}( t_n + k_nT_n )   &   \\mbox{(definition of $t_n$)} \\\\\n       & = {\\pmb{\\gamma}}(t_n)             & \\mbox{(by $k_nT_n$-periodicity)} \\,.\n\\end{align*}\\] Therefore \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\gamma}}(t_n) \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\tag{1.27}\\] Also notice that \\[\n0 \\leq t_n \\leq T_n \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\] by construction. Since \\(T_n \\to 0\\), by the Squeeze Theorem we conclude that \\[\nt_n \\to 0  \\quad \\mbox{as } \\, n \\to \\infty \\,.\n\\] Using the continuity of \\({\\pmb{\\gamma}}\\), we can pass to the limit in (1.27) and obtain \\[\n{\\pmb{\\gamma}}(t) = \\lim_{n \\to \\infty} {\\pmb{\\gamma}}(t_n) = {\\pmb{\\gamma}}(0) \\,.\n\\] Since \\(t \\in \\mathbb{R}\\) was arbitrary, we have shown that \\[\n{\\pmb{\\gamma}}(t) =  {\\pmb{\\gamma}}(0) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\] Therefore \\({\\pmb{\\gamma}}\\) is constant. This is a contradiction, as we were assuming that \\({\\pmb{\\gamma}}\\) is closed, and, in particular, not constant.\n\n\n\n\n\nFor each \\(t \\in \\mathbb{R}\\) there exist unique \\(k_n \\in \\mathbb{Z}\\) and \\(\\tilde{t}_n \\in [0,T_n]\\) such that \\(t=\\tilde{t} + k_n T_n\\). In this skecth \\(k_n =3\\).\n\n\n\nExample 64\nSome examples of closed curves:\n\nThe circumference \\[\n{\\pmb{\\gamma}}(t) = (\\cos(t), \\sin(t)) \\,, \\quad t \\in \\mathbb{R}\n\\] is not costant and is \\(2\\pi\\)-periodic. Thus \\({\\pmb{\\gamma}}\\) is closed. The period of \\({\\pmb{\\gamma}}\\) is \\(2 \\pi\\).\nThe Lemniscate \\[\n{\\pmb{\\gamma}}(t) = (\\sin(t), \\sin(t) \\cos(t)) \\,, \\quad t \\in \\mathbb{R}\n\\] is not costant and is \\(2\\pi\\)-periodic. Thus \\({\\pmb{\\gamma}}\\) is closed. The period of \\({\\pmb{\\gamma}}\\) is \\(2 \\pi\\).\nConsider again the curve from Example 58 \\[\n{\\pmb{\\gamma}}(t) := (t^2-1, t^3 -t) \\,, \\quad \\, t \\in \\mathbb{R}\\,.\n\\] According to our definition, \\({\\pmb{\\gamma}}\\) is not periodic. Therefore \\({\\pmb{\\gamma}}\\) is not closed. However there is a point of self-intersection on \\({\\pmb{\\gamma}}\\), namely \\[\np := (0,0) \\,,\n\\] for which we have \\[\np = {\\pmb{\\gamma}}(-1) = {\\pmb{\\gamma}}(1) \\,.\n\\]\n\n\n\nThe last curve in the above example motivates the definition of self-intersecting curve.\n\nDefinition 65: Self-intersecting curve\nLet \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^n\\) be a parametrized curve. We say that \\({\\pmb{\\gamma}}\\) is self-intersecting at a point \\(p\\) on the curve if\n\nThere exist two times \\(a \\neq b\\) such that \\[\np = {\\pmb{\\gamma}}(a)={\\pmb{\\gamma}}(b)  \\,,\n\\]\nIf \\({\\pmb{\\gamma}}\\) is closed with period \\(T\\), then \\(b-a\\) is not an integer multiple of \\(T\\).\n\n\n\n\nRemark 66The second condition in the above definition is important: if we did not require it, then any closed curve would be self-intersecting. Indeed consider a closed curve \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^n\\) and let \\(T\\) be its period. Then by Point 6 in Remark 61 we have \\[\n{\\pmb{\\gamma}}(a) = {\\pmb{\\gamma}}(a + kT) \\,, \\quad \\forall \\ a \\in \\mathbb{R}, \\, k \\in \\mathbb{Z}\\,.\n\\] Therefore every point \\({\\pmb{\\gamma}}(a)\\) would be of self-intersection. Point 2 in the above definition rules this example out. Indeed set \\(b:=a + kT\\), then \\[\nb - a = k T \\,,\n\\] meaning that \\(b-a\\) is an integer multiple of \\(T\\).\n\n\n\nExample 67Let us go back to the curve of Example 58, that is, \\[\n{\\pmb{\\gamma}}(t) := (t^2-1, t^3 -t) \\,, \\quad \\, t \\in \\mathbb{R}\\,.\n\\] We have that \\({\\pmb{\\gamma}}\\) is not periodic, and therefore not closed. However \\(p = (0,0)\\) is a point of self-intersection on \\({\\pmb{\\gamma}}\\), since we have \\[\np = {\\pmb{\\gamma}}(-1) = {\\pmb{\\gamma}}(1) \\,.\n\\]\n\n\n\nExample 68: The LimaçonDefine the parametrized curve \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^2\\) by \\[\n{\\pmb{\\gamma}}(t) = ( (1+2\\cos(t)) \\cos(t) ,  (1 + 2 \\cos(t)) \\sin(t)   ) \\,,\n\\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\] Such curve, plotted bolow, is called limaçon (French for snail). This curve is non constant and \\(2\\pi\\)-periodic. Therefore it is closed. The period of \\({\\pmb{\\gamma}}\\) is \\(2 \\pi\\). Moreover we have \\[\n{\\pmb{\\gamma}}( a ) = {\\pmb{\\gamma}}(b) = (0,0)\\,.\n\\] with \\(a = 2\\pi/3\\) and \\(b = 4\\pi/3\\). Note that \\[\nb-a = \\frac{4\\pi}{3} - \\frac{2\\pi}{3} = \\frac{2\\pi}{3}\n\\] which is not an integer multiple of the period \\(2\\pi\\). Therefore \\({\\pmb{\\gamma}}\\) is self-intersecting at \\((0,0)\\).\n\n\n\n\n\nLimaçon curve",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Curves</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html",
    "href": "sections/chap_2.html",
    "title": "2  Curvature and Torsion",
    "section": "",
    "text": "2.1 Curvature\nWe start with an informal discussion. Suppose \\({\\pmb{\\gamma}}\\) is a straight line \\[\n{\\pmb{\\gamma}}(t) = \\mathbf{a} + t \\mathbf{v}\n\\] with \\(\\mathbf{a}, \\mathbf{v} \\in \\mathbb{R}^3\\). The tangent vector to \\({\\pmb{\\gamma}}\\) is constant \\[\n\\dot{{\\pmb{\\gamma}}}(t) =  \\mathbf{v} \\,.\n\\] Whatever the definition of curvature will be, it has to hold that \\({\\pmb{\\gamma}}\\) has zero curvature in this case. If we further derive the tangent vector, we obtain \\[\n\\ddot{{\\pmb{\\gamma}}}(t) =  {\\pmb{0}}\\,.\n\\] Thus \\(\\ddot{{\\pmb{\\gamma}}}\\) seems to be a good candidate for the definition of curvature of \\({\\pmb{\\gamma}}\\) at the point \\({\\pmb{\\gamma}}(t)\\).\nSuppose now that \\({\\pmb{\\gamma}}\\) is a curve in \\(\\mathbb{R}^2\\) with unit speed. We have proven that in this case \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0 \\,,\n\\] that is, the vector \\(\\ddot{{\\pmb{\\gamma}}}\\) is orthogonal to the tangent \\(\\dot{{\\pmb{\\gamma}}}\\) at all times. Now let \\(\\mathbf{n}(t)\\) be the unit vector orthogonal to \\(\\dot{{\\pmb{\\gamma}}}(t)\\) at the point \\({\\pmb{\\gamma}}(t)\\). The amount that the curve \\({\\pmb{\\gamma}}\\) deviates from its tangent at \\({\\pmb{\\gamma}}(t)\\) after time \\(t_0\\) is \\[\n( {\\pmb{\\gamma}}(t + t_0) - {\\pmb{\\gamma}}(t) ) \\cdot \\mathbf{n}(t) \\,,\n\\tag{2.1}\\] as seen in the figure below.\nEquation (2.1) is what we take as measure of curvature. Since \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\cdot \\ddot{{\\pmb{\\gamma}}}(t) = 0 \\quad \\mbox{ and } \\quad   \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t)= 0 \\,,\n\\] we conclude that \\(\\ddot{{\\pmb{\\gamma}}}(t)\\) is parallel to \\(\\mathbf{n}(t)\\). Since \\(\\mathbf{n}(t)\\) is a unit vector, there exists a scalar \\(\\kappa(t)\\) such that \\[\n\\ddot{{\\pmb{\\gamma}}}(t)  = \\kappa(t) \\, \\mathbf{n}(t) \\,.\n\\] As \\(\\mathbf{n}\\) is unitary, we have \\[\n\\kappa(t) = \\left\\|  \\ddot{{\\pmb{\\gamma}}}(t)  \\right\\|\n\\]\nNow, approximate \\({\\pmb{\\gamma}}\\) at \\(t\\) with its second order Taylor polynomial: \\[\n{\\pmb{\\gamma}}(t+t_0) = {\\pmb{\\gamma}}(t) + \\dot{{\\pmb{\\gamma}}}(t) t_0 + \\frac{\\ddot{{\\pmb{\\gamma}}}(t)}{2} t_0^2 + o(t_0)\n\\] where the remainder \\(o(t_0)\\) is such that \\[\n\\lim_{t_0 \\to 0} \\ \\frac{o(t_0)}{t_0^2} = 0 \\,.\n\\] Therefore, discarding the remainder, \\[\n{\\pmb{\\gamma}}(t+t_0) - {\\pmb{\\gamma}}(t) \\approx \\dot{{\\pmb{\\gamma}}}(t) t_0 + \\frac{\\ddot{{\\pmb{\\gamma}}}(t)}{2} t_0^2 \\,.\n\\] Multiplying by \\(\\mathbf{n}(t)\\) we get \\[\n({\\pmb{\\gamma}}(t+t_0) - {\\pmb{\\gamma}}(t)) \\cdot \\mathbf{n}(t) \\approx \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t) t_0 +\n\\frac{\\ddot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t) }{2} t_0^2\\,.\n\\] Recalling that \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t) = 0\\,, \\quad  \\ddot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t) = \\kappa(t) \\,,\n\\] we then obtain \\[\n({\\pmb{\\gamma}}(t+t_0) - {\\pmb{\\gamma}}(t)) \\cdot \\mathbf{n}(t) \\approx\n\\frac{1}{2} \\, \\kappa(t) \\, t_0^2\n\\]\nWe take this as definition of curvature for a general unit speed curve in \\(\\mathbb{R}^n.\\)\nNote that \\(\\kappa(t)\\) is a function of time. Therefore the curvature of \\({\\pmb{\\gamma}}\\) can change from point to point.\nWe now define curvature for curves which are regular, but not necessarily unit speed.\nWe conclude with two examples in which we compute the curvature \\(\\kappa\\) using unit speed reparametrizations.\nBefore proceeding with the next example, let us give a short overview of the Hyperbolic functions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#curvature",
    "href": "sections/chap_2.html#curvature",
    "title": "2  Curvature and Torsion",
    "section": "",
    "text": "Amount that \\({\\pmb{\\gamma}}\\) deviates from tangent is \\(({\\pmb{\\gamma}}(t+t_0)-{\\pmb{\\gamma}}(t)) \\cdot \\mathbf{n}(t)\\)\n\n\n\n\n\nImportantThe amount that \\({\\pmb{\\gamma}}\\) deviates from a straight line is proportional to \\[\n\\kappa(t) = \\left\\| \\ddot{{\\pmb{\\gamma}}}(t) \\right\\|\\,.\n\\]\n\n\n\n\nDefinition 1Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a unit speed curve. The curvature of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is \\[\n\\kappa^{\\pmb{\\gamma}}(t) := \\left\\| \\ddot{{\\pmb{\\gamma}}}(t) \\right\\| \\,.\n\\]\n\n\n\n\n\nDefinition 2Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\\) be a regular. The curvature of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is \\[\n\\kappa^{\\pmb{\\gamma}}(t) :=   \\left\\| \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(\\phi(t)) \\right\\| \\,, \\quad \\forall \\, t \\in (a,b)\\,,\n\\] where \\(\\widetilde{{\\pmb{\\gamma}}}\\) is a unit speed reparametrization of \\({\\pmb{\\gamma}}\\), with \\({\\pmb{\\gamma}}= \\widetilde{{\\pmb{\\gamma}}}\\circ \\phi\\).\n\n\n\nRemark 3\nThe above definition is well posed:\n\nSince \\({\\pmb{\\gamma}}\\) is regular, there exist a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) of \\({\\pmb{\\gamma}}\\).\nIf \\(\\hat{{\\pmb{\\gamma}}}\\) is another unit speed reaprametrization of \\({\\pmb{\\gamma}}\\), with \\({\\pmb{\\gamma}}= \\hat{{\\pmb{\\gamma}}} \\circ \\hat\\phi\\), then \\[\n\\kappa^{{\\pmb{\\gamma}}} (t) =   \\left\\| \\ddot{\\hat{\\pmb{\\gamma}}} (\\hat\\phi(t)) \\right\\| \\,,\n\\] showing that there is no ambiguity in the definition of \\(\\kappa^{\\pmb{\\gamma}}\\).\n\n\nIndeed, since \\(\\widetilde{{\\pmb{\\gamma}}}\\) and \\(\\hat{{\\pmb{\\gamma}}}\\) are both reparametrizations of \\({\\pmb{\\gamma}}\\), then \\[\n{\\pmb{\\gamma}}(t) = \\widetilde{{\\pmb{\\gamma}}}(  \\tilde{\\phi}(t)) \\,, \\quad\n{\\pmb{\\gamma}}(t) = \\hat{{\\pmb{\\gamma}}} (\\hat{\\phi}(t)  )\n\\] for some diffeomorphisms \\(\\tilde{\\phi}, \\hat{\\phi}\\). Hence \\[\n{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\hat{\\pmb{\\gamma}}(\\phi(t))\\,, \\quad \\phi:= \\hat{\\phi} \\circ (\\tilde{\\phi})^{-1} \\,,\n\\tag{2.2}\\] where \\(\\phi\\) is a diffeomorphism, since it is composition of diffeomorphisms. Differentiating (2.2) we get \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\dot{\\hat{{\\pmb{\\gamma}}}}(\\phi(t)) \\dot\\phi(t) \\,.\n\\tag{2.3}\\] Taking the norms of the above, and recalling that \\(\\widetilde{{\\pmb{\\gamma}}}\\) and \\(\\hat{\\pmb{\\gamma}}\\) are unit speed, we get \\[\n|\\dot\\phi(t)| = 1 \\,, \\quad  \\forall \\, t \\,.\n\\tag{2.4}\\] Since \\(\\phi\\) is a diffeomorphism, we already know that \\(|\\dot\\phi| \\neq 0\\). As \\(\\dot\\phi\\) is continuous, this means that the sign of \\(\\dot\\phi\\) is constant. Thus (2.4) implies \\[\n\\dot\\phi(t) \\equiv 1 \\quad \\mbox{or} \\quad\n\\dot\\phi(t) \\equiv -1 \\,.\n\\] In both cases, we have \\[\n\\ddot \\phi\\equiv 0 \\,.\n\\] Differentiating (2.3) we then obtain \\[\\begin{align*}\n\\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) & = \\ddot{\\hat{{\\pmb{\\gamma}}}}(\\phi(t)) \\dot\\phi^2(t) +\n\\dot{\\hat{{\\pmb{\\gamma}}}}(\\phi(t)) \\ddot\\phi(t) \\\\\n& = \\ddot{\\hat{{\\pmb{\\gamma}}}}(\\phi(t)) \\dot\\phi^2(t) \\,.\n\\end{align*}\\] Taking the norms and using again that \\(|\\dot\\phi| \\equiv 1\\), we get that \\[\n\\left\\|   \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\| = \\left\\|  \\ddot{\\hat{{\\pmb{\\gamma}}}}(\\phi(t)) \\right\\| \\,.\n\\] Recalling that \\(\\phi  = \\hat\\phi\\circ (\\tilde{\\phi})^{-1}\\) we get \\[\n\\left\\|   \\ddot{\\widetilde{{\\pmb{\\gamma}}}}( \\tilde{\\phi}(t)) \\right\\| = \\left\\|  \\ddot{\\hat{{\\pmb{\\gamma}}}}(\\hat\\phi(t)) \\right\\| \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] Therefore \\[\n\\kappa^{\\pmb{\\gamma}}(t) =  \\left\\|   \\ddot{\\widetilde{{\\pmb{\\gamma}}}}( \\tilde{\\phi}(t)) \\right\\| = \\left\\|  \\ddot{\\hat{{\\pmb{\\gamma}}}}(\\hat\\phi(t)) \\right\\| \\,.\n\\]\n\n\n\n\nRemark 4: Methods for computing curvatureIn summary, the curvature of a regular curve \\[\n{\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\n\\] is defined via unit speed reparametrizations of \\({\\pmb{\\gamma}}\\). To compute \\(\\kappa\\) we do the following:\n\nWe find a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) of the regular curve \\({\\pmb{\\gamma}}\\)\nThis can be done by computing \\(s\\) the arc-length of \\({\\pmb{\\gamma}}\\), and then defining \\[\n\\widetilde{{\\pmb{\\gamma}}}:= {\\pmb{\\gamma}}\\circ \\psi \\,, \\quad \\psi:=s^{-1}\n\\]\nThen we compute \\[\n\\kappa^{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\left\\| \\ddot{\\widetilde{{\\pmb{\\gamma}}}} \\right\\|(t)\n\\]\nWe obtain the curvature of \\({\\pmb{\\gamma}}\\) by \\[\n\\kappa^{\\pmb{\\gamma}}(t)= \\kappa^{\\widetilde{{\\pmb{\\gamma}}}} (t)\n\\]\n\nWhen \\({\\pmb{\\gamma}}\\) is regular and has values in \\(\\mathbb{R}^3\\), there is a way to compute \\(\\kappa\\) without reparametrizing. To do this, we will need the notion of cross product, or vector product. We will see this in the following sections.\n\n\n\n\n\nProcedure for computing curvature \\(\\kappa\\)\n\n\n\n\nExample 5Consider the circle of radius \\(R&gt;0\\): \\[\n{\\pmb{\\gamma}}(t) = (R\\cos(t),R\\sin(t)) \\,, \\quad t \\in [0,2\\pi] \\,.\n\\] To compute the curvature of \\({\\pmb{\\gamma}}\\) we need to find a unit speed reparametrization. We have shown that: \\[\n{\\pmb{\\gamma}}\\, \\mbox{ regular } \\,\\,\\, \\implies \\,\\,\\, \\phi= s^{-1} \\, \\mbox{ unit speed reparametrization}\n\\] where \\(s\\) is the arc length of \\({\\pmb{\\gamma}}\\): \\[\ns(t):= \\int_{t_0}^t \\left\\| \\dot{{\\pmb{\\gamma}}}(\\tau) \\right\\| \\, d\\tau  \\,.\n\\] In our case \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (-R\\sin(t), R\\cos(t))  \\quad \\implies \\quad\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| = R  \n\\] and so \\({\\pmb{\\gamma}}\\) is regular. However \\({\\pmb{\\gamma}}\\) is not unit speed, therefore we need to find a unit speed reparametrization. The arc length starting at \\(t_0 = 0\\) is \\[\ns(t) = \\int_{0}^t R d \\tau = t R \\,.\n\\] The inverse of \\(s\\) is \\[\n\\phi(t) := s^{-1} (t) = \\frac{t}{R} \\,.\n\\] Therefore a unit speed reparametrization of \\({\\pmb{\\gamma}}\\) is \\[\n\\widetilde{{\\pmb{\\gamma}}}:={\\pmb{\\gamma}}\\circ \\phi\n\\] which reads \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) :=  \\left( R \\cos \\left( \\frac{t}{R} \\right) , R \\sin \\left( \\frac{t}{R} \\right)\\right) \\,.\n\\] We have \\[\\begin{align*}\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) & =  \\left( - \\sin \\left( \\frac{t}{R} \\right) ,  \\cos \\left( \\frac{t}{R} \\right)\\right) \\\\\n\\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) & =  \\left( -\\frac{1}{R} \\cos \\left( \\frac{t}{R} \\right) ,  - \\frac{1}{R} \\sin \\left( \\frac{t}{R} \\right)\\right)\n\\end{align*}\\] Therefore the curvature of \\({\\pmb{\\gamma}}\\) is \\[\n\\kappa(t) = \\left\\|  \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t)  \\right\\| = \\frac{1}{R} \\,.\n\\] In this case \\(\\kappa(t)\\) is constant. The curvature also tells us that the smaller the circle, the higher the curvature. For a large circle, like the Earth, the curvature is barely noticeable.\n\n\n\n\nRemark 6: Hyperbolic functions\nThe Hyperbloic functions are the analogous of the trigonometric functions, but defined using the hyperbola rather than the circle. Their formulas can be obtained by means of the exponential function \\(e^t\\). We have:\n\nHyperbolic cosine: The even part of the function \\(e^t\\), that is, \\[\n\\cosh (t) = \\frac {e^t + e^{-t}} {2} = \\frac {e^{2t} + 1} {2e^t} = \\frac {1 + e^{-2t}} {2e^{-t}} \\,.\n\\]\nHyperbolic sine: The odd part of the function \\(e^t\\), that is, \\[\n\\sinh (t) = \\frac {e^t - e^{-t}} {2} = \\frac {e^{2t} - 1} {2e^t} = \\frac {1 - e^{-2t}} {2e^{-t}} \\,.\n\\]\nHyperbolic tangent: Defined by \\[\n\\tanh(t) = \\frac{\\sinh t}{\\cosh t} = \\frac {e^t - e^{-t}} {e^t + e^{-t}}\n= \\frac{e^{2t} - 1} {e^{2t} + 1} \\,.\n\\]\nHyperbolic cotangent: The reciprocal of \\(\\tanh\\) for \\(t \\neq 0\\), \\[\n\\coth t = \\frac{\\cosh t}{\\sinh t} = \\frac {e^t + e^{-t}} {e^t - e^{-t}}\n= \\frac{e^{2t} + 1} {e^{2t} - 1} \\,.\n\\]\nHyperbolic secant: The reciprocal of \\(\\cosh\\) \\[\n\\mathop{\\mathrm{sech}}(t) = \\frac{1}{\\cosh t} = \\frac {2} {e^t + e^{-t}}\n= \\frac{2e^t} {e^{2t} + 1} \\,.\n\\]\nHyperbolic cosecant: The reciprocal of \\(\\sinh\\) for \\(t \\neq 0\\), \\[\n\\mathop{\\mathrm{csch}}(t) = \\frac{1}{\\sinh t} = \\frac {2} {e^t - e^{-t}}\n= \\frac{2e^t} {e^{2t} - 1} \\,.\n\\]\n\nFor a plot \\(\\cosh, \\sinh, \\tanh\\) see Figure 2.1 below. The properties of the hyperbolic functions which are of interest to us are:\n\nIdentities: \\[\\begin{align*}\n&\\cosh(t) + \\sinh(t) = e^t \\\\\n&\\cosh(t) - \\sinh(t) = e^{-t} \\\\\n&\\cosh^2(t) - \\sinh^2(t)  = 1 \\\\\n&{\\mathop{\\mathrm{sech}}}^2(t) - \\tanh^2(t)  = 1  \n\\end{align*}\\]\nDerivatives: \\[\\begin{align*}\n\\frac{d}{dt} \\left[ \\sinh(t) \\right] & = \\cosh (t) \\\\\n\\frac{d}{dt} \\left[ \\cosh(t) \\right] & = \\sinh (t) \\\\\n\\frac{d}{dt} \\left[ \\tanh(t) \\right] & = 1 - \\tanh^2 (t) = - {\\mathop{\\mathrm{csch}}}^2(t)\n\\end{align*}\\]\nIntegrals: \\[\\begin{align*}\n\\int_{t_0}^t \\sinh(u) \\, du & = \\cosh (t) - \\cosh( t_0 ) \\\\\n\\int_{t_0}^t \\cosh(u) \\, du & = \\sinh (t) - \\sinh( t_0 ) \\\\\n\\int_{t_0}^t \\tanh(u) \\, du & = \\log ( \\cosh (t) ) - \\log ( \\cosh (t_0) )\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nFigure 2.1: Plot of \\(\\cosh, \\sinh, \\tanh\\).\n\n\n\n\nExample 7: The CatenaryThe catenary is the shape of a heavy chain suspended at its ends. The chain is only subjected to gravity, see Figure 2.2. This shape looks similar to a parabola, but it is not a parabola. This was first noted by Galilei, see this Wikipedia page. The profile of the hanging chain can be obtained via a minimization problem, and one can show it is of the form \\[\n{\\pmb{\\gamma}}(t) = ( t, \\cosh(t) ) \\,, \\quad t \\in \\mathbb{R}\\,.\n\\] See Figure 2.3 for a plot of \\({\\pmb{\\gamma}}\\). Let us check if \\({\\pmb{\\gamma}}\\) is regular. We have \\[\n\\dot{{\\pmb{\\gamma}}}(t) = (1 , \\sinh(t))\n\\] so that \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}} \\right\\|^2 = 1 + {\\sinh}^2 (t) = \\cosh^2 (t)\n\\quad \\implies \\quad\n\\left\\|  \\dot{{\\pmb{\\gamma}}} \\right\\| = \\cosh (t) \\,.\n\\] Note that \\[\n\\cosh(t) \\geq 1\n\\] showing that \\({\\pmb{\\gamma}}\\) is regular. However \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(1) \\right\\| = \\cosh (1) = \\frac{e + e^{-1}}{2} \\approx 1.54 \\,,\n\\] proving that \\({\\pmb{\\gamma}}\\) is not unit speed. Let us then compute the arc length of \\({\\pmb{\\gamma}}\\) starting at \\(t_0 = 0\\) \\[\ns(t) = \\int_0^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(u)  \\right\\| \\, du =  \\int_0^t \\cosh (u) \\, du = \\sinh (t)\n\\] since \\(\\sinh(0) = 0\\). We need to invert \\(s\\). We have \\[\ns = \\sinh(t) \\quad \\iff \\quad s = \\frac{e^t - e^{-t}}{2} \\quad \\iff \\quad e^{2t} - 2s e^{t} - 1 = 0\\,,\n\\] where the last equation was obtained multuplying both sides by \\(e^t\\). Now we substitute \\[\ny = e^t\n\\] and obtain \\[\ne^{2t} - 2s e^{t} - 1 = 0 \\quad \\iff \\quad y^{2} - 2s y - 1 = 0  \\quad \\iff \\quad y = s \\pm \\sqrt{1+s^2} \\,.\n\\] Recalling that \\(y=e^t\\), we only consider the positive solution, and obtain that \\[\ne^t = s + \\sqrt{1 + s^2 } \\quad \\implies \\quad t = \\log \\left( s + \\sqrt{1 + s^2} \\right) \\,.\n\\] We have proven that the inverse of the arc length \\(s(t)\\) is \\[\n\\psi(t) := s^{-1}(t) = \\log \\left( t + \\sqrt{ 1+ t^2} \\right) \\,.\n\\] Therefore \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) := {\\pmb{\\gamma}}( \\psi(t) )\n\\] is a unit speed reparametrization of \\({\\pmb{\\gamma}}\\). Substituting \\(\\psi\\) and using the definition of \\({\\pmb{\\gamma}}\\) we have \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) = \\left(  \\log \\left( t + \\sqrt{ 1+ t^2} \\right) , \\sqrt{1 + t^2}  \\right) \\,.\n\\] We can now compute the curvature. We have: \\[\\begin{align*}\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) &  = \\left(  \\frac{1}{ \\sqrt{1 + t^2} } , \\frac{t}{ \\sqrt{1 + t^2}}   \\right) \\\\\n\\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) & = \\left( - \\frac{t}{ (1 + t^2)^{3/2} } , \\frac{1}{(1 + t^2)^{3/2} }   \\right)\n\\end{align*}\\] Moreover \\[\n\\left\\| \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\|^2 = \\frac{t^2}{(1+t^2)^3} + \\frac{1}{(1+t^2)^3} = \\frac{1}{(1+t^2)^2} \\,.\n\\] Therefore the curvature is \\[\n\\kappa (t) = \\left\\| \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\| = \\frac{1}{1+t^2} \\,.\n\\]\n\n\n\n\n\n\n\n\nFigure 2.2: The catenary is the shape of a heavy chain suspended at its ends. Image from Wikipedia.\n\n\n\n\n\n\n\n\n\nFigure 2.3: Plot of the catenary curve \\({\\pmb{\\gamma}}(t) = (t, \\cosh(t))\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#vector-product-in-mathbbr3",
    "href": "sections/chap_2.html#vector-product-in-mathbbr3",
    "title": "2  Curvature and Torsion",
    "section": "2.2 Vector product in \\(\\mathbb{R}^3\\)",
    "text": "2.2 Vector product in \\(\\mathbb{R}^3\\)\nThe discussion in this section follows (do Carmo 2017). We start by defining orientation for a vector space.\n\nDefinition 8: Same orientationConsider two ordered basis of \\(\\mathbb{R}^3\\) \\[\nB = (\\mathbf{b}_1,\\mathbf{b}_2,\\mathbf{b}_3) \\,, \\quad \\tilde{B} = (\\widetilde{\\mathbf{b}}_1,\\widetilde{\\mathbf{b}}_2,\\widetilde{\\mathbf{b}}_3) \\,.\n\\] We say that \\(B\\) and \\(\\widetilde{B}\\) have the same orientation if the matrix of change of basis has positive determinant.\n\n\nWhen two basis \\(B\\) and \\(\\widetilde{B}\\) have the same orientation, we write \\[\n\\mathbf{b}\\sim \\widetilde{\\mathbf{b}} \\,.\n\\] The above is clearly an equivalence relation on the set of ordered basis. Therefore the set of ordered basis of \\(\\mathbb{R}^3\\) can be decomposed into equivalence classes. Since the determinant of the matrix of change of basis can only be positive or negative, there are only two equivalence classes.\n\nDefinition 9: OrientationThe two equivalence classes determined by \\(\\sim\\) on the set of ordered basis are called orientations.\n\n\n\nDefinition 10: Positive orientation\nConsider the standard basis of \\(\\mathbb{R}^3\\) \\[\nE = (\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_3)\n\\] where we set \\[\n\\mathbf{e}_1 = (1,0,0)\\,, \\quad \\mathbf{e}_2 = (0,1,0) \\,, \\quad \\mathbf{e}_3 = (0,0,1) \\,.\n\\] Then:\n\nThe orientation corresponding to \\(E\\) is called positive orientation of \\(\\mathbb{R}^3\\).\nThe orientation corresponding to the other equivalence class is called negative orientation of \\(\\mathbb{R}^3\\).\n\nFor a basis \\(B\\) of \\(\\mathbb{R}^3\\) we say that:\n\n\\(B\\) is a positive basis if it belongs to the class of \\(e\\).\n\\(B\\) is a negative basis if it does not belong to the class of \\(e\\).\n\n\n\n\nExample 11Since we are dealing with ordered basis, the order in which vectors appear is fundamental. For example, we defined the equivalence class of \\[\nE = (\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_3) \\,,\n\\] to be the positive orientation of \\(\\mathbb{R}^3\\). In particular \\(e\\) is a positive basis.\nConsider instead \\[\n\\widetilde{E} = (\\mathbf{e}_2,\\mathbf{e}_1,\\mathbf{e}_3) \\,.\n\\] The matrix of change of variables between \\(\\widetilde{E}\\) and \\(E\\) is \\[\n(\\mathbf{e}_2 | \\mathbf{e}_1 | \\mathbf{e}_3 ) = \\left(\n\\begin{array}{ccc}\n0 & 1 & 0 \\\\\n1 & 0 & 0 \\\\\n0 & 0 & 1 \\\\\n\\end{array}\n\\right)\n\\] and the latter has negative determinant. Thus \\(\\widetilde{E}\\) does not belong to the class of \\(E\\), and is therefore a negative basis.\n\n\nWe are now ready to define the vector product in \\(\\mathbb{R}^3\\).\n\nDefinition 12: Vector product in \\(\\mathbb{R}^3\\)Let \\(\\mathbf{u},\\mathbf{v}\\in \\mathbb{R}^3\\). The vector product of \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) is the unique vector \\[\n\\mathbf{u}\\times \\mathbf{v}\\in \\mathbb{R}^3\n\\] which satisfies the property: \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{w}=\n\\left|\n\\begin{array}{ccc}\nu_1 & u_2 & u_3 \\\\\nv_1 & v_2 & v_3 \\\\\nw_1 & w_2 & w_3 \\\\\n\\end{array}\n\\right| \\,, \\quad \\forall \\, \\mathbf{w}\\in \\mathbb{R}^3 \\,.\n\\tag{2.5}\\] Here \\(|a_{ij}|\\) denotes the determinant of the matrix \\((a_{ij})\\), and \\[\n\\mathbf{u}= \\sum_{i=1}^3 u_i \\mathbf{e}_i \\,, \\quad\n\\mathbf{v}= \\sum_{i=1}^3 v_i \\mathbf{e}_i \\,, \\quad\n\\mathbf{w}= \\sum_{i=1}^3 w_i \\mathbf{e}_i \\,,\n\\] with \\((\\mathbf{e}_1,\\mathbf{e}_2,\\mathbf{e}_3)\\) standard basis of \\(\\mathbb{R}^3\\).\n\n\nThe following proposition gives an explicit formula for computing \\(\\mathbf{u}\\times \\mathbf{v}\\).\n\nProposition 13Let \\(\\mathbf{u},\\mathbf{v}\\in \\mathbb{R}^3\\). Then \\[\n\\mathbf{u}\\times \\mathbf{v}=\n\\left|\n\\begin{array}{cc}\nu_2 & u_3  \\\\\nv_2 & v_3\n\\end{array}\n\\right| \\mathbf{e}_1 -\n\\left|\n\\begin{array}{cc}\nu_1 & u_3  \\\\\nv_1 & v_3\n\\end{array}\n\\right| \\mathbf{e}_2 +\n\\left|\n\\begin{array}{cc}\nu_1 & u_2  \\\\\nv_1 & v_2\n\\end{array}\n\\right| \\mathbf{e}_3  \\,.\n\\tag{2.6}\\]\n\n\n\nProofDenote by \\((\\mathbf{u}\\times \\mathbf{v})_i\\) the \\(i\\)-th component of \\(\\mathbf{u}\\times \\mathbf{v}\\) with respect to the standard basis, that is, \\[\n\\mathbf{u}\\times \\mathbf{v}= \\sum_{i=1}^3  (\\mathbf{u}\\times \\mathbf{v})_i \\, \\mathbf{e}_i \\,.\n\\] We can use (2.5) with \\(\\mathbf{w}= \\mathbf{e}_1\\) to obtain \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{e}_1  =\n\\left|\n\\begin{array}{ccc}\nu_1 & u_2 & u_3 \\\\\nv_1 & v_2 & v_3 \\\\\n1  & 0   &   0 \\\\\n\\end{array}\n\\right| =\n\\left|\n\\begin{array}{cc}\nu_2 & u_3  \\\\\nv_2 & v_3\n\\end{array}\n\\right|\n\\] where we used the Laplace expansion for computing the determinant of the \\(3 \\times 3\\) matrix. As the standard basis is orthonormal, by bilinearity of the scalar product we get \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{e}_1 = \\sum_{i=1}^3  (\\mathbf{u}\\times \\mathbf{v})_i \\, \\mathbf{e}_i \\cdot \\mathbf{e}_1 = (\\mathbf{u}\\times \\mathbf{v})_i \\,.\n\\] Therefore we have shown \\[\n(\\mathbf{u}\\times \\mathbf{v})_1 = \\left|\n\\begin{array}{cc}\nu_2 & u_3  \\\\\nv_2 & v_3\n\\end{array}\n\\right| \\,.\n\\] Similarly we obtain \\[\n(\\mathbf{u}\\times \\mathbf{v})_2  = \\left|\n\\begin{array}{ccc}\nu_1 & u_2 & u_3 \\\\\nv_1 & v_2 & v_3 \\\\\n0  & 1   &   0 \\\\\n\\end{array}\n\\right| = -\n\\left|\n\\begin{array}{cc}\nu_1 & u_3  \\\\\nv_1 & v_3\n\\end{array}\n\\right|\n\\] and \\[\n(\\mathbf{u}\\times \\mathbf{v})_3  = \\left|\n\\begin{array}{ccc}\nu_1 & u_2 & u_3 \\\\\nv_1 & v_2 & v_3 \\\\\n0  & 0   &   1 \\\\\n\\end{array}\n\\right| =\n\\left|\n\\begin{array}{cc}\nu_1 & u_2  \\\\\nv_1 & v_2\n\\end{array}\n\\right| \\,,\n\\] from which we conclude.\n\n\nSometimes we will denote formula (2.6) by \\[\n\\mathbf{u}\\times \\mathbf{v}=\n\\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\nu_1 & u_2 & u_2 \\\\\nv_1 & v_2 & v_3\n\\end{array}\n\\right| \\,.\n\\]\nLet us collect some crucial properties of the vector product.\n\nProposition 14\nThe vector product in \\(\\mathbb{R}^3\\) satisfies the following properties: For all \\(\\mathbf{u}, \\mathbf{v}\\in \\mathbb{R}^3\\)\n\n\\(\\mathbf{u}\\times \\mathbf{v}= - \\mathbf{v}\\times \\mathbf{u}\\)\n\\(\\mathbf{u}\\times \\mathbf{v}= {\\pmb{0}}\\) if and only if \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are linearly dependent\n\\((\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{u}= 0\\), \\((\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{v}= 0\\)\nFor all \\(\\mathbf{w}\\in \\mathbb{R}^3\\), \\(a,b \\in \\mathbb{R}\\) \\[\n(a\\mathbf{u}+ b\\mathbf{w}) \\times \\mathbf{v}= a \\mathbf{u}\\times \\mathbf{v}+ b\\mathbf{w}\\times \\mathbf{w}\n\\]\n\n\n\nThe proof, which is based on the properties of determinants, is omitted.\n\nRemark 15: Geometric interpretation of vector product\nLet \\(\\mathbf{u}, \\mathbf{v}\\in \\mathbb{R}^3\\) be linearly independent. We make some observations:\n\nProperty 3 in Proposition 14 says that \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{u}= 0 \\,, \\quad  (\\mathbf{u}\\times \\mathbf{v}) \\cdot \\mathbf{v}= 0 \\,.\n\\] Therefore \\(\\mathbf{u}\\times \\mathbf{v}\\) is orthogonal to both \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\).\nIn particular \\(\\mathbf{u}\\times \\mathbf{v}\\) is orthogonal to the plane generated by \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\).\nSince \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\) are linearly independent, Property 2 in Proposition 14 says that \\[\n\\mathbf{u}\\times \\mathbf{v}\\neq {\\pmb{0}}\n\\]\nTherefore we have \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot (\\mathbf{u}\\times \\mathbf{v}) = \\left\\|  \\mathbf{u}\\times \\mathbf{v} \\right\\|^2 &gt; 0\n\\]\nOn the other hand, using the definition of \\(\\mathbf{u}\\times \\mathbf{v}\\) with \\(\\mathbf{w}= \\mathbf{v}\\times \\mathbf{w}\\) yields \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot (\\mathbf{u}\\times \\mathbf{v}) =\n\\left|\n\\begin{array}{ccc}\nu_1 & u_2 & u_3 \\\\\nv_1 & v_2 & v_3 \\\\\n(\\mathbf{u}\\times \\mathbf{v})_1 & (\\mathbf{u}\\times \\mathbf{v})_2 & (\\mathbf{u}\\times \\mathbf{v})_3 \\\\\n\\end{array}\n\\right|\n\\]\nTherefore the determinant of the matrix \\[\n(\\mathbf{u}| \\mathbf{v}| \\mathbf{u}\\times \\mathbf{v})\n\\] is positive. This shows that \\[\n(\\mathbf{u}, \\mathbf{v}, \\mathbf{u}\\times \\mathbf{v})\n\\] is a positive basis of \\(\\mathbb{R}^3\\).\nFor all \\(\\mathbf{u},\\mathbf{v},\\mathbf{x},\\mathbf{y}\\in \\mathbb{R}^3\\) it holds \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\cdot (\\mathbf{x}\\times \\mathbf{y}) =\n\\left|\n\\begin{array}{cc}\n\\mathbf{u}\\cdot \\mathbf{x}& \\mathbf{v}\\cdot \\mathbf{x}\\\\\n\\mathbf{u}\\cdot \\mathbf{y}& \\mathbf{v}\\cdot \\mathbf{y}\n\\end{array}\n\\right| \\,.\n\\tag{2.7}\\] Indeed, one can check that the above formula holds for the standard vectors \\(\\mathbf{e}_i\\), and thus the general formula follows by linearity.\nUsing (2.7) we get \\[\\begin{align*}\n\\left\\| \\mathbf{u}\\times \\mathbf{v} \\right\\|^2 & = (\\mathbf{u}\\times \\mathbf{v}) \\cdot (\\mathbf{u}\\times \\mathbf{v}) =\n\\left|\n\\begin{array}{cc}\n\\mathbf{u}\\cdot \\mathbf{u}& \\mathbf{v}\\cdot \\mathbf{u}\\\\\n\\mathbf{u}\\cdot \\mathbf{v}& \\mathbf{v}\\cdot \\mathbf{v}\n\\end{array}\n\\right|   \\\\\n& = \\left\\| \\mathbf{u} \\right\\|^2 \\left\\| \\mathbf{v} \\right\\|^2 - |\\mathbf{u}\\cdot \\mathbf{v}|^2 \\\\\n& = \\left\\| \\mathbf{u} \\right\\|^2 \\left\\| \\mathbf{v} \\right\\|^2 - \\left\\| \\mathbf{u} \\right\\|^2 \\left\\| \\mathbf{v} \\right\\|^2 \\cos^2(\\theta) \\\\\n& = \\left\\| \\mathbf{u} \\right\\|^2\\left\\| \\mathbf{v} \\right\\|^2 (1-\\cos^2(\\theta)) \\\\\n& = \\left\\| \\mathbf{u} \\right\\|^2\\left\\| \\mathbf{v} \\right\\|^2 \\sin^2(\\theta) \\\\\n& = A^2  \n\\end{align*}\\] where \\(A\\) is the area of the parallelogram with sides \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\).\n\n\n\n\n\n\nFor \\(\\mathbf{u},\\mathbf{v}\\) linearly independent, \\(\\mathbf{u}\\times \\mathbf{v}\\) is orthogonal to the plane generated by \\(\\mathbf{u},\\mathbf{v}\\). Moreover \\(|\\mathbf{u}\\times \\mathbf{v}|\\) is the area of the parallelogram with sides \\(\\mathbf{u},\\mathbf{v}\\), and \\((\\mathbf{u},\\mathbf{v},\\mathbf{u}\\times \\mathbf{v})\\) is a positive basis of \\(\\mathbb{R}^3\\)\n\n\nLet us summarize the above remark.\n\nRemark 16: Summary: Properties of \\(\\mathbf{u}\\times \\mathbf{v}\\)\nLet \\(\\mathbf{u},\\mathbf{v}\\in \\mathbb{R}^3\\) be linearly independent. Then\n\n\\(\\mathbf{u}\\times \\mathbf{v}\\) is orthogonal to the plane spanned by \\(\\mathbf{u},\\mathbf{v}\\)\n\\(\\left\\| \\mathbf{u}\\times \\mathbf{v} \\right\\|\\) is equal to the area of the parallelogram with sides \\(\\mathbf{u},\\mathbf{v}\\)\n\\(\\mathbf{u}\\times \\mathbf{v}\\) is such that \\[\n(\\mathbf{u},\\mathbf{v},\\mathbf{u}\\times \\mathbf{v})\n\\] is a positive basis of \\(\\mathbb{R}^3\\).\n\n\n\nWe conclude with noting that the cross product is not associative, and with a useful proposition for differentiating the cross product of curves in \\(\\mathbb{R}^3\\).\n\nProposition 17The vector product is not associative. In particular, for all \\(\\mathbf{u}, \\mathbf{v}, \\mathbf{w}\\in \\mathbb{R}^3\\) it holds: \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\times \\mathbf{w}= ( \\mathbf{u}\\cdot \\mathbf{w}) \\mathbf{v}- ( \\mathbf{v}\\cdot \\mathbf{w}) \\mathbf{u}\\,.\n\\tag{2.8}\\]\n\n\nThe proof is omitted. It follows by observing that both sides of (2.8) are linear in \\(\\mathbf{u}, \\mathbf{v}, \\mathbf{w}\\). Therefore it is sufficient to verify (2.8) for the standard basis vectors \\(\\mathbf{e}_i\\). This is left as an exercise.\n\nProposition 18Suppose \\({\\pmb{\\gamma}},{\\pmb{\\eta}}\\ \\colon (a,b) \\to \\mathbb{R}^3\\) are parametrized curves. Then the curve \\[\n{\\pmb{\\gamma}}\\times {\\pmb{\\eta}}\\ \\colon (a,b) \\to \\mathbb{R}^3\n\\] is smooth, and \\[\n\\frac{d}{dt} ( {\\pmb{\\gamma}}\\times {\\pmb{\\eta}}) = \\dot{{\\pmb{\\gamma}}}\\times {\\pmb{\\eta}}+ {\\pmb{\\gamma}}\\times \\dot{{\\pmb{\\eta}}} \\,.\n\\tag{2.9}\\]\n\n\nThe proof is omitted. It follows immediately from formula (2.6).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#curvature-formula-in-mathbbr3",
    "href": "sections/chap_2.html#curvature-formula-in-mathbbr3",
    "title": "2  Curvature and Torsion",
    "section": "2.3 Curvature formula in \\(\\mathbb{R}^3\\)",
    "text": "2.3 Curvature formula in \\(\\mathbb{R}^3\\)\nGiven a unit speed curve \\[\n{\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^n\n\\] we defined its curvature as \\[\n\\kappa(t) = \\left\\|  \\ddot{{\\pmb{\\gamma}}}(t)  \\right\\| \\,.\n\\] If \\({\\pmb{\\gamma}}\\) is not unit speed then the curvature is not defined. However, when \\({\\pmb{\\gamma}}\\) is regular, then we can find a unit-speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) of \\({\\pmb{\\gamma}}\\), and compute \\(\\kappa\\) as \\[\n\\kappa(t) = \\left\\|  \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t)  \\right\\| \\,.\n\\] If \\({\\pmb{\\gamma}}\\) is a regular curve in \\(\\mathbb{R}^3\\), there is a way to compute \\(\\kappa\\) without passing through \\(\\widetilde{{\\pmb{\\gamma}}}\\). The formula for computing \\(\\kappa\\) is as follows.\n\nProposition 19: Curvature formulaLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a regular curve. The curvature \\(\\kappa(t)\\) of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\kappa(t) = \\frac{ \\left\\| \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| }{ \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^3 } \\,.\n\\tag{2.10}\\]\n\n\nWe delay the proof of the above Proposition, as this will get easier when the Frenet frame is introduced. For a proof which does not make use of the Frenet frame, see the proof of Proposition 2.1.2 in (Pressley 2010).\nFor now we use (2.10) the above proposition to compute the curvature on specific curves.\n\nExample 20Consider the straight line \\[\n{\\pmb{\\gamma}}(t) = \\mathbf{a} + t \\mathbf{v}\n\\] for some \\(\\mathbf{a}, \\mathbf{v} \\in \\mathbb{R}^3\\) fixed, with \\(\\mathbf{v} \\neq {\\pmb{0}}\\). Then \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\mathbf{v} \\,, \\quad \\ddot{{\\pmb{\\gamma}}}(t) = {\\pmb{0}}\\,.\n\\] Therefore \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| = \\left\\| \\mathbf{v} \\right\\| \\neq 0\n\\] showing that \\({\\pmb{\\gamma}}\\) is regular. We have \\[\n\\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}= \\mathbf{v} \\times {\\pmb{0}}= {\\pmb{0}}\\,.\n\\] Therefore the curvature is \\[\n\\kappa = \\frac{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| }{ \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^3 } = 0 \\,,\n\\] as expected.\n\n\n\nExample 21\nConsider the Helix of radius \\(R&gt;0\\) and rise \\(H&gt;0\\) \\[\n{\\pmb{\\gamma}}(t) = ( R\\cos(t) , R\\sin(t) , Ht) \\,, \\quad t \\in \\mathbb{R}\\,.\n\\] Then \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}(t) & = ( -R\\sin(t) , R\\cos(t) , H)  \\\\\n\\ddot{{\\pmb{\\gamma}}}(t) & = ( -R\\cos(t) , -R\\sin(t) , 0)\n\\end{align*}\\] From this we deduce that \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|  = \\sqrt{R^2 + H^2}\\,,\n\\] showing that \\({\\pmb{\\gamma}}\\) is regular. Finally \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}& =\n\\left|\n\\begin{array}{cc}\n{\\dot\\gamma}_2 & {\\dot\\gamma}_3  \\\\\n{\\ddot\\gamma}_2 & {\\ddot\\gamma}_3\n\\end{array}\n\\right| \\mathbf{e}_1 -\n\\left|\n\\begin{array}{cc}\n{\\dot\\gamma}_1 & {\\dot\\gamma}_3  \\\\\n{\\ddot\\gamma}_1 & {\\ddot\\gamma}_3\n\\end{array}\n\\right| \\mathbf{e}_2 +\n\\left|\n\\begin{array}{cc}\n{\\dot\\gamma}_1 & {\\dot\\gamma}_2  \\\\\n{\\ddot\\gamma}_1 & {\\ddot\\gamma}_2\n\\end{array}\n\\right| \\mathbf{e}_3 \\\\\n& =\n\\left|\n\\begin{array}{cc}\nR\\cos(t) & H \\\\\n-R\\sin(t) & 0\n\\end{array}\n\\right| \\mathbf{e}_1 -\n\\left|\n\\begin{array}{cc}\n-R\\sin(t) & H \\\\\n-R\\cos(t) & 0\n\\end{array}\n\\right| \\mathbf{e}_2 +\n\\left|\n\\begin{array}{cc}\n-R\\sin(t) & R\\cos(t) \\\\\n-R\\cos(t) & -R\\sin(t)  \n\\end{array}\n\\right| \\mathbf{e}_3 \\\\\n& =\n\\left(   \nRH\\sin(t),    \n-RH\\cos(t),\nR^2\\cos^2(t) + R^2\\sin^2(t)\n\\right) \\\\\n& =\n\\left(   \nRH\\sin(t),    \n-RH\\cos(t),\nR^2\n\\right)\n\\end{align*}\\] and therefore \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| =  R\\sqrt{R^2 + H^2   } \\,.\n\\] By the general formula we have \\[\n\\kappa = \\frac{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| }{ \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^3 } =\n\\frac{ R (R^2 + H^2)^{\\frac12} }{  (R^2 + H^2)^{\\frac32}    } =\n\\frac{ R }{  R^2 + H^2   }\n\\]\nWe notice the following:\n\nIf \\(H=0\\) then the Helix is just a circle of radius \\(R\\). In this case the curvature is \\[\n\\kappa  = \\frac{1}{R}\n\\] which agrees with the curvature computed for the circle of radius \\(R\\).\nIf \\(R=0\\) then the Helix is just parametrizing the \\(z\\)-axis. In this case the curvature is \\[\n\\kappa  = 0 \\,,\n\\] which agrees with the curvature of a straight line.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#signed-curvature-of-plane-curves",
    "href": "sections/chap_2.html#signed-curvature-of-plane-curves",
    "title": "2  Curvature and Torsion",
    "section": "2.4 Signed curvature of plane curves",
    "text": "2.4 Signed curvature of plane curves\nIn this section we assume to have plane curves, that is, curves with values in \\(\\mathbb{R}^2\\). In this case we can give a geometric interpretation for the sign of the curvature. This cannot be done in higher dimension.\n\nDefinition 22Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^2\\) be unit speed. We define the signed unit normal to \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) as the unit vector \\(\\mathbf{n}(t)\\) obtained by rotating \\(\\dot{{\\pmb{\\gamma}}}(t)\\) anti-clockwise by an angle of \\(\\pi/2\\).\n\n\n\nDefinition 23Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^2\\) be unit speed. The signed curvature of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is the scalar \\(\\kappa_s(t)\\) such that \\[\n\\ddot{{\\pmb{\\gamma}}}(t) = k_s(t) \\mathbf{n}(t)\n\\]\n\n\n\nRemark 24Notice that since \\(\\mathbf{n}\\) is a unit vector and \\({\\pmb{\\gamma}}\\) is unit speed, then \\[\n|\\kappa_s(t)| = \\left\\| \\ddot{{\\pmb{\\gamma}}}(t) \\right\\| = \\kappa(t) \\,.\n\\] Thus the signed curvature is related to the curvature by \\[\n\\kappa_s(t) = \\pm \\kappa(t) \\,.\n\\]\n\n\n\nRemark 25It can be shown that the signed curvature is the rate at which the tangent vector \\(\\dot{{\\pmb{\\gamma}}}\\) of the curve \\({\\pmb{\\gamma}}\\) rotates. The signed curvature is:\n\npositive if \\(\\dot{{\\pmb{\\gamma}}}\\) is rotating anti-clockwise\nnegative if \\(\\dot{{\\pmb{\\gamma}}}\\) is rotating clockwise\n\nIn other words,\n\n\\(k_s &gt; 0\\) means the curve is turning left,\n\\(k_s &lt; 0\\) means the curve is turning right.\n\nA rigorous justification of the above statement is found in Proposition 2.2.3 in (Pressley 2010).\n\n\nFor curves which are not unit speed, we define the signed curvature as the signed curvature of the unit speed reparametrization.\n\nDefinition 26Let \\({\\pmb{\\gamma}}\\ \\colon (a,b) \\to \\mathbb{R}^2\\) be regular and let \\(\\widetilde{{\\pmb{\\gamma}}}\\) be a unit speed reparametrization of \\({\\pmb{\\gamma}}\\). The signed curvature of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is the scalar \\(\\kappa_s(t)\\) such that \\[\n\\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) = k_s(t) \\mathbf{n}(t) \\,,\n\\] where \\(\\mathbf{n}(t)\\) is the unit vector obtained by rotating \\(\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t)\\) anti-clockwise by an angle \\(\\pi/2\\).\n\n\nThe signed curvature completely characterizes plane curves, in the sense of the following theorem.\n\nTheorem 27: Characterization of plane curves\nLet \\(\\phi\\ \\colon \\mathbb{R}\\to \\mathbb{R}\\) be smooth. Then:\n\nThere exists a unit speed curve \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^2\\) such that its signed curvature \\(\\kappa_s\\) satisfies \\[\n\\kappa_s(t) = \\phi(t) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\]\nSuppose that \\(\\widetilde{{\\pmb{\\gamma}}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^2\\) is a unit speed curve such that its signed curvature \\(\\tilde{\\kappa}_s\\) satisfies \\[\n\\tilde{\\kappa}_s(t) = \\phi(t) \\,, \\quad \\forall \\, t \\in \\mathbb{R}\\,.\n\\] Then \\[\n\\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\n\\] up to rotations and translations.\n\n\n\nWe do not prove the above theorem. For a proof, see Theorem 2.2.6 in (Pressley 2010).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#space-curves",
    "href": "sections/chap_2.html#space-curves",
    "title": "2  Curvature and Torsion",
    "section": "2.5 Space curves",
    "text": "2.5 Space curves\nIn this section we deal with space curves, that is, curves with values in \\(\\mathbb{R}^3\\). There are several issues compare to the plane case:\n\nA 3D counterpart of the signed curvature does not exist, since there is no notion of turning left or turning right.\nWe have seen in the previous section that the signed curvature completely characterizes plane curves. In 3D however curvature is not enough to characterize curves: there exist \\({\\pmb{\\gamma}}\\) and \\({\\pmb{\\eta}}\\) space curves such that \\[\n\\kappa^{{\\pmb{\\gamma}}} = \\kappa^{{\\pmb{\\eta}}} \\,, \\quad  {\\pmb{\\gamma}}\\neq {\\pmb{\\eta}}\\,,\n\\] that is, \\({\\pmb{\\gamma}}\\) and \\({\\pmb{\\eta}}\\) have same curvature but are different curves.\n\n\nExample 28Let \\({\\pmb{\\gamma}}\\) be a circle of radius \\(R&gt;0\\) \\[\n{\\pmb{\\gamma}}(t) = (R\\cos(t),R\\sin(t),0) \\,,\n\\] and \\({\\pmb{\\eta}}\\) be a helix of radius \\(S&gt;0\\) and rise \\(H&gt;0\\) \\[\n{\\pmb{\\eta}}(t) = (S\\cos(t),S\\sin(t),Ht) \\,.\n\\] We have computed that \\[\n\\kappa^{\\pmb{\\gamma}}= \\frac{1}{R}\\,, \\quad\n\\kappa^{\\pmb{\\eta}}= \\frac{S}{S^2 + H^2} \\,.\n\\] If we now choose \\(R=2\\) and we impose that \\(\\kappa^{\\pmb{\\gamma}}= \\kappa^{\\pmb{\\eta}}\\) we get \\[\n\\frac1R = \\frac{S}{S^2 + H^2} \\quad \\implies \\quad  H^2 = 2S - S^2\n\\] Therefore choosing \\(S=1\\) and \\(H=1\\) yields \\[\n\\kappa^{\\pmb{\\gamma}}= \\kappa^{\\pmb{\\eta}}\\,, \\quad   {\\pmb{\\gamma}}\\neq {\\pmb{\\eta}}\\,..\n\\]\n\n\nTherefore curvature is not enough for characterizing space curves, and we need a new quantity. As we did with curvature, we start by considering the simpler case of unit speed curves. We will also need to assume that the curvature is never zero.\n\nDefinition 29: Principal normal vectorLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve with \\[\n\\kappa(t) \\neq 0 \\,, \\quad \\forall \\,t \\in (a,b) \\,.\n\\] The principal normal vector to \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is \\[\n\\mathbf{n}(t) := \\frac{1}{\\kappa (t)} \\, \\ddot{{\\pmb{\\gamma}}}(t) \\,.\n\\]\n\n\n\nRemark 30\nSince for \\({\\pmb{\\gamma}}\\) unit speed we defined \\[\n\\kappa (t) := \\left\\|  \\ddot{{\\pmb{\\gamma}}}(t)  \\right\\| \\,,\n\\] we have that \\[\n\\left\\|  \\mathbf{n}(t)  \\right\\| = 1 \\,,\n\\] thus \\(\\mathbf{n}\\) is a unit vector. Moreover \\(\\mathbf{n}\\) is orthogonal to \\(\\dot{{\\pmb{\\gamma}}}\\), that is, \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{n}= 0 \\,.\n\\]\n\nThis is because \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{n}= \\frac{1}{\\kappa} \\, \\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0 \\,,\n\\] where the last equality follows from \\(\\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0\\), being \\({\\pmb{\\gamma}}\\) unit speed.\n\n\n\n\n\n\nPrincipal normal vector \\(\\mathbf{n}(t)\\) to \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\).\n\n\n\nQuestion 31Why is the principal normal interesting? Because it can tell the difference beween a plane curve and a space curve. See picture below.\n\n\n\n\n\nLeft: Principal normal to a circle. Note that \\(\\mathbf{n}\\) always points towards the origin \\({\\pmb{0}}\\). Right: Principal normal to a helix. Note that \\(\\mathbf{n}\\) points towards the \\(z\\)-axis, but never towards the same point.\n\n\n\nDefinition 32: Binormal vectorLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve with \\[\n\\kappa(t) \\neq 0 \\,, \\quad \\forall \\,t \\in (a,b) \\,.\n\\] The binormal vector to \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is \\[\n\\mathbf{b}(t) := \\dot{{\\pmb{\\gamma}}}(t) \\times \\mathbf{n}(t) \\,.\n\\]\n\n\n\nDefinition 33: Orthonormal basisLet \\(\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3\\) be vectors in \\(\\mathbb{R}^3\\). We say that the triple \\[\n\\{\\mathbf{v}_1, \\mathbf{v}_2,\\mathbf{v}_3\\}\n\\] is orthonormal if \\[\n\\left\\| v_i \\right\\| = 1 \\,, \\quad   v_i \\cdot v_j = 0 \\,, \\,\\, \\mbox{ for } \\, i \\neq j \\,.\n\\]\n\n\n\nProposition 34Let \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve with \\[\n\\kappa(t) \\neq 0 \\,, \\quad \\forall \\,t \\in (a,b) \\,.\n\\] Then the triple \\[\nB = (  \\dot{{\\pmb{\\gamma}}}(t), \\mathbf{n}(t), \\mathbf{b}(t)  )\n\\] is a positive orthonormal basis of \\(\\mathbb{R}^3\\) for all \\(t \\in (a,b)\\).\n\n\n\nProofSince \\({\\pmb{\\gamma}}\\) is unit speed we have \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\equiv 1 \\,.\n\\] Moreover we have already observed that \\[\n\\left\\| \\mathbf{n}(t) \\right\\| \\equiv 1 \\,, \\quad \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{n}(t) \\equiv 0 \\,.\n\\] As \\(\\mathbf{b}\\) is defined by \\[\n\\mathbf{b}:= \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}\\,,\n\\] by the properties of the vector product, see Proposition 14, it follows that \\[\n\\mathbf{b}\\cdot \\dot{{\\pmb{\\gamma}}}= 0 \\,, \\quad  \\mathbf{b}\\cdot \\mathbf{n}= 0  \\,.\n\\] By the calculation in Remark 15 Point 8, we have that \\[\n\\left\\|  \\mathbf{b} \\right\\|^2 = \\| \\dot{{\\pmb{\\gamma}}}\\|^2 \\|\\mathbf{n}\\|^2 -   |\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{n}|^2 = 1   \\,.\n\\] This shows that the vectors \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b}\\}\n\\] are orthonormal. By the properties of the vector product, see Remark 15 Point 6, we also know that \\[\n( \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b})\n\\] is a positive basis of \\(\\mathbb{R}^3\\).\n\n\n\nProposition 35Let \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve with \\(\\kappa \\neq 0\\). Then \\[\n\\mathbf{b}= \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}\\,, \\quad\n\\mathbf{n}= \\mathbf{b}\\times \\dot{{\\pmb{\\gamma}}}\\,, \\quad\n\\dot{{\\pmb{\\gamma}}}= \\mathbf{n}\\times \\mathbf{b}\\,.\n\\tag{2.11}\\]\n\n\n\nProofThe first equality in (2.11) is true by definition of \\(\\mathbf{b}\\). For the other \\(2\\) equalities, recall formula (2.8): \\[\n(\\mathbf{u}\\times \\mathbf{v}) \\times \\mathbf{w}= ( \\mathbf{u}\\cdot \\mathbf{w}) \\mathbf{v}- ( \\mathbf{v}\\cdot \\mathbf{w}) \\mathbf{u}\\,,\n\\tag{2.12}\\] for all \\(\\mathbf{u},\\mathbf{v},\\mathbf{w}\\in \\mathbb{R}^3\\). Applying the above with \\[\n\\mathbf{u}= \\dot{{\\pmb{\\gamma}}}\\,, \\quad \\mathbf{v}= \\mathbf{n}\\,, \\quad \\mathbf{w}= \\dot{{\\pmb{\\gamma}}}\\,,\n\\] yields \\[\\begin{align*}\n( \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) \\times \\dot{{\\pmb{\\gamma}}}& = ( \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}) \\mathbf{n}- (\\mathbf{n}\\cdot \\dot{{\\pmb{\\gamma}}}) \\dot{{\\pmb{\\gamma}}}\\\\\n                                      & = \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^2 \\mathbf{n}- 0 \\\\\n                                      & = \\mathbf{n}\\,,\n\\end{align*}\\] where we used that \\(\\dot{{\\pmb{\\gamma}}}\\) is a unit vector and \\(\\mathbf{n}\\cdot \\dot{{\\pmb{\\gamma}}}= 0\\). Therefore, by definition of \\(\\mathbf{b}\\), we have \\[\n\\mathbf{b}\\times \\dot{{\\pmb{\\gamma}}}= ( \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) \\times \\dot{{\\pmb{\\gamma}}}= \\mathbf{n}\n\\] showing the second equality in (2.11). For showing the third equality in (2.11), we apply (2.12) with \\[\n\\mathbf{u}= \\dot{{\\pmb{\\gamma}}}\\,, \\quad \\mathbf{v}= \\mathbf{n}\\,, \\quad \\mathbf{w}= \\mathbf{n}\\,,\n\\] to get \\[\\begin{align*}\n( \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) \\times \\mathbf{n}& = ( \\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{n}) \\mathbf{n}- (\\mathbf{n}\\cdot \\mathbf{n}) \\dot{{\\pmb{\\gamma}}}\\\\\n                                      & = 0 - \\left\\| \\mathbf{n} \\right\\|^2 \\dot{{\\pmb{\\gamma}}}\\\\\n                                      & = - \\dot{{\\pmb{\\gamma}}}\n\\end{align*}\\] where we used that \\(\\mathbf{n}\\) is a unit vector and \\(\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{n}= 0\\). Therefore, by definition of \\(\\mathbf{b}\\) and anti-commutativity of the vector product, we have \\[\n\\mathbf{n}\\times \\mathbf{b}= - \\mathbf{b}\\times \\mathbf{n}= - (\\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) \\times \\mathbf{n}= \\dot{{\\pmb{\\gamma}}}\\,,\n\\] showing the last equality in (2.11).\n\n\n\nProposition 36Let \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve with \\(\\kappa \\neq 0\\). Then \\[\n\\dot{\\mathbf{b}} (t) = - \\tau(t) \\mathbf{n}(t) \\,,\n\\tag{2.13}\\] for some \\(\\tau(t) \\in \\mathbb{R}\\).\n\n\n\nProofBy definition of \\(\\mathbf{b}\\) and the formula of derivation of the cross product (2.9) we have \\[\\begin{align*}\n\\dot{\\mathbf{b}} & = \\frac{d}{dt} ( \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) \\\\\n          & = \\ddot{{\\pmb{\\gamma}}}\\times \\mathbf{n}+ \\dot{{\\pmb{\\gamma}}}\\times \\dot{\\mathbf{n}} \\\\\n          & =  \\dot{{\\pmb{\\gamma}}}\\times \\dot{\\mathbf{n}} \\,,\n\\end{align*}\\] where we used that \\[\n\\ddot{{\\pmb{\\gamma}}}\\times \\mathbf{n}= 0\\,,\n\\] since \\(\\mathbf{n}\\) is defined by \\(\\mathbf{n}:=  \\ddot{{\\pmb{\\gamma}}}/\\kappa\\), and therefore \\(\\mathbf{n}\\) and \\(\\ddot{{\\pmb{\\gamma}}}\\) are parallel. Hence, we have proven that \\[\n\\dot{\\mathbf{b}} = \\dot{{\\pmb{\\gamma}}}\\times \\dot{\\mathbf{n}} \\,.\n\\tag{2.14}\\] By the properties of the cross product we have that \\(\\mathbf{u}\\times \\mathbf{v}\\) is orthogonal to both \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). Thus (2.14) implies that \\[\n\\dot{\\mathbf{b}} \\cdot \\dot{{\\pmb{\\gamma}}}= 0 \\,.\n\\] Further, observe that \\[\n\\frac{d}{dt}( \\mathbf{b}\\cdot \\mathbf{b}) = \\dot{\\mathbf{b}} \\cdot \\mathbf{b}+ \\mathbf{b}\\cdot \\dot{\\mathbf{b}} = 2\\dot{\\mathbf{b}} \\cdot \\mathbf{b}\\,.\n\\] On the other hand, since \\(\\mathbf{b}\\) is a unit vector, we have \\[\n\\frac{d}{dt}( \\mathbf{b}\\cdot \\mathbf{b}) = \\frac{d}{dt}( \\left\\| \\mathbf{b} \\right\\|^2 ) = \\frac{d}{dt}( 1 ) = 0 \\,  \n\\] Therefore \\[\n\\dot{\\mathbf{b}} \\cdot \\mathbf{b}= 0 \\,.\n\\] To summarize, we have shown that \\(\\dot{\\mathbf{b}}\\) is orthogonal to \\(\\mathbf{b}\\) and \\(\\dot{{\\pmb{\\gamma}}}\\). Since \\[\n( \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b})\n\\] is an orthonormal basis of \\(\\mathbb{R}^3\\) we conclude that \\(\\dot{\\mathbf{b}}\\) is parallel to \\(\\mathbf{n}\\). Therefore there exists \\(\\tau(t) \\in \\mathbb{R}\\) such that \\[\n\\dot{\\mathbf{b}} = - \\tau(t) \\mathbf{n}(t) \\,,\n\\] concluding the proof.\n\n\nThe scalar \\(\\tau\\) in equation (2.13) is called the torsion of \\({\\pmb{\\gamma}}\\).\n\nDefinition 37: Torsion of unit speed curveLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve, with \\(\\kappa \\neq 0\\). The torsion of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is the unique scalar \\[\n\\tau (t) \\in \\mathbb{R}\n\\] such that \\[\n\\dot{\\mathbf{b}} (t) = - \\tau(t) \\mathbf{n}(t) \\,.\n\\]\n\n\n\nRemark 38\nIn particular the torsion satisfies: \\[\n\\tau(t) = - \\dot{\\mathbf{b}} (t) \\cdot \\mathbf{n}(t) \\,.\n\\]\n\nThe above can be immediately obtained by multiplying (2.13) by \\(\\mathbf{n}\\). Indeed, \\[\n\\dot{\\mathbf{b}} = - \\tau \\mathbf{n}\\quad \\implies \\quad\n\\dot{\\mathbf{b}} \\cdot \\mathbf{n}= - \\tau \\mathbf{n}\\cdot \\mathbf{n}= - \\tau \\,,\n\\] since \\(\\mathbf{n}\\) is a unit vector.\n\n\n\n\nWarningWe defined the torsion only for space curves \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) which are unit speed and have non-vanishing curvature, that is, such that \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| = 1 \\,, \\quad \\kappa(t) = \\left\\|  \\ddot{{\\pmb{\\gamma}}}(t)  \\right\\|  \\neq 0 \\,,\n\\] for all \\(t \\in (a,b)\\).\n\n\nWe can extend the definition of torsion to regular curves \\({\\pmb{\\gamma}}\\) with non-vanishing curvature. In this case the torsion of \\({\\pmb{\\gamma}}\\) is defined as the torsion of a unit speed reparametrization of \\({\\pmb{\\gamma}}\\).\n\nDefinition 39Let \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a regular curve with non-vanishing curvature. Let \\(\\widetilde{{\\pmb{\\gamma}}}\\) be a unit speed reparametrization of \\({\\pmb{\\gamma}}\\), with \\[\n{\\pmb{\\gamma}}= \\widetilde{{\\pmb{\\gamma}}}\\circ \\phi \\,,  \\quad \\phi\\colon  (a,b) \\to (\\tilde{a},\\tilde{b})  \\,.\n\\] We define the torsion of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) as \\[\n\\tau^{\\pmb{\\gamma}}(t) := \\tau^{\\widetilde{{\\pmb{\\gamma}}}} ( \\phi(t) ) \\,,\n\\] where \\({\\tau}^{\\widetilde{{\\pmb{\\gamma}}}}(s)\\) denotes the torsion of \\(\\widetilde{{\\pmb{\\gamma}}}\\) at \\(\\widetilde{{\\pmb{\\gamma}}}(s)\\).\n\n\nAs usual, it is possible to check that the above definition of torsion does not depend on the choice of unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\). As with curvature, there is a general formula to compute the torsion without having to reparametrize.\n\nProposition 40: Torsion formulaLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a regular curve with non-vanishing curvature. The torsion \\(\\tau(t)\\) of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\tau (t) = \\frac{ ( \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}) \\cdot \\dddot{{\\pmb{\\gamma}}}}{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\|^2 } \\,.\n\\]\n\n\nWe delay the proof of the above proposition for a bit. In the meantime, let us look at examples.\n\nExample 41: Torsion HelixConsider the Helix of radius \\(R&gt;0\\) and rise \\(H&gt;0\\) \\[\n{\\pmb{\\gamma}}(t) = ( R\\cos(t) , R\\sin(t) , Ht) \\,, \\quad t \\in \\mathbb{R}\\,.\n\\] We have already shown that \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|  = \\sqrt{R^2 + H^2}\\,,  \\quad  \\kappa = \\frac{R}{R^2 + H^2} \\,.\n\\] Therefore the Helix is regular with non-vanishing curvature. The torsion can be then computed via the formula \\[\n\\tau (t) = \\frac{ ( \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}) \\cdot \\dddot{{\\pmb{\\gamma}}}}{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\|^2 } \\,.\n\\] Let us compute the quantities appearing in the formula for \\(\\tau\\) \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}(t) & = ( -R\\sin(t) , R\\cos(t) , H)  \\\\\n\\ddot{{\\pmb{\\gamma}}}(t) & = ( -R\\cos(t) , -R\\sin(t) , 0) \\\\\n\\dddot{{\\pmb{\\gamma}}}(t) & = ( R\\sin(t) , -R\\cos(t) , 0)\n\\end{align*}\\] Moreover we had already computed that \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}& = \\left( RH\\sin(t), -RH\\cos(t), R^2 \\right)  \\\\\n\\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| & =  R\\sqrt{R^2 + H^2   } \\,.\n\\end{align*}\\] Finally we compute \\[\n(\\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}) \\cdot \\dddot{{\\pmb{\\gamma}}}= R^2 H \\,.\n\\] We are ready to find the torsion: \\[\n\\tau = \\frac{ ( \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}) \\cdot \\dddot{{\\pmb{\\gamma}}}}{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\|^2 }\n       = \\frac{ H }{ R^2 + H^2 } \\,.\n\\]\n\n\n\nExample 42: Curvature and Torsion of CircleThe Circle of radius \\(R&gt;0\\) is \\[\n{\\pmb{\\gamma}}(t) := ( R \\cos(t), R \\sin(t) , 0 ) \\,.\n\\] The curvature and torsion of the Helix of radius \\(R\\) and rise \\(H&gt;0\\) are \\[\n\\kappa = \\frac{R}{R^2 + H^2}\\,, \\quad \\tau = \\frac{H}{R^2 + H^2}  \\,.\n\\] For \\(H=0\\) the Helix coincides with the Circle \\({\\pmb{\\gamma}}\\). Therefore we can set \\(H=0\\) in the above formulas to obtain the curvature and torsion of the Circle \\[\n\\kappa = \\frac{1}{R}\\,, \\quad \\tau = 0  \\,.\n\\]\n\n\nFrom the above example we notice that the torsion of the circle is \\(0\\). This is true in general for space curves which are contained in a plane: we will prove this result in general. For the moment, let us give an example for which this happens, that is, an example of space curve \\({\\pmb{\\gamma}}\\) which is contained in a plane.\n\nExample 43Define the space curve \\[\n{\\pmb{\\gamma}}(t) := \\left( \\frac45 \\cos(t),  1 - \\sin(t) , -\\frac35 \\cos(t)  \\right) \\,,\n\\] for \\(t \\in \\mathbb{R}\\). As seen in the plot below, \\({\\pmb{\\gamma}}\\) is just a Circle which has been rotated an translated. Therefore \\({\\pmb{\\gamma}}\\) is contained in a plane, and we expect curvature and torsion to be \\[\n\\kappa = \\frac1R , \\quad \\tau = 0\\,,\n\\] for some \\(R&gt;0\\), radius of the Circle \\({\\pmb{\\gamma}}\\). Let us proceed with the calculations: \\[\n\\dot{{\\pmb{\\gamma}}}=   \\left( -\\frac45 \\sin(t),  - \\cos(t) , \\frac35 \\sin(t)  \\right)\n\\] so that \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}} \\right\\|^2 = \\frac{16}{25} \\sin^2(t) + \\cos^2(t) + \\frac{9}{25} \\sin^2(t) = 1\\,,\n\\] showing that \\({\\pmb{\\gamma}}\\) is regular and unit speed. Further \\[\n\\ddot{{\\pmb{\\gamma}}}=  \\left( -\\frac45 \\cos(t),  \\sin(t) , \\frac35 \\cos(t)  \\right) \\,.\n\\] As \\({\\pmb{\\gamma}}\\) is unit speed, we have \\[\n\\kappa = \\left\\|  \\ddot {\\pmb{\\gamma}} \\right\\| = \\frac{16}{25} \\cos^2(t) + \\sin^2(t) + \\frac{9}{25} \\cos^2(t) = 1 \\,.\n\\] As \\({\\pmb{\\gamma}}\\) is unit speed, the normal vector is \\[\n\\mathbf{n}= \\frac{1}{\\kappa}  \\ddot{{\\pmb{\\gamma}}}=  \\left( -\\frac45 \\cos(t),  \\sin(t) , \\frac35 \\cos(t)  \\right) \\,.\n\\] We can then compute the binormal \\[\\begin{align*}\n\\mathbf{b}& = \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}\\\\\n    & =\n    \\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n-\\frac{4}{5} \\sin (t)  & - \\cos(t) & \\frac35 \\sin(t) \\\\\n-\\frac45 \\cos(t) &  \\sin(t) & \\frac35 \\cos(t)\n\\end{array} \\right| \\\\\n    & = \\left(  -\\frac35 \\cos^2(t) - \\frac35 \\sin^2(t), - \\frac{12}{25} \\cos(t) \\sin(t) + \\frac{12}{25} \\cos(t) \\sin(t), - \\frac45 \\sin^2(t) - \\frac45 \\cos^2(t)   \\right) \\\\\n    & = \\left( -\\frac35, 0 ,-\\frac45  \\right) \\,.\n\\end{align*}\\] Therefore \\[\n\\dot{\\mathbf{b}} = 0\\,,\n\\] and we obtain that the torsion is \\[\n\\tau = - \\dot{\\mathbf{b}} \\cdot \\mathbf{n}= 0 \\,.\n\\]\n\n\n\n\n\n\n\nPlot of the curve in example above",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#frenet-frame",
    "href": "sections/chap_2.html#frenet-frame",
    "title": "2  Curvature and Torsion",
    "section": "2.6 Frenet frame",
    "text": "2.6 Frenet frame\nFor a unit speed curve \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) with non-vanishing curvature we computed the triple \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b}\\} \\,.\n\\] We saw that the above is a positive orthonormal basis of \\(\\mathbb{R}^3\\). We also used this triple to compute curvature \\(\\kappa\\) and torsion \\(\\tau\\) of \\({\\pmb{\\gamma}}\\): \\[\n\\kappa = \\left\\|  \\ddot{{\\pmb{\\gamma}}} \\right\\| \\,, \\quad \\tau = - \\dot{\\mathbf{b}} \\cdot \\mathbf{n}\\,.\n\\] This triple is so important that it has a name.\n\nDefinition 44: Frenet frameLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be unit speed with \\(\\kappa \\neq 0\\). The positive orthonormal basis \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b}\\}\n\\] is called Frenet frame of \\({\\pmb{\\gamma}}\\).\n\n\nWe can also define the Frenet frame for regular curves with non-vanishing curvature.\n\nDefinition 45Let \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be regular with \\(\\kappa \\neq 0\\). The Frenet frame of \\({\\pmb{\\gamma}}\\) is defined as the Frenet frame of a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) of \\({\\pmb{\\gamma}}\\).\n\n\n\nRemark 46\nWe should check that the above definition is well-posed:\n\nNote that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed. Moreover the curvature of \\({\\kappa}^{\\widetilde{{\\pmb{\\gamma}}}}\\) is given by \\[\n{\\kappa}^{\\widetilde{{\\pmb{\\gamma}}}} (t) = {\\kappa}^{{\\pmb{\\gamma}}} (\\phi(t))\n\\] for some \\(\\phi\\) diffeomorphism. Therefore \\({\\kappa}^{\\widetilde{{\\pmb{\\gamma}}}} \\neq 0\\) as we are assuming \\({\\kappa}^{{\\pmb{\\gamma}}} \\neq 0\\). Therefore the Frenet-Frame of \\(\\widetilde{{\\pmb{\\gamma}}}\\) is well defined.\nIf \\(\\hat{{\\pmb{\\gamma}}}\\) is another unit speed reparametrization of \\({\\pmb{\\gamma}}\\), then the Frenet frame generated by \\(\\hat{{\\pmb{\\gamma}}}\\) coincides with the one generated by \\(\\widetilde{{\\pmb{\\gamma}}}\\). The proof is left as an exercise.\n\n\n\nFrom the Frenet frame we can define the Frenet-Serret equations.\n\nTheorem 47: Frenet-Serret equationsLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be unit speed with \\(\\kappa \\neq 0\\). The Frenet-Serret equations are \\[\\begin{align*}  \n\\ddot{{\\pmb{\\gamma}}}& = \\kappa \\mathbf{n}\\\\\n\\dot{\\mathbf{n}} & = - \\kappa \\dot{{\\pmb{\\gamma}}}+ \\tau \\mathbf{b}\\\\\n\\dot{\\mathbf{b}} & = -\\tau \\mathbf{n}\n\\end{align*}\\]\n\n\n\nProofThe first Frenet-Serret equation \\[\n\\ddot{{\\pmb{\\gamma}}}= \\kappa \\mathbf{n}\n\\tag{2.15}\\] holds by definition of \\(\\mathbf{n}\\) and \\(\\kappa\\). The third Frenet-Serret equation \\[\n\\dot{\\mathbf{b}} = - \\tau \\mathbf{n}\n\\tag{2.16}\\] holds by Proposition 36. Now, recall that in Proposition 35 we have proven \\[\n\\mathbf{b}= \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}\\,, \\quad\n\\mathbf{n}= \\mathbf{b}\\times \\dot{{\\pmb{\\gamma}}}\\,, \\quad\n\\dot{{\\pmb{\\gamma}}}= \\mathbf{n}\\times \\mathbf{b}\\,.\n\\tag{2.17}\\] Differentiating the second equation in (2.17) and using (2.15)-(2.16) we get \\[\\begin{align*}\n\\dot{\\mathbf{n}} & = \\dot{\\mathbf{b}} \\times \\dot{{\\pmb{\\gamma}}}+ \\mathbf{b}\\times \\ddot{{\\pmb{\\gamma}}}& \\\\\n          & = ( - \\tau \\mathbf{n}\\times \\dot{{\\pmb{\\gamma}}}) + \\mathbf{b}\\times \\kappa \\mathbf{n}\\\\\n          & = \\tau ( \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}) - \\kappa (\\mathbf{n}\\times \\mathbf{b}) \\\\\n          & = \\tau \\mathbf{b}- \\kappa \\dot{{\\pmb{\\gamma}}}\\,,\n\\end{align*}\\] where in the last equality we used the first and third equations in (2.17). The above is exactly the second Frenet-Serret equation.\n\n\n\nRemark 48We can write the Frenet-Serret ODE sysyem in vectorial form. To this end, introduce the matrix \\[\nF : =\n\\left(\n\\begin{array}{ccc}\n0 & \\kappa & 0 \\\\\n- \\kappa & 0 & \\tau \\\\\n0 & \\tau & 0\n\\end{array}\n\\right) \\,.\n\\] It is immediate to check that the Frenet-Serret equations are equivalent to \\[\n\\left(\n\\begin{array}{c}\n\\ddot{{\\pmb{\\gamma}}}\\\\\n\\dot{\\mathbf{n}} \\\\\n\\dot{\\mathbf{b}}\n\\end{array}\n\\right)\n=\nF\n\\left(\n\\begin{array}{c}\n\\dot{{\\pmb{\\gamma}}}\\\\\n\\mathbf{n}\\\\\n\\mathbf{b}\n\\end{array}\n\\right)  \\,.\n\\]\n\n\n\nImportant: SummaryRecall that:\n\nCurvature \\(\\kappa\\) is defined only for regular curves.\nTorsion \\(\\tau\\) is defined only for regular curves with non-vanishing \\(\\kappa\\).\n\nThe two strategies for computing \\(\\kappa\\) and \\(\\tau\\) are discussed in the diagram in Figure 2.4 below.\n\n\n\n\n\n\n\n\nFigure 2.4: Summary for computing \\(\\kappa\\) and \\(\\tau\\) for regular curve \\({\\pmb{\\gamma}}\\).\n\n\n\nLet us conclude the section with an example. We compute the Frenet frame of the helix. As a consequence we obtain curvature and torsion.\n\nExample 49: Frenet frame of helixConsider the helix of radius \\(1\\) and rise \\(1\\) given by \\[\n{\\pmb{\\gamma}}(t) = ( \\cos(t), \\sin(t),t )\\,,\n\\] for \\(t \\in \\mathbb{R}\\). We now proceed following the diagram at Figure 2.4. We ask the first question: \\[\n\\mbox{Is ${\\pmb{\\gamma}}$ unit speed?}\n\\] We have that \\[\n\\dot{{\\pmb{\\gamma}}}(t) = ( -\\sin(t), \\cos(t), 1 )    \\,,\n\\] and therefore \\[\n\\left\\|  \\dot{{\\pmb{\\gamma}}} \\right\\| = \\sqrt{2} \\,.\n\\] This shows that \\({\\pmb{\\gamma}}\\) is regular but not unit speed. We ask the second question in the diagram: \\[\n\\mbox{Can we find a unit speed reparametrization of ${\\pmb{\\gamma}}$?}\n\\] Let us try. We compute the arc length of \\({\\pmb{\\gamma}}\\) starting at \\(t_0 = 0\\) \\[\ns(t) := \\int_0^t \\left\\|  \\dot{{\\pmb{\\gamma}}}(u)  \\right\\| \\, du = \\sqrt{2} \\, t \\,.  \n\\] The arc length is invertible with \\[\n\\psi(t) := s^{-1}(t) = \\frac{t}{\\sqrt{2}} \\,.\n\\] Therefore a unit speed reparametrization of \\({\\pmb{\\gamma}}\\) is given by \\[\n\\widetilde{{\\pmb{\\gamma}}}(t):={\\pmb{\\gamma}}( \\psi(t)) = \\left(  \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , \\frac{t}{\\sqrt{2}}    \\right) \\,.\n\\] The next step in the diagram is \\[\n\\mbox{Compute Frenet frame $\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{n}, \\mathbf{b}\\}$ and curvature $\\kappa$, torsion $\\tau$}\n\\] We compute \\[\\begin{align*}\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) & = \\frac{1}{\\sqrt{2}} \\left(  -\\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , 1    \\right) \\\\\n\\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) & = \\frac12 \\left(  -\\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , -\\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , 0    \\right)\n\\end{align*}\\] Therefore the curvature is \\[\n\\kappa (t) = \\left\\|  \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t)  \\right\\| = \\frac12 \\,.\n\\] From the curvature we obtain the principal normal vector \\[\n\\mathbf{n}(t) = \\frac{1}{\\kappa(t)} \\, \\ddot{\\widetilde{{\\pmb{\\gamma}}}}(t) =  \\left(  -\\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , -\\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , 0    \\right) \\,.\n\\] We can now compute the binormal \\[\\begin{align*}\n\\mathbf{b}(t) & = \\dot{\\widetilde{{\\pmb{\\gamma}}}}\\times \\mathbf{n}\\\\\n    & = \\frac{1}{\\sqrt{2}}\n    \\left|\n    \\begin{array}{ccc}\n    \\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n    - \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right)  & \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) & 1 \\\\\n    - \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) & - \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) & 0\n    \\end{array}\n    \\right| \\\\\n    & =  \\frac{1}{\\sqrt{2}} \\left(  \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , - \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , 1   \\right) \\,.\n\\end{align*}\\] We have therefore computed the Frenet frame of \\({\\pmb{\\gamma}}\\). This is given by \\[\\begin{align*}\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) & = \\frac{1}{\\sqrt{2}}  \\left( -\\sin\\left( \\frac{t}{\\sqrt{2}}  \\right) , \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , 1   \\right) \\\\\n\\mathbf{n}(t) & =  \\left(  -\\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , -\\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , 0    \\right) \\\\\n\\mathbf{b}(t) & = \\frac{1}{\\sqrt{2}} \\left(  \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , - \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , 1   \\right) \\,.\n\\end{align*}\\] See below for a picture of the Frenet frame of the helix. Given the Frenet frame, we can compute the torsion via the formula \\[\n\\tau (t) = - \\dot{\\mathbf{b}} \\cdot \\mathbf{n}\\,.\n\\] Indeed, we have \\[\n\\dot{\\mathbf{b}} = \\frac12 \\left(  \\cos \\left( \\frac{t}{\\sqrt{2}}  \\right) , - \\sin \\left( \\frac{t}{\\sqrt{2}}  \\right) , 0   \\right)\n\\] and therefore \\[\n\\dot{\\mathbf{b}} \\cdot \\mathbf{n}= \\frac12 \\left( - \\cos^2 \\left( \\frac{t}{\\sqrt{2}}  \\right) - \\sin^2 \\left( \\frac{t}{\\sqrt{2}}  \\right) \\right) = - \\frac12 \\,.\n\\] The torsion is then \\[\n\\tau (t) = - \\dot{\\mathbf{b}} \\cdot \\mathbf{n}= \\frac12 \\,.\n\\] The Frenet-Frame of the unit-speed Helix is plotted in Figure 2.5.\n\n\n\n\n\n\n\n\n\n\nFigure 2.5: Frenet frame of the helix of radius 1 and rise 1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_2.html#consequences-of-frenet-serret",
    "href": "sections/chap_2.html#consequences-of-frenet-serret",
    "title": "2  Curvature and Torsion",
    "section": "2.7 Consequences of Frenet-Serret",
    "text": "2.7 Consequences of Frenet-Serret\nThe most important consequence of the Frenet-Serret equations is that they allow to fully characterize space curves in terms of curvature and torsion. Precisely, the following theorem holds.\n\nTheorem 50: Characterization of space curves\nLet \\(\\kappa, \\tau \\ \\colon \\mathbb{R}\\to \\mathbb{R}\\) be smooth functions, with \\(\\kappa&gt;0\\). Then:\n\nThere exists aunit speed curve \\({\\pmb{\\gamma}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^3\\) such that its curvature \\(\\kappa^{{\\pmb{\\gamma}}}\\) and torsion \\(\\tau^{{\\pmb{\\gamma}}}\\) satisfy \\[\n\\kappa^{{\\pmb{\\gamma}}}(t) = \\kappa(t) \\,, \\quad\n\\tau^{{\\pmb{\\gamma}}}(t) = \\tau(t) \\,,\n  \\,\\, \\forall \\, t \\in \\mathbb{R}\\,.\n\\]\nSuppose that \\(\\widetilde{{\\pmb{\\gamma}}}\\ \\colon \\mathbb{R}\\to \\mathbb{R}^3\\) is a unit speed curve such that its curvature \\(\\tilde{\\kappa}^{\\widetilde{{\\pmb{\\gamma}}}}\\) and torsion \\(\\tau^{\\widetilde{{\\pmb{\\gamma}}}}\\) satisfy \\[\n\\kappa^{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\kappa(t) \\,, \\quad\n\\tau^{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\tau(t)\n  \\,,\\,\\, \\forall \\, t \\in \\mathbb{R}\\,.\n\\] Then \\[\n\\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\n\\] up to rotations and translations.\n\n\n\nThe proof of Theorem 50 is omitted, and it can be found in Theorem 2.3.6 in (Pressley 2010).\nTheorem 50 is a very strong result. It is saying two things:\n\nIf we prescribe curvature and torsion, then there exists a unit speed curve which has such curvature and torsion.\nIf two unit speed curves have same curvature and torsion, then they must be the same curve, up to translations and rotations.\n\nIn other words, curvature and torsion fully characterize space curves. This result is the 3D counterpart of Theorem 27, which said that signed curvature characterizes 2D curves.\n\nExample 51In Example 43 we have considered the unit speed curve \\[\n{\\pmb{\\gamma}}(t) := \\left( \\frac45 \\cos(t),  1 - \\sin(t) , -\\frac35 \\cos(t)  \\right) \\,,\n\\] for \\(t \\in [0,2\\pi]\\). We have computed that \\[\n\\kappa^{{\\pmb{\\gamma}}} = 1 \\,, \\quad \\tau^{{\\pmb{\\gamma}}} = 0 \\,.\n\\] If we plot \\({\\pmb{\\gamma}}\\), we clearly see that \\({\\pmb{\\gamma}}\\) is just obtained by translating and rotating a unit circle, see plot below. Theorem 50 enables us to rigorously prove this claim. Indeed, consider the unit speed circle \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) := \\left( \\cos(t), \\sin(t) , 0  \\right) \\,,\n\\] for \\(t \\in [0,2\\pi]\\). In Example 42 we have proven that curvature and torsion are\n\\[\n\\kappa^{\\widetilde{{\\pmb{\\gamma}}}} = 1 \\,, \\quad \\tau^{\\widetilde{{\\pmb{\\gamma}}}} = 1 \\,.\n\\] Therefore \\[\n\\kappa^{{\\pmb{\\gamma}}} = \\kappa^{\\widetilde{{\\pmb{\\gamma}}}} \\,, \\quad \\tau^{{\\pmb{\\gamma}}} = \\tau^{\\widetilde{{\\pmb{\\gamma}}}}  \\,,\n\\] and by Theorem 50 we conclude that \\({\\pmb{\\gamma}}\\) is equal to \\(\\widetilde{{\\pmb{\\gamma}}}\\) up to rotations and translations.\n\n\n\n\n\n\n\nPlot of the curve in example above\n\n\n\n\nAnother consequence of the Frenet-Serret equations is that they allow us to finally prove the curvature and torsion formulas given in Proposition 19 and Proposition 40. For reader’s convenience we recall these two results.\n\nProposition 52: Curvature and torsion formulasLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a regular curve. The curvature \\(\\kappa(t)\\) of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\kappa(t) = \\frac{ \\left\\| \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\| }{ \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^3 } \\,.\n\\] Suppose in addition that \\({\\pmb{\\gamma}}\\) has non-vanishing curvature. The torsion \\(\\tau(t)\\) of \\({\\pmb{\\gamma}}\\) at \\({\\pmb{\\gamma}}(t)\\) is given by \\[\n\\tau (t) = \\frac{ ( \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}}) \\cdot \\dddot{{\\pmb{\\gamma}}}}{ \\left\\|  \\dot{{\\pmb{\\gamma}}}\\times \\ddot{{\\pmb{\\gamma}}} \\right\\|^2 } \\,.\n\\]\n\n\nBefore proceeding with the proof, we need to establish some notation.\n\nNotation: Compact notation for arc length reparametrization\nSuppose \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\) is regular and denote by \\[\ns \\colon (a,b) \\to (\\tilde{a},\\tilde{b})\\,, \\quad t \\mapsto s(t)  \n\\] its arc length. We already know that in this case \\(s\\) invertible, with inverse \\(s^{-1}\\) giving a unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\colon (\\tilde{a},\\tilde{b}) \\to \\mathbb{R}^n\\) of \\({\\pmb{\\gamma}}\\), defined by \\[\n\\widetilde{{\\pmb{\\gamma}}}= {\\pmb{\\gamma}}\\circ \\psi \\,, \\quad \\psi:=s^{-1} \\colon (\\tilde{a},\\tilde{b}) \\to (a,b)\n\\] Sometimes it is more convenient to adopt more compact notation. In the new notation the unit speed reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) is denoted by \\({\\pmb{\\gamma}}(s)\\): \\[\nt \\mapsto \\widetilde{{\\pmb{\\gamma}}}(t) \\qquad \\leadsto \\qquad s \\mapsto {\\pmb{\\gamma}}(s) \\,.\n\\] Thus, the reparametrization is denoted with the same symbol \\({\\pmb{\\gamma}}\\), but this time \\({\\pmb{\\gamma}}\\) is considered as a function of the arc length parameter \\[\ns \\in (\\tilde{a}, \\tilde{b}) \\,.\n\\] We will denote:\n\nThe derivative of \\(s\\) by \\[\n\\frac{ds}{dt}\n\\]\nThe derivative of \\(\\psi = s^{-1}\\) by \\[\n\\frac{dt}{ds} \\,.\n\\]\n\nMoreover:\n\nThe derivative of \\({\\pmb{\\gamma}}(t)\\) is denoted by \\[\n\\frac{d{\\pmb{\\gamma}}}{dt}(t) = \\dot{{\\pmb{\\gamma}}}(t) \\,, \\quad  t \\in (a,b)\n\\]\nThe derivative of \\({\\pmb{\\gamma}}(s)\\) is denoted by \\[\n\\frac{d{\\pmb{\\gamma}}}{ds}(s) = \\dot{{\\pmb{\\gamma}}}(s) \\,, \\quad  s \\in (\\tilde{a},\\tilde{b}) \\,.\n\\]\n\nWe also have new notations for the chain rule:\n\nThe chain rule for \\({\\pmb{\\gamma}}\\) is the old notations is: \\[\n{\\pmb{\\gamma}}(t) = \\widetilde{{\\pmb{\\gamma}}}(s(t)) \\quad  \\implies \\quad \\dot{{\\pmb{\\gamma}}}(t) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(s(t)) \\, \\dot{s} (t) \\,, \\quad t \\in (a,b) \\,.\n\\] In the new notations the above chain rule is written \\[\n\\frac{d{\\pmb{\\gamma}}}{dt}(t) = \\frac{d{\\pmb{\\gamma}}}{ds}(s(t)) \\, \\frac{ds}{dt}(t) \\,, \\quad t \\in (a,b) \\,.\n\\] We will often omit the dependence on the point \\(t\\) by writing \\[\n\\frac{d{\\pmb{\\gamma}}}{ds} = \\frac{d{\\pmb{\\gamma}}}{dt} \\, \\frac{dt}{ds} \\,.\n\\]\nThe chain rule for the reparametrization \\(\\widetilde{{\\pmb{\\gamma}}}\\) in the old notation is: \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) = {\\pmb{\\gamma}}( \\psi (t)) \\quad \\implies \\quad \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\dot{{\\pmb{\\gamma}}}( \\psi(t) ) \\, \\dot{\\psi}(t) \\,, \\quad\nt \\in (\\tilde{a},\\tilde{b}) \\,.\n\\] In the new notations the above chain rule is written \\[\n\\frac{d{\\pmb{\\gamma}}}{ds}(s) = \\frac{d{\\pmb{\\gamma}}}{dt}( \\psi(s) )  \\, \\frac{dt}{ds} ( s ) \\,,\\quad s \\in (\\tilde{a},\\tilde{b}) \\,,\n\\] since \\(\\dot \\psi\\) is written \\(dt/ds\\) in the new notations. Without dependence on the point \\(s\\), the above reads \\[\n\\frac{d{\\pmb{\\gamma}}}{ds} = \\frac{d{\\pmb{\\gamma}}}{dt} \\, \\frac{dt}{ds}  \\,.\n\\]\n\n\n\n\nExample 53: How to use the new notationsLet \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) be as above. We know that \\(\\widetilde{{\\pmb{\\gamma}}}\\) is unit speed. Thus \\({\\pmb{\\gamma}}(s)\\) is unit speed with respect to \\(s\\), that is, \\[\n\\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| = 1\\,, \\quad \\forall \\, s \\in (\\tilde{a}, \\tilde{b})  \\,.\n\\tag{2.18}\\] As an exercise, let us check that (2.18) holds, using the new notations. By chain rule we have \\[\\begin{align*}\n\\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| & = \\left\\|  \\frac{d{\\pmb{\\gamma}}}{ds} (s)  \\right\\| \\\\\n              & = \\left\\| \\frac{d{\\pmb{\\gamma}}}{dt} (\\psi(s)) \\right\\| \\, \\left| \\frac{dt}{ds}(s) \\right| \\\\\n              & = \\left\\| \\dot{{\\pmb{\\gamma}}}(\\psi(s)) \\right\\| \\, \\left| \\frac{dt}{ds}(s) \\right| \\,.\n\\end{align*}\\] Now, recall that \\[\n\\frac{ds}{dt}(t) = \\dot{s}(t) = \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\tag{2.19}\\] According to the new notations and the inverse function theorem, \\[\n\\frac{dt}{ds}(s) = \\frac{1}{\\left(\\dfrac{ds}{dt} (\\psi(s)) \\right)} =\n\\frac{1}{\\left\\| \\dot{{\\pmb{\\gamma}}}(\\psi(s)) \\right\\|} \\,, \\quad \\forall \\, s \\in (\\tilde{a},\\tilde{b}) \\,,\n\\] where we used (2.19) evaluated at \\(t = \\psi(s)\\). Thus \\[\\begin{align*}\n\\left\\| \\dot{{\\pmb{\\gamma}}}(s) \\right\\| & = \\left\\| \\dot{{\\pmb{\\gamma}}}(\\psi(s)) \\right\\| \\, \\left| \\frac{dt}{ds}(s) \\right|  \\\\\n              & = \\left\\| \\dot{{\\pmb{\\gamma}}}(\\psi(s)) \\right\\| \\, \\frac{1}{\\left\\| \\dot{{\\pmb{\\gamma}}}(\\psi(s)) \\right\\| }  \\\\\n              & = 1 \\,,\n\\end{align*}\\] concluding (2.18).\n\n\nLet us highlight the main feature of the above notation.\n\nImportant: New Notation!\nLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\) be a regular curve:\n\nWe denote by \\[\nt \\mapsto {\\pmb{\\gamma}}(t)  \\,, \\quad t \\in (a,b)\n\\] the given curve \\({\\pmb{\\gamma}}\\).\nWe denote by \\[\ns \\mapsto {\\pmb{\\gamma}}(s)  \\,, \\quad s \\in (\\tilde{a},\\tilde{b})\n\\] the arc length reparametrization of the curve \\({\\pmb{\\gamma}}\\). The parameter \\(s\\) is the arc length parameter. In particular \\({\\pmb{\\gamma}}(s)\\) is unit speed with respect to \\(s\\).\n\n\n\nWe will heavily rely on the new notations for proving Proposition 52.\n\nProof: Proof of Proposition 52We only prove the formula for \\(\\kappa\\), as the one for \\(\\tau\\) can be obtained similarly, just with more calculations. For a proof see Proposition 2.3.1 in (Pressley 2010).\nSince \\({\\pmb{\\gamma}}\\) is regular, we can reparametrize \\({\\pmb{\\gamma}}\\) by arc length \\(s(t)\\). We denote the arc lenght reparametrization by \\({\\pmb{\\gamma}}(s)\\). We know that \\({\\pmb{\\gamma}}(s)\\) is unit speed, that is, \\[\n\\left\\|   \\frac{d{\\pmb{\\gamma}}}{ds}   \\right\\| = 1 \\,.\n\\] Therefore is well define the Frenet frame \\[\n\\{\\mathbf{t}(s), \\mathbf{n}(s), \\mathbf{b}(s) \\}  \\,, \\quad \\mathbf{t}(s):=\\dot{{\\pmb{\\gamma}}}(s) = \\frac{d {\\pmb{\\gamma}}}{ds} (s)\\,.\n\\] The Frenet-Serret equations are \\[\\begin{align*}\n\\dot{\\mathbf{t}}(s) & = \\kappa(s) \\mathbf{n}(s) \\\\\n\\dot{\\mathbf{n}}(s) & = -\\kappa(s) \\mathbf{t}(s) + \\tau(s) \\mathbf{b}(s) \\\\\n\\dot{\\mathbf{b}}(s) & = - \\tau(s) \\mathbf{n}(s)\n\\end{align*}\\] By chain rule \\[\n\\frac{d {\\pmb{\\gamma}}}{dt} = \\frac{d{\\pmb{\\gamma}}}{ds} \\, \\frac{ds}{dt} =\\left( \\frac{ds}{dt} \\right) \\, \\mathbf{t}\\,.\n\\] Differentiating the above we infer \\[\\begin{align*}\n\\frac{d^2 {\\pmb{\\gamma}}}{dt^2} & = \\frac{d}{dt} \\left[ \\left( \\frac{ds}{dt} \\right) \\, \\mathbf{t}\\right] \\\\\n                    & = \\frac{d^2 s}{dt^2} \\, \\mathbf{t}+  \\left( \\frac{ds}{dt} \\right) \\, \\frac{d\\mathbf{t}}{dt}  \\,. \\\\\n\\end{align*}\\] By chain rule we have \\[\n\\frac{d\\mathbf{t}}{dt}  =  \\frac{d\\mathbf{t}}{ds} \\, \\frac{dt}{ds} \\,,\n\\] and therefore \\[\\begin{align*}\n\\frac{d^2 {\\pmb{\\gamma}}}{dt^2} & = \\frac{d^2 s}{dt^2} \\, \\mathbf{t}+  \\left( \\frac{ds}{dt} \\right) \\, \\frac{d\\mathbf{t}}{dt}  \\\\\n   & = \\frac{d^2 s}{dt^2} \\, \\mathbf{t}+  \\left( \\frac{ds}{dt} \\right)^2 \\, \\frac{d\\mathbf{t}}{ds} \\,.\n\\end{align*}\\] Hence \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}(t) \\times \\ddot{{\\pmb{\\gamma}}}(t) & = \\frac{d {\\pmb{\\gamma}}}{dt} \\times  \\frac{d^2 {\\pmb{\\gamma}}}{dt^2}  \\\\\n& =   \\left(\\frac{ds}{dt} \\right) \\mathbf{t}\\times  \\left[  \\frac{d^2 s}{dt^2} \\, \\mathbf{t}+  \\left( \\frac{ds}{dt} \\right)^2 \\, \\frac{d\\mathbf{t}}{ds}  \\right] \\\\\n& =  \\left[ \\left(\\frac{ds}{dt} \\right) \\left(\\frac{d^2s}{dt^2} \\right)  \\mathbf{t}\\times \\mathbf{t}\\right] +\n     \\left[ \\left( \\frac{ds}{dt} \\right)^3  \\,\\, \\mathbf{t}\\times \\frac{d\\mathbf{t}}{ds} \\right] \\\\\n& =  \\left( \\frac{ds}{dt} \\right)^3  \\,\\, \\mathbf{t}\\times \\frac{d\\mathbf{t}}{ds} \\,,\n\\end{align*}\\] since \\(\\mathbf{t}\\times \\mathbf{t}= 0\\) by the properties of the cross product. Now we recall that \\[\n\\frac{d\\mathbf{t}}{ds} = \\kappa(s) \\, \\mathbf{n}(s)\n\\] by the first Frenet-Serret equation. Moreover \\[\n\\frac{ds}{dt}(t) = \\left\\|   \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^2 \\,.\n\\] Therefore \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}(t) \\times \\ddot{{\\pmb{\\gamma}}}(t) & = \\left( \\frac{ds}{dt} \\right)^3  \\,\\, \\mathbf{t}\\times \\frac{d\\mathbf{t}}{ds} \\\\\n                       & = \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^3 \\, \\kappa(s(t)) \\,\\, \\mathbf{t}\\times \\mathbf{n}\\\\\n                       & = \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^3 \\, \\kappa(s(t)) \\,\\, \\mathbf{b}\\,,\n\\end{align*}\\] where in the last line we used the definition of \\(\\mathbf{b}\\) \\[\n\\mathbf{b}(s) = \\dot{{\\pmb{\\gamma}}}(s) \\times \\mathbf{n}(s) = \\mathbf{t}(s) \\times \\mathbf{n}(s) \\,.\n\\] We can now take the norms and obtain \\[\\begin{align*}\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\times \\ddot{{\\pmb{\\gamma}}}(t) \\right\\| & = \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^3 \\, \\kappa(s(t)) \\,  \\left\\| \\mathbf{b} \\right\\| \\\\\n                              & = \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^3 \\, \\kappa(s(t))\n\\end{align*}\\] using that \\(\\left\\| \\mathbf{b} \\right\\| = 1\\). As \\({\\pmb{\\gamma}}\\) is regular, we can divide by \\(\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^3\\) and obtain \\[\n\\kappa(s (t)) = \\frac{\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\times \\ddot{{\\pmb{\\gamma}}}(t) \\right\\|}{\\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\|^3} \\,.\n\\] Recalling that the curvature of \\({\\pmb{\\gamma}}\\) at \\(t\\) is defined as the curvature of \\({\\pmb{\\gamma}}(s)\\) at \\(s(t)\\), we conclude that the above is the desired formula.\n\n\nWe now state and prove two more results which directly follow from the Frenet-Serret equations. They state, respectivley:\n\nA curve has torsion \\(\\tau = 0\\) if and only if it is contained in a plane.\nA curve has constant curvature and zero torsion if and only if it is part of a circle.\n\nBefore proceeding, we recall the following.\n\nRemark 54: Equation of a planeThe general equation of a plane \\(\\pmb{\\pi}_d\\) in \\(\\mathbb{R}^3\\) is given by\n\\[\n\\pmb{\\pi}_d = \\{ \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\,  \\mathbf{x}\\cdot \\mathbf{P} = d \\}\\,,\n\\] for some vector \\(\\mathbf{P} \\in \\mathbb{R}^3\\) and scalar \\(d \\in \\mathbb{R}\\). Note that:\n\nIf \\(d = 0\\), the condition \\[\n\\mathbf{x}\\cdot \\mathbf{P} = 0\n\\] is saying that the plane \\(\\pmb{\\pi}_0\\) contains all the points \\(\\mathbf{x}\\) in \\(\\mathbb{R}^3\\) which are orthogonal to \\(\\mathbf{P}\\). In particular \\(\\pmb{\\pi}_0\\) contains the origin \\({\\pmb{0}}\\).\nIf \\(d \\neq 0\\), then \\(\\pmb{\\pi}_d\\) is the translation of \\(\\pmb{\\pi}_0\\) by the quantity \\(d\\) in direction \\(\\mathbf{P}\\).\n\nIn both cases, \\(\\mathbf{P}\\) is the normal vector to the plane, as shown in Figure 2.6 below.\n\n\n\n\n\n\n\n\nFigure 2.6: The plane \\(\\pmb{\\pi}_0\\) is the set of points of \\(\\mathbb{R}^3\\) orthogonal to \\(\\mathbf{P}\\). The plane \\(\\pmb{\\pi}_d\\) is obtained by translating \\(\\pmb{\\pi}_0\\) by a quantity \\(d\\) in direction \\(\\mathbf{P}\\).\n\n\n\n\nProposition 55\nLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be regular and such that \\(\\kappa \\neq 0\\). They are equivalent:\n\nThe torsion of \\({\\pmb{\\gamma}}\\) satisfies \\(\\tau(t) = 0\\) for all \\(t \\in (a,b)\\).\nThe image of \\({\\pmb{\\gamma}}\\) is contained in a plane, that is, there exists a vector \\(\\mathbf{P} \\in \\mathbb{R}^3\\) and a scalar \\(d \\in \\mathbb{R}\\) such that \\[\n{\\pmb{\\gamma}}(t)\\cdot \\mathbf{P} = d \\,, \\quad \\forall t \\in (a,b) \\,.\n\\]\n\n\n\n\nProofWithout loss of generality we can assume that \\({\\pmb{\\gamma}}\\) is unit speed. Indeed, if we were to consider \\(\\widetilde{{\\pmb{\\gamma}}}\\) a unit speed reparametrization of \\({\\pmb{\\gamma}}\\), then\n\n\\(\\widetilde{{\\pmb{\\gamma}}}\\) would still be contained in the same plane in which \\({\\pmb{\\gamma}}\\) is contained.\nThe torsion of \\(\\widetilde{{\\pmb{\\gamma}}}\\) would not change, i.e., it would still be identically zero.\n\nThefore the Frenet frame of \\({\\pmb{\\gamma}}\\) exists. We denote it by \\[\n\\{ \\dot{{\\pmb{\\gamma}}}(t), \\mathbf{n}(t) ,\\mathbf{b}(t) \\} \\,.\n\\]\nStep 1. Suppose that \\(\\tau = 0\\) for all \\(t\\). By the Frenet-Serret equations we have \\[\n\\dot{\\mathbf{b}} = -\\tau(t) \\mathbf{n}= {\\pmb{0}}\\,,\n\\] so that \\(\\mathbf{b}(t)\\) is constant. As by definition \\[\n\\mathbf{b}= \\dot{{\\pmb{\\gamma}}}\\times \\mathbf{n}\\,,\n\\] we conclude that the vectors \\(\\dot{{\\pmb{\\gamma}}}(t)\\) and \\(\\mathbf{n}(t)\\) always span the same plane, which has constant normal vector \\(\\mathbf{b}\\). Intuition suggests that \\({\\pmb{\\gamma}}\\) should be contained in such plane, see Figure Figure 2.7 below. Indeed, recall that the Frenet frame is orthonormal. Hence \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{b}= 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] Then \\[\n\\frac{d}{dt} ( {\\pmb{\\gamma}}\\cdot \\mathbf{b}) = \\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{b}+ {\\pmb{\\gamma}}\\cdot \\dot{\\mathbf{b}} = 0\\,,  \\quad \\forall \\, t \\in (a,b) \\,,\n\\] since \\(\\dot{\\mathbf{b}}=0\\). Thus \\({\\pmb{\\gamma}}\\cdot \\mathbf{b}\\) is a constant scalar function, meaning that there exists costant \\(d \\in \\mathbb{R}\\) such that \\[\n{\\pmb{\\gamma}}(t) \\cdot \\mathbf{b}= d \\,, \\,\\, \\forall \\, t \\in (a,b) \\,.\n\\] The says that \\({\\pmb{\\gamma}}\\) is contained in a plane.\nStep 2. Suppose that \\({\\pmb{\\gamma}}\\) is contained in a plane. Hence there exists \\(\\mathbf{P} \\in \\mathbb{R}^3\\) and \\(d \\in \\mathbb{R}\\) such that \\[\n{\\pmb{\\gamma}}(t)\\cdot \\mathbf{P} = d \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] We can differentiate the above equation twice to obtain \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{P} = 0 \\,, \\quad   \\ddot{{\\pmb{\\gamma}}}\\cdot \\mathbf{P} = 0 \\,,\n\\] where we used that \\(\\mathbf{P}\\) and \\(d\\) are constant. By Frenet-Serret we have \\[\n\\ddot{{\\pmb{\\gamma}}}(t)= \\kappa (t) \\mathbf{n}(t) \\,.\n\\] Therefore the already proven relation \\(\\ddot{{\\pmb{\\gamma}}}\\cdot \\mathbf{P} = 0\\) implies \\[\n\\kappa (t) \\mathbf{n}(t) \\cdot \\mathbf{P} = 0 \\,.\n\\] As we are assuming \\(\\kappa \\neq 0\\), we deduce that \\[\n\\mathbf{n}(t) \\cdot \\mathbf{P} = 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] We have shown that \\(\\dot{{\\pmb{\\gamma}}}(t)\\) and \\(\\mathbf{n}(t)\\) are both orthogonal to \\(\\mathbf{P}\\). Since \\(\\mathbf{b}(t)\\) is orthogonal to \\(\\dot{{\\pmb{\\gamma}}}(t)\\) and \\(\\mathbf{n}(t)\\), we conclude that \\(\\mathbf{b}(t)\\) is parallel to \\(\\mathbf{P}\\). Hence, there exists \\(\\lambda(t) \\in \\mathbb{R}\\) such that \\[\n\\mathbf{b}(t) = \\lambda(t) \\mathbf{P} \\,\\forall \\, t \\in (a,b) \\,.\n\\tag{2.20}\\] Since \\(\\left\\| \\mathbf{b} \\right\\| = 1\\) and \\(\\mathbf{P}\\) is constant, from (2.20) we conclude that \\(\\lambda(t)\\) is constant. Differentiating (2.20) we obtain \\[\n\\dot{\\mathbf{b}}(t) = 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] By definition of torsion we thus have \\[\n\\tau(t) = - \\dot{\\mathbf{b}} \\cdot \\mathbf{n}(t) = 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\]\n\n\n\n\n\n\n\n\nFigure 2.7: If \\(\\mathbf{b}\\) is constant, then \\({\\pmb{\\gamma}}\\) lies in the plane spanned by \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{n}\\).\n\n\n\n\nProposition 56\nLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a unit speed curve. They are equivalent:\n\nThe image of \\({\\pmb{\\gamma}}\\) is contained in a circle of radius \\(1/c\\).\nThe curvature and torsion of \\({\\pmb{\\gamma}}\\) satisfy \\[\n\\kappa (t) = c \\,, \\quad  \\tau(t) = 0\\,,  \\quad \\forall \\, t \\in (a,b)\\,,\n\\] for some constant \\(c \\in \\mathbb{R}\\).\n\n\n\nProposition 56 is actually a consequence of Theorem 50, and of the fact that we have computed that for a circle of radius \\(R\\) one has \\[\n\\kappa  = \\frac1R \\,, \\quad  \\tau = 0\\,.\n\\] Therefore, by Theorem 50, every unit speed curve \\({\\pmb{\\gamma}}\\) with constant curvature and torsion must be equal to a circle, up to rigid motions.\nNevertheless, we still give a proof of Proposition 56, to show yet another application of the Frenet-Serret equations.\n\nProofStep 1. Suppose the image of \\({\\pmb{\\gamma}}\\) is contained in a circle of radius \\(1/c\\). Then, up to a translation, \\({\\pmb{\\gamma}}\\) is parametrized by \\[\n{\\pmb{\\gamma}}(t) = \\left( \\frac{1}{c} \\cos(t) ,   \\frac{1}{c} \\sin(t) , 0 \\right)\n\\] for \\(t\\) in some interval \\((\\tilde{a},\\tilde{b})\\). We have already seen that in this case \\[\n\\kappa = c  \\,, \\quad \\tau = 0 \\,,\n\\] concluding the proof.\nStep 2. Suppose that \\[\n\\kappa (t) = c \\,, \\quad  \\tau(t) = 0\\,,  \\quad \\forall \\, t \\in (a,b)\\,,\n\\] for some constant \\(c \\in \\mathbb{R}\\). Since \\({\\pmb{\\gamma}}\\) is unit speed, its Frenet-Serret equations are: \\[\\begin{align*}\n\\ddot{{\\pmb{\\gamma}}}& = \\kappa \\mathbf{n}= c \\mathbf{n}\\\\\n\\dot{\\mathbf{n}} & = - \\kappa \\dot{{\\pmb{\\gamma}}}+ \\tau \\mathbf{b}= -c \\dot{{\\pmb{\\gamma}}}\\\\\n\\dot{\\mathbf{b}} & = -\\tau \\mathbf{n}= 0  \n\\end{align*}\\] In particular \\(\\dot{\\mathbf{b}}=0\\) and so \\(\\mathbf{b}\\) is a constant vector. As seen in the proof Proposition 55, this implies that \\({\\pmb{\\gamma}}\\) is contained in a plane \\({\\pmb{\\pi}}\\) orthogonal to \\(\\mathbf{b}\\), see Figure 2.7. As \\(c\\) is constant we get \\[\n\\frac{d}{dt} \\left(  {\\pmb{\\gamma}}+ \\frac1c \\mathbf{n}\\right)  = \\dot{{\\pmb{\\gamma}}}+ \\frac{1}{c} \\dot{\\mathbf{n}} = \\dot{{\\pmb{\\gamma}}}- \\frac1c\n\\, c \\dot{{\\pmb{\\gamma}}}= 0 \\,,\n\\] where we used the second Frenet-Serret equation. Therefore \\[\n{\\pmb{\\gamma}}(t)  + \\frac1c \\mathbf{n}(t) = \\mathbf{p}\\,, \\quad  t \\in (a,b) \\,,\n\\] for some constant point \\(\\mathbf{p}\\in \\mathbb{R}^3\\). In particular \\[\n\\left\\|  {\\pmb{\\gamma}}(t) - \\mathbf{p} \\right\\| =   \\left\\|   -\\frac 1c \\mathbf{n}(t)  \\right\\| = \\frac1c \\,,\n\\] since \\(\\mathbf{n}\\) is a unit vector. The above shows that \\({\\pmb{\\gamma}}\\) is contained in a sphere of radius \\(1/c\\) and center \\(\\mathbf{p}\\). In formulas: \\[\n{\\pmb{\\gamma}}((a,b) ) \\subset \\mathcal{S}:= \\{  \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\,  \\left\\| \\mathbf{x}- \\mathbf{p} \\right\\| = 1/c    \\} \\,.\n\\] The intersection of \\(\\mathcal{S}\\) with the plane \\({\\pmb{\\pi}}\\) is a circle \\(\\mathcal{C}\\) with some radius \\(R\\). Since \\[\n{\\pmb{\\gamma}}((a,b) ) \\subset {\\pmb{\\pi}}\\,, \\quad {\\pmb{\\gamma}}((a,b) ) \\subset \\mathcal{S}\\,,\n\\] this implies \\[\n{\\pmb{\\gamma}}((a,b) ) \\subset  {\\pmb{\\pi}}\\cap \\mathcal{S}= \\mathcal{C} \\,.\n\\tag{2.21}\\] Thus \\({\\pmb{\\gamma}}\\) parametrizes part of \\(\\mathcal{C}\\). From Step 1 it follows that the curvature and torsion of \\({\\pmb{\\gamma}}\\) must satisfy \\[\n\\kappa = \\frac1R \\,, \\quad \\tau = 0 \\,.\n\\] Since we already know that \\(\\kappa=c\\), we conclude that \\(R=1/c\\). Therefore the circle \\(\\mathcal{C}\\) has radius \\(1/c\\) and the thesis follows by (2.21).\n\n\n\n\n\n\ndo Carmo, Manfredo P. 2017. Differential Geometry of Curves and Surfaces. Second Edition. Dover Books on Mathematics.\n\n\nPressley, Andrew. 2010. Elementary Differential Geometry. Second Edition. Springer.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Curvature and Torsion</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html",
    "href": "sections/chap_3.html",
    "title": "3  Topology",
    "section": "",
    "text": "3.1 Closed sets\nThe opposite of open sets are closed sets.\nIn words, a set is closed if its complement is open.\nWe could have defined a topology starting from closed sets. We would have had to replace the properties (A1)-(A2)-(A3) with suitable properties for closed sets. Such properties are detailed in the following proposition.\nAs a consequence of the above proposition, we can define a topology by declaring what the closed sets are. We then need to verify that (C1)-(C2)-(C3) are satisfied by such topology. Let us make an example.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#closed-sets",
    "href": "sections/chap_3.html#closed-sets",
    "title": "3  Topology",
    "section": "",
    "text": "Definition 8: Closed setLet \\((X,\\mathcal{T})\\) be a topological space. A set \\(C \\subseteq X\\) is closed if \\[\nC^c   \\in \\mathcal{T}\\,,\n\\] where \\(C^c:= X \\smallsetminus C\\) is the complement of \\(C\\) in \\(X\\).\n\n\n\n\nWarning\nThere are sets which are neither open nor closed. For example consider \\(\\mathbb{R}\\) equipped with Euclidean topology. Then the interval \\[\nA:=[0,1)\n\\] is neither open nor closed.\n\nFor the moment we do not have the tools to prove this. We will have them shortly.\n\n\n\n\n\nProposition 9\nLet \\((X,\\mathcal{T})\\) be a topological space. Properties (A1)-(A2)-(A3) of \\(\\mathcal{T}\\) are equivalent to (C1)-(C2)-(C3), where\n\n(C1) \\(\\emptyset, X\\) are closed.\n(C2) If \\(C_i\\) is closed for all \\(i \\in I\\), then \\[\n\\bigcap_{i \\in I} \\, C_i\n\\] is closed.\n(C3) If \\(C_1,C_2\\) are closed then \\[\nC_1 \\cup C_2\n\\] is closed.\n\n\n\n\nProof\nWe have 3 points to check:\n\nThe equivalence between (A1) and (C1) is clear, since \\[\n\\emptyset^c = X \\,, \\quad X^c = \\emptyset \\,.\n\\]\nSuppose \\(C_i\\) are closed for all \\(i \\in I\\). Therefore \\(C_i^c\\) are open for all \\(i \\in I\\). By De Morgan’s laws we have that \\[\n\\left(  \\bigcap_{i \\in I} \\, C_i \\right)^c =  \\bigcup_{i \\in I} \\, C_i^c\n\\] showing that \\[\n\\bigcap_{i \\in I} \\, C_i  \\, \\mbox{ is closed} \\quad\n\\iff \\quad\n\\bigcup_{i \\in I} \\, C_i^c  \\, \\mbox{ is open} \\,.\n\\] Therefore (A2) and (C2) are equivalent.\nSuppose \\(C_1,C_2\\) are closed. Therefore \\(C_1^c, C_2^c\\) are open. By De Morgan’s laws we have that \\[\n\\left(  C_1 \\cup  C_2 \\right)^c =  C_1^c \\cap C_2^c\n\\] showing that \\[\nC_1 \\cup  C_2 \\, \\mbox{ is closed} \\quad\n\\iff \\quad\nC_1^c \\cap C_2^c  \\, \\mbox{ is open} \\,.\n\\] Therefore (A3) and (C3) are equivalent.\n\n\n\n\n\nExample 10: The Zariski topologyLet \\((\\mathbb{K}, + , \\cdot)\\) be a field. Define \\[\nX:=\\mathbb{K}^n := \\{  (a_1, \\ldots, a_n) \\, \\colon \\,a_i \\in \\mathbb{K}  \\} \\,.\n\\] Consider the set of polynomials with coefficients in the field \\[\n\\mathbb{K}[x_1,\\ldots,x_n] \\,.\n\\] Therefore \\(f \\in \\mathbb{K}[x_1,\\ldots,x_n]\\) has the form \\[\nf(x_1,\\ldots,x_n) = \\lambda_1 x_1 + \\ldots + \\lambda_n x_n \\,,\n\\] where \\(\\lambda_1, \\ldots, \\lambda_n\\) are given elements of \\(\\mathbb{K}\\). For \\(I \\subset \\mathbb{K}[x_1,\\ldots,x_n]\\) define \\[\nV(I):= \\{  (a_1,\\ldots,a_n) \\in \\mathbb{K}^n \\, \\colon \\,\nf(a_1,\\ldots,a_n) = 0 \\,, \\,\\, \\forall \\, f \\in I    \\} \\,.\n\\] Define \\[\n\\mathcal{C} := \\{ V(I) \\, \\colon \\,I \\subset \\mathbb{K}[x_1,\\ldots,x_n] \\} \\,.\n\\] Then \\(\\mathcal{C}\\) satisfies (C1), (C2) and (C3). This is an easy check, and is left as exercise. \\(\\mathcal{C}\\) is called the Zariski Topology on the field \\(\\mathbb{K}^n\\). This is used in algebraic geometry to study Affine Varieties, an algebraic version of surfaces, see Wikipedia page.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#comparing-topologies",
    "href": "sections/chap_3.html#comparing-topologies",
    "title": "3  Topology",
    "section": "3.2 Comparing topologies",
    "text": "3.2 Comparing topologies\nConsider the situation where you have two topologies \\(\\mathcal{T}_1\\) and \\(\\mathcal{T}_2\\) on the same set \\(X\\). We would like to have some notions of comparison between \\(\\mathcal{T}_1\\) and \\(\\mathcal{T}_2\\).\n\nDefinition 11: Finer and coarser topologyLet \\(X\\) be a set and let \\(\\mathcal{T}_1\\), \\(\\mathcal{T}_2\\) be topologies on \\(X\\). Suppose that \\[\n\\mathcal{T}_2 \\subseteq \\mathcal{T}_1 \\,.\n\\] We say that:\n\n\\(\\mathcal{T}_1\\) is finer than \\(\\mathcal{T}_2\\).\n\\(\\mathcal{T}_2\\) is coarser than \\(\\mathcal{T}_1\\).\n\nIf it holds \\[\n\\mathcal{T}_2 \\subsetneq \\mathcal{T}_1 \\,,\n\\] we say that:\n\n\\(\\mathcal{T}_1\\) is strictly finer than \\(\\mathcal{T}_2\\).\n\\(\\mathcal{T}_2\\) is strictly coarser than \\(\\mathcal{T}_1\\).\n\nWe say that \\(\\mathcal{T}_1\\) and \\(\\mathcal{T}_2\\) are the same topology if \\[\n\\mathcal{T}_1 = \\mathcal{T}_2 \\,.\n\\]\n\n\n\nExample 12Let \\(X\\) be a set and consider the trivial and discrete topologies \\[\n\\mathcal{T}_{\\textrm{trivial}} = \\{ \\emptyset, X\\} \\,, \\quad \\mathcal{T}_{\\textrm{discrete}} = \\{ A \\, \\colon \\,A \\subseteq X \\} \\,.\n\\] Then \\[\n\\mathcal{T}_{\\textrm{trivial}} \\subsetneq \\mathcal{T}_{\\textrm{discrete}} \\,,\n\\] so that \\(\\mathcal{T}_{\\textrm{discrete}}\\) is strictly finer than \\(\\mathcal{T}_{\\textrm{trivial}}\\).\n\n\nAnother interesting example is given by the cofinite topology on \\(\\mathbb{R}\\). The sets in this topology are open if they are either empty, or coincide with \\(\\mathbb{R}\\) with a finite number of points removed.\n\nExample 13: Cofinite topology on \\(\\mathbb{R}\\)\nConsider the following family \\(\\mathcal{T}_{\\textrm{cofinite}}\\) of subsets of \\(\\mathbb{R}\\) \\[\n\\mathcal{T}_{\\textrm{cofinite}} := \\{ U \\subseteq \\mathbb{R}\\, \\colon \\,U^c \\, \\mbox{ is finite, }  \\mbox{or } U^c = \\mathbb{R}\\}\\,.\n\\] Then \\((\\mathbb{R},\\mathcal{T}_{\\textrm{cofinite}})\\) is a topological space, and \\(\\mathcal{T}_{\\textrm{cofinite}}\\) is called the cofinite topology. We have that \\[\n\\mathcal{T}_{\\textrm{cofinite}} \\subsetneq \\mathcal{T}_{\\textrm{euclidean}} \\,.\n\\]\n\nExercise: Show that \\(\\mathcal{T}_{\\textrm{cofinite}}\\) is a topology on \\(\\mathbb{R}\\) and that \\(\\mathcal{T}_{\\textrm{cofinite}} \\subsetneq \\mathcal{T}_{\\textrm{euclidean}}\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#convergence",
    "href": "sections/chap_3.html#convergence",
    "title": "3  Topology",
    "section": "3.3 Convergence",
    "text": "3.3 Convergence\nWe have generalized the notion of open set to arbitrary sets. Next we generalize the notion of convergence of sequences.\n\nDefinition 14: Convergent sequenceLet \\((X,\\mathcal{T})\\) be a topological. Consider a sequence \\(\\{x_n\\}_{n \\in \\mathbb{N}} \\subseteq X\\) and a point \\(x \\in X\\). We say that \\(x_n\\) converges to \\(x_0\\) if the following property holds: \\[\n\\forall \\, U \\in \\mathcal{T}\\, \\text{ s.t. } \\, x_0 \\in U\\,, \\,\\, \\exists \\, N = N(U) \\in \\mathbb{N}\\, \\text{ s.t. } \\, x_n \\in U \\,, \\, \\forall \\, n \\geq N \\,.\n\\tag{3.4}\\]\n\n\n\nNotationThe convergence of \\(x_n\\) to \\(x_0\\) is denoted by \\[\nx_n \\to x_0 \\quad \\mbox{ or } \\quad  \\lim_{n \\to \\infty} x_n = x_0 \\,.\n\\]\n\n\nLet us analyze the definition of convergence in the topologies we have encountered so far. We will have that:\n\nTrivial topology: Every sequence converges to every point.\nDiscrete topology: A sequence converges if and only if it is eventually constant.\nEuclidean topology: Topological convergence coincides with classical notion of convergence.\n\nWe now precisely state and prove the above claims.\n\nProposition 15: Convergence for trivial topologyLet \\((X,\\mathcal{T})\\) be topological space, with \\(\\mathcal{T}\\) the trivial topology, that is, \\[\n\\mathcal{T}= \\{ \\emptyset, X \\} \\,.\n\\] Let \\(\\{x_n\\} \\subseteq X\\) be a sequence and \\(x_0 \\in X\\) a point. Then \\[\nx_n \\to x_0 \\,.\n\\]\n\n\n\nProofTo show that \\(x_n \\to x_0\\) we need to check that (3.4) holds. Therefore, let \\(U \\in \\mathcal{T}\\) with \\(x_0 \\in U\\). We have two cases:\n\n\\(U = \\emptyset\\): This case is not possible, since \\(x_0\\) cannot be in \\(U\\).\n\\(U = X\\): Take \\(N=1\\). Since \\(U\\) is the whole space, then \\(x_n \\in U\\) for all \\(n \\geq 1\\).\n\nAs these are all the open sets, we conclude that \\(x_n \\to x_0\\).\n\n\n\nWarningThis example is saying that in general the topological limit of a sequence is not unique!\n\n\n\nProposition 16: Convergence for discrete topology\nLet \\((X,\\mathcal{T})\\) be topological space, with \\(\\mathcal{T}\\) the discrete topology, that is, \\[\n\\mathcal{T}= \\{ A  \\, \\colon \\,A \\subseteq X \\} \\,.\n\\] Let \\(\\{x_n\\} \\subseteq X\\) be a sequence and \\(x_0 \\in X\\) a point. They are equivalent:\n\n\\(x_n \\to x_0\\).\n\\(\\{x_n\\}\\) is eventually constant, that is, there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n = x_0 \\,, \\quad \\forall \\, n \\geq N \\,.\n\\]\n\n\n\n\nProofPart 1. Assume that \\(x_n \\to x_0\\).\nWe have to prove that \\(\\{x_n\\}\\) is eventually constant. To this end, let \\[\nU = \\{x_0\\} \\,.\n\\] Then \\(U \\in \\mathcal{T}\\). Since \\(x_n \\to x_0\\), by (3.4) there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n \\in U  \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] As \\(U = \\{x_0\\}\\), the above is saying that \\(x_n = x_0\\) for all \\(n \\geq N\\). Hence \\(x_n\\) is eventually constant.\nPart 2. Assume that \\(x_n\\) is eventually equal to \\(x_0\\).\nBy assumption there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n = x_0 \\,, \\quad \\forall \\, n \\geq N \\,.\n\\tag{3.5}\\] Let \\(U \\in \\mathcal{T}\\) be an open set such that \\(x_0 \\in U\\). By (3.5) we have that \\[\nx_n \\in U \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Since \\(U\\) was arbitrary, we conclude that \\(x_n \\to x_0\\).\n\n\nBefore proceeding to examining convergence in the Euclidean topology, let us recall the classical definition of convergence in \\(\\mathbb{R}^n\\).\n\nDefinition 17: Classical convergence in \\(\\mathbb{R}^n\\)Let \\(\\{\\mathbf{x}_n\\} \\subseteq \\mathbb{R}^n\\) and \\(\\mathbf{x}_0 \\in \\mathbb{R}^n\\). We say that \\(\\mathbf{x}_n\\) converges \\(\\mathbf{x}_0\\) in the classical sense if \\[\n\\lim_{n \\to \\infty} \\left\\| \\mathbf{x}_n - \\mathbf{x}_0 \\right\\|  = 0 \\,.\n\\] The above is equivalent to: For all \\(\\varepsilon&gt;0\\) there exists \\(N \\in \\mathbb{N}\\) such that \\[\n\\left\\| \\mathbf{x}_n - \\mathbf{x}_0 \\right\\| &lt; \\varepsilon\\,, \\quad \\forall \\, n \\geq N \\,.\n\\]\n\n\n\nProposition 18: Convergence for Euclidean topology\nLet \\(\\mathbb{R}^n\\) be equipped with \\(\\mathcal{T}\\) the Euclidean topology. Let \\(\\{\\mathbf{x}_n\\} \\subseteq \\mathbb{R}^n\\) be a sequence and \\(\\mathbf{x}_0 \\in \\mathbb{R}^n\\) a point. They are equivalent:\n\n\\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) with respect to \\(\\mathcal{T}\\).\n\\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) in the classical sense.\n\n\n\n\nProofPart 1. Assume \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) with respect to \\(\\mathcal{T}\\).\nFix \\(\\varepsilon&gt;0\\) and consider the set \\[\nU := B_{\\varepsilon}(\\mathbf{x}_0) \\,.\n\\] By Proposition 7 we know that \\(U \\in \\mathcal{T}\\). Moreover \\(\\mathbf{x}_0 \\in U\\). By the convergence \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) with respect to \\(\\mathcal{T}\\), there exists \\(N \\in \\mathbb{N}\\) such that \\[\n\\mathbf{x}_n \\in U \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] As \\(U = B_{\\varepsilon}(\\mathbf{x}_0)\\), the above reads \\[\n\\left\\| \\mathbf{x}_n - \\mathbf{x}_0 \\right\\| &lt; \\varepsilon\\,, \\quad \\forall \\, n \\geq N \\,,\n\\] showing that \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) in the classical sense.\nPart 2. Assume \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) in the classical sense.\nLet \\(U \\in \\mathcal{T}\\) be such that \\(\\mathbf{x}_0 \\in U\\). By definition of Euclidean topology, this means that there exists \\(r&gt;0\\) such that \\[\nB_r(\\mathbf{x}_0) \\subseteq U \\,.\n\\] As \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) in the classical sense, there exists \\(N \\in \\mathbb{N}\\) such that \\[\n\\left\\| \\mathbf{x}_n - \\mathbf{x}_0 \\right\\| &lt; r \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] The above is equivalent to \\[\n\\mathbf{x}_n \\in B_{r}(\\mathbf{x}_0) \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Since \\(B_r(\\mathbf{x}_0) \\subseteq U\\), we have proven that \\[\n\\mathbf{x}_n \\in U \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Since \\(U\\) is arbitrary, we conclude that \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) with respect to \\(\\mathcal{T}\\).\n\n\n\nNotationSince classical convergence in \\(\\mathbb{R}^n\\) agrees with topological convergence with respect to \\(\\mathcal{T}\\), we will just say that \\(\\mathbf{x}_n \\to \\mathbf{x}_0\\) in \\(\\mathbb{R}^n\\) without ambiguity.\n\n\nWe conclude with a useful proposition which relates convergences when multiple topologies are present.\n\nProposition 19Let \\(X\\) be a set and \\(\\mathcal{T}_1,\\mathcal{T}_2\\) be topologies on \\(X\\). Suppose that \\[\n\\mathcal{T}_2 \\subseteq \\mathcal{T}_1 \\,.\n\\] Let \\(\\{x_n\\} \\subset X\\) and \\(x_0 \\in X\\). We have \\[\nx_n \\to x_0 \\,\\, \\mbox{ in } \\,\\, \\mathcal{T}_1  \\quad \\implies\n\\quad\nx_n \\to x_0 \\,\\, \\mbox{ in } \\,\\, \\mathcal{T}_2 \\,.\n\\]\n\n\n\nProofAssume \\(x_n \\to x_0\\) in \\(\\mathcal{T}_1\\). We need to prove that \\(x_n \\to x_0\\) in \\(\\mathcal{T}_2\\). Therefore, let \\(U \\in \\mathcal{T}_2\\) be such that \\(x_0 \\in U\\). Since \\(\\mathcal{T}_2 \\subseteq \\mathcal{T}_1\\), we have that \\(U \\in \\mathcal{T}_1\\). As \\(x_n \\to x_0\\) in \\(\\mathcal{T}_1\\), there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n \\in U \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Since \\(U \\in \\mathcal{T}_2\\), the above proves \\(x_n \\to x_0\\) in \\(\\mathcal{T}_2\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#metric-spaces",
    "href": "sections/chap_3.html#metric-spaces",
    "title": "3  Topology",
    "section": "3.4 Metric spaces",
    "text": "3.4 Metric spaces\nWe will now define a class of topological spaces known as metric spaces.\n\nDefinition 20: Distance\nLet \\(X\\) be a set. A distance on \\(X\\) is a function \\[\nd \\colon X \\times X \\to \\mathbb{R}\n\\] such that, for all \\(x,y,z \\in X\\) they hold:\n\n(M1) Positivity: The distance is non-negative \\[\nd(x,y) \\geq 0 \\,.\n\\] Moreover \\[\nd(x,y) = 0 \\quad \\iff x=y \\,.\n\\]\n(M2) Symmetry: The distance is symmetric \\[\nd(x,y) = d(y,x) \\,.\n\\]\n(M3) Triangle Inequality: It holds \\[\nd(x,z) \\leq d(x,y) + d(y,z) \\,.\n\\]\n\n\n\n\nDefinition 21: Metric spaceLet \\(X\\) be a set and \\(d \\colon X \\times X \\to \\mathbb{R}\\) be a distance on \\(X\\). We say that the pair \\((X,d)\\) is a metric space.\n\n\n\nExample 22: \\(\\mathbb{R}^n\\) as metric space\nThe Euclidean norm naturally induces a distance over \\(\\mathbb{R}^n\\) by setting \\[\nd(\\mathbf{x},\\mathbf{y}) := \\left\\|  \\mathbf{x}- \\mathbf{y} \\right\\| \\,.\n\\] Then \\((\\mathbb{R}^n,d)\\) is a metric space.\n\nIt is trivial to check that the Euclidean distance satisfies (M1) and (M2). To show (M3), recalling the triangle inequality in \\(\\mathbb{R}^n\\): \\[\n\\| \\mathbf{x}+ \\mathbf{y}\\| \\leq \\| \\mathbf{x}\\|   + \\| \\mathbf{y}\\| \\,,\n\\] for all \\(\\mathbf{x}, \\mathbf{y}\\in \\mathbb{R}^n\\). Using the above we obtain \\[\\begin{align*}\nd(\\mathbf{x},\\mathbf{y}) & = \\| \\mathbf{x}- \\mathbf{y}\\| \\\\\n& = \\| (\\mathbf{x}- \\mathbf{z}) + (\\mathbf{z}- \\mathbf{y}) \\| \\\\\n& \\leq  \\| \\mathbf{x}- \\mathbf{z}\\| + \\| \\mathbf{z}- \\mathbf{y}\\|  \\\\\n& = d (\\mathbf{x},\\mathbf{z}) + d (\\mathbf{z},\\mathbf{y}) \\,,\n\\end{align*}\\] proving that \\(d\\) satisfies (M3). This prove that \\((\\mathbb{R}^n,d)\\) is a metric space.\n\n\n\n\nExample 23: \\(p\\)-distance on \\(\\mathbb{R}^n\\)\nFor \\(\\mathbf{x},\\mathbf{y}\\in \\mathbb{R}^n\\) and \\(p \\in [1,\\infty)\\) define \\[\nd_p ( \\mathbf{x}, \\mathbf{y}) := \\left(  \\sum_{i=1}^n |x_i - y_i|^p   \\right)^{\\frac1p} \\,.\n\\] Note that \\(d_2\\) coincides with the Euclidean distance. For \\(p = \\infty\\) we set \\[\nd_{\\infty} ( \\mathbf{x}, \\mathbf{y}) := \\max_{i = 1 \\ldots, n} |x_i - y_i|  \\,.\n\\] We have that \\((\\mathbb{R}^n,d_p)\\) is a metric space.\n\nIndeed properties (M1)-(M2) hold trivially. The triangle inequality is also trivially satisfied by \\(d_{\\infty}\\). We are left with checking the triangle inequality for \\(d_p\\) with \\(p \\geq 1\\). To this end, define \\[\n\\| \\mathbf{x}\\|_p :=  \\left(  \\sum_{i=1}^n |x_i|^p  \\right)^{\\frac1p} \\,.\n\\] Minkowski’s inequality, see Wikipedia page, states that \\[\n\\| \\mathbf{x}+ \\mathbf{y}\\|_p \\leq   \\| \\mathbf{x}\\|_p  +  \\|  \\mathbf{y}\\|_p \\,,\n\\] for all \\(\\mathbf{x},\\mathbf{y}\\in \\mathbb{R}^n\\). Therefore \\[\\begin{align*}\nd_p(\\mathbf{x},\\mathbf{y}) & = \\| \\mathbf{x}- \\mathbf{y}\\|_p  \\\\\n& = \\| (\\mathbf{x}- \\mathbf{z}) + (\\mathbf{z}- \\mathbf{y}) \\|_p \\\\\n& \\leq  \\| \\mathbf{x}- \\mathbf{z}\\|_p + \\| \\mathbf{z}- \\mathbf{y}\\|_p  \\\\\n& = d_p (\\mathbf{x},\\mathbf{z}) + d_p (\\mathbf{z},\\mathbf{y}) \\,,\n\\end{align*}\\] proving that \\(d_p\\) satisfies (M3). Hence \\((\\mathbb{R}^n,d_p)\\) is a metric space.\n\n\n\nA metric \\(d\\) on a set \\(X\\) naturally induces a topology which is compatible with the metric.\n\nDefinition 24: Topology induced by the metricLet \\((X,d)\\) be a metric space. We define the topology \\(\\mathcal{T}_d\\) induced by the metric \\(d\\) as the collection of sets \\(U \\subseteq X\\) that satisfy the following property: \\[\n\\forall \\, x \\in U \\,, \\, \\exists \\, r \\in \\mathbb{R}, \\, r &gt; 0 \\, \\, \\text{ s.t. } \\, \\, B_r(x) \\subseteq U \\,,\n\\] where \\(B_r(x)\\) is the ball centered at \\(x\\) of radius \\(r\\). This is defined by \\[\nB_r(x) := \\{ y \\in X  \\, \\colon \\,  d(x,y)&lt;r  \\} \\,.\n\\]\n\n\nWe need to check that the above definition is well-posed, that is, we need to show that \\(\\mathcal{T}_d\\) is actually a topology on \\(X\\). The proof follows, line by line, the proof that the Euclidean topology is indeed a topology, see proof immediately below Definition 6. This is left as an exercise.\n\nExample 25: Topology induced by Euclidean distance\nConsider the metric space \\((\\mathbb{R}^n,d)\\) with \\(d\\) the Euclidean distance. Then \\[\n\\mathcal{T}_d = \\mathcal{T}_{\\textrm{euclidean}} \\,,\n\\] where \\(\\mathcal{T}_{\\textrm{euclidean}}\\) is the Euclidean topology on \\(\\mathbb{R}^n\\).\n\nExercise: Prove the above statement. It is an immediate consequence of definitions.\n\n\n\n\nExample 26: Discrete distance\nLet \\(X\\) be a set. Define the function \\(d \\colon X \\times X \\to \\mathbb{R}\\) by \\[\nd(x,y) :=\n\\begin{cases}\n    0 & \\mbox{ if } \\, x = y \\\\\n    1 & \\mbox{ if } \\, x \\neq y\n\\end{cases}\n\\] Then \\((X,d)\\) is a metric space, and \\(d\\) is called the discrete distance. Moreover \\[\n\\mathcal{T}_d = \\mathcal{T}_{\\textrm{discrete}}\n\\] where \\(\\mathcal{T}_{\\textrm{discrete}}\\) is the discrete topology on \\(X\\).\n\nExercise: Prove that \\((X,d)\\) is a metric space and \\(\\mathcal{T}_d = \\mathcal{T}_{\\textrm{discrete}}\\).\n\n\n\nThe following proposition tells us that balls in a metric space \\(X\\) are open sets. Moreover balls are the building blocks of all open sets in \\(X\\). The proof is left as an exercise.\n\nProposition 27\nLet \\((X,d)\\) be a metric space and \\(\\mathcal{T}_d\\) the topology induced by \\(d\\). Then:\n\nFor all \\(x \\in X\\), \\(r&gt;0\\) we have \\(B_r(x) \\subseteq \\mathcal{T}_d\\).\n\\(U \\in \\mathcal{T}_d\\) if and only if \\[\nU = \\bigcup_{ i \\in I } B_{r_i}(x_i) \\,,\n\\] with \\(I\\) family of indices and \\(x_i \\in X\\), \\(r_i &gt; 0\\).\n\n\n\nWe now define the concept of equivalent metrics.\n\nDefinition 28: Equivalent metricsLet \\(X\\) be a set and \\(d_1,d_2\\) be metrics on \\(X\\). We say that \\(d_1\\) and \\(d_2\\) are equivalent if \\[\n\\mathcal{T}_{d_1} = \\mathcal{T}_{d_2} \\,.\n\\]\n\n\nThe following proposition gives a sufficent condition for the equivalence of two metrics.\n\nProposition 29Let \\(X\\) be a set and \\(d_1,d_2\\) be metrics on \\(X\\). Suppose that there exists a constant \\(\\alpha &gt; 0\\) such that \\[\n\\frac{1}{\\alpha} \\, d_2 (x,y) \\leq d_1 (x,y) \\leq \\alpha \\, d_2(x,y) \\,, \\quad \\forall \\, x,y \\in X \\,.\n\\] Then \\(d_1\\) and \\(d_2\\) are equivalent metrics.\n\n\nThe proof of Proposition 29 is trivial, and is left as an exercise.\n\nExample 30\nLet \\(p &gt; 1\\). The metrics \\(d_p\\) and \\(d_{\\infty}\\) on \\(\\mathbb{R}^n\\) are equivalent.\n\nThis follows from Proposition 29 and the estimate \\[\nd_{\\infty} (\\mathbf{x},\\mathbf{y}) \\leq d_p (\\mathbf{x},\\mathbf{y}) \\leq n \\, d_{\\infty} (\\mathbf{x},\\mathbf{y}) \\,, \\quad \\forall \\mathbf{x}\\,, \\, \\mathbf{y}\\in \\mathbb{R}^n \\,.\n\\]\n\n\n\n\nWarningIf two metrics are equivalent, that does not mean they have the same balls. For example the balls of the metrics \\(d_1\\), \\(d_2\\) and \\(d_{\\infty}\\) on \\(\\mathbb{R}^n\\) look very different, see Figure 3.3.\n\n\n\n\n\n\n\n\nFigure 3.3: Balls \\(B_r(0)\\) for the metrics \\(d_2, d_\\infty, d_1\\) in \\(\\mathbb{R}^2\\).\n\n\n\nWe can characterize the convergence of sequences in metric spaces.\n\nProposition 31: Convergence in metric space\nSuppose \\((X,d)\\) is a metric space and denote by \\(\\mathcal{T}_d\\) the topology induce by \\(d\\). Let \\(\\{x_n\\} \\subseteq X\\) and \\(x_0 \\in X\\). They are equivalent:\n\n\\(x_n \\to x_0\\) with respect to the topology \\(\\mathcal{T}_d\\).\n\\(d(x_n,x_0) \\to 0\\) in \\(\\mathbb{R}\\).\nFor all \\(\\varepsilon&gt;0\\) there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n \\in B_r(x_0) \\, , \\,\\, \\forall \\, n \\geq \\mathbb{N}\\,.\n\\]\n\n\n\nThe proof is similar to the one of Proposition 18, and it is left as an exercise.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#interior-closure-and-boundary",
    "href": "sections/chap_3.html#interior-closure-and-boundary",
    "title": "3  Topology",
    "section": "3.5 Interior, closure and boundary",
    "text": "3.5 Interior, closure and boundary\nWe now define interior, closure and boundary of a set \\(A\\) contained in a topological space.\n\nDefinition 32: Interior of a setLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. The interior of \\(A\\) is the set \\[\n\\mathop{\\mathrm{Int}}{A} :=  \\bigcup_{ \\substack{U \\subseteq A \\\\ U \\in \\mathcal{T}} } \\, U \\,.\n\\]\n\n\n\nRemark 33The definition of \\(\\mathop{\\mathrm{Int}}{A}\\) is well-posed, since \\(\\emptyset \\subseteq A\\) and \\(\\emptyset \\in \\mathcal{T}\\). Therefore the union is taken over a non-empty family.\n\n\n\nProposition 34\nLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. Then \\(\\mathop{\\mathrm{Int}}{A}\\) is the largest open set contained in \\(A\\), that is:\n\n\\(\\mathop{\\mathrm{Int}}{A}\\) is open.\n\\(\\mathop{\\mathrm{Int}}{A} \\subseteq A\\).\nIf \\(V \\in \\mathcal{T}\\) and \\(V \\subseteq A\\), then \\(V \\subseteq \\mathop{\\mathrm{Int}}{A}\\).\n\\(A\\) is open if and only if \\[\nA = \\mathop{\\mathrm{Int}}{A} \\,.\n\\]\n\n\n\n\nProof\nWe have:\n\n\\(\\mathop{\\mathrm{Int}}{A}\\) is open, since it is union of open sets, see property (A2).\n\\(\\mathop{\\mathrm{Int}}{A} \\subseteq A\\), since \\(\\mathop{\\mathrm{Int}}{A}\\) is union of sets contained in \\(A\\).\nSuppose \\(V \\in \\mathcal{T}\\) and \\(V \\subseteq A\\). Therefore \\[\nV \\subseteq   \\bigcup_{ \\substack{U \\subseteq A \\\\ U \\in \\mathcal{T}} } \\, U = \\mathop{\\mathrm{Int}}{A} \\,.\n\\]\nSuppose that \\(A\\) is open. Then \\[\nA \\subseteq \\bigcup_{ \\substack{U \\subseteq A \\\\ U \\in \\mathcal{T}}  } \\, U  = \\mathop{\\mathrm{Int}}{A}  \\,.\n\\] As we already know that \\(\\mathop{\\mathrm{Int}}{A} \\subseteq A\\), we conclude that \\(A = \\mathop{\\mathrm{Int}}{A}\\).\nConversely, suppose that \\(A = \\mathop{\\mathrm{Int}}{A}\\). Since \\(\\mathop{\\mathrm{Int}}{A}\\) is open, then also \\(A\\) is open.\n\n\n\n\nDefinition 35: Closure of a setLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. The closure of \\(A\\) is the set \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} :=  \\bigcap_{ \\substack{A \\subseteq C \\\\ C \\, \\text{closed} } } \\, C \\,,\n\\] that is, \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is the intersection of all closed sets containing \\(A\\).\n\n\n\nRemark 36The definition of \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is well-posed, since \\(A \\subseteq X\\), and \\(X\\) is closed. Therefore the intersection is taken over a non-empty family.\n\n\n\nProposition 37\nLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. Then \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is the smallest closed set containing \\(A\\), that is:\n\n\\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is closed.\n\\(A \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\nIf \\(V\\) is closed \\(A \\subseteq V\\), then \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\subseteq V\\).\n\\(A\\) is closed if and only if \\[\nA = {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\,.\n\\]\n\n\n\n\nProof\nWe have:\n\n\\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is closed, since it is intersection of closed sets, see property (C2).\n\\(A \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\), since \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is intersection of sets which contain \\(A\\).\nSuppose \\(V\\) is closed and \\(A \\subseteq V\\). Therefore \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} =  \\bigcap_{ \\substack{A \\subseteq C \\\\ C \\, \\text{closed}  } } \\, C  \\subseteq V \\,.\n\\]\nSuppose that \\(A\\) is closed. Then \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} =  \\bigcap_{ \\substack{A \\subseteq C \\\\ C \\, \\text{closed}} } \\, C  \\subseteq A \\,,\n\\] showing that \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\subseteq A\\). As we already know that \\(A \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\), we conclude that \\(A = {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\nConversely, suppose that \\(A = {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\). Since \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is closed, then also \\(A\\) is closed.\n\n\n\n\nLemma 38\nLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. They are equivalent:\n\n\\(x_0 \\in {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\nFor every \\(U \\in \\mathcal{T}\\) such that \\(x_0 \\in U\\), it holds \\[\nU \\cap A \\neq \\emptyset  \\,.\n\\]\n\n\n\n\nProof\nWe prove the contronominal statement: \\[\nx_0 \\notin {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\quad \\iff \\quad\n\\exists \\,\\, U \\in \\mathcal{T}\\, \\text{ s.t. } \\, x_0 \\in U \\,, \\,\\, \\, U \\cap A = \\emptyset \\,.\n\\]\nLet us check the two implications hold:\n\nSuppose \\(x_0 \\notin {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\). Then \\(x_0 \\in U := ({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c\\). Note that \\(U\\) is open, since \\(U^c = {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is closed. We have \\[\nA \\cap U = A \\cap (\\overline{A})^c = \\emptyset \\,,\n\\] since \\(A \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\nAssume there exists \\(U \\in \\mathcal{T}\\) such that \\(x_0 \\in U\\) and \\(U \\cap A = \\emptyset\\). Therefore \\(A \\subseteq U^c\\). Since \\(U\\) is open, \\(U^c\\) is closed. Then \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = \\bigcap_{ \\substack{  A \\subseteq C    \\\\ C \\, \\text{closed}  }   } \\, C \\subseteq U^c \\,.\n\\] Since \\(x_0 \\notin U^c\\), we conclude that \\(x_0 \\notin {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\n\n\n\n\nDefinition 39: Boundary of a setLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. The boundary of \\(A\\) is the set \\[\n\\partial A := {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\smallsetminus \\mathop{\\mathrm{Int}}{A} \\,.\n\\]\n\n\n\nProposition 40Let \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. Then \\(\\partial A\\) is closed.\n\n\n\nProofWe can write \\[\n\\partial A =  {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\smallsetminus \\mathop{\\mathrm{Int}}{A} = {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\cap (\\mathop{\\mathrm{Int}}{A})^c \\,.\n\\] Note that \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is closed and \\((\\mathop{\\mathrm{Int}}{A})^c\\) is closed, since \\(\\mathop{\\mathrm{Int}}{A}\\) is open. Then \\(\\partial A\\) is intersection of two closed sets, and in hence closed by (C2).\n\n\nWe can characterize \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) as the set of limit points of sequences in \\(A\\).\n\nDefinition 41Let \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\). The set of limit points of \\(A\\) is defined as \\[\nL(A):=\\{  x \\in X \\, \\colon \\,\\exists \\, \\{x_n \\} \\subseteq A \\, \\text{ s.t. } \\, x_n \\to x    \\} \\,.\n\\]\n\n\n\nProposition 42Let \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. Let \\(\\{x_n\\} \\subseteq A\\) and \\(x_0 \\in X\\) be such that \\(x_n \\to x_0\\). Then \\(x_0 \\in {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\). Therefore \\[\nL(A) \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\,.\n\\]\n\n\n\nProofSuppose by contradiction \\(x_0 \\notin {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\), so that \\[\nx_0 \\in ({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c \\,.\n\\] Since \\(({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c\\) is open and \\(x_n \\to x_0\\), there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n \\in ({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] This is a contradiction, since we were assuming that \\(\\{x_n\\} \\subseteq A\\). This shows \\(x_0 \\in {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) and therefore \\(L(A) \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\).\n\n\n\nWarningThe converse of Proposition 42 is false in general, that is, \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\not\\subset L(A) \\,.\n\\] We show a counterexample of the above in Example 43. The above relation holds in the so-called first countable topological spaces, such as metric spaces, see Proposition 44 below.\n\n\n\nExample 43: Co-countable topology\nLet \\(X=\\mathbb{R}\\) with the co-countable topology \\[\n\\mathcal{T}:= \\{ A \\subseteq \\mathbb{R}\\, \\colon \\,A^c = \\mathbb{R}\\,\\, \\mbox{ or } \\,\\, A^c \\,\n\\mbox{ countable }\\} \\,.\n\\] The set \\[\nA = (-\\infty,0]\n\\] is not closed and \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = \\mathbb{R}\\). Moreover, convergent sequences in \\((X,\\mathcal{T})\\) are eventually constant. Therefore \\(L(A) = A\\), showing that \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\not\\subset L(A)\\).\n\nExercise: Prove all the above statements.\n\n\n\nIn metric spaces we can characterize the interior of a set and the closure in the following way.\n\nProposition 44Let \\((X,d)\\) be a metric space. Denote by \\(\\mathcal{T}_d\\) the topology induced by \\(d\\). Let \\(A \\subseteq X\\). We have \\[\n\\mathop{\\mathrm{Int}}{A} = \\{ x \\in A \\, \\colon \\,\\exists \\,\\, r&gt;0  \\, \\text{ s.t. } \\, B_r(x) \\subseteq A   \\} \\,.\n\\tag{3.6}\\] and \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = L(A):= \\{  x \\in X \\, \\text{ s.t. } \\, \\exists \\,\\, \\{ x_n \\} \\subseteq A \\, \\text{ s.t. } \\, x_n \\to x   \\} \\,.\n\\tag{3.7}\\]\n\n\n\nProofThe proof of (3.6) is left as an exercise. Let us prove (3.7). The inclusion \\(L(A) \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) holds by Proposition 42. We are left to show that \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\subseteq L(A) \\,.\n\\] To this end, let \\(x_0 \\in {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\). For \\(n \\in \\mathbb{N}\\), consider the ball \\(B_{1/n}(x_0)\\). Since \\(B_{1/n}(x_0) \\in \\mathcal{T}_d\\) and \\(x_0 \\in B_{\\varepsilon}(x_0)\\), we can apply Lemma 38 and deduce that \\[\nB_{1/n}(x_0) \\cap A \\neq \\emptyset \\,.\n\\] Let \\(x_n \\in B_{1/n}(x_0) \\cap A\\). Since \\(n\\) was arbitrary, we have constructed a sequence \\(\\{x_n\\} \\subseteq A\\) such that \\[\nx_n \\in B_{1/n}(x_0) \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\] In particular, we have that \\[\nd(x_n,x_0) &lt; \\frac{1}{n} \\to 0\n\\] as \\(n \\to \\infty\\). Thus \\(x_n \\to x_0\\), showning that \\(x_0 \\in L(A)\\).\n\n\n\nExample 45\nConsider \\(\\mathbb{R}\\) with the Euclidean topology and \\(A :=[0,1)\\). We have that \\[\n\\mathop{\\mathrm{Int}}{A} = (0,1) \\,, \\quad {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = [0,1] \\,, \\quad \\partial A = \\{0,1\\} \\,.\n\\] In particular \\[\n\\mathop{\\mathrm{Int}}{A}  \\neq A \\,, \\quad {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\neq A \\,,\n\\] showing that \\(A\\) is neither open, nor closed.\n\nThe proof of the above statements is left as an exercise.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#density",
    "href": "sections/chap_3.html#density",
    "title": "3  Topology",
    "section": "3.6 Density",
    "text": "3.6 Density\n\nDefinition 46: DensityLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. We say that \\(A\\) is dense in \\(X\\) if \\[\nA \\cap U \\neq \\emptyset \\,, \\quad \\, \\forall \\,\\, U \\in \\mathcal{T}\\,, \\,\\, U \\neq \\emptyset \\,.\n\\]\n\n\nDensity can be characterized in terms of closure.\n\nProposition 47\nLet \\((X,\\mathcal{T})\\) be a topological space and \\(A \\subseteq X\\) a set. They are equivalent:\n\n\\(A\\) is dense in \\(X\\).\nIt holds \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = X \\,.\n\\]\n\n\n\n\nProofPart 1. Let \\(A\\) be dense in \\(X\\). Suppose by contradiction that \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\neq X \\,.\n\\] This means \\(({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c \\neq \\emptyset\\). Note that \\(({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c\\) is open, being \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) closed. By density of \\(A\\) in \\(X\\) we have \\[\nA \\cap ({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {})^c \\neq \\emptyset \\,.\n\\] Since \\(A \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\), the above is a contradiction.\nPart 2. Suppose that \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = X\\). Let \\(U \\in \\mathcal{T}\\) with \\(U \\neq \\emptyset\\). By contradiction, assume that \\[\nA \\cap U = \\emptyset \\,.\n\\] Therefore \\(A \\subseteq U^c\\). As \\(U^c\\) is closed, we have \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\subseteq U^c\\,,\n\\] because \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\) is the smallest closed set containing \\(A\\). Recalling that \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = X\\), we conclude that \\(U^c = X\\). Therefore \\(U = \\emptyset\\), which is a contradiction.\n\n\n\nExample 48\nConsider \\(\\mathbb{R}\\) with the Euclidean topology.\n\nWe have that the set of integers \\(\\mathbb{Z}\\) is closed in \\(\\mathbb{R}\\). Indeed, \\[\n\\mathbb{Z}^c = \\bigcup_{ z \\in \\mathbb{Z}}  \\, (z , z + 1 ) \\,.\n\\] Since \\((z,z+1)\\) is open in \\(\\mathbb{R}\\), by (A2) we conclude that \\(\\mathbb{Z}^c\\) is open, so that \\(\\mathbb{Z}\\) is closed. Therefore \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu \\mathbb{Z} \\mkern-2mu}\\mkern 2mu {} = \\mathbb{Z}\\,,\n\\] showing that \\(\\mathbb{Z}\\) is not dense in \\(\\mathbb{R}\\).\nThe rational numbers \\(\\mathbb{Q}\\) are instead dense in \\(\\mathbb{R}\\), as proven in the Analysis module. Therefore \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu \\mathbb{Q} \\mkern-2mu}\\mkern 2mu {} = \\mathbb{R}\\,.\n\\] It is also easy to check that \\[\n\\mathop{\\mathrm{Int}}{\\mathbb{Q}} = \\emptyset \\,.\n\\] Therefore \\[\n\\mathop{\\mathrm{Int}}{\\mathbb{Q}} \\neq \\mathbb{Q}\\,, \\quad {}\\mkern 2mu \\overline{\\mkern-2mu \\mathbb{Q} \\mkern-2mu}\\mkern 2mu {} \\neq \\mathbb{Q}\\,,\n\\] showing that \\(\\mathbb{Q}\\) is neither open, nor closed.\n\n\n\n\nExample 49\nConsider \\(\\mathbb{R}\\) with the cofinite topology \\[\n\\mathcal{T}_{\\textrm{cofinite}} := \\{ U \\subset \\mathbb{R}\\, \\colon \\,U^c \\, \\mbox{ is finite, }  \\mbox{ or } U^c = \\mathbb{R}\\}\\,.\n\\] We have that \\[\n{}\\mkern 2mu \\overline{\\mkern-2mu \\mathbb{Z} \\mkern-2mu}\\mkern 2mu {} = \\mathbb{R}\\,,\n\\] showing that \\(\\mathbb{Z}\\) is dense in \\(\\mathbb{R}\\).\n\nProof. Suppose \\(C\\) is a closed set such that \\(\\mathbb{Z}\\subseteq C\\). By definition of \\(\\mathcal{T}_{\\textrm{cofinite}}\\) we have \\(C = \\mathbb{R}\\) or \\(C\\) finite. Since \\(\\mathbb{Z}\\subseteq C\\) and \\(\\mathbb{Z}\\) is not finite, we conclude \\(C = \\mathbb{R}\\). This proves that \\(\\mathbb{R}\\) is the only closed set containing \\(\\mathbb{Z}\\), and so \\({}\\mkern 2mu \\overline{\\mkern-2mu \\mathbb{Z} \\mkern-2mu}\\mkern 2mu {} = \\mathbb{R}\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#hausdorff-spaces",
    "href": "sections/chap_3.html#hausdorff-spaces",
    "title": "3  Topology",
    "section": "3.7 Hausdorff spaces",
    "text": "3.7 Hausdorff spaces\nHausdorff space are topological spaces in which points can be separated by means of disjoint open sets.\n\nDefinition 50Let \\((X,\\mathcal{T})\\) be a topological space. We say that \\(X\\) is a Hausdorff space if for every two points \\(x,y \\in X\\) with \\(x \\neq y\\) there exist \\(U,V \\in \\mathcal{T}\\) such that \\[\nx \\in U \\,, \\quad y \\in V \\,, \\quad U \\cap V = \\emptyset \\,.\n\\]\n\n\nThe main example of Hausdorff spaces are metrizable spaces.\n\nProposition 51Let \\((X,d)\\) be a metric space with \\(\\mathcal{T}_d\\) the topology induced by \\(d\\). Then \\((X, \\mathcal{T}_d)\\) is a Hausdorff space.\n\n\n\nProofLet \\(x,y \\in X\\) with \\(x \\neq y\\). Set \\[\n\\varepsilon:= \\frac12 \\, d(x,y) \\,,\n\\] and define \\[\nU := B_{\\varepsilon}(x)\\,, \\quad\nV := B_{\\varepsilon}(y) \\,.\n\\] By Proposition 27 we know that \\(U, V \\in \\mathcal{T}_d\\). Moreover \\(x \\in U\\), \\(y \\in V\\). We are left to show that \\[\nU \\cap V = \\emptyset \\,.\n\\] Suppose by contradiction that \\(U \\cap V \\neq \\emptyset\\) and let \\(z \\in U \\cap V\\). Therefore \\[\nd(x,z) &lt; \\varepsilon\\,,  \\quad d(y,z) &lt; \\varepsilon\\,.\n\\] By triangle inequality we have \\[\nd(x,y) \\leq d(x,z) +  d(y,z) &lt; \\varepsilon+ \\varepsilon= d(x,y) \\,,\n\\] where in the last inequality we used the definition of \\(\\varepsilon\\). This is a contradiction. Therefore \\(U \\cap V = \\emptyset\\) and \\((X,\\mathcal{T}_d)\\) is Hausdorff.\n\n\nIn general, every metrizable space is Hausdorff.\n\nDefinition 52: Metrizable spaceLet \\((X,\\mathcal{T})\\) be a topological space. We say that the topology \\(\\mathcal{T}\\) is metrizable if there exists a metric \\(d\\) on \\(X\\) such that \\[\n\\mathcal{T}= \\mathcal{T}_d \\,,\n\\] with \\(\\mathcal{T}_d\\) the topology induced by \\(d\\).\n\n\n\nCorollary 53Let \\((X,\\mathcal{T})\\) be a metrizable space. Then \\(X\\) is Hausforff.\n\n\n\nProofSince \\((X,\\mathcal{T})\\) is metrizable, there exists a metric \\(d\\) on \\(X\\) such that \\[\n\\mathcal{T}= \\mathcal{T}_d \\,.\n\\] By Proposition 51 we know that \\((X,\\mathcal{T}_d)\\) is Hausdorff. Hence \\((X,\\mathcal{T})\\) is Hausdorff.\n\n\nAs a conseuqence of Corollary 53 we have that spaces which are not metrizable are not Hausdorff. Let us make a few examples.\n\nExample 54: Trivial topology is not Hausdorff\nLet \\((X,\\mathcal{T})\\) be a topological space with \\(\\mathcal{T}\\) trivial topology. Assume that \\(X\\) has more than one element. Then \\(X\\) is not Hausdorff.\n\nIndeed, let \\(x,y \\in X\\) with \\(x \\neq y\\). Suppose by contradiction that \\(X\\) is Hausdorff. Then there exist \\(U,V \\in \\mathcal{T}\\) such that \\[\nx \\in U \\,, \\quad y \\in V \\,, \\quad U \\cap V = \\emptyset \\,.\n\\] Recall that \\[\n\\mathcal{T}= \\{  \\emptyset, X \\} \\,.\n\\] Since \\(x \\in U\\) and \\(y \\in V\\), we deduce that \\(U\\) and \\(V\\) are non-empty. Since \\(U\\) and \\(V\\) are open, the only possibility is that \\[\nU = V = X \\,.\n\\] In this case we have \\[\nU \\cap V = X \\cap X = X \\neq \\emptyset \\,,\n\\] leading to a contradiciton. Hence \\(X\\) is not Hausdorff.\n\n\n\n\nExample 55: Cofinite topology on \\(\\mathbb{R}\\)\nConsider the following family \\(\\mathcal{T}\\) of subsets of \\(\\mathbb{R}\\) \\[\n\\mathcal{T}:= \\{ U \\subseteq \\mathbb{R}\\, \\colon \\,U^c \\, \\mbox{ is finite, }  \\mbox{or } U^c = \\mathbb{R}\\}\\,.\n\\] Then \\((\\mathbb{R},\\mathcal{T})\\) is a topological space which is not Hausdorff. The topology \\(\\mathcal{T}\\) is called the cofinite topology.\n\nExercise: Show that \\((\\mathbb{R},\\mathcal{T})\\) is not Hausdorff.\n\n\n\n\nExample 56\nConsider the following family \\(\\mathcal{T}\\) of subsets of \\(\\mathbb{R}\\) \\[\n\\mathcal{T}:= \\{ U = (-\\infty,a)  \\, \\colon \\,- \\infty \\leq a \\leq \\infty  \\}\\,.\n\\] Then \\((\\mathbb{R},\\mathcal{T})\\) is a topological space which is not Hausdorff.\n\nWe start by showing that \\((\\mathbb{R},\\mathcal{T})\\) is a topological space. We need to check the properties of topologies:\n\n(A1) We have that \\[\n(\\infty,\\infty) = \\emptyset \\in \\mathcal{T}\\,, \\quad (-\\infty,\\infty) = \\mathbb{R}\\in \\mathcal{T}\\,.\n\\]\n(A2) Suppose that \\(A_i \\in \\mathcal{T}\\) for all \\(i \\in I\\). By definition \\[\nA_i = (-\\infty, a_i) \\,, \\quad - \\infty \\leq a_i \\leq \\infty \\,.\n\\] Set \\[\na := \\sup_{i \\in I} \\ a_i \\,, \\quad A := (-\\infty, a) \\,.\n\\] Note that \\(a\\) always exists, and possibly \\(a=\\infty\\). Moreover \\(A \\in \\mathcal{T}\\). We claim \\[\nA = \\bigcup_{i \\in I} \\, A_i \\,.\n  \\tag{3.8}\\] To prove (3.8) first suppose that \\(x \\in A\\). Then \\(x &lt; a\\). Set \\(\\varepsilon:= a - x\\), so that \\(\\varepsilon&gt;0\\). By definition of supremum there exists \\(i_{0} \\in I\\) such that \\[\na - \\varepsilon&lt; a_{i_0} \\,.\n\\] From the above, and from the definition of \\(\\varepsilon\\), we deduce \\[\na_{i_0} &gt; a - \\varepsilon= a - a + x = x \\,,\n\\] showing that \\(x \\in (-\\infty, a_{i_0}) = A_{i_0}\\). Therefore \\[\nA \\subseteq \\bigcup_{i \\in I} \\, A_i \\,.\n\\] Conversely, assume that \\(x \\in \\cup_{i \\in I} \\, A_i\\). Therefore there exists \\(i_0 \\in I\\) such that \\(x \\in A_{i_0} = (-\\infty, a_{i_0})\\). In particular \\[\nx &lt; a_{i_0} \\leq \\sup_{i \\in I} a_i = a \\,,\n\\] showing that \\(x \\in (-\\infty,a) = A\\). Therefore \\[\n\\bigcup_{i \\in I} \\, A_i \\subseteq A\\,,\n\\] and (3.8) is proven.\n(A3) Let \\(A, B \\in \\mathcal{T}\\). Therefore \\[\nA = (-\\infty, a)\\,, \\quad B = (-\\infty, b)\\,,\n\\] for some \\(a,b \\in [-\\infty, \\infty]\\). Set \\[\nU := A \\cap B \\,, \\quad z:= \\min \\{a,b\\} \\,.\n\\] It is immediate to check that \\[\nU = (-\\infty, z) \\,,\n\\] showing that \\(U \\in \\mathcal{T}\\).\n\nTherefore \\((\\mathbb{R},\\mathcal{T})\\) is a topological space. We now show that \\((\\mathbb{R},\\mathcal{T})\\) is not Hausdorff. Suppose by contradiction that \\((\\mathbb{R},\\mathcal{T})\\) is Hausdorff. Let \\(x,y \\in \\mathbb{R}\\) with \\(x \\neq y\\). By assumption there exist \\(U,V \\in \\mathcal{T}\\) such that \\[\nx \\in U \\,, \\quad y \\in V \\,, \\quad U \\cap V = \\emptyset \\,.\n\\] By definition of \\(\\mathcal{T}\\) there exist \\(a,b \\in [-\\infty,\\infty]\\) such that \\[\nU = (-\\infty,a) \\,, \\quad V = (- \\infty, b) \\,.\n\\] Since \\(x \\in U\\) and \\(y \\in V\\), in particular \\(U\\) and \\(V\\) are non-empty. Therefore \\(a,b&gt;-\\infty\\). Set \\[\nz := \\min\\{a , b \\}\\,, \\quad Z:= U \\cap V = (-\\infty,z) \\,.\n\\] As \\(a,b&gt;-\\infty\\), we have \\(z &gt; - \\infty\\). Therefore \\(Z \\neq \\emptyset\\). This is a contradiction, since \\(U \\cap V = \\emptyset\\). Therefore \\((\\mathbb{R},\\mathcal{T})\\) is not Hausdorff.\n\n\n\nIn Hausdorff spaces the limit of a sequence is unique.\n\nProposition 57: Uniqueness of limit in Hausdorff spacesLet \\((X,\\mathcal{T})\\) be a Hausdorff space. If a sequence \\(\\{x_n\\} \\subseteq X\\) converges, then the limit is unique.\n\n\n\nProofLet \\(\\{x_n\\} \\subseteq X\\) be a convergent sequence. Suppose by contradiction that \\[\nx_n \\to x_0 \\,, \\quad x_n \\to y_0\n\\] in \\(X\\), for some \\(x_0,y_0 \\in X\\) with \\(x_0 \\neq y_0\\). Since \\(X\\) is Hausdorff, there exist \\(U,V \\in \\mathcal{T}\\) such that \\[\nx_0 \\in U \\,, \\quad y_0 \\in V \\,, \\quad U \\cap V = \\emptyset \\,.\n\\] As \\(x_n \\to x_0\\) and \\(U \\in \\mathcal{T}\\) with \\(x_0 \\in U\\), there exists \\(N_1 \\in \\mathbb{N}\\) such that \\[\nx_n \\in U \\,, \\quad \\forall \\, n \\geq N_1  \\,.\n\\] Similarly, since \\(x_n \\to y_0\\) and \\(V \\in \\mathcal{T}\\) with \\(y_0 \\in U\\), there exists \\(N_2 \\in \\mathbb{N}\\) such that \\[\nx_n \\in V \\,, \\quad \\forall \\, n \\geq N_2  \\,.\n\\] Take \\(N:=\\max\\{N_1,N_2\\}\\). Then \\[\nx_n \\in U \\cap V \\,, \\quad \\forall \\, n \\geq N  \\,.\n\\] Since \\(U \\cap V = \\emptyset\\), the above is a contradiction. Therefore the limit of \\(x_n\\) is unique.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#continuity",
    "href": "sections/chap_3.html#continuity",
    "title": "3  Topology",
    "section": "3.8 Continuity",
    "text": "3.8 Continuity\nWe extend the notion of continuity to topological spaces. To this end, we need the concept of pre-image of a set under a function.\n\nDefinition 58: Images and Pre-images\nLet \\(X, Y\\) be sets and \\(f \\colon X \\to Y\\) be a function.\n\nLet \\(U \\subseteq X\\). The image of \\(U\\) under \\(f\\) is the subset of \\(Y\\) defined by \\[\nf (U) := \\{ y \\in Y \\, \\colon \\,\\exists \\, x \\in X \\, \\text{ s.t. } \\, y = f(x) \\} = \\{ f(x) \\, \\colon \\,x \\in X \\} \\,.\n\\]\nLet \\(V \\subseteq Y\\). The pre-image of \\(V\\) under \\(f\\) is the subset of \\(X\\) defined by \\[\nf^{-1} (V) := \\{ x \\in X \\, \\colon \\,f(x) \\in V \\} \\,.\n\\]\n\n\n\n\nWarningThe notation \\(f^{-1}(V)\\) does not mean that we are inverting \\(f\\). In fact, the pre-image is defined for all functions.\n\n\nLet us gather useful properties of images and pre-images.\n\nProposition 59Let \\(X,Y\\) be sets and \\(f \\colon X \\to Y\\). We denote with the letter \\(A\\) sets in \\(X\\) and with the letter \\(B\\) sets in \\(Y\\). We have\n\n\\(A \\subseteq f^{-1}(f(A))\\)\n\\(A = f^{-1}(f(A))\\) if \\(f\\) is injective\n\\(f(f^{-1}(B)) \\subseteq B\\)\n\\(f(f^{-1}(B)) = B\\) if \\(f\\) is surjective\nIf \\(A_1 \\subseteq A_2\\) then \\(f(A_1) \\subseteq f(A_2)\\)\nIf \\(B_1 \\subseteq B_2\\) then \\(f^{-1}(B_1) \\subseteq f^{-1}(B_2)\\)\nIf \\(A_i \\subseteq X\\) for \\(i \\in I\\) we have \\[\\begin{gather*}\nf \\left(  \\bigcup_{i \\in I} A_i \\right)  = \\bigcup_{i \\in I} f(A_i) \\\\\nf \\left(  \\bigcap_{i \\in I} A_i \\right)  \\subseteq \\bigcap_{i \\in I} f(A_i)\n\\end{gather*}\\]\nIf \\(B_i \\subseteq Y\\) for \\(i \\in I\\) we have \\[\\begin{gather*}\nf^{-1} \\left(  \\bigcup_{i \\in I} B_i \\right)  = \\bigcup_{i \\in I} f^{-1}(B_i) \\\\\nf^{-1} \\left(  \\bigcap_{i \\in I} B_i \\right)  = \\bigcap_{i \\in I} f^{-1}(B_i)\n\\end{gather*}\\]\n\nSuppose \\(Z\\) is another set and \\(g \\colon Y \\to Z\\). Let \\(C \\subseteq Z\\). Then \\[\\begin{align*}\n& (g \\circ f)(A)  = g(f(A)) \\\\\n& (g \\circ f)^{-1}(C)  = f^{-1}(g^{-1}(C))\n\\end{align*}\\]\n\n\nIt is a good exercise to try and prove a few of the above properties. We omit the proof. We can now define continuous functions between topological spaces.\n\nDefinition 60: Continuous function\nLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Let \\(f \\colon X \\to Y\\) be a function.\n\nLet \\(x_0 \\in X\\). We say that \\(f\\) is continuous at \\(x_0\\) if it holds: \\[\n\\forall \\, V \\in \\mathcal{T}_Y \\, \\text{ s.t. } \\, f(x_0) \\in V \\,, \\,\\, \\exists \\, U \\in \\mathcal{T}_X \\, \\text{ s.t. } \\, x_0 \\in U \\,, \\,\\, f(U) \\subseteq V \\,.\n\\]\nWe say that \\(f\\) is continuous from \\((X,\\mathcal{T}_X)\\) to \\((Y,\\mathcal{T}_Y)\\) if \\(f\\) is continuous at each point \\(x_0 \\in X\\).\n\n\n\nThe following proposition presents a useful characterization of continuous functions in terms of pre-images.\n\nProposition 61\nLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Let \\(f \\colon X \\to Y\\) be a function. They are equivalent:\n\n\\(f\\) is continuous from \\((X,\\mathcal{T}_X)\\) to \\((Y,\\mathcal{T}_Y)\\).\nIt holds: \\[\nf^{-1}(V) \\in \\mathcal{T}_X  \\,, \\quad \\forall \\, V \\in \\mathcal{T}_Y \\,.\n\\]\n\n\n\n\nImportantIn other words, a function \\(f \\colon X \\to Y\\) is continuous if and only if the pre-image of open sets in \\(Y\\) are open sets in \\(X\\).\n\n\nThe proof of Proposition 61 is simple, but very tedious. We choose to skip it.\n\nExample 62\nLet \\(X\\) be a set and \\(\\mathcal{T}_1\\), \\(\\mathcal{T}_2\\) be topologies on \\(X\\). Define the identity map \\[\n{\\mathop{\\mathrm{Id}}}_{X} \\colon (X,\\mathcal{T}_1) \\to (X,\\mathcal{T}_2)  \\,, \\quad {\\mathop{\\mathrm{Id}}}_{X} (x):= x \\,.\n\\] They are equivalent:\n\n\\({\\mathop{\\mathrm{Id}}}_{X}\\) is continuous from \\((X,\\mathcal{T}_1)\\) to \\((X,\\mathcal{T}_2)\\).\n\\(\\mathcal{T}_1\\) is finer than \\(\\mathcal{T}_2\\) \\[\n\\mathcal{T}_2 \\subseteq \\mathcal{T}_1 \\,.\n\\]\n\n\nIndeed, \\({\\mathop{\\mathrm{Id}}}_{X}\\) is continuous if and only if \\[\n{\\mathop{\\mathrm{Id}}}_{X}^{-1} (V) \\in \\mathcal{T}_1  \\,, \\quad \\forall \\, V \\in \\mathcal{T}_2 \\,.\n\\] But \\({\\mathop{\\mathrm{Id}}}_{X}^{-1} (V) = V\\), so that the above reads \\[\nV \\in \\mathcal{T}_1  \\,, \\quad \\forall \\, V \\in \\mathcal{T}_2 \\,,\n\\] which is equivalent to \\(\\mathcal{T}_2 \\subseteq \\mathcal{T}_1\\).\n\n\n\nLet us compare our new definition of contiuity with the classical notion of continuity in \\(\\mathbb{R}^n\\). Let us recall the definition of continuous function in \\(\\mathbb{R}^n\\).\n\nDefinition 63: Continuity in the classical senseLet \\(f \\colon \\subseteq \\mathbb{R}^n \\to \\mathbb{R}^m\\). We say that \\(f\\) is continuous at \\(\\mathbf{x}_0\\) if it holds: \\[\n\\forall \\, \\varepsilon&gt; 0 \\,, \\, \\exists \\, \\delta &gt;0 \\, \\text{ s.t. } \\, \\|f(\\mathbf{x}) - f(\\mathbf{x}_0)\\|&lt; \\varepsilon\\,\\, \\mbox{ if } \\,\\, \\| \\mathbf{x}- \\mathbf{x}_0 \\| &lt; \\delta \\,.   \n\\]\n\n\n\nProposition 64\nLet \\(f \\colon  \\mathbb{R}^n \\to \\mathbb{R}^m\\) and suppose \\(\\mathbb{R}^n,\\mathbb{R}^m\\) are equipped with the Euclidean topology. Let \\(\\mathbf{x}_0 \\in \\mathbb{R}^n\\). They are equivalent:\n\n\\(f\\) is continuous at \\(\\mathbf{x}_0\\) in the topological sense.\n\\(f\\) is continuous at \\(\\mathbf{x}_0\\) in the classical sense.\n\n\n\n\nProofPart 1. Suppose that \\(f\\) is continuous at \\(\\mathbf{x}_0\\) in the topological sense. Let \\(\\varepsilon&gt;0\\) and consider the set \\[\nV := B_{\\varepsilon}(f(\\mathbf{x}_0))\\,.\n\\] We have that \\(V \\subset \\mathbb{R}^m\\) is open and \\(f(\\mathbf{x}_0) \\in V\\). As \\(f\\) is continuous in the topological sense, there exists \\(U \\subset \\mathbb{R}^n\\) open with \\(\\mathbf{x}_0 \\in U\\) and such that \\[\nf(U) \\subset V = B_{\\varepsilon}(f(\\mathbf{x}_0)) \\,.\n\\tag{3.9}\\] Since \\(U\\) is open and \\(\\mathbf{x}_0 \\in U\\), there exists \\(\\delta&gt;0\\) such that \\[\nB_{\\delta}(\\mathbf{x}_0) \\subset U \\,.\n\\] By the above inclusion and (3.9) we conclude that \\[\nf(B_{\\delta}(\\mathbf{x}_0)) \\subset f(U) \\subset V = B_{\\varepsilon}(f(\\mathbf{x}_0)) \\,.\n\\] This is equivalent to \\[\n\\mathbf{x}\\in B_{\\delta}(\\mathbf{x}_0) \\quad \\implies  \\quad f(\\mathbf{x}) \\in B_{\\varepsilon}(f(\\mathbf{x}_0))\\,,\n\\] which reads \\[\n\\| \\mathbf{x}- \\mathbf{x}_0 \\| &lt; \\delta \\quad \\implies \\quad\n\\| f(\\mathbf{x}) - f(\\mathbf{x}_0) \\| &lt; \\varepsilon\\,.\n\\] Therefore \\(f\\) is continuous at \\(\\mathbf{x}_0\\) in the classical sense.\nPart 2. Suppose \\(f\\) is continuous at \\(x_0\\) in the classical sense. Let \\(V \\subset \\mathbb{R}^m\\) be open and such that \\(f(\\mathbf{x}_0) \\in V\\). Since \\(V\\) is open, there exists \\(\\varepsilon&gt;0\\) such that \\[\nB_{\\varepsilon} (f(\\mathbf{x}_0)) \\subset V \\,.\n\\tag{3.10}\\] Since \\(f\\) is continous in the classical sense, there exists \\(\\delta&gt;0\\) such that \\[\n  \\| \\mathbf{x}- \\mathbf{x}_0 \\| &lt; \\delta \\quad \\implies \\|f(\\mathbf{x}) - f(\\mathbf{x}_0)\\|&lt; \\varepsilon\\,.\n\\] The above is equivalent to \\[\n\\mathbf{x}\\in B_{\\delta}(\\mathbf{x}_0)  \\quad \\implies \\quad f(\\mathbf{x}) \\in B_{\\varepsilon} (f (\\mathbf{x}_0))  \\,.\n\\tag{3.11}\\] Set \\[\nU:= B_{\\delta}(\\mathbf{x}_0)\n\\] and note that \\(U\\) is open in \\(\\mathbb{R}^n\\) and \\(\\mathbf{x}_0 \\in U\\). By definition of image of a set, (3.11) reads \\[\nf(U) = f( B_{\\delta}(\\mathbf{x}_0))   \\subseteq  B_{\\varepsilon} (f(\\mathbf{x}_0)) \\,.\n\\] Recalling (3.10) we conclude that \\[\nf(U) \\subset V \\,.\n\\] In summary, we have shown that given \\(V \\subset \\mathbb{R}^m\\) open and such that \\(f(\\mathbf{x}_0) \\in V\\), there exists \\(U\\) open in \\(\\mathbb{R}^n\\) such that \\(\\mathbf{x}_0 \\in U\\) and \\(f(U) \\subset V\\). Therefore \\(f\\) is continuous at \\(\\mathbf{x}_0\\) in the topological sense.\n\n\nA similar proof yields the characterization of continuity in metric spaces. The proof is left as an exercise.\n\nProposition 65\nLet \\((X,d_X)\\) and \\((Y,d_Y)\\) be metric spaces. Denote by \\(\\mathcal{T}_X\\) and \\(\\mathcal{T}_Y\\) the topologies induced by the metrics. Let \\(f \\colon X \\to Y\\) and \\(x_0 \\in X\\). They are equivalent:\n\n\\(f\\) is continuous at \\(x_0\\) in the topological sense.\nIt holds: \\[\n\\forall \\, \\varepsilon&gt; 0 \\,, \\, \\exists \\, \\delta &gt;0 \\, \\text{ s.t. } \\, \\, d_Y(f(x),f(x_0))&lt;\\varepsilon\\,\\,\n\\mbox{ if } \\,\\, d_X(x , x_0) &lt; \\delta \\,.\n\\]\n\n\n\nLet us examine continuity in the cases of the trivial and discrete topologies.\n\nExample 66\nLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be a topological space. Suppose that \\(\\mathcal{T}_Y\\) is the trivial topology, that is, \\[\n\\mathcal{T}_Y = \\{ \\emptyset, Y \\} \\,.\n\\] Then every function \\(f \\colon X \\to Y\\) is continuous.\n\nIndeed, we know that \\(f\\) is continuous if and only if it holds: \\[\nf^{-1}(V) \\in \\mathcal{T}_X \\,, \\quad \\forall \\,\\, V \\in \\mathcal{T}_Y \\,.\n\\] We have two cases:\n\n\\(V=\\emptyset\\): Then \\[\nf^{-1}(V) = f^{-1}(\\emptyset) = \\emptyset \\in \\mathcal{T}_X \\,.\n\\]\n\\(V=Y\\): Then \\[\nf^{-1}(V) = f^{-1}(Y) = X \\in \\mathcal{T}_X \\,.\n\\]\n\nTherefore \\(f\\) is continuous.\n\n\n\n\nExample 67\nLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Suppose that \\(\\mathcal{T}_Y\\) is the discrete topology, that is, \\[\n\\mathcal{T}_Y = \\{ V \\, \\text{ s.t. } \\, V \\subseteq Y \\} \\,.\n\\] Let \\(f \\colon X \\to Y\\). They are equivalent:\n\n\\(f\\) is continuous from \\(X\\) to \\(Y\\).\n\\(f^{-1}(\\{y\\}) \\in \\mathcal{T}_X\\) for all \\(y \\in Y\\).\n\n\nIndeed, suppose that \\(f\\) is continuous. Then \\[\nf^{-1}(V) \\in \\mathcal{T}_X \\,, \\quad \\forall \\,\\, V \\in \\mathcal{T}_Y \\,.\n\\] As \\(V=\\{y\\} \\in \\mathcal{T}_Y\\), we conclude that \\(f^{-1}(\\{y\\}) \\in \\mathcal{T}_X\\).\nConversely, assume that \\(f^{-1}(\\{y\\}) \\in \\mathcal{T}_X\\) for all \\(y \\in Y\\). Let \\(V \\in \\mathcal{T}_Y\\). Trivially, we have \\[\nV = \\bigcup_{y \\in V} \\, \\{ y \\} \\,.\n\\] Therefore \\[\nf^{-1}(V) = f^{-1}\\left( \\bigcup_{y \\in V}\\, \\{ y \\} \\right) = \\bigcup_{y \\in V} \\, f^{-1}( \\{y \\} ) \\,.\n\\] As \\(f^{-1}( \\{y \\}) \\in \\mathcal{T}_X\\) for all \\(y \\in Y\\), by property (A2) we conclude that \\(f^{-1}(V) \\in \\mathcal{T}_X\\). Therefore \\(f\\) is continuous.\n\n\n\nIn a topological space, continuity preserves limits of sequences.\n\nProposition 68Let \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Let \\(f \\colon X \\to Y\\) be continuous. Let \\(\\{x_n\\} \\subset X\\) and \\(x_0 \\in X\\). We have \\[\nx_n \\to x_0 \\,\\, \\mbox{ in }\\, X \\quad \\implies \\quad\nf(x_n) \\to f(x_0) \\,\\, \\mbox{ in }\\, Y\\,.\n\\]\n\n\n\nProofLet \\(V \\in \\mathcal{T}_Y\\) be such that \\(f(x_0) \\in V\\). Since \\(f\\) is continuous there exists \\(U \\in \\mathcal{T}_X\\) with \\(x_0 \\in U\\) such that \\[\nf(U) \\subset V \\,.\n\\] Since \\(U \\in \\mathcal{T}_X\\) and \\(x_n \\to x_0\\) in \\(X\\), there exists \\(N \\in \\mathbb{N}\\) such that \\[\nx_n \\in U \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Therefore \\[\nf(x_n) \\in f(U) \\,, \\quad \\forall \\, n \\geq N \\,.\n\\] Seeing that \\(f(U) \\subset V\\), we conclude \\[\nf(x_n) \\in V \\,, \\quad \\forall \\, n \\geq N \\,,\n\\] showing that \\(f(x_n) \\to f(x_0)\\) in \\(Y\\).\n\n\n\nWarningThe converse implication of Proposition 68 is false. That is, even if it holds \\[\nx_n \\to x_0 \\,\\, \\mbox{ in }\\, X \\quad \\implies \\quad\nf(x_n) \\to f(x_0) \\,\\, \\mbox{ in }\\, Y\\,.\n\\] for all sequences \\(\\{x_n\\} \\subset X\\), the function \\(f\\) might not be continuous. A counterexample is given in Example 70 below.\nFor the above to hold, it is necessary for the topologies on \\(X\\) and \\(Y\\) to be first countable, as for example is the case for metrizable topologies, see Proposition 69 below.\n\n\n\nProposition 69Let \\((X,d_X)\\) and \\((Y,d_Y)\\) be metric spaces. Let \\(f \\colon X \\to Y\\) and suppose that for all convergent sequences \\(\\{x_n\\} \\subseteq X\\), the sequence \\(\\{f(x_n)\\}\\) is convergent in \\(Y\\). Then \\(f\\) is continuous.\n\n\n\nProofSuppose by contradiction \\(f\\) is not continuous at some point \\(x_0 \\in X\\). Then there exists \\({\\varepsilon}_0 &gt;0\\) such that, for all \\(\\delta&gt;0\\) it holds \\[\nd_Y(f(x),f(x_0)) &gt; \\varepsilon_0 \\,, \\quad d_X(x,x_0)&lt;\\delta \\,.\n\\] We can therefore choose \\(\\delta = 1/n\\) and construct a sequence \\(\\{x_n\\} \\subseteq X\\) such that \\[\nd_Y(f(x_n),f(x_0)) &gt; \\varepsilon_0 \\,, \\quad d_X(x_n,x_0)&lt; \\frac{1}{n} \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\] Therefore \\(x_n \\to x_0\\) in \\(X\\). Define the sequence \\[\ny_n :=\n\\begin{cases}\nx_n  & \\,\\, \\mbox{ if } \\, n \\, \\mbox{ even} \\\\\nx_0  & \\,\\, \\mbox{ if } \\, n \\, \\mbox{ odd}\n\\end{cases}\n\\] As \\(x_n \\to x_0\\), we have \\(y_n \\to x_0\\). However \\(\\{f(y_n)\\}\\) does not converge to any point in \\(Y\\): Indeed \\(\\{f(y_n)\\}\\) cannot converge to \\(f(x_0)\\), since for \\(n\\) even we have \\[\nd_Y(f(y_n),f(x_0)) = d_Y(f(x_n),f(x_0)) &gt; \\varepsilon_0 \\,.\n\\] Also \\(\\{f(y_n)\\}\\) cannot converge to a point \\(y \\neq f(x_0)\\), since for \\(n\\) odd \\[\nd_Y (f(y_n), y) = d_Y (f(x_0), y) &gt; 0 \\,.\n\\] Hence, we have produced a sequence \\(\\{y_n\\}\\) which is convergent, but such that \\(\\{f(y_n)\\}\\) does not converge. This contradicts our assumption. Hence \\(f\\) must be continuous.\n\n\n\nExample 70\nConsider \\(\\mathbb{R}\\) with the co-countable topology: \\[\n{\\mathcal{T}}_{\\textrm{cc}} := \\{ A \\subseteq \\mathbb{R}\\, \\colon \\,A^c = \\mathbb{R}\\, \\mbox{ or } \\, A^c \\, \\mbox{ countable} \\} \\,.\n\\] Sequences in \\((\\mathbb{R},{\\mathcal{T}}_{\\textrm{cc}})\\) converge if and only if they are eventually constant. Also consider the discrete topology on \\(\\mathbb{R}\\), denoted by \\({\\mathcal{T}}_{\\textrm{discrete}}\\). We have seen that sequences in \\((\\mathbb{R},{\\mathcal{T}}_{\\textrm{discrete}})\\) converge if and only if they are eventually constant. Consider the identity function \\[\nf \\colon (\\mathbb{R},{\\mathcal{T}}_{\\textrm{cc}}) \\to (\\mathbb{R},{\\mathcal{T}}_{\\textrm{discrete}}) \\,, \\quad f(x):=x \\,.\n\\] We have that:\n\n\\(f\\) is not continuous: Indeed \\(\\{x\\} \\in {\\mathcal{T}}_{\\textrm{discrete}}\\) but \\[\nf^{-1}(\\{ x\\}) = \\{x\\} \\notin {\\mathcal{T}}_{\\textrm{cc}} \\,,\n\\] since \\(\\{x\\}^c\\) is neither \\(\\mathbb{R}\\), nor countable.\nIf \\(\\{x_n\\}\\) is convergent in \\({\\mathcal{T}}_{\\textrm{cc}}\\), then it is eventually constant. Therefore \\(\\{f(x_n)\\}\\) is eventually constant, and so it is convergent in \\({\\mathcal{T}}_{\\textrm{discrete}}\\).\n\n\n\nLet us make an observation on continuity of compositions.\n\nProposition 71Let \\((X,\\mathcal{T}_X), (Y,\\mathcal{T}_Y), (Z,\\mathcal{T}_Z)\\) be topological spaces. Let \\[\nf \\colon X \\to Y \\,, \\quad g \\colon Y \\to Z \\,,\n\\] be given functions. If \\(f\\) and \\(g\\) are continuous, then \\[\n(g \\circ f) \\colon X \\to Z\n\\] is continuous.\n\n\n\nProofLet \\(C \\in \\mathcal{T}_Z\\). As \\(g\\) is continuous, we have that \\[\ng^{-1}(C) \\in \\mathcal{T}_Y \\,.\n\\] Since \\(f\\) is continuous, we also have \\[\nf^{-1} ( g^{-1}(C) ) \\in \\mathcal{T}_X \\,.\n\\] Therefore \\[\n(g \\circ f)^{-1} ( C ) = f^{-1} ( g^{-1}(C) ) \\in \\mathcal{T}_X \\,,\n\\] so that \\(g \\circ f\\) is continuous.\n\n\nWe conclude the section by introducing homeomorphisms.\n\nDefinition 72: Homeomoprhim\nLet \\((X,\\mathcal{T}_X)\\), \\((Y,\\mathcal{T}_Y)\\) be topological space. A function \\(f \\colon X \\to Y\\) is called an homeomorphism if they hold:\n\n\\(f\\) is continuous.\nThere exists \\(g \\colon Y \\to X\\) continuous such that \\[\ng \\circ f = {\\mathop{\\mathrm{Id}}}_{X} \\,, \\quad f \\circ g = {\\mathop{\\mathrm{Id}}}_{Y}  \\,.\n\\]\n\n\n\nThe above is saying that \\(f\\) is a homeomorphism if it is continuous and has continuous inverse. Homeomorphisms are the way we say that two topological spaces look the same.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#subspace-topology",
    "href": "sections/chap_3.html#subspace-topology",
    "title": "3  Topology",
    "section": "3.9 Subspace topology",
    "text": "3.9 Subspace topology\nAny subset \\(Y\\) in a topological space \\(X\\) inherits naturally a topological structure. Such structure is called subspace topology.\n\nDefinition 73: Subspace topologyLet \\((X,\\mathcal{T})\\) be a topological space and \\(Y \\subseteq X\\) a subset. Define the family of sets \\[\n\\mathcal{S}:= \\{ A \\subset Y \\, \\colon \\,\\exists \\,\\, U \\in \\mathcal{T}\\, \\text{ s.t. } \\, A = U \\cap Y   \\} \\,.\n\\] The family \\(\\mathcal{S}\\) is called subspace topology on \\(Y\\) induced by the inclusion \\(Y \\subset X\\).\n\n\n\nProof: Well-posedness of Definition 73\nWe have to show that \\((Y,\\mathcal{S})\\) is a topological space:\n\n(A1) \\(\\emptyset \\in \\mathcal{S}\\) since \\[\n\\emptyset = \\emptyset \\cap Y\n\\] and \\(\\emptyset \\in \\mathcal{T}\\). Similarly we have \\(Y \\in \\mathcal{S}\\), since \\[\nY = X \\cap Y \\,,\n\\] and \\(X \\in \\mathcal{T}\\).\n(A2) Let \\(A_i \\in \\mathcal{S}\\) for \\(i \\in I\\). By definition there exist \\(U_i \\in \\mathcal{T}\\) such that \\[\nA_i =  U_i \\cap Y \\,, \\quad \\forall \\, i \\in I \\,.\n\\] Therefore \\[\n\\bigcup_{i \\in I} \\, A_i =\n\\bigcup_{i \\in I} (U_i \\cap Y ) =\n\\left(\\bigcup_{i \\in I} U_i \\right) \\cap Y  \\,.\n\\] The above proves that \\(\\cup_{i \\in I} \\, A_i \\in \\mathcal{S}\\), since \\(\\cup_{i \\in I} \\, U_i \\in \\mathcal{T}\\).\n(A3) Let \\(A_1, A_2 \\in \\mathcal{S}\\). By definition there exist \\(U_1,U_2 \\in \\mathcal{T}\\) such that \\[\nA_1 =  U_1 \\cap Y \\,, \\quad\nA_2 =  U_2 \\cap Y\n\\] Therefore \\[\nA_1 \\cap A_2  = (  U_1 \\cap Y ) \\cap (U_2 \\cap Y) = (U_1 \\cap U_2) \\cap Y\n\\] The above proves that \\(A_1 \\cap A_2  \\in \\mathcal{S}\\), since \\(U_1 \\cap U_2 \\in \\mathcal{T}\\).\n\n\n\nIf the set \\(Y\\) is open, then sets are open in the subspace topology if and only if they are open in \\(X\\).\n\nProposition 74Let \\((X,\\mathcal{T})\\) be a topological space and \\(Y \\in \\mathcal{T}\\) a subset. Let \\(A \\subset Y\\). Then \\[\nA \\in \\mathcal{S}\\quad \\iff \\quad A \\in \\mathcal{T}\\,.\n\\]\n\n\n\nProofSuppose \\(A \\in \\mathcal{S}\\). Then there exists \\(U \\in \\mathcal{T}\\) such that \\[\nA = U \\cap Y \\,.\n\\] Since \\(U, Y \\in \\mathcal{T}\\), by property (A3) of topologies it follows that \\[\nA = U \\cap Y  \\in \\mathcal{T}\\,.\n\\]\nConversely, assume that \\(A \\in \\mathcal{T}\\). Then \\[\nA = A \\cap Y \\,,\n\\] showing that \\(A \\in \\mathcal{S}\\).\n\n\n\nWarning\nLet \\((X,\\mathcal{T})\\) be a topological space, \\(A \\subset Y \\subset X\\). In general we could have \\[\nA \\in \\mathcal{S}\\quad \\mbox{and} \\quad A \\notin \\mathcal{T}\n\\]\n\nFor example consider \\(X=\\mathbb{R}\\) with \\(\\mathcal{T}\\) the euclidean topology. Consider the subset \\(Y = [0,2)\\) and equip \\(Y\\) with the subspace topology \\(\\mathcal{S}\\). Let \\(A = [0,1)\\). Then \\(A \\notin \\mathcal{T}\\) but \\(A \\in \\mathcal{S}\\), since \\[\nA =  (-1,1)  \\cap Y\n\\] and \\((-1,1) \\in \\mathcal{T}\\).\n\n\n\n\nExample 75\nLet \\(X=\\mathbb{R}\\) be equipped with \\(\\mathcal{T}\\) the euclidean topology. Let \\(\\mathcal{S}\\) be the subspace topology on \\(\\mathbb{Z}\\). Then \\(\\mathcal{S}\\) coincides with the discrete topology.\n\nProof. The set \\(\\{z\\}\\) is open in \\(\\mathcal{S}\\) for all \\(z \\in \\mathbb{Z}\\). Indeed, \\[\n\\{z\\} = \\left(  z-1 , z + 1   \\right)   \\cap \\mathbb{Z}\\,\n\\] and \\((z - 1, z + 1) \\in \\mathcal{T}\\). Thus \\(\\{z\\} \\in \\mathcal{S}\\). Let now \\(A \\subseteq \\mathbb{Z}\\). Then \\[\nA = \\bigcup_{z \\in A} \\, \\{ z \\} \\,,\n\\] and therefore \\(A \\in \\mathcal{S}\\) by (A2). This proves that \\[\n\\mathcal{S}= \\{ A \\, \\text{ s.t. } \\, A \\subseteq \\mathbb{Z}\\} \\,,\n\\] that is, \\(\\mathcal{S}\\) is the discrete topology on \\(\\mathbb{Z}\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#topological-basis",
    "href": "sections/chap_3.html#topological-basis",
    "title": "3  Topology",
    "section": "3.10 Topological basis",
    "text": "3.10 Topological basis\nWe have seen that in metric spaces every open set is union of open balls, see Propostion 27. We can then regard the open balls as building blocks for the whole topology. In this context, we call the open balls a basis for the topology.\nWe can generalize the concept of basis to arbitrary topological spaces.\n\nDefinition 76: Topological basisLet \\((X,\\mathcal{T})\\) be a topological space and let \\(\\mathcal{B} \\subseteq \\mathcal{T}\\). We say that \\(\\mathcal{B}\\) is a topological basis for the topology \\(\\mathcal{T}\\) if for all \\(U \\in \\mathcal{T}\\) there exist open sets \\(\\{B_i\\} \\subseteq \\mathcal{B}\\), with \\(I\\) family of indices, such that \\[\nU = \\bigcup_{i \\in I} \\, B_i \\,.\n\\tag{3.12}\\]\n\n\n\nExample 77\n\nLet \\((X,\\mathcal{T})\\) be a topological space. Then \\(\\mathcal{B}:=\\mathcal{T}\\) is a basis for \\(\\mathcal{T}\\).\n\n\nThis is true because one can just take \\(B=U\\) in (3.12).\n\n\n\\((X,d)\\) metric space with topology \\(\\mathcal{T}_d\\) induced by the metric. Then \\[\n\\mathcal{B} :=\\{ B_r(x) \\, \\colon \\,x \\in X \\,, \\,\\, r&gt;0  \\}\n\\] is a basis for \\(\\mathcal{T}_d\\).\n\n\nThis is true by Propostion 27.\n\n\nLet \\((X,\\mathcal{T})\\) with \\(X\\) the discrete topology. Then \\[\n\\mathcal{B}:=\\{   \\{x\\}  \\, \\colon \\,x \\in X \\}\n\\] is a basis for \\(\\mathcal{T}\\).\n\n\nThis is true because for any \\(U \\in \\mathcal{T}\\) we have \\[\nU = \\bigcup_{ x \\in U }  \\, \\{x\\} \\,.\n\\]\n\n\n\n\nProposition 78\nLet \\((X,\\mathcal{T})\\) be a topological space and \\(\\mathcal{B}\\) a basis for \\(\\mathcal{T}\\). They hold:\n\n(B1) We have \\[\n\\bigcup_{B \\in \\mathcal{B}} \\, B = X \\,.\n\\]\n(B2) If \\(U_1,U_2 \\in \\mathcal{B}\\) then there exist \\(\\{B_i \\} \\subseteq \\mathcal{B}\\) such that \\[\nU_1 \\cap U_2 = \\bigcup_{i \\in I} \\, B_i \\,.\n\\]\n\n\n\n\nProof\n\n(B1) This holds because \\(X \\in \\mathcal{T}\\). Therefore by definition of basis there exist \\(B_i \\in \\mathcal{B}\\) such that \\[\nX = \\bigcup_{i \\in I} \\, B_i  \\,.\n\\] Therefore taking the union over all \\(B \\in \\mathcal{B}\\) yields \\(X\\), and (B1) follows.\n(B2) Let \\(U_1 , U_2 \\in \\mathcal{B}\\). Then \\(U_1 , U_2 \\in \\mathcal{T}\\), since \\(\\mathcal{B} \\subseteq \\mathcal{T}\\). By property (A3) we get that \\(U_1 \\cap U_2 \\in \\mathcal{T}\\). Since \\(\\mathcal{B}\\) is a basis we conclude (B2).\n\n\n\nProperties (B1) and (B2) from Proposition 78 are sufficient for generating a topology.\n\nProposition 79\nLet \\(X\\) be a set and \\(\\mathcal{B}\\) a collection of subsets of \\(X\\) such that (B1)-(B2) hold. Define \\[\n\\mathcal{T}:= \\left\\{  U \\subseteq X \\, \\colon \\,U = \\bigcup_{i \\in I} B_i \\,, \\,\\, B_i \\in \\mathcal{B}     \\right\\} \\,.\n\\] Then:\n\n\\(\\mathcal{T}\\) is a topology on \\(X\\).\n\\(\\mathcal{B}\\) is a basis for \\(\\mathcal{T}\\).\n\n\n\n\nProof\n\nWe need to verify that \\(\\mathcal{T}\\) is a topology:\n\n\n(A1) We have that \\(X \\in \\mathcal{T}\\) by (B1). Moreover \\(\\emptyset \\in \\mathcal{T}\\), since \\(\\emptyset\\) can be obtained as empty union. Therefore (A1) holds.\n(A2) Let \\(U_i \\in \\mathcal{T}\\) for all \\(i \\in I\\). By definition of \\(\\mathcal{T}\\) we have \\[\nU_i = \\bigcup_{k \\in K_i} \\, B_k^i  \n\\] for some family of indices \\(K_i\\) and \\(B_k^i \\in \\mathcal{B}\\). Therefore \\[\nU := \\bigcup_{i \\in I} \\, U_i  = \\bigcup_{i \\in I, \\, k \\in K_i} \\,  B_k^i \\,,\n\\] showing that \\(U \\in \\mathcal{T}\\).\n(A3) Suppose that \\(U_1, U_2 \\in \\mathcal{T}\\). Then \\[\nU_1 = \\bigcup_{i \\in I_1} \\, B_i^1 \\,, \\quad\nU_2 = \\bigcup_{i \\in I_2} \\, B_i^2\n\\] for \\(B_i^1,B_i^2 \\in \\mathcal{B}\\). From the above we have \\[\nU_1 \\cap U_2 = \\bigcup_{ i \\in I_1 ,\\, k \\in I_2 } \\, B_i^1 \\cap B_k^2 \\,.\n\\] From property (B2) we have that for each pair of indices \\((i,k)\\) the set \\(B_i^1 \\cap B_k^2\\) is the union of sets in \\(\\mathcal{B}\\). Therefore \\(U_1 \\cap U_2\\) is union of sets in \\(\\mathcal{B}\\), showing that \\(U_1 \\cap U_2 \\in \\mathcal{T}\\).\n\n\nThis trivially follows from defintion of \\(\\mathcal{T}\\) and definition of basis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#product-topology",
    "href": "sections/chap_3.html#product-topology",
    "title": "3  Topology",
    "section": "3.11 Product topology",
    "text": "3.11 Product topology\nGiven two topological spaces \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) we would like to equip the cartesian product \\[\nX \\times Y  = \\{  (x,y) \\, \\colon \\,x \\in X \\,, \\,\\, y \\in Y \\}\n\\] with a topology. We proceed as follows.\n\nProposition 80Let \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Define the family \\(\\mathcal{B}\\) of subsets of \\(X \\times Y\\) as \\[\n\\mathcal{B} := \\{   U \\times V \\, \\colon \\,U \\in \\mathcal{T}_X \\,, \\,\\, V \\in \\mathcal{T}_Y  \\} \\subset X \\times Y \\,.\n\\] Then \\(\\mathcal{B}\\) satisfies properties (B1) and (B2) from Proposition 78.\n\n\nThe proof is an easy check, and is left as an exercise. As \\(\\mathcal{B}\\) satisfies (B1)-(B2), by Proposition 79 we know that \\[\n\\mathcal{T}_{X \\times Y} := \\left\\{  U \\times V  \\, \\colon \\,U \\times V = \\bigcup_{i \\in I} B_i \\,, ,\\,\\, B_i \\in \\mathcal{B}     \\right\\}\n\\tag{3.13}\\] is a topology on \\(X \\times Y\\).\n\nDefinition 81: Product topologyLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces. We call \\(\\mathcal{T}_{X \\times Y}\\) at (3.13) the product topology on \\(X \\times Y\\).\n\n\n\nExample 82Let \\(\\mathbb{R}\\) be equipped with the Euclidean topology. The product topology on \\(\\mathbb{R}\\times \\mathbb{R}\\) coincides with the topology on \\(\\mathbb{R}^2\\) equipped with the Euclidean topology.\n\n\nConsider the projection maps \\[\n\\pi_X \\colon X \\times Y \\to X   \\,, \\quad \\pi_X (x,y):=x\n\\] and \\[\n\\pi_Y \\colon X \\times Y \\to Y   \\,, \\quad \\pi_Y (x,y):=y\n\\]\n\nProposition 83Let \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces and equip \\(X \\times Y\\) with the product topology \\(\\mathcal{T}_{X \\times Y}\\). Then \\(\\pi_X\\) and \\(\\pi_Y\\) are continuous.\n\n\n\nProofLet \\(U \\in \\mathcal{T}_X\\). Then \\[\n{\\pi}_{X}^{-1} (U) = U \\times Y \\,.\n\\] We have that \\(U \\times Y \\in \\mathcal{T}_{X \\times Y}\\) since \\(U \\in \\mathcal{T}_X\\) and \\(Y \\in \\mathcal{T}_Y\\). Therefore \\(\\pi_X\\) is continuous. The proof that \\(\\pi_Y\\) is continuous is similar, and is left as an exercise.\n\n\nThe following proposition gives a useful criterion to check whether a map into \\(X \\times Y\\) is continuous.\n\nProposition 84\nLet \\((X,\\mathcal{T}_X)\\) and \\((Y,\\mathcal{T}_Y)\\) be topological spaces and equip \\(X \\times Y\\) with the product topology \\(\\mathcal{T}_{X \\times Y}\\). Let \\((Z,\\mathcal{T}_Z)\\) be a topological space and \\[\nf \\colon Z \\to X \\times Y\n\\] a function. They are equivalent:\n\n\\(f\\) is continuous.\nThe compositions \\[\n\\pi_X \\circ f \\colon Z \\to X  \\,, \\quad  \n\\pi_Y \\circ f \\colon Z \\to Y\n\\] are continuous.\n\n\n\nThe proof is left as an exercise.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#connectedness",
    "href": "sections/chap_3.html#connectedness",
    "title": "3  Topology",
    "section": "3.12 Connectedness",
    "text": "3.12 Connectedness\nSuppose that \\((X,\\mathcal{T})\\) is a topological space. By property (A1) we have that \\[\n\\emptyset \\,, \\,\\, X \\in \\mathcal{T}\n\\] Therefore \\[\n\\emptyset^c = X \\,, \\quad X^c = \\emptyset\n\\] are closed. It follows that \\(\\emptyset\\) and \\(X\\) are both open and closed.\n\nDefinition 85: Connected space\nLet \\((X,\\mathcal{T})\\) be a topological space. We say that:\n\n\\(X\\) is connected if the only subsets of \\(X\\) which are both open and closed are \\(\\emptyset\\) and \\(X\\).\n\\(X\\) is disconnected if it is not connected.\n\n\n\nThe following proposition gives two extremely useful equivalent definitions of connectedness. Before stating it, we define the concept of proper set.\n\nDefinition 86: Proper subsetLet \\(X\\) be a set. A subset \\(A \\subseteq X\\) is proper if \\[\nA \\neq \\emptyset \\,, \\quad A \\neq X \\,.\n\\]\n\n\n\nProposition 87: Equivalent definition for connectedness\nLet \\((X,\\mathcal{T})\\) be a topological space. They are equivalent:\n\n\\(X\\) is disconnected.\n\\(X\\) is the disjoint union of two proper open subsets.\n\\(X\\) is the disjoint union of two proper closed subsets.\n\n\n\n\nProofPart 1. Point 1 implies Points 2 and 3.\nSuppose \\(X\\) is disconnected. Then there exists \\(U \\subseteq X\\) which is open, closed, and such that \\[\nU \\neq \\emptyset \\,, \\quad U \\neq X \\,.\n\\tag{3.14}\\] Define \\[\nA:= U \\,, \\quad B:= U^c \\,.\n\\] By definition of complement we have \\[\nX = A \\cup B  \\,, \\quad A \\cap B = \\emptyset \\,.\n\\] Moreover:\n\n\\(A\\) and \\(B\\) are both open and closed, since \\(U\\) is both open and closed.\n\\(A\\) and \\(B\\) are proper, since (3.14) holds.\n\nTherefore we conclude Points 2, 3.\nPart 2. Point 2 implies Point 1. Suppose \\(A,B\\) are open, proper, and such that \\[\nX = A \\cup B \\,, \\quad  A \\cap B = \\emptyset \\,.\n\\] This implies \\[\nA^c = X \\smallsetminus A = B \\,,\n\\] showing that \\(A^c\\) is open, and hence \\(A\\) is closed. Therefore \\(A\\) is proper, open and closed, showing that \\(X\\) is disconnected.\nPart 3. Point 3 implies Point 1. Suppose \\(A,B\\) are closed, proper, and such that \\[\nX = A \\cup B \\,, \\quad  A \\cap B = \\emptyset \\,.\n\\] This implies \\[\nA^c = X \\smallsetminus A = B \\,,\n\\] showing that \\(A^c\\) is closed, and hence \\(A\\) is open. Therefore \\(A\\) is proper, open and closed, showing that \\(X\\) is disconnected.\n\n\nIn the following we will use Point 2 and Point 3 in Proposition 87 as equivalent definitions of disconnected topological space.\n\nExample 88\nConsider the set \\(X = \\{0,1\\}\\) with the subspace topology induced by the inclusion \\(X \\subset \\mathbb{R}\\), where \\(\\mathbb{R}\\) is equipped with the Euclidean topology \\(\\mathcal{T}_{\\textrm{euclidean}}\\). Then \\(X\\) is disconnected.\n\nProof. Note that \\[\nX = \\{ 0 \\} \\cup \\{ 1 \\} \\,, \\quad \\{ 0 \\} \\cap \\{ 1 \\} = \\emptyset \\,.\n\\] The set \\(\\{ 0 \\}\\) is open for the subspace topology, since \\[\n\\{ 0 \\} = X \\cap (-1,1) \\,, \\quad\n(-1,1) \\in \\mathcal{T}_{\\textrm{euclidean}} \\,.\n\\] Similarly, also \\(\\{ 1 \\}\\) is open for the subspace topology, since \\[\n\\{ 1 \\} = X \\cap (0,2) \\,, \\quad\n(0,2) \\in \\mathcal{T}_{\\textrm{euclidean}} \\,.\n\\] Clearly \\[\n\\{ 0 \\} \\neq \\emptyset \\,, \\quad \\{ 1 \\} \\neq \\emptyset \\,,\n\\] showing that \\(X\\) is disconnected.\n\n\n\n\nExample 89\nLet \\(p \\in \\mathbb{R}\\). The set \\(X = \\mathbb{R}\\smallsetminus \\{p\\}\\) is disconnected.\n\nProof. Define the sets \\[\nA = (-\\infty,p) \\,, \\quad B = (p , \\infty) \\,.\n\\] Then \\(A,B\\) are proper subsets of \\(X\\), since \\(p \\notin X\\). Moreover \\[\nX = A \\cup B \\,,  \\quad A \\cap B = \\emptyset \\,.\n\\] Finally we have that \\(A,B\\) are open for the subspace topology, since they are open in \\(\\mathbb{R}\\). Therefore \\(X\\) is disconnected.\n\n\n\n\nExample 90\nLet \\(n \\geq 2\\) and \\(A \\subseteq \\mathbb{R}^n\\) be open and connected. Let \\(p \\in A\\). Then \\(X = A \\smallsetminus \\{p\\}\\) is connected.\n\nExercise: Prove that \\(X\\) is connected.\n\n\n\nThe next theorem shows that connectedness is preserved by continuous maps.\n\nTheorem 91Let \\((X,\\mathcal{T}_X)\\), \\((Y,\\mathcal{T}_Y)\\) be topological spaces. Suppose that \\(f \\colon X \\to Y\\) is continuous and let \\(f(X) \\subseteq Y\\) be equipped with the subspace topology. If \\(X\\) is connected, then \\(f(X)\\) is connected.\n\n\n\nProofSuppose that \\(A,B\\) are open in \\(f(X)\\) and such that \\[\nf(X) = A \\cup B \\,, \\quad A \\cap B = \\emptyset \\,.\n\\] if we show that \\[\nA = \\emptyset \\,\\, \\mbox{ or } \\,\\, B = \\emptyset\n\\tag{3.15}\\] the proof is concluded. Since \\(A,B\\) are open for the subspace topology, there exist \\(\\widetilde{A}, \\widetilde{B} \\in \\mathcal{T}_Y\\) such that \\[\nA = \\widetilde{A} \\cap f(X) \\,, \\quad\nB = \\widetilde{B} \\cap f(X) \\,.\n\\tag{3.16}\\] Since \\(f(X) = A \\cup B\\) we have \\[\\begin{align*}\nX & = {f}^{-1} (A \\cup B) \\\\\n  & = {f}^{-1} (A ) \\cup {f}^{-1} (B) \\\\\n  & =  {f}^{-1} (\\widetilde{A} ) \\cup {f}^{-1} (\\widetilde{B})\n\\end{align*}\\] where in the last equality we used (3.16). Since \\(A \\cap B = \\emptyset\\), we also have that \\[\\begin{align*}\n{f}^{-1} (\\widetilde{A} ) \\cap {f}^{-1} (\\widetilde{B})\n  & = {f}^{-1} (A ) \\cap {f}^{-1} (B) \\\\\n  & =  {f}^{-1} (A \\cap B) \\\\\n  & =  {f}^{-1} (\\emptyset) \\\\\n  & = \\emptyset\n\\end{align*}\\] where in the first equality we used (3.16). By continuity of \\(f\\) we have that \\[\nf^{-1}(\\widetilde{A}) \\,, \\,\\,\nf^{-1}(\\widetilde{B}) \\in \\mathcal{T}_X \\,.\n\\] Therefore, using that \\(X\\) is connected, we deduce that \\[\nf^{-1}(\\widetilde{A}) = \\emptyset \\,\\, \\mbox{ or } \\,\\,\nf^{-1}(\\widetilde{B}) = \\emptyset \\,.\n\\] The above implies \\[\n\\widetilde{A} \\cap f(X) = \\emptyset \\,\\, \\mbox{ or } \\,\\,\n\\widetilde{B} \\cap f(X) = \\emptyset \\,.\n\\] Recalling (3.16), we obtain (3.15), ending the proof.\n\n\nAn immediate corollary of Theorem 91 is that connectedness is a topological invariant, e.g., connectedness is preserved by homeomorphisms.\n\nCorollary 92Let \\((X,\\mathcal{T}_X)\\), \\((Y,\\mathcal{T}_Y)\\) be homeomorhic topological spaces. Then \\[\nX \\, \\mbox{ is connected } \\,\\, \\iff \\,\\,\nY \\, \\mbox{ is connected }\n\\]\n\n\nThe proof follows immediately by Theorem 91, and is left to the reader as an exercise.\n\nExample 93\nLet \\(n \\geq 2\\). \\(\\mathbb{R}^n\\) not homeomorphic to \\(\\mathbb{R}\\).\n\nProof. Suppose by contradiction that there exists an omeomorphism \\[\nf \\colon \\mathbb{R}^n \\to \\mathbb{R}\\,.\n\\] Define \\(p = f(0)\\) and the restriction \\[\ng \\colon \\mathbb{R}^n \\smallsetminus \\{0\\} \\to \\mathbb{R}\\smallsetminus \\{p\\} \\,, \\quad g(x) = f(x) \\,.\n\\] Since \\(g\\) is a restriction of an omeomorphism, then \\(g\\) is an omeomorphism. We have that \\(\\mathbb{R}^n \\smallsetminus \\{0\\}\\) is connected, as a consequence of\nExample 90. Hence, by Corollary 92, we infer that \\(\\mathbb{R}\\smallsetminus \\{p\\}\\) is connected. This is a contradiction, since \\(\\mathbb{R}\\smallsetminus \\{p\\}\\) is disconnected, as shown in Example 89.\n\n\n\n\nExample 94\nDefine the 1D unit circle \\[\n\\mathbb{S}^1 := \\{(x,y) \\in \\mathbb{R}^2 \\, \\colon \\, x^2 + y^2 = 1 \\} \\,.\n\\] Then \\(\\mathbb{S}^1\\) and \\([0,1]\\) are not homeomorphic.\n\nProof. Suppose by contradiction that there exists and omeomorphism \\[\nf  \\colon [0,1] \\to \\mathbb{S}^1 \\,.\n\\] The restriction of \\(f\\) to \\([0,1] \\smallsetminus \\{\\frac12\\}\\) defines an omeomorphism \\[\ng \\ \\colon \\left( [0,1] \\smallsetminus \\left\\{\\frac12\\right\\} \\right) \\to \\left( \\mathbb{S}^1 \\smallsetminus \\{\\mathbf{p}\\} \\right) \\,, \\quad \\mathbf{p} := f\\left(\\frac12 \\right) \\,.\n\\] The set \\([0,1] \\smallsetminus \\left\\{ \\frac12 \\right\\}\\) is disconnected, since \\[\n[0,1] \\smallsetminus \\{1/2\\} = [0,1/2) \\, \\cup \\, (1/2,1]\n\\] with \\([0,1/2)\\) and \\((1/2,1]\\) open for the subset topology, non-empty and disjoint. Therefore, using that \\(g\\) is an omeomorphism, we conclude that also \\(\\mathbb{S}^1 \\smallsetminus \\{\\mathbf{p}\\}\\) is disconnected. Let \\(\\theta_0 \\in [0,2\\pi)\\) be the unique angle such that \\[\n\\mathbf{p} = (\\cos (\\theta_0),\\sin(\\theta_0)) \\,.\n\\] Thus \\(\\mathbb{S}^1 \\smallsetminus \\{\\mathbf{p}\\}\\) is parametrized by \\[\n{\\pmb{\\gamma}}(t):=(\\cos(t),\\sin(t)) \\,, \\quad t \\in (\\theta_0,\\theta_0 + 2\\pi) \\,.\n\\] Since \\({\\pmb{\\gamma}}\\) is continuous and \\((\\theta_0,\\theta_0 + 2\\pi)\\) is connected, by Theorem 91, we conclude that \\(\\mathbb{S}^1 \\smallsetminus \\{\\mathbf{p}\\}\\) is connected. Contradiction.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#intermediate-value-theorem",
    "href": "sections/chap_3.html#intermediate-value-theorem",
    "title": "3  Topology",
    "section": "3.13 Intermediate Value Theorem",
    "text": "3.13 Intermediate Value Theorem\nAnother consequence of Theorem 91 is a generalization of the Intermediate Value Theorem to arbitrary topological spaces. Before providing statement and proof of such Theorem, we need to characterize the connected subsets of \\(\\mathbb{R}\\).\n\nDefinition 95: IntervalA subset \\(I \\subset \\mathbb{R}\\) is an interval if it holds: \\[\n\\forall \\, a,b \\in I \\,, \\, x \\in \\mathbb{R}\\, \\, \\text{ s.t. } \\, a&lt;x&lt;b \\quad\n\\implies \\quad x \\in I \\,.\n\\]\n\n\n\nTheorem 96\nLet \\(\\mathbb{R}\\) be equipped with the Euclidean topology and let \\(I \\subseteq \\mathbb{R}\\). They are equivalent:\n\n\\(I\\) is connected.\n\\(I\\) is an interval.\n\n\n\n\nProofPart 1. Suppose \\(I\\) is connected. If \\(I=\\{p\\}\\) for some \\(p \\in \\mathbb{R}\\) then \\(I\\) is an interval and the thesis is achieved. Otherwise there exist \\(a,b \\in I\\) with \\(a&lt;b\\). Assume that \\(x \\in \\mathbb{R}\\) is such that \\[\na &lt; x &lt; b \\,.\n\\] We need to show that \\(x \\in I\\). Suppose by contradiction that \\(x \\notin I\\) and define the open sets \\[\nA = (-\\infty,x) \\,, \\quad B = (x,\\infty) \\,.\n\\] Then \\[\n\\widetilde{A} = (-\\infty,x) \\cap I \\,, \\quad \\widetilde{B} = (x,\\infty) \\cap I\n\\] are open in \\(I\\) for the subspace topology. Clearly \\[\n\\widetilde{A}  \\cap \\widetilde{B} = \\emptyset  \\,.\n\\] Moreover \\[\nI = \\widetilde{A} \\cup \\widetilde{B}\n\\] since \\(x \\notin I\\). We have:\n\nSince \\(a&lt;x\\) and \\(a \\in I\\), we have that \\(a \\in \\widetilde{A}\\). Therefore \\(\\widetilde{A} \\neq \\emptyset\\).\nSimilarly, \\(b&gt;x\\) and \\(b \\in I\\), therefore \\(b \\in \\widetilde{B}\\). Hence \\(\\widetilde{B} \\neq \\emptyset\\).\n\nTherefore \\(I\\) is disconnected, which is a contradiction.\nPart 2. Suppose \\(I\\) is an interval. Suppose by contradiction that \\(I\\) is disconnected. Then there exist \\(A,B\\) proper and closed, such that \\[\nI = A \\cup B \\,, \\quad A \\cap B = \\emptyset \\,.\n\\] Since \\(A\\) and \\(B\\) are proper, there exist points \\(a \\in A\\), \\(b \\in B\\). WLOG we can assume \\(a&lt;b\\). Define \\[\n\\alpha = \\sup \\ S \\,, \\quad S:= \\{ x \\in \\mathbb{R}\\colon [a,x) \\cap I \\subseteq A \\} \\,.\n\\]\nNote that \\(\\alpha\\) exists finite since \\(b\\) is an upper bound for the set \\(S\\).\n\nSuppose by contradiction \\(b\\) is not an upper bound for \\(S\\). Hence there exists \\(x \\in \\mathbb{R}\\) such that \\([a,x) \\cap I \\subseteq A\\) and that \\(x&gt;b\\). As \\(b&gt;a\\), we conclude that \\(b \\in [a,x) \\cap I \\subseteq A\\). Thus \\(b \\in A\\), which is a contradiction, since \\(b \\in B\\) and \\(A \\cap B = \\emptyset\\).\n\nMoreover we have that \\(\\alpha \\in A\\).\n\nThis is because the supremum \\(\\alpha\\) is the limit of a sequence in \\(S\\), and hence of a sequence in \\(A\\). Therefore \\(\\alpha\\) belongs to \\(\\overline{A}\\). Since \\(A\\) is closed, we infer \\(\\alpha \\in A\\).\n\nNote that \\(A^c = B\\), which is closed. Therefore \\(A^c\\) is closed, showing that \\(A\\) is open. As \\(\\alpha \\in A\\) and \\(A\\) is open in \\(I\\), there exists \\(\\varepsilon&gt;0\\) such that \\[\n(\\alpha - \\varepsilon, \\alpha + \\varepsilon) \\cap I \\subseteq A \\,.\n\\] In particular \\[\n[a , \\alpha + \\varepsilon) \\cap I \\subseteq A \\,,\n\\] showing that \\(\\alpha + \\varepsilon\\in S\\). This is a contradiction, since \\(\\alpha\\) is the supremum of \\(S\\).\n\n\nWe are finally ready to prove the Intermediate Value Theorem.\n\nTheorem 97: Intermediate Value TheoremLet \\((X,\\mathcal{T})\\) be a connected topological space. Suppose that \\(f \\colon X \\to \\mathbb{R}\\) is continuous. Suppose that \\(a,b \\in X\\) are such that \\(f(a)&lt;f(b)\\). It holds: \\[\n\\forall \\, c \\in \\mathbb{R}\\, \\text{ s.t. } \\, f(a)&lt; c &lt; f(b) \\,, \\,\\, \\exists \\, \\xi \\in X \\, \\text{ s.t. } \\, f(\\xi) = c \\,.\n\\]\n\n\n\nProofAs \\(f\\) is continuous and \\(X\\) is connected, by Theorem 91 we know that \\(f(X)\\) is connected in \\(\\mathbb{R}\\). By Theorem 96 we have that \\(f(X)\\) is an interval. Since \\(a,b \\in X\\) it follows \\(f(a), f(b) \\in f(X)\\). Therefore, if \\(c \\in \\mathbb{R}\\) is such that \\[\nf(a) &lt; c &lt; f(b)\n\\] we conclude that \\(c \\in f(X)\\), since \\(f(X)\\) is an interval. Hence there exists \\(\\xi \\in X\\) such that \\(f(\\xi) = c\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_3.html#path-connectedness",
    "href": "sections/chap_3.html#path-connectedness",
    "title": "3  Topology",
    "section": "3.14 Path connectedness",
    "text": "3.14 Path connectedness\n\nDefinition 98: Path connectednessLet \\((X,\\mathcal{T})\\) be a topological space. We say that \\(X\\) is path connected if for every \\(x,y \\in X\\) there exist \\(a,b \\in \\mathbb{R}\\) with \\(a&lt;b\\), and a continuous function \\[\n\\alpha \\colon [a,b] \\to X\n\\] such that \\[\n\\alpha (a) = x \\,, \\quad \\alpha(b) = y \\,.\n\\]\n\n\n\nExample 99\nLet \\(A \\subset \\mathbb{R}^n\\) be convex. Then \\(A\\) is path connected.\n\nA is convex if for all \\(x,y \\in A\\) the segment connecting \\(x\\) to \\(y\\) is contained in \\(A\\), namely, \\[\n[x,y] := \\{ (1-t)x + t y \\, \\colon \\,t \\in [0,1] \\} \\subseteq A \\,.\n\\] Therefore we can define \\[\n\\alpha \\colon [0,1] \\to A \\,, \\quad \\alpha(t):=(1-t)x + t y \\,.\n\\] Clearly \\(\\alpha\\) is continuous, and \\(\\alpha(0)=x, \\alpha(1)=y\\).\n\n\n\nIt turns out that path-connectedness implies connectedness.\n\nTheorem 100Let \\((X,\\mathcal{T})\\) be a path connected topological space. Then \\(X\\) is connected.\n\n\n\nProofSuppose that \\(X = A \\cup B\\) with \\(A, B \\in \\mathcal{T}\\) and non-empty. In order to conclude that \\(X\\) is connected, we need to show that \\[\nA \\cap B \\neq \\emptyset \\,.\n\\] Since \\(A\\) and \\(B\\) are non-empty, we can find two points \\(x \\in A\\) and \\(b \\in B\\). As \\(X\\) is path connected, there exists \\(\\alpha \\colon [0,1] \\to X\\) continuous such that \\[\n\\alpha(0) = x \\,,  \n\\quad\n\\alpha(1) = y \\,.\n\\] In particular \\[\n\\alpha^{-1} (A) \\neq \\emptyset \\, , \\quad\n\\alpha^{-1} (B) \\neq \\emptyset \\,.\n\\] Moreover \\[\\begin{align*}\n[0,1] & = \\alpha^{-1}(X) \\\\\n      & = \\alpha^{-1}(A \\cup B) \\\\\n      & = \\alpha^{-1}(A) \\cup \\alpha^{-1}(B) \\,.\n\\end{align*}\\] As \\(\\alpha\\) is continuous, \\(\\alpha^{-1}(A)\\) and \\(\\alpha^{-1}(B)\\) are open in \\([0,1]\\). Suppose by contradiction that \\(A \\cap B = \\emptyset\\). Then \\[\n\\alpha^{-1}(A) \\cap \\alpha^{-1}(B) = \\alpha^{-1}(A \\cap B)  = \\alpha^{-1}(\\emptyset) = \\emptyset \\,.\n\\] Hence \\([0,1]\\) is disconnected, which is a contradiction. Therefore \\(A \\cap B \\neq \\emptyset\\) and \\(X\\) is connected.\n\n\nThe converse of the above theorem does not hold. A counterexample is given by the so-called topologist curve, which will be examined in Proposition 102. Prior to this, we need a basic Lemma.\n\nLemma 101Let \\((X,\\mathcal{T})\\) be a topological space. Let \\(A,  U \\subseteq X\\) with \\(A\\) connected and \\(U\\) open and closed. Suppose that \\(A \\cap U \\neq \\emptyset\\), then \\(A \\subseteq U\\).\n\n\n\nProofThe following set identities hold for any pair of sets \\(U\\) and \\(A\\): \\[\\begin{align*}\nA & = ( A \\cap U ) \\cup (A \\cap U^c)  \\\\\n\\emptyset & = ( A \\cap U ) \\cap (A \\cap U^c)\n\\end{align*}\\] Now, suppose by contradiction \\(A \\not\\subseteq U\\). This means \\(A \\cap U^c \\neq \\emptyset\\). By assumption we also have \\(A \\cap U \\neq \\emptyset\\). Moreover the sets \\(A \\cap U\\) and \\(A \\cap U^c\\) are open for the subspace topology on \\(A\\), since \\(U\\) and \\(U^c\\) are open in \\(X\\). Hence \\(A\\) is the disjoint union of non-empty open sets, showing that \\(A\\) is disconnected. Contradiction. We conclude that \\(A \\subseteq U\\).\n\n\n\nProposition 102: Topologist curveConsider \\(\\mathbb{R}^2\\) with the Euclidean topology and define the sets \\[\nX := A \\cup B\n\\] where \\[\\begin{align*}\nA & := \\left\\{   \\left(  t, \\sin \\left( \\frac{1}{t} \\right)  \\right) \\, \\colon \\,t&gt;0   \\right\\} \\\\\nB & := \\{(0,t) \\, \\colon \\,t \\in [-1,1] \\}\n\\end{align*}\\] Then \\(X\\) is connected, but not path connected.\n\n\n\nProofStep 1. \\(X\\) is not path connected.\nLet \\(x \\in A\\) and \\(y \\in B\\). There is no continuous function \\(\\alpha \\colon [0,1] \\to X\\) such that \\(\\alpha(0)=x\\) and \\(\\alpha(1)=y\\). If such \\(\\alpha\\) existed, then we would obtain a continuous extension for \\(t=0\\) of the function \\[\nf(t) = \\sin \\left( \\frac{1}{t} \\right)  \\,, \\quad x&gt;0\n\\] which is not possible. Hence \\(X\\) is not path connected.\nStep 2. Preliminary facts.\n\n\\(A\\) is connected: Define the curve \\({\\pmb{\\gamma}}\\colon (0,\\infty) \\to \\mathbb{R}^2\\) by \\[\n{\\pmb{\\gamma}}(t):=   \\left(  t, \\sin \\left( \\frac{1}{t} \\right)  \\right) \\,.\n\\] Clearly \\({\\pmb{\\gamma}}\\) is continuous. Since \\((0,\\infty)\\) is connected, by Theorem 91 we have that \\({\\pmb{\\gamma}}((0,\\infty)) = A\\) is connected.\n\\(B\\) is connected: Indeed \\(B\\) is homeomorphic to the interval \\([-1,1]\\). Since \\([-1,1]\\) is connected, by Corollary 92 we conclude that \\(B\\) is connected.\n\\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = X\\): This is because each point \\(y \\in B\\) is of the form \\(y = (0,t_0)\\) for some \\(t_0 \\in [-1,1]\\). By continuity of \\(\\sin\\) and the Intermediate Value Theorem there exists some \\(z&gt;0\\) such that \\[\n\\sin(z) = t_0 \\,.\n\\] Therefore \\(z_n := z + 2n\\pi\\) satisfies \\[\nz_n \\to \\infty \\,, \\quad \\sin(z_n) = t_0 \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\] Define \\(s_n:=1/z_n\\). Trivially \\[\ns_n \\to 0 \\,, \\quad  \\sin \\left(  \\frac{1}{s_n}  \\right) = t_0 \\,, \\quad \\forall \\, n \\in \\mathbb{N}\\,.\n\\] Therefore we obtain \\[\n\\left(  s_n , \\sin \\left(  \\frac{1}{s_n}  \\right)    \\right) \\to  (0,t_0) \\,.\n\\] Hence the set \\(B\\) is contained in the set \\(L(A)\\) of limit points of \\(A\\). Since we are in \\(\\mathbb{R}^2\\), we have that \\(L(A)={}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\), proving that \\(B \\subseteq {}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}\\). Thus \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {}= A \\cup B = X\\).\n\nStep 3. \\(X\\) is connected.\nLet \\(U \\subseteq X\\) be non-empty, open and closed. If we prove that \\(U = X\\), we conclude that \\(X\\) is connected. Let us proceed.\nSince \\(U\\) is non-empty, we can fix a point \\(x \\in U\\). We have two possibilities:\n\n\\(x \\in A\\): In this case \\(A \\cap U \\neq \\emptyset\\). Since \\(A\\) is connected and \\(U\\) is open and closed, by Lemma 101 we conclude \\(A \\subseteq U\\). As \\(U\\) is closed and contains \\(A\\), then \\({}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} \\subseteq U\\). But we have shown that\n\\[\n{}\\mkern 2mu \\overline{\\mkern-2mu A \\mkern-2mu}\\mkern 2mu {} = X \\,,\n\\] and therefore \\(U = X\\).\n\\(x \\in B\\): Then \\(U \\cap B \\neq \\emptyset\\). Since \\(B\\) is connected and \\(U\\) is open and closed, we can invoke Lemma 101 and conclude that \\(B \\subseteq U\\). Since \\((0,0) \\in B\\), it follows that \\[\n(0,0) \\in U \\,.\n\\] As \\(U\\) is open in \\(X\\), and \\(X\\) has the subspace topology induced by the inclusion \\(X \\subseteq \\mathbb{R}^2\\), there exists an open set \\(W\\) of \\(\\mathbb{R}^2\\) such that \\[\nU = X \\cap W \\,.\n\\] Therefore \\((0,0) \\in W\\). As \\(W\\) is open in \\(\\mathbb{R}^2\\), there exists a radius \\(\\varepsilon&gt;0\\) such that \\[\nB_{\\varepsilon} (0,0) \\subseteq W \\,.\n\\] Hence \\[\nX \\cap B_{\\varepsilon} (0,0)  \\subseteq X \\cap W = U \\,.\n\\] The ball \\(B_{\\varepsilon} (0,0)\\) contains points of \\(A\\), and therefore \\[\nA \\cap U \\neq \\emptyset \\,.\n\\] Since \\(A\\) is connected and \\(U\\) is open and closed, we can again use Lemma 101 and obtain that \\(A \\subseteq U\\). Since we already had \\(B \\subseteq U\\), and since \\(U \\subseteq X = A \\cup B\\), we conclude hence \\(U = X\\).\n\nTherefore \\(U = X\\) in all possible cases, showing that \\(X\\) is connected.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Topology</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html",
    "href": "sections/chap_4.html",
    "title": "4  Surfaces",
    "section": "",
    "text": "4.1 Preliminaries\nBefore proceeding with the formal definition of surface, we need to establish some basic notation and terminology regarding linear algebra, the topology of \\(\\mathbb{R}^n\\), and calculus for smooth maps from \\(\\mathbb{R}^n\\) into \\(\\mathbb{R}^m\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#preliminaries",
    "href": "sections/chap_4.html#preliminaries",
    "title": "4  Surfaces",
    "section": "",
    "text": "4.1.1 Linear algebra\n\nDefinition 2: Bilinear formLet \\(V\\) be a vector space and \\(B \\colon V \\times V \\to \\mathbb{R}\\). We say that:\n\n\\(B\\) is bilinear if \\[\\begin{align*}\nB(\\lambda_1 \\mathbf{v}_1 + \\lambda_2 \\mathbf{v}_2 , \\mathbf{w}) & = \\lambda_1 B(\\mathbf{v}_1,\\mathbf{w}) + \\lambda_2 B(\\mathbf{v}_2,\\mathbf{w}) \\,, \\\\\nB(\\mathbf{w}, \\lambda_1 \\mathbf{v}_1 + \\lambda_2 \\mathbf{v}_2 ) & = \\lambda_1 B(\\mathbf{w},\\mathbf{v}_1) + \\lambda_2 B(\\mathbf{w}, \\mathbf{v}_2) \\,.\n\\end{align*}\\] for all \\(\\mathbf{v}_i,\\mathbf{w}\\in V\\), \\(\\lambda_i \\in \\mathbb{R}\\).\n\\(B\\) is symmetric if \\[\nB(\\mathbf{v},\\mathbf{w}) = B(\\mathbf{w}, \\mathbf{v})\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in V\\).\n\nA bilinear map \\(B\\) is called bilinear form on \\(V\\).\n\n\n\nNotationLet \\(V\\) be a vector space with basis \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\). Then, for a vector \\(\\mathbf{v}\\in V\\) there exist coefficients \\(\\lambda_1, \\ldots, \\lambda_n\\) such that \\[\n\\mathbf{v}= \\lambda_1 \\mathbf{v}_1 +  \\ldots  +\\lambda_n \\mathbf{v}_n \\,.\n\\] We denote the vector of coefficients of \\(\\mathbf{v}\\) by the column vector \\[\n\\mathbf{x}:= (\\lambda_1, \\ldots, \\lambda_n)^T \\in \\mathbb{R}^n \\,.\n\\] The coefficients of a vector \\(\\mathbf{w}\\) are denoted by \\[\n\\mathbf{y}:= (\\mu_1 , \\ldots, \\mu_n )^T \\,.\n\\]\n\n\nBilinear forms can be represented by a matrix.\n\nRemark 3: Matrix representation for bilinear forms\nLet \\(\\{\\mathbf{v}_1, \\ldots , \\mathbf{v}_n \\}\\) be a basis for the vector space \\(V\\). Given a bilinear form \\(B \\colon V \\times V \\to \\mathbb{R}\\) we define the matrix \\[\nM := \\left(  B(\\mathbf{v}_i,\\mathbf{v}_j) \\right)_{i,j=1}^n \\in \\mathbb{R}^{n \\times n} \\,.\n\\] Then \\[\nB(\\mathbf{v},\\mathbf{w}) = \\mathbf{x}^T \\,M \\, \\mathbf{y}\\,.\n\\]\n\nProof. We can write \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) in cordinates as \\[\n\\mathbf{v}= \\sum_{i=1}^n \\lambda_i \\mathbf{v}_i \\,, \\quad\n\\mathbf{w}= \\sum_{i=1}^n \\mu_i \\mathbf{v}_i \\,,\n\\] for suitable coefficients \\(\\lambda_i, \\mu_i \\in \\mathbb{R}\\). Using bilinearity of \\(B\\) we get \\[\\begin{align*}\nB(\\mathbf{v},\\mathbf{w}) & = B \\left(  \\sum_{i=1}^n \\lambda_i \\mathbf{v}_i, \\sum_{j=1}^n \\mu_j \\mathbf{v}_j   \\right) \\\\\n& = \\sum_{i,j=1}^n \\lambda_i \\mu_j B(\\mathbf{v}_i,\\mathbf{v}_j) \\\\\n& = \\mathbf{x}^T M \\mathbf{y}\\,.\n\\end{align*}\\]\n\n\n\n\nDefinition 4: Quadratic formLet \\(V\\) be a vector space and \\(B \\colon V \\times V \\to \\mathbb{R}\\) be a bilinear form. The quadratic form associated to \\(B\\) is the map \\[\nQ \\colon V \\to \\mathbb{R}\\,, \\quad Q(\\mathbf{v}) := B(\\mathbf{v}, \\mathbf{v}) \\,.\n\\]\n\n\nA symmetric bilinear form is uniquely determinded by its quadratic form, as stated in the following proposition.\n\nProposition 5Let \\(B \\colon V \\times V \\to \\mathbb{R}\\) be a symmetric bilinear form and \\(Q \\colon V \\to \\mathbb{R}\\) the associated quadratic form. Then \\[\nB(u,v) = \\frac12 \\left(  Q(\\mathbf{v}+ \\mathbf{w}) - Q(\\mathbf{v}) - Q(\\mathbf{w})       \\right) \\,.\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in V\\).\n\n\nThe proof is an easy check, and is left as an exercise.\n\nDefinition 6: Inner product\nLet \\(V\\) be a vector space. An inner product on \\(V\\) is a symmetric bilinear form \\(\\left\\langle \\cdot,\\cdot \\right\\rangle \\colon V \\times V \\to \\mathbb{R}\\) such that \\[\n\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle &gt; 0 \\,, \\quad \\forall \\, \\mathbf{v}\\in V \\,.\n\\] Moreover:\n\nThe length of a vector \\(\\mathbf{v}\\in V\\) with respect to \\(B\\) is defined as \\[\n\\| \\mathbf{v}\\|  := \\sqrt{\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle} \\,.\n\\]\nTwo vectors \\(\\mathbf{v},\\mathbf{w}\\in V\\) are orthogonal if \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle = 0 \\,.\n\\]\n\n\n\n\nExample 7Let \\(V = \\mathbb{R}^n\\) and consider the euclidean scalar product \\[\n\\mathbf{v}\\cdot \\mathbf{w}= \\sum_{i=1}^n v_i w_i \\,,\n\\] where \\(\\mathbf{v}= (v_1,\\ldots,v_n)\\), \\(\\mathbf{w}= (w_1,\\ldots,w_n)\\). Then \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle := \\mathbf{v}\\cdot \\mathbf{w}\n\\] is an inner product on \\(\\mathbb{R}^n\\).\n\n\n\nProposition 8Let \\(V\\) be a vector space and \\(\\left\\langle \\cdot,\\cdot \\right\\rangle\\) an inner product on \\(V\\). There exists an orthonormal basis \\(\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}\\) of \\(V\\), that is, such that \\[\n\\left\\langle \\mathbf{v}_i,\\mathbf{v}_j \\right\\rangle =\n\\begin{cases}\n1 & \\mbox{ if } \\, i = j  \\\\\n0 & \\mbox{ if } \\, i \\neq j  \\\\\n\\end{cases}\n\\] In particular, the matrix \\(M\\) associated to \\(\\left\\langle \\cdot,\\cdot \\right\\rangle\\) is the identity.\n\n\n\nDefinition 9: Linear mapLet \\(V,W\\) be vector spaces and \\(L \\colon V \\to W\\). We say that \\(L\\) is linear if \\[\nL(\\lambda \\mathbf{v}+ \\mu \\mathbf{w}) = \\lambda L(\\mathbf{v}) + \\mu L(\\mathbf{w})\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in V\\) and \\(\\lambda,\\mu \\in \\mathbb{R}\\).\n\n\n\nRemark 10: Matrix representation of linear mapsLet \\(V,W\\) be vector spaces and \\(L \\colon V \\to W\\) be a linear map. Let \\(\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}\\) be a basis of \\(V\\) and \\(\\{ {\\mathbf{w}}_1 , \\ldots, \\mathbf{w}_m\\}\\) be a basis of \\(W\\). Then there exists a matrix \\(M \\in \\mathbb{R}^{m \\times n}\\) such that \\[\nL \\mathbf{v}= M \\mathbf{x}\\,, \\quad \\forall \\, \\mathbf{v}\\in V \\,.\n\\] Specifically, \\(M \\in \\mathbb{R}^{n \\times n}\\) is called the matrix associated to \\(L\\) with respect to the basis \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\) of \\(V\\) and \\(\\{\\mathbf{w}_1 \\ldots,\\mathbf{w}_m\\}\\) of \\(W\\), and is defined by \\[\nM := \\left(  \n\\begin{array}{ccc}\na_{11} & \\ldots & a_{1n} \\\\\n\\vdots & \\ddots & \\vdots \\\\\na_{m1} & \\ldots & a_{mn}\n\\end{array}\n\\right) \\,,\n\\] where the coefficients \\(a_{ij}\\) are such that \\[\nL(\\mathbf{v}_j) = a_{1j} \\mathbf{w}_1 + \\ldots + a_{mj} \\mathbf{w}_m = \\sum_{i=1}^m a_{ij} \\mathbf{w}_i  \\,.\n\\] In other words, the columns of \\(M\\) are given by the coordinates of the vectors \\(L(\\mathbf{v}_i)\\) with respect to the basis \\(\\{ \\mathbf{w}_1 , \\ldots, \\mathbf{w}_m \\}\\).\n\n\n\nDefinition 11: Eigenvalues and eigenvectorsLet \\(V\\) be a vector space and \\(L \\colon V \\to V\\) a linear map. We say that \\(\\lambda \\in \\mathbb{R}\\) is an eigenvalue of \\(L\\) if \\[\nL(\\mathbf{v}) = \\lambda \\mathbf{v}\n\\] for some \\(\\mathbf{v}\\in V\\) with \\(\\mathbf{v}\\neq 0\\). Such \\(\\mathbf{v}\\) is called eigenvector of \\(L\\) associated to the eigenvalue \\(\\lambda\\).\n\n\n\nDefinition 12: Self-adjoint mapLet \\(V\\) be a vector space, \\(\\left\\langle \\cdot,\\cdot \\right\\rangle\\) an inner product and \\(L \\colon V \\to V\\) a linear map. We say that \\(L\\) is self-adjoint if \\[\n\\left\\langle \\mathbf{v},L(\\mathbf{w}) \\right\\rangle = \\left\\langle L(\\mathbf{v}),\\mathbf{w} \\right\\rangle \\,, \\quad \\forall \\, \\mathbf{v}, \\, \\mathbf{w}\\in V \\,.\n\\]\n\n\n\nTheorem 13: Spectral TheoremLet \\(V\\) be a vector space, \\(\\left\\langle \\cdot,\\cdot \\right\\rangle\\) an inner product, and \\(L \\colon V \\to V\\) a self-adjoint linear map. There exist an orthonormal basis of \\(V\\) \\[\n\\{ \\mathbf{v}_1, \\ldots, \\mathbf{v}_n \\} \\,,\n\\] where \\(\\mathbf{v}_i\\) are eigenvectors of \\(L\\), that is, \\[\nL \\mathbf{v}_i = \\lambda_i \\mathbf{v}_i\n\\] for some eigevalue \\(\\lambda_i \\in \\mathbb{R}\\). In particular, the matrix of \\(L\\) with respect to the basis \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\) is diagonal: \\[\nM = \\operatorname{diag} (\\lambda_1,\\ldots, \\lambda_n)  =\n\\left(  \n\\begin{array}{cccc}\n\\lambda_1 &  0         & \\ldots & 0 \\\\\n    0     &  \\lambda_2 & \\ldots & 0 \\\\\n  \\vdots     &  \\vdots & \\ddots & \\vdots \\\\\n  0     &  0 & \\ldots & \\lambda_n \\\\\n\\end{array}\n\\right) \\,.\n\\]\n\n\nThere is also a matrix version of the spectral theorem. To state it, we need to introduce some terminology.\n\nDefinition 14\nLet \\(A \\in \\mathbb{R}^{n \\times n}\\) be a matrix. We say that:\n\n\\(A\\) is symmetric if \\[\nA^T = A \\,.\n\\]\n\\(A\\) is orthogonal if \\[\nA^T A = I  \\,,\n\\] where \\(I\\) is the identity matrix.\n\n\n\n\nRemark 15\nLet \\(L \\colon V \\to V\\) be linear and \\(A \\in \\mathbb{R}^{n \\times n}\\) be the matrix associated to \\(L\\) with respect to any basis \\(\\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}\\) of \\(V\\). They are equivalent:\n\n\\(L\\) is self-adjoint,\n\\(A\\) is symmetric.\n\n\n\n\nDefinition 16: Matrix eigenvaluesLet \\(A \\in \\mathbb{R}^{n \\times n}\\) be a matrix. An eigenvalue of \\(A\\) is a number \\(\\lambda \\in \\mathbb{R}\\) such that \\[\nA \\mathbf{v}= \\lambda \\mathbf{v}\\,,\n\\] for some \\(\\mathbf{v}\\in \\mathbb{R}^n\\) with \\(\\mathbf{v}\\neq 0\\). The vector \\(\\mathbf{v}\\) is called an eigenvector of \\(A\\) with eigenvalue \\(\\lambda\\).\n\n\n\nRemark 17Let \\(A \\in \\mathbb{R}^{n \\times n}\\). The eigenvalues of \\(\\lambda\\) of \\(A\\) can be computed by solving the characteristic equation \\[\nP(\\lambda) = 0 \\,,\n\\] where \\(P\\) is the characteristic polynomial of \\(A\\), defined by \\[\nP(\\lambda) := \\det ( A - \\lambda I  ) \\,.\n\\]\n\n\n\nRemark 18\nLet \\(L \\colon V \\to V\\) be a linear map and \\(A\\) the associated matrix with respect to any basis of \\(V\\). Then \\[\nL(\\mathbf{v}) = A \\mathbf{x}\\,, \\quad \\, \\forall \\, \\mathbf{v}\\in V\\,,\n\\] where \\(\\mathbf{x}\\in \\mathbb{R}^n\\) is the vector of coordinates of \\(\\mathbf{v}\\). They are equivalent:\n\n\\(\\lambda\\) is an eigenvalue of \\(L\\) of eigenvector \\(\\mathbf{v}\\),\n\\(\\lambda\\) is an eigenvalue of \\(A\\) of eigenvector \\(\\mathbf{x}\\).\n\n\n\n\nTheorem 19: Spectral Theorem for matricesLet \\(A \\in \\mathbb{R}^{n \\times n}\\) be a symmetric matrix. Consider \\(\\mathbb{R}^n\\) equipped with the euclidean scalar product. There exist an orthonormal basis of \\(V\\) \\[\n\\{ \\mathbf{v}_1, \\ldots, \\mathbf{v}_n \\} \\,,\n\\] where \\(\\mathbf{v}_i\\) are eigenvectors of \\(A\\), that is, \\[\nA \\mathbf{v}_i = \\lambda_i \\mathbf{v}_i\n\\] for some eigevalue \\(\\lambda_i \\in \\mathbb{R}\\). Moreover \\[\nA = P D P^T \\,,\n\\] where \\[\\begin{align*}\nP & := \\left( \\mathbf{v}_1 \\vert \\ldots \\vert \\mathbf{v}_n \\right) \\\\\nD & := \\operatorname{diag} (\\lambda_1,\\ldots, \\lambda_n)  =\n\\left(  \n\\begin{array}{cccc}\n\\lambda_1 &  0         & \\ldots & 0 \\\\\n    0     &  \\lambda_1 & \\ldots & 0 \\\\\n  \\vdots     &  \\vdots & \\ddots & \\vdots \\\\\n  0     &  0 & \\ldots & \\lambda_n \\\\\n\\end{array}\n\\right) \\,.\n\\end{align*}\\]\n\n\n\nRemark 20The corresponedence between Theorem 13 and Theorem 19 is as follows. Let \\(A \\in \\mathbb{R}^{n \\times n}\\) be symmetric and \\(\\{\\mathbf{w}_1, \\ldots, \\mathbf{w}_n\\}\\) be any orthonormal basis of the vector space \\(V\\). Define the linear map \\(L \\colon V \\to V\\) such that \\[\nL(\\mathbf{v}_j) =  \\sum_{i=1}^n a_{ij} \\mathbf{w}_i  \\,, \\quad \\forall \\, j =1 , \\ldots , n \\, .\n\\] In this way \\(A\\) is the matrix associated to \\(L\\) with respect to the basis \\(\\{\\mathbf{w}_1, \\ldots, \\mathbf{w}_n\\}\\). Then \\(L\\) is self-adjoint. Moreover \\(L\\) and \\(A\\) have the same eigenvalues. By the Spectral Theorem there exists an orthonormal basis \\(\\{\\mathbf{v}_1,\\ldots, \\mathbf{v}_n\\}\\) of \\(V\\) such that the matrix of \\(L\\) with respect to such basis, say \\(D\\), is diagonal. Then \\[\nA = P D P^T\n\\] where \\(P\\) is the matrix of change of basis between \\(\\{\\mathbf{w}_1, \\ldots, \\mathbf{w}_n\\}\\) and \\(\\{\\mathbf{v}_1, \\ldots, \\mathbf{v}_n\\}\\), that is, \\(P = (p_{ij})\\) where \\[\n\\mathbf{w}_j = \\sum_{i=1}^n p_{ij} \\mathbf{v}_i \\,.\n\\]\n\n\n\n\n4.1.2 Topology of \\(\\mathbb{R}^n\\)\nThe Euclidean norm on \\(\\mathbb{R}^n\\) is denoted by \\[\n\\| \\mathbf{x}\\| := \\sqrt{ \\sum_{i=1}^n x_i^2 }\\,, \\quad \\mathbf{x}= (x_1 , \\ldots, x_n) \\in \\mathbb{R}^n \\,.\n\\] The Euclidean norm induces the distance \\[\nd(\\mathbf{x},\\mathbf{y}) := \\| \\mathbf{x}- \\mathbf{y}\\| =   \\sqrt{ \\sum_{i=1}^n (x_i - y_i)^2 } \\,.\n\\]\n\nDefinition 21: Euclidean TopologyThe pair \\((\\mathbb{R}^n,d)\\) is a metric space. The topology induced by the metric \\(d\\) is called the Euclidean topology, denoted by \\(\\mathcal{T}\\). In this chapter we will always assume that \\(\\mathbb{R}^n\\) is equipped with the Euclidean topology \\(\\mathcal{T}\\).\n\n\n\nDefinition 22: Open SetsA set \\(U \\subseteq \\mathbb{R}^n\\) is open if for all \\(\\mathbf{x}\\in U\\) there exists \\(\\varepsilon&gt;0\\) such that \\(B_{\\varepsilon}(\\mathbf{x}) \\subseteq U\\), where \\[\nB_{\\varepsilon}(\\mathbf{x}) := \\{  \\mathbf{y}\\in \\mathbb{R}^n \\, \\colon \\,\\| \\mathbf{x}- \\mathbf{y}\\| &lt; \\varepsilon\\}\n\\] is the open ball of radius \\(\\varepsilon&gt;0\\) and centered at \\(\\mathbf{x}\\). In this case we denote \\(U \\in \\mathcal{T}\\), with \\(\\mathcal{T}\\) the Euclidean topology in \\(\\mathbb{R}^n\\).\n\n\n\nDefinition 23: Closed SetsA set \\(V \\subseteq \\mathbb{R}^n\\) is closed if \\(V^c := \\mathbb{R}^n \\smallsetminus U\\) is open.\n\n\n\nExample 24\n\nThe \\(n\\)-dimensional unit sphere \\[\n\\mathbb{S}^n = \\{ \\mathbf{x}\\in \\mathbb{R}^{n+1} \\, \\colon \\,\\| x \\| = 1 \\}\n\\] is not open in \\(\\mathbb{R}^{n+1}\\), since for any \\(\\mathbf{x}\\in \\mathbb{S}^n\\) we have \\[\nB_{\\varepsilon} (\\mathbf{x}) \\not\\subseteq \\mathbb{S}^{n} \\,.\n\\]\nThe \\(n\\)-dimensional unit cube \\[\nC := \\{ \\mathbf{x}\\in \\mathbb{R}^n \\, \\colon \\,|x_1| + \\ldots + |x_n| &lt;1  \\}\n\\] is open in \\(\\mathbb{R}^n\\), since one can always find \\(\\varepsilon&gt;0\\) small enough so that \\[\nB_{\\varepsilon} (\\mathbf{x}) \\not\\subseteq C \\,.\n\\]\nThe set \\[\nV := \\{ \\mathbf{x}\\in \\mathbb{R}^n \\, \\colon \\,|x_1| + \\ldots + |x_n| \\geq 1  \\}\n\\] is closed, since \\(V^c = C\\) is the unit cube, which is open.\n\n\n\n\nDefinition 25: Subspace TopologyGiven a subset \\(A \\subseteq \\mathbb{R}^n\\) the subspace topology on \\(A\\) is the family of sets \\[\n\\mathcal{T}_A := \\{  U \\subseteq A \\, \\colon \\,\\exists \\,\\, W \\in \\mathcal{T}\\, \\text{ s.t. } \\, U = A \\cap W  \\} \\,.\n\\] If \\(U \\in \\mathcal{T}_A\\) we say that \\(U\\) is open in \\(A\\).\n\n\n\n\n4.1.3 Smooth functions\nWe recall some basic facts about smooth functions from \\(\\mathbb{R}^n\\) into \\(\\mathbb{R}^m\\). For a vector valued function \\(f \\colon \\mathbb{R}^n \\to \\mathbb{R}^m\\) we denote its components by \\[\nf = (f_1,\\ldots,f_m) \\,.\n\\]\n\nDefinition 26: Continuous FunctionLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}^m\\) with \\(U\\) open. We say that \\(f\\) is continuous at \\(\\mathbf{x}\\in U\\) if \\(\\forall \\, \\varepsilon&gt;0\\), , \\(\\exists \\, \\delta &gt; 0\\) such that \\[\n\\|  \\mathbf{x}- \\mathbf{y}\\| &lt; \\delta \\quad \\implies \\quad\n\\| f(\\mathbf{x}) - f (\\mathbf{y}) \\| &lt; \\varepsilon\\,.\n\\] We say that \\(f\\) is continuous in \\(U\\) if it is continuous for all \\(\\mathbf{x}\\in U\\).\n\n\n\nRemark 27Let \\(f \\colon U \\subseteq \\mathbb{R}^n \\to V \\subseteq \\mathbb{R}^m\\), with \\(U,V\\) open. We have that \\(f\\) is continuous if and only if \\(f^{-1}(A)\\) is open in \\(U\\), for all \\(A\\) open in \\(V\\).\n\n\n\nDefinition 28: HomeomorphismLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to V \\subseteq \\mathbb{R}^m\\) with \\(U,V\\) open. We say that \\(f\\) is a homeomorphism if \\(f\\) is continuous and there exists inverse \\(f^{-1} \\colon V \\to U\\) continuous.\n\n\n\nDefinition 29: Differentiable FunctionLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}^m\\) with \\(U\\) open. We say that \\(f\\) is differentiable at \\(\\mathbf{x}\\in U\\) if there exists a linear map \\(df_{\\mathbf{x}} \\colon \\mathbb{R}^n \\to \\mathbb{R}^m\\) such that \\[\n\\lim_{\\varepsilon\\to 0} \\   \\frac{ f(\\mathbf{x}+ \\varepsilon\\mathbf{h} )  - f(\\mathbf{x}) - \\varepsilon\\, df_{\\mathbf{x}}(\\mathbf{h}) }{ \\varepsilon} = 0 \\,,\n\\] for all \\(\\mathbf{h} \\in \\mathbb{R}^n\\), where the limit is taken in \\(\\mathbb{R}^m\\). The map \\(df_{\\mathbf{x}}\\) is called the differential of \\(f\\) at \\(\\mathbf{x}\\).\n\n\nWe denote by \\(\\{\\mathbf{e}_i\\}_{i=1}^n\\) the standard basis of \\(\\mathbb{R}^n\\).\n\nDefinition 30: Partial DerivativeLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}^m\\) with \\(U\\) open be differentiable. The partial derivative of \\(f\\) at \\(\\mathbf{x}\\in U\\) in direction \\(\\mathbf{e}_i\\) is given by \\[\n\\frac{\\partial f}{\\partial x_i} := \\lim_{\\varepsilon\\to 0}  \\frac{ f( \\mathbf{x}+ \\varepsilon\\mathbf{e}_i ) - f(\\mathbf{x}) }{ \\varepsilon} \\,.\n\\]\n\n\n\nDefinition 31: Jacobian MatrixThe linear map \\(df_{\\mathbf{x}} \\colon \\mathbb{R}^n \\to \\mathbb{R}^m\\) can be represented in matrix form, with respect to the Euclidean basis, by the Jacobian matrix \\[\nJf(x):= \\left( \\frac{\\partial f_i}{\\partial x_j} \\right)_{i,j}  \\in \\mathbb{R}^{m \\times n} \\,.\n\\] If \\(m=n\\) then \\(Jf \\in \\mathbb{R}^{n \\times n}\\) is a square matrix and we can compute its determinant, denoted by \\[\n\\det (Jf) \\,.\n\\]\n\n\n\nDefinition 32: Multi-index notationFor a multi-index \\[\n\\alpha := (\\alpha_1, \\ldots , \\alpha_n) \\in \\mathbb{N}^n\n\\] we denote by \\[\n|\\alpha|:= \\sum_{i=1}^n   |\\alpha_i|\n\\] the length of the multi-index.\n\n\n\nDefinition 33: Smooth FunctionLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}^m\\) with \\(U\\) open. We say that \\(f\\) is smooth if the derivatives \\[\n\\frac{\\partial^{|\\alpha|} f}{d\\mathbf{x}^\\alpha} :=  \\frac{\\partial^{\\alpha_1}}{ \\partial x_1^{\\alpha_1}} \\cdots \\frac{\\partial^{\\alpha_n}}{ \\partial x_n^{\\alpha_n}} \\, f\n\\] exist for each multi-index \\(\\alpha \\in \\mathbb{N}^n\\). Note that in this case all the derivatives of \\(f\\) are automatically continuous.\n\n\n\nNotation: Gradient and partial derivativesLet \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}\\) be smooth. We denote the partial derivatives by \\[\n\\partial_{x_i} f := \\frac{\\partial f}{\\partial x_i} \\,, \\quad\n\\partial_{x_i x_j} f := \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\,,\n\\quad\n\\partial_{x_i x_j x_k} f := \\frac{\\partial^3 f}{\\partial x_i \\partial x_j \\partial x_k} \\,.\n\\]\nFor \\(f \\colon U \\subseteq \\mathbb{R}^n \\to \\mathbb{R}\\) smooth we denote the gradient by \\[\n\\nabla f (\\mathbf{x}) = \\left(  f_{x_1}(\\mathbf{x}) , \\ldots ,  f_{x_n}(\\mathbf{x}) \\right) \\,.\n\\]\n\n\n\nExample 34The functions \\(f \\colon \\mathbb{R}^2 \\to \\mathbb{R}\\) and \\(g \\colon \\mathbb{R}^2 \\to \\mathbb{R}^3\\) defined by \\[\nf(x,y) := \\cos(x)y \\,, \\quad\ng(x,y) := (x^2,y^2,x-y)\n\\] are both smooth.\n\n\n\nDefinition 35: DiffeomorphismLet \\(f \\colon U \\to V\\) with \\(U \\subseteq \\mathbb{R}^n\\) and \\(V \\subseteq \\mathbb{R}^n\\) open. We say that \\(f\\) is a diffeomorphism between \\(U\\) and \\(V\\) if \\(f\\) is smooth and there exists smooth inverse \\(f^{-1} \\colon V \\to U\\).\n\n\nWe recall, without proof, the Inverse Function Theorem. Please note that in the statement the function \\(f\\) is defined from \\(\\mathbb{R}^n\\) into \\(\\mathbb{R}^n\\).\n\nTheorem 36: Inverse Function TheoremLet \\(f \\colon U \\to \\mathbb{R}^n\\) with \\(U \\subseteq \\mathbb{R}^n\\) open. Suppose \\(f\\) is a smooth function and \\[\n\\det J f(\\mathbf{x}_0) \\neq 0 \\,,\n\\] for some \\(\\mathbf{x}_0 \\in U\\). Then there exist open sets \\(U_0 , V \\subseteq \\mathbb{R}^n\\) such that \\(\\mathbf{x}_0 \\in U_0\\), \\(f(\\mathbf{x}_0) \\in V\\) and \\(f \\colon U_0 \\to V\\) is a diffeomorphism.\n\n\n\nWarningEven if \\[\n\\det J f(\\mathbf{x}) \\neq 0 \\,,\n\\] for all \\(\\mathbf{x}\\in U\\), it is not guaranteed that \\(f\\) is a diffeomorphism between \\(U\\) and \\(f(U)\\).\n\n\nNon-vanishing Jacobian determinant is a necessary condition for being a diffeomorphism.\n\nProposition 37Let \\(f \\colon U \\to \\mathbb{R}^n\\) with \\(U \\subseteq \\mathbb{R}^n\\) open. Suppose \\(f\\) is a diffeomorphism on \\(U\\). Then \\[\n\\det Jf (\\mathbf{x}) \\neq 0 \\,, \\quad   \\forall \\, \\mathbf{x}\\in U \\,.\n\\]\n\n\n\nExample 38Define \\(f \\colon \\mathbb{R}^2 \\to \\mathbb{R}^2\\) by \\[\nf(x,y) := (\\cos(x) \\sin(y), \\sin(x) \\sin(y)) \\,.\n\\] Then \\[\nJ f (x,y) =\n\\left(\n\\begin{array}{cc}\n- \\sin(x) \\sin(y)  &   \\cos(x) \\cos(y) \\\\\n\\cos(x) \\sin(y)    &   \\sin(x) \\cos(y)\n\\end{array}\n\\right) \\,.\n\\] and \\[\\begin{align*}\n\\det Jf(x,y) & = - \\sin^2(x) \\cos(y) \\sin(y) - \\cos^2(x) \\cos(y) \\sin(y) \\\\\n             & = - \\sin(y) \\cos(y) \\\\\n             & = - \\frac{1}{2} \\sin(2y) \\,.\n\\end{align*}\\] Therefore \\[\n\\det Jf(x,y) \\neq 0 \\quad \\iff \\quad\ny \\neq \\frac{n \\pi}{2} \\,, \\,\\, n \\in \\mathbb{N}\\,.\n\\] Hence \\(f\\) is a diffeomorphism away from the lines \\[\nL_n := \\left\\{ \\left(x, \\frac{n \\pi}{2} \\right) \\, \\colon \\,x \\in \\mathbb{R}\\right\\} \\,.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#definition-of-surface",
    "href": "sections/chap_4.html#definition-of-surface",
    "title": "4  Surfaces",
    "section": "4.2 Definition of Surface",
    "text": "4.2 Definition of Surface\nWe give our main definition of surface in \\(\\mathbb{R}^3\\).\n\nDefinition 39: Surface\nLet \\(\\mathcal{S}\\subseteq \\mathbb{R}^3\\) be a connected set. We say that \\(\\mathcal{S}\\) is a surface if for every point \\(\\mathbf{p}\\in \\mathcal{S}\\) there exist an open set \\(U \\subseteq \\mathbb{R}^2\\) and a smooth map \\[\n{\\pmb{\\sigma}}\\colon U \\to  {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\,\n\\] such that\n\n\\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\)\n\\({\\pmb{\\sigma}}(U)\\) is open in \\(\\mathcal{S}\\)\n\\({\\pmb{\\sigma}}\\) is a homeomorphism between \\(U\\) and \\({\\pmb{\\sigma}}(U)\\)\n\nFurther:\n\nThe homeomorphism \\({\\pmb{\\sigma}}\\) is called a surface chart at \\(\\mathbf{p}\\).\nFor each \\(i \\in I\\) suppose to have a surface chart \\[\n{\\pmb{\\sigma}}_i  \\colon U_i \\to {\\pmb{\\sigma}}(U_i) \\subseteq \\mathcal{S}\\,.\n\\] We say that the family \\[\n\\mathcal{A} = \\{ {\\pmb{\\sigma}}_i\\}_{i \\in I}\n\\] is an atlas of \\(\\mathcal{S}\\) if \\[\n\\mathcal{S}= \\bigcup_{i \\in I} {\\pmb{\\sigma}}_i(U_i)  \\,.\n\\]\n\n\n\n\nRemark 40\n\nA surface chart \\({\\pmb{\\sigma}}\\) is a map \\[\n{\\pmb{\\sigma}}\\colon U  \\to \\mathbb{R}^3 \\,,\n\\] with \\(U \\subseteq \\mathbb{R}^2\\) open. Therefore smoothness of \\({\\pmb{\\sigma}}\\) is intended in the classical sense.\nGiven a chart \\({\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U)\\), the set \\(U\\) is open in \\(\\mathbb{R}^2\\) while \\({\\pmb{\\sigma}}(U)\\) is open in \\(\\mathcal{S}\\) with the subspace topology. This means that there exists \\(W \\subseteq \\mathbb{R}^3\\) open such that \\[\n{\\pmb{\\sigma}}(U) = W \\cap \\mathcal{S}\\,.\n\\]\nThe omeomorphism condition is saying that \\({\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\) looks locally (around \\(\\mathbf{p}\\)) like an open set \\(U \\subseteq \\mathbb{R}^2\\).\n\n\n\n\n\n\nSketch of the surface \\(\\mathcal{S}\\) and chart \\({\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\). The set \\(U \\subseteq \\mathbb{R}^2\\) is open in \\(\\mathbb{R}^2\\) and \\({\\pmb{\\sigma}}(U)\\) is open in \\(\\mathcal{S}\\). This means there exists \\(W\\) open in \\(\\mathbb{R}^3\\) such that \\({\\pmb{\\sigma}}(U) = \\mathcal{S}\\cap W\\).\n\n\n\nNotation\n\nPoints in \\(U\\) will be denoted with the pair \\((u,v)\\).\nPartial derivatives of a chart \\({\\pmb{\\sigma}}= {\\pmb{\\sigma}}(u,v)\\) will be denoted by \\[\n{\\pmb{\\sigma}}_u := \\frac{\\partial {\\pmb{\\sigma}}}{\\partial u} \\,, \\quad\n{\\pmb{\\sigma}}_v := \\frac{\\partial {\\pmb{\\sigma}}}{\\partial v} \\,.\n\\] Similar notations are adopted for higher order derivatives, e.g., \\[\\begin{align*}\n{\\pmb{\\sigma}}_{uu} & := \\frac{\\partial^2 {\\pmb{\\sigma}}}{\\partial u^2} \\,,\n& {\\pmb{\\sigma}}_{uv} & :=  \\frac{\\partial^2 {\\pmb{\\sigma}}}{\\partial u \\partial v} \\,, \\\\\n{\\pmb{\\sigma}}_{vu} & := \\frac{\\partial^2 {\\pmb{\\sigma}}}{\\partial v  \\partial u  } \\,,  \n& {\\pmb{\\sigma}}_{vv} & :=  \\frac{\\partial^2 {\\pmb{\\sigma}}}{\\partial v^2 } \\,, \\\\\n\\end{align*}\\]\nComponents of \\({\\pmb{\\sigma}}\\) will be denoted by \\[\n{\\pmb{\\sigma}}= (\\sigma^1, \\sigma^2, \\sigma^3) \\,.\n\\]\n\n\n\n\nExample 41: 2D Plane in \\(\\mathbb{R}^3\\)Planes in \\(\\mathbb{R}^3\\) are surfaces with atlas containing one chart. Namely, a plane \\(\\pi \\subseteq \\mathbb{R}^3\\) is described by \\[\n\\pi  = \\{  \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\,\\mathbf{x}\\cdot \\mathbf{w}= \\lambda \\} \\,.\n\\] Let\n\n\\(\\mathbf{p},\\mathbf{q} \\in \\mathbb{R}^3\\) be ortoghonal to each other and to \\(\\mathbf{w}\\).\n\\(\\mathbf{a} \\in \\pi\\) be any point in the plane.\n\nIf \\(\\mathbf{x}\\in \\pi\\) then \\(\\mathbf{x}-\\mathbf{a}\\) is parallel to the plane and \\(\\pi\\) can be equivalently represented as \\[\n\\pi = \\{ \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\, \\colon \\,u,v \\in \\mathbb{R}\\} \\,.\n\\] Define the map \\[\n{\\pmb{\\sigma}}\\colon \\mathbb{R}^2 \\to \\pi \\,, \\quad {\\pmb{\\sigma}}(u,v):= \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\,.\n\\] We have:\n\n\\({\\pmb{\\sigma}}\\) is smooth.\n\\(\\mathbb{R}^2\\) is obviously open.\n\\({\\pmb{\\sigma}}(\\mathbb{R}^2)\\) is open in \\(\\pi\\), since \\({\\pmb{\\sigma}}(\\mathbb{R}^2) = \\pi\\).\nThe inverse of \\({\\pmb{\\sigma}}\\) is \\[\n{\\pmb{\\sigma}}^{-1} \\colon \\pi \\to \\mathbb{R}^2 \\,, \\quad\n{\\pmb{\\sigma}}^{-1} (\\mathbf{x}) = ( (\\mathbf{x}- \\mathbf{a}) \\cdot \\mathbf{p}, (\\mathbf{x}- \\mathbf{a}) \\cdot \\mathbf{q}  ) \\,.\n\\]\nAs \\({\\pmb{\\sigma}}^{-1}\\) is continuous, then \\({\\pmb{\\sigma}}\\) is a homeomorphism between \\(\\mathbb{R}^2\\) and \\(\\pi\\).\n\nTherefore \\({\\pmb{\\sigma}}\\) is a chart for \\(\\pi\\). Since \\[\n{\\pmb{\\sigma}}(\\mathbb{R}^2) = \\pi \\,,\n\\] we have that \\(\\{{\\pmb{\\sigma}}\\}\\) is an atlas for \\(\\pi\\), and hence \\(\\pi\\) is a surface.\n\n\n\n\n\nA plane \\(\\pi\\) is a surface with atlas containing a single chart \\({\\pmb{\\sigma}}\\colon \\mathbb{R}^2 \\to \\pi\\).\n\n\n\nExample 42: Unit cylinder\nConsider the infinite unit cylinder \\[\n\\mathcal{S}= \\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = 1 \\} \\,.\n\\] \\(\\mathcal{S}\\) is a surface with an atlas consisting of two charts: \\[\n{\\pmb{\\sigma}}_i \\colon U_i \\to \\mathbb{R}^3   \\,, \\quad\n{\\pmb{\\sigma}}_i(u,v):= (\\cos(u),\\sin(u),v)\n\\] for \\(i=1,2\\), where \\[\nU_1 := \\left( 0,\\frac{ 3 \\pi}{2} \\right) \\times \\mathbb{R}\\,, \\quad\nU_2 := \\left( \\pi,\\frac{ 5 \\pi}{2} \\right) \\times \\mathbb{R}\\,.\n\\]\n\nIndeed:\n\n\\({\\pmb{\\sigma}}_i\\) is smooth.\n\\(U_i\\) is clearly open in \\(\\mathbb{R}^2\\).\nOne can check that \\({\\pmb{\\sigma}}_i(U_i)\\) is open in \\(\\mathcal{S}\\).\n\\({\\pmb{\\sigma}}_i\\) is a homeomorphism of \\(U_i\\) in \\({\\pmb{\\sigma}}(U_i)\\).\n\\(\\{{\\pmb{\\sigma}}_1 , {\\pmb{\\sigma}}_2\\}\\) is an atlas for \\(\\mathcal{S}\\), since \\[\n\\mathcal{S}= {\\pmb{\\sigma}}_1(U_1) \\cup {\\pmb{\\sigma}}_2(U_2) \\,.\n\\]\n\n\n\n\n\n\n\nUnit cylinder \\(\\mathcal{S}\\) is a surface with atlas \\(\\mathcal{A} = \\{{\\pmb{\\sigma}}_1,{\\pmb{\\sigma}}_2\\}\\). Depicted are the images \\({\\pmb{\\sigma}}_1(U_1)\\) and \\({\\pmb{\\sigma}}_2(U_2)\\).\n\n\n\nImportantConsider again the unit cylinder \\[\n\\mathcal{S}= \\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = 1 \\} \\,.\n\\] Define the map \\[\n{\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3   \\,, \\quad\n{\\pmb{\\sigma}}(u,v):= (\\cos(u),\\sin(u),v)\n\\] where \\[\nU:= [ 0, 2 \\pi ] \\times \\mathbb{R}\\,.\n\\] Clearly we have \\[\n{\\pmb{\\sigma}}(U) = \\mathcal{S}\\,.\n\\] However \\(\\{{\\pmb{\\sigma}}\\}\\) is not an atlas for \\(\\mathcal{S}\\), since \\({\\pmb{\\sigma}}\\) is not a chart. This is because \\({\\pmb{\\sigma}}\\) is not invertible, as for example \\[\n{\\pmb{\\sigma}}(0,0) = {\\pmb{\\sigma}}(2\\pi,0) \\,.\n\\] Therefore \\({\\pmb{\\sigma}}\\) cannot be an omeomorphism between \\(U\\) and \\(\\mathcal{S}\\).\n\n\n\nExample 43: Graph of a function\nLet \\(U \\subseteq \\mathbb{R}^2\\) be open and \\(f \\colon U \\to \\mathbb{R}\\) be smooth. The graph of \\(f\\) is the set \\[\n\\Gamma_f := \\{ (u,v,f(u,v)) \\, \\colon \\,(u,v) \\in U  \\}  \\,.\n\\] We have that \\(\\Gamma_f\\) is a surface with atlas given by \\[\n\\mathcal{A} = \\{ {\\pmb{\\sigma}}\\}\n\\] where \\({\\pmb{\\sigma}}\\colon U \\to \\Gamma_f\\) is \\[\n{\\pmb{\\sigma}}(u,v):=(u,v,f(u,v)) \\,.\n\\]\n\nLet us check that \\(\\Gamma_f\\) is a surface:\n\n\\({\\pmb{\\sigma}}\\) is smooth since \\(f\\) is smooth.\n\\(U\\) is open in \\(\\mathbb{R}^2\\) by assumption.\n\\({\\pmb{\\sigma}}(U) = \\Gamma_f\\), and therefore \\({\\pmb{\\sigma}}(U)\\) is open in \\(\\Gamma_f\\).\nThe inverse of \\({\\pmb{\\sigma}}\\) is given by \\(\\widetilde{{\\pmb{\\sigma}}} \\colon \\Gamma_f \\to U\\) defined as \\[\n\\widetilde{{\\pmb{\\sigma}}}(u,v,f(u,v)) := (u,v) \\,.\n\\] Clearly \\(\\widetilde{{\\pmb{\\sigma}}}\\) is continuous.\nTherefore \\({\\pmb{\\sigma}}\\) is a homeomorphism of \\(U\\) into \\(\\Gamma_f\\).\n\\(\\mathcal{A}=\\{{\\pmb{\\sigma}}\\}\\) is an atlas for \\(\\Gamma_f\\), since \\[\n\\Gamma_f = {\\pmb{\\sigma}}(U) \\,.\n\\]\n\n\n\n\nLet us conclude the section with an example of a set which is not a surface.\n\nExample 44: Circular coneConsider the circular cone \\[\n\\mathcal{S}:= \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = z^2  \\} \\,.\n\\] Then \\(\\mathcal{S}\\) is not a surface. This is essentially consequence of the fact that \\[\n\\mathcal{S}\\smallsetminus \\{{\\pmb{0}}\\}\n\\] is a disconnected set.\nTo see that \\(\\mathcal{S}\\) is not a surface, suppose there exists an atlas \\(\\{{\\pmb{\\sigma}}_i\\}\\) of \\(\\mathcal{S}\\) \\[\n{\\pmb{\\sigma}}_i \\colon U_i \\to {\\pmb{\\sigma}}_i(U_i) \\subseteq \\mathcal{S}\\,.\n\\] In particular there exists a chart \\({\\pmb{\\sigma}}\\) such that \\[\n{\\pmb{0}}\\in {\\pmb{\\sigma}}(U) \\,.\n\\] Let \\(\\mathbf{x}_0 \\in U\\) be the point such that \\[\n{\\pmb{\\sigma}}(\\mathbf{x}_0) = {\\pmb{0}}\\,.\n\\] Since \\(U\\) is open in \\(\\mathbb{R}^2\\), there exists \\(\\varepsilon&gt;0\\) such that \\(B_{\\varepsilon}(\\mathbf{x}_0) \\subseteq U\\). Since \\({\\pmb{\\sigma}}\\) is a homeomorphism, we deduce that \\[\n{\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0))\n\\] is open in \\(\\mathcal{S}\\). Hence there exists an open set \\(W\\) in \\(\\mathbb{R}^3\\) such that \\[\n{\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0)) = {\\pmb{\\sigma}}(U) \\cap W \\,.\n\\] As \\({\\pmb{0}}\\in {\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0))\\), we conclude that \\({\\pmb{0}}\\in W\\). Since \\(W\\) is open in \\(\\mathbb{R}^3\\), there exists \\(\\delta &gt; 0\\) such that \\[\nB_{\\delta} ({\\pmb{0}}) \\subseteq W \\,.\n\\] In particular we deduce that \\[\nB_{\\delta} ({\\pmb{0}}) \\cap {\\pmb{\\sigma}}(U) \\subseteq  {\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0)) \\,.\n\\] Hence \\({\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0))\\) contains points of both \\(\\mathcal{S}^-\\) and \\(\\mathcal{S}^+\\), with \\[\n\\mathcal{S}^- := \\mathcal{S}\\cap \\{ z &lt; 0 \\}   \\,, \\quad\n\\mathcal{S}^+ := \\mathcal{S}\\cap \\{ z &gt; 0 \\}   \\,.\n\\] This implies that \\[\nV := {\\pmb{\\sigma}}(B_{\\varepsilon}(\\mathbf{x}_0)) \\smallsetminus \\{{\\pmb{0}}\\}\n\\] is disconnected, with disconnection given by \\[\nV = ( V \\cap \\mathcal{S}^- ) \\cup (V \\cap \\mathcal{S}^+) \\,.\n\\] However \\(V\\) is homeomorphic to \\[\nB_{\\varepsilon} (\\mathbf{x}_0) \\smallsetminus \\{ \\mathbf{x}_0 \\} \\,,\n\\] which is instead connected. Contradiction. Hence \\(\\mathcal{S}\\) is not a surface.\n\n\n\n\n\nThe circular cone is not a surface. This is because \\(\\mathcal{S}\\smallsetminus \\{{\\pmb{0}}\\}\\) is disconnected.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#regular-surfaces",
    "href": "sections/chap_4.html#regular-surfaces",
    "title": "4  Surfaces",
    "section": "4.3 Regular Surfaces",
    "text": "4.3 Regular Surfaces\nWe have defined a regular curve to be a map \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^n\\) such that \\[\n\\left\\| {\\pmb{\\gamma}}(t) \\right\\| \\neq 0 \\,, \\quad \\forall \\, t \\in (a,b) \\,.\n\\] This allowed us to define tangent vectors and, eventually, Frenet frame.\nWe want to do something similar for surfaces: We look for a condition that eventually will allow us to define tangent planes. This is why we introduce regular charts and regular surfaces.\n\nDefinition 45: Regular ChartLet \\(U \\subseteq \\mathbb{R}^2\\) be open. A map \\[\n{\\pmb{\\sigma}}= {\\pmb{\\sigma}}(u,v)  \\colon U \\to \\mathbb{R}^3\n\\] is called a regular chart if the partial derivatives \\[\n{\\pmb{\\sigma}}_u(u,v) = \\frac{d{\\pmb{\\sigma}}}{du}(u,v) \\,, \\quad\n{\\pmb{\\sigma}}_v(u,v) = \\frac{d{\\pmb{\\sigma}}}{dv}(u,v)\n\\] are linearly independent vectors of \\(\\mathbb{R}^3\\) for all \\((u,v) \\in U\\).\n\n\nThe following gives more insight into the regularity condition.\n\nProposition 46\nLet \\(U \\subseteq \\mathbb{R}^2\\) be open and consider a map \\[\n{\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3 \\,.\n\\] They are equivalent:\n\n\\({\\pmb{\\sigma}}\\) is a regular chart.\nThe differential \\(d{\\pmb{\\sigma}}_{\\mathbf{x}} \\colon \\mathbb{R}^2 \\to \\mathbb{R}^3\\) is injective for all \\(\\mathbf{x}\\in U\\).\nThe Jacobian matrix \\[\nJ{\\pmb{\\sigma}}(u,v) =\n\\left(\n\\begin{array}{ccc}\n\\sigma^1_{u}  &  \\sigma^1_{v} \\\\\n\\sigma^2_{u}  &  \\sigma^2_{v} \\\\\n\\sigma^3_{u}  &  \\sigma^3_{v} \\\\\n\\end{array}\n\\right)\n\\] has rank \\(2\\) for all \\((u,v) \\in U\\).\nIt holds \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\neq 0 \\, \\quad  \\forall \\, (u,v) \\in U \\,.\n\\]\n\n\n\n\nProofPart 1. Equivalence of Point 1 and Point 4.\nBy the properties of vector product, we have that \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\neq 0 \\, \\quad \\, \\forall (u,v) \\in U\n\\] if and only if \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent for all \\((u,v) \\in U\\).\nPart 2. Equivalence of Point 2 and Point 3.\nThe differential \\(d{\\pmb{\\sigma}}_{\\mathbf{x}} \\colon \\mathbb{R}^2 \\to \\mathbb{R}^3\\) is represented in matrix form by the Jacobian \\[\nJ{\\pmb{\\sigma}}(u,v) =\n\\left(\n\\begin{array}{ccc}\n\\sigma^1_{u}  &  \\sigma^1_{v} \\\\\n\\sigma^2_{u}  &  \\sigma^2_{v} \\\\\n\\sigma^3_{u}  &  \\sigma^3_{v} \\\\\n\\end{array}\n\\right)\n\\] By standard linear algebra results, \\(J{\\pmb{\\sigma}}\\) has rank 2 if and only if \\(d{\\pmb{\\sigma}}\\) is injective.\nPart 3. Equivalence of Point 1 and Point 3.\nA \\(3 \\times 2\\) matrix has rank 2 if and only if its columns are linearly independent. Since the columns of \\(J{\\pmb{\\sigma}}\\) are \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\), we conclude that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent.\n\n\nWe are now ready to define regular surfaces.\n\nDefinition 47: Regular surface\nLet \\(\\mathcal{S}\\) be a surface. Let \\[\n\\mathcal{A} = \\{ {\\pmb{\\sigma}}_i \\}_{i \\in I} \\,,\n\\] be an atlas for \\(\\mathcal{S}\\). We say that:\n\n\\(\\mathcal{A}\\) is a regular atlas if the map \\({\\pmb{\\sigma}}_i\\) is a regular chart for all \\(i \\in I\\).\n\\(\\mathcal{S}\\) is a regular surface if there exists a regular atlas for \\(\\mathcal{S}\\).\n\n\n\n\nExample 48: 2D Plane in \\(\\mathbb{R}^3\\)Let \\(\\mathbf{a}, \\mathbf{p}, \\mathbf{q} \\in \\mathbb{R}^3\\), with \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) orthogonal. We have shown that the plane \\[\n\\pi = \\{ \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\, \\colon \\,u,v \\in \\mathbb{R}\\}\n\\] is a surface with atlas \\(\\mathcal{A} = \\{{\\pmb{\\sigma}}\\}\\), where \\[\n{\\pmb{\\sigma}}\\colon \\mathbb{R}^2 \\to \\pi \\,, \\quad {\\pmb{\\sigma}}(u,v):= \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\,.\n\\] Then \\(\\pi\\) is a regular surface, because \\({\\pmb{\\sigma}}\\) is a regular chart. To see this, compute \\[\n{\\pmb{\\sigma}}_u = \\mathbf{p}\\,, \\quad {\\pmb{\\sigma}}_v = \\mathbf{q} \\,.\n\\] Since \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) are orthogonal, then they are linearly independent. Thus \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent, and \\({\\pmb{\\sigma}}\\) is a regular chart.\n\n\n\nExample 49: Unit cylinderConsider the infinite unit cylinder \\[\n\\mathcal{S}= \\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = 1 \\} \\,.\n\\] We have seen that \\(\\mathcal{S}\\) is a surface with atlas \\(\\mathcal{A} = \\{ {\\pmb{\\sigma}}_1,{\\pmb{\\sigma}}_2\\}\\) where we define \\[\n{\\pmb{\\sigma}}\\colon \\mathbb{R}^2 \\to \\mathbb{R}^3   \\,, \\quad\n{\\pmb{\\sigma}}(u,v):= (\\cos(u),\\sin(u),v)\n\\] and \\[\\begin{align*}\n{\\pmb{\\sigma}}_1 & := {\\pmb{\\sigma}}|_{U_1} \\,,   & {\\pmb{\\sigma}}_2 & := {\\pmb{\\sigma}}|_{U_2} \\,, \\\\\nU_1 & := \\left( 0,\\frac{ 3 \\pi}{2} \\right) \\times \\mathbb{R}\\,,\n& U_2 & := \\left( \\pi,\\frac{ 5 \\pi}{2} \\right) \\times \\mathbb{R}\\,.\n\\end{align*}\\] We have that \\(\\mathcal{S}\\) is a regular surface, since the atlas \\(\\mathcal{A}\\) is regular. Indeed: \\[\n{\\pmb{\\sigma}}_u = (-\\sin(u),\\cos(u),0) \\,, \\quad\n{\\pmb{\\sigma}}_v = (0,0,1) \\,,\n\\] and therefore \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v = (\\cos (u), \\sin(u), 0)  \\,, \\quad \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| = 1 \\,.\n\\] This implies \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\neq 0 \\,, \\quad \\forall \\, (u,v) \\in \\mathbb{R}^2 \\,,\n\\] showing that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent. Therefore \\({\\pmb{\\sigma}}_1\\) and \\({\\pmb{\\sigma}}_2\\) are regular charts, being restrictions of \\({\\pmb{\\sigma}}\\).\n\n\n\nExample 50: Graph of a functionLet \\(U \\subseteq \\mathbb{R}^2\\) be open and \\(f \\colon U \\to \\mathbb{R}\\) be smooth. The graph of \\(f\\) is the set \\[\n\\Gamma_f := \\{ (u,v,f(u,v)) \\, \\colon \\,(u,v) \\in U  \\}  \\,.\n\\] We have seen that \\(\\Gamma_f\\) is surface with atlas given by \\(\\mathcal{A} = \\{ {\\pmb{\\sigma}}\\}\\), where \\({\\pmb{\\sigma}}\\colon U \\to \\Gamma_f\\) is \\[\n{\\pmb{\\sigma}}(u,v):=(u,v,f(u,v)) \\,.\n\\] We have that \\(\\Gamma_f\\) is regular, since \\(\\mathcal{A}\\) is a regular atlas. Indeed, \\[\n{\\pmb{\\sigma}}_u = (1,0,f_u) \\,, \\quad\n{\\pmb{\\sigma}}_v = (0,1,f_v) \\,,\n\\] and so \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v = (-f_u, - f_v, 1 ) \\neq {\\pmb{0}}\\,,\n\\] since the last component never vanishes. Therefore \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent and \\({\\pmb{\\sigma}}\\) is a regular chart.\n\n\n\nExample 51: Unit sphere\nConsider the unit sphere in \\(\\mathbb{R}^3\\) \\[\n\\mathbb{S}^2 := \\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 + z^2 = 1  \\} \\,.\n\\] We have that \\(\\mathbb{S}^2\\) is a regular surface, with regular atlas \\[\n\\mathcal{A} = \\{ {\\pmb{\\sigma}}_i \\}_{i=1}^6 \\,,\n\\] defined as follows: Let \\[\nU:= \\{ (u,v) \\in \\mathbb{R}^2 \\colon u^2 + v^2 &lt; 1  \\}\n\\] be the unit open ball in \\(\\mathbb{R}^2\\) and define \\({\\pmb{\\sigma}}_i \\colon U \\to \\mathbb{R}^3\\) by \\[\\begin{align*}\n{\\pmb{\\sigma}}_1 (u,v) & = \\left(u,v,\\sqrt{1-u^2-v^2}  \\right) \\\\\n{\\pmb{\\sigma}}_2 (u,v) & = \\left(u,v,-\\sqrt{1-u^2-v^2}  \\right) \\\\\n{\\pmb{\\sigma}}_3 (u,v) & = \\left(u,\\sqrt{1-u^2-v^2},v  \\right) \\\\\n{\\pmb{\\sigma}}_4 (u,v) & = \\left(u, -\\sqrt{1-u^2-v^2}, v  \\right) \\\\\n{\\pmb{\\sigma}}_5 (u,v) & = \\left(\\sqrt{1-u^2-v^2} , u ,v \\right) \\\\\n{\\pmb{\\sigma}}_6 (u,v) & = \\left(-\\sqrt{1-u^2-v^2}, u,v,  \\right) \\\\\n\\end{align*}\\]\n\nExercise: Check that \\(\\mathbb{S}^2\\) is a regular surface.\n\n\n\n\nRemark 52: Spherical coordinates\nThe equivalent of polar coordinates in dimension \\(3\\) are spherical coordinates. A point \\((x,y,z) \\in \\mathbb{R}^3 \\smallsetminus \\{{\\pmb{0}}\\}\\) can be represented in spherical coordinates by \\[\\begin{align*}\nx & = \\rho \\cos (\\theta)  \\cos(\\phi)  \\\\\ny & = \\rho \\cos (\\theta)  \\sin(\\phi) \\\\\nz & = \\rho \\sin (\\theta)\n\\end{align*}\\] where \\[\n\\rho:=\\sqrt{ x^2 + y^2 + z^2 } \\,, \\quad \\phi\\in [0,2\\pi] \\,, \\quad \\theta \\in \\left[ -\\frac{\\pi}{2}, \\frac{\\pi}{2} \\right] \\,,\n\\] with the angles \\(\\phi\\) and \\(\\theta\\) as in Figure Figure 4.1.\n\nIt is clear that \\(z = \\rho \\sin(\\theta)\\), by basic trigonometry. To compute \\(x\\) and \\(y\\), we note that the segment joining \\({\\pmb{0}}\\) to \\(\\mathbf{p}\\) has length \\[\nL = \\rho \\cos \\theta \\,.\n\\] Therefore we get \\[\\begin{align*}\nx & = L \\cos (\\phi) = \\rho \\cos (\\theta)  \\cos(\\phi) \\\\\ny & = L \\sin (\\phi) = \\rho \\cos (\\theta)  \\sin(\\phi)\n\\end{align*}\\] concluding.\n\n\n\n\n\n\n\n\n\nFigure 4.1: Spherical coordinates in \\(\\mathbb{R}^3\\).\n\n\n\n\nExample 53: Unit sphere in spherical coordinatesConsider again the unit sphere in \\(\\mathbb{R}^3\\) \\[\n\\mathbb{S}^2 := \\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 + z^2 = 1  \\} \\,.\n\\] We want to give an alternative atlas for \\(\\mathbb{S}^2\\) based on spherical coordinates. To this end, define \\[\nU := \\left\\{ (\\theta,\\phi)  \\in \\mathbb{R}^2 \\, \\colon \\,-\\frac{\\pi}{2} &lt; \\theta &lt; \\frac{\\pi}{2} \\,, \\,\\,\n0&lt; \\phi &lt; 2 \\pi    \\right\\}\n\\] and \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) by \\[\n{\\pmb{\\sigma}}( \\theta , \\phi ) :=  ( \\cos(\\theta) \\cos(\\phi), \\cos(\\theta) \\sin(\\phi), \\sin (\\theta)  ) \\,.\n\\] We have:\n\n\\({\\pmb{\\sigma}}\\) is smooth.\n\\(U\\) is open in \\(\\mathbb{R}^2\\).\nMoreover \\[\n{\\pmb{\\sigma}}(U) = \\mathbb{S}^2 \\smallsetminus \\{ (x,0,z) \\in \\mathbb{R}^3 \\, \\colon \\,x \\geq 0  \\} \\,,\n\\] as seen also in the left picture in Figure 4.2.\nThe set \\({\\pmb{\\sigma}}(U)\\) is evidently open in \\(\\mathbb{S}^2\\).\nIt is easy to check that \\({\\pmb{\\sigma}}\\) is invertible, with continuous inverse.\nThus \\({\\pmb{\\sigma}}\\) is a homeomorphism from \\(U\\) into \\({\\pmb{\\sigma}}(U)\\).\n\nLet us check that \\({\\pmb{\\sigma}}\\) is a regular chart: \\[\\begin{align*}\n{\\pmb{\\sigma}}_{\\theta} & = (-\\sin(\\theta) \\cos(\\phi), -\\sin(\\theta) \\sin(\\phi), \\cos(\\theta) ) \\\\\n{\\pmb{\\sigma}}_{\\phi} & = ( - \\cos(\\theta) \\sin(\\phi), \\cos(\\theta) \\cos(\\phi), 0 )  \\,.\n\\end{align*}\\] Therefore \\[\n{\\pmb{\\sigma}}_{\\theta} \\times {\\pmb{\\sigma}}_{\\phi} =\n( - \\cos^2(\\theta) \\cos(\\phi), - \\cos^2(\\theta) \\sin(\\phi), - \\sin(\\theta) \\cos ( \\theta ) ) \\,,\n\\] from which \\[\n\\left\\|  {\\pmb{\\sigma}}_{\\theta} \\times {\\pmb{\\sigma}}_{\\phi}  \\right\\| = |\\cos (\\theta)| \\, .\n\\] Since \\((\\theta,\\phi)\\in U\\), we have \\(\\theta \\in ( -\\pi/2, \\pi/2 )\\), and so \\[\n\\left\\|  {\\pmb{\\sigma}}_{\\theta} \\times {\\pmb{\\sigma}}_{\\phi}  \\right\\| = |\\cos (\\theta)| \\neq 0 \\,,\n\\] showing that \\({\\pmb{\\sigma}}_{\\theta}\\) and \\({\\pmb{\\sigma}}_{\\phi}\\) are linearly independent, and \\({\\pmb{\\sigma}}\\) is regular.\nSince \\({\\pmb{\\sigma}}(U) \\neq \\mathbb{S}^2\\), the chart \\({\\pmb{\\sigma}}\\) does not form an atlas. We need a second chart. An option is to define \\(\\widetilde{{\\pmb{\\sigma}}} \\colon U \\to \\mathbb{R}^3\\) by \\[\n\\widetilde{{\\pmb{\\sigma}}} := ( - \\cos(\\theta) \\cos (\\phi), -\\sin(\\theta) , - \\cos (\\theta) \\sin(\\phi)) \\,.\n\\] Notice that \\(\\widetilde{{\\pmb{\\sigma}}}\\) is obtained by rotating \\({\\pmb{\\sigma}}\\) by \\(\\pi\\) about the \\(z\\)-axis and by \\(\\pi/2\\) about the \\(y\\)-axis, as seen in the right picture in Figure 4.2. It is an exercise to check that \\(\\widetilde{{\\pmb{\\sigma}}}\\) is a regular chart.\nSince we have \\[\n\\widetilde{{\\pmb{\\sigma}}} (U) = \\mathbb{S}^2 \\smallsetminus \\{ (x,y,0) \\in \\mathbb{R}^3 \\, \\colon \\,x \\leq 0  \\} \\,,\n\\] it is immediate to see that \\[\n\\mathbb{S}^2 = {\\pmb{\\sigma}}(U) \\cup \\widetilde{{\\pmb{\\sigma}}}(U) \\,.\n\\] Hence \\[\n\\mathcal{A} := \\{   {\\pmb{\\sigma}}, \\widetilde{{\\pmb{\\sigma}}} \\}\n\\] is a regular atlas for \\(\\mathbb{S}^2\\).\n\n\n\n\n\n\n\n\n\n\nFigure 4.2: Image of the charts of the sphere from the above example.\n\n\n\n\n\nLet us make an example of a non-regular surface.\n\nExample 54The surface parametrized by \\[\n{\\pmb{\\sigma}}(u,v) = (u,v^2,v^3) \\,, \\quad \\forall (u,v) \\in \\mathbb{R}^2\n\\] is not regular. This is because \\[\n{\\pmb{\\sigma}}_u = (1,0,0) \\,, \\quad\n{\\pmb{\\sigma}}_v = (0,2v,3v^2)\n\\] and therefore \\[\n{\\pmb{\\sigma}}_v(u,0) = (0,0,0) \\,,\n\\] showing that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly dependent along the line \\[\nL = \\{ (u,0) \\, \\colon \\,u \\in \\mathbb{R}\\} \\,.\n\\] Hence \\({\\pmb{\\sigma}}\\) is not a regular chart.\nLooking at Figure Figure 4.3, it is clear that \\(\\mathcal{S}\\) is not regular, since \\(\\mathcal{S}\\) has a cusp along the line \\({\\pmb{\\sigma}}(L)\\).\n\n\n\n\n\n\n\n\n\n\nFigure 4.3: Example of non-regular surface.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#level-surfaces",
    "href": "sections/chap_4.html#level-surfaces",
    "title": "4  Surfaces",
    "section": "4.4 Level surfaces",
    "text": "4.4 Level surfaces\n\nDefinition 55: Level surfaceLet \\(V \\subseteq \\mathbb{R}^3\\) be an open set and \\(f \\colon V \\to \\mathbb{R}\\) be smooth. The level surface associated with \\(f\\) is the set \\[\n\\mathcal{S}_f := f^{-1}(0) = \\{ (x,y,z) \\in V \\, \\colon \\,f(x,y,z) = 0  \\} \\,.\n\\]\n\n\nWe now give a result concerning regularity of level surfaces. The proof, rather technical, is based on the Implicit Function Theorem and can be found in Proposition 3.1.25 of (Abate, Marco and Tovena, Francesca 2011). We decide to omit it.\n\nTheorem 56Let \\(V \\subseteq \\mathbb{R}^3\\) be an open set and \\(f \\colon V \\to \\mathbb{R}\\) be smooth. Consider the level surface \\[\n\\mathcal{S}_f = \\{ (x,y,z) \\in V \\, \\colon \\,f(x,y,z) = 0  \\} \\,.\n\\] Suppose that \\[\n\\nabla f (x,y,z) \\neq 0 \\,, \\quad \\forall \\, (x,y,z) \\in V \\,.\n\\] Then \\(\\mathcal{S}_f\\) is a regular surface.\n\n\n\nExample 57We want to determine if the set defined by the equation \\[\n\\mathcal{S}= \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = 1 \\}  \n\\] is a regular surface. Note that \\(\\mathcal{S}\\) is a unit cylinder: From Example 49 we already know that \\(\\mathcal{S}\\) is a regular surface.\nLet us prove that \\(\\mathcal{S}\\) is regular by using Theorem 56. To this end, define the open set \\[\nV := \\mathbb{R}^3 \\smallsetminus \\{ (0,0,z) \\, \\colon \\,z \\in \\mathbb{R}\\} \\,.\n\\] Note that \\(V\\) is obtained by removing the \\(z\\)-axis from \\(\\mathbb{R}^3\\). Also define the function \\(f \\colon \\mathbb{R}^3 \\to \\mathbb{R}\\) by \\[\nf(x,y,z) := x^2 + y^2 -1 \\,.\n\\] We have \\[\n\\nabla f (x,y,z) = ( 2x, 2y, 0 ) \\neq 0  \\,, \\quad\n\\forall \\, (x,y,z) \\in V \\,.\n\\] Since \\[\n\\mathcal{S}= \\mathcal{S}_f \\,,\n\\] by Theorem 56 we conclude that \\(\\mathcal{S}\\) is a regular surface.\n\n\n\nExample 58: Circular coneWe saw that the circular cone \\[\n\\mathcal{S}:= \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = z^2  \\} \\,.\n\\] is not a surface. However the positive sheet \\[\n\\mathcal{S}^+ := \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 = z^2 \\,, \\,  z&gt;0  \\} \\,.\n\\] is a regular surface, see Figure 4.4 Indeed, define the open set \\[\nV := \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,z &gt; 0 \\}\n\\] and the function \\(f \\colon V \\to \\mathbb{R}\\) by \\[\nf(x,y,z) := x^2 + y^2 - z^2 \\,.\n\\] We have \\[\n\\nabla f (x,y,z) = ( 2x, 2y, -2z ) \\neq 0  \\,, \\quad\n\\forall \\, (x,y,z) \\in V \\,.\n\\] Since \\[\n\\mathcal{S}^+ = \\mathcal{S}_f \\,,\n\\] by Theorem 56 we conclude that \\(\\mathcal{S}\\) is a regular surface.\nAs a side note, a regular atlas for \\(\\mathcal{S}^+\\) is given by \\(\\mathcal{A} = \\{{\\pmb{\\sigma}}\\}\\) where \\({\\pmb{\\sigma}}\\colon \\mathbb{R}^2 \\to \\mathbb{R}^3\\) is defined by \\[\n{\\pmb{\\sigma}}(u,v) := (u,v,\\sqrt{u^2 + v^2}) \\,.\n\\]\n\n\n\n\n\n\n\n\n\n\nFigure 4.4: Positive sheet of circular cone.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#reparametrizations",
    "href": "sections/chap_4.html#reparametrizations",
    "title": "4  Surfaces",
    "section": "4.5 Reparametrizations",
    "text": "4.5 Reparametrizations\nWe have defined the reparametrization of curves. In a similar way, one can reparametrize surface charts.\n\nDefinition 59Suppose that \\(U, \\widetilde{U} \\subseteq \\mathbb{R}^2\\) are open sets and \\[\n{\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3 \\,, \\quad\n\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\mathbb{R}^3 \\,,\n\\] are surface charts. We say that \\(\\widetilde{{\\pmb{\\sigma}}}\\) is a reparametrization of \\({\\pmb{\\sigma}}\\) if there exists a diffeomorphism \\[\n\\Phi \\colon \\widetilde{U} \\to U \\,,\n\\] such that \\[\n\\widetilde{{\\pmb{\\sigma}}} = {\\pmb{\\sigma}}\\circ \\Phi \\,,\n\\] that is, \\[\n\\widetilde{{\\pmb{\\sigma}}}( \\tilde{u},\\tilde{v} ) = {\\pmb{\\sigma}}(  \\Phi ( \\tilde{u},\\tilde{v}) ) \\,, \\quad \\forall \\,\\, (\\tilde{u},\\tilde{v} ) \\in\n\\widetilde{U} \\,.\n\\] We call \\(\\Phi\\) a reparametrization map.\n\n\n\n\n\nSchematic illustration of surface chart \\({\\pmb{\\sigma}}\\) and reparametrization \\(\\widetilde{{\\pmb{\\sigma}}}\\).\n\n\nWe will show that reparametrizations of regular charts are regular. To prove this, first we need to recall the chain rule for multivariable functions.\n\nRemark 60: Chain ruleSuppose that \\(U, \\widetilde{U} \\subseteq \\mathbb{R}^2\\) are open sets, \\[\nf \\colon U \\to \\mathbb{R}^3\n\\] is smooth, and \\[\n\\Phi \\colon \\widetilde{U} \\to U\n\\] is a diffeomorphism. Define \\(\\tilde{f} \\colon \\widetilde{U} \\to \\mathbb{R}^3\\) by composition: \\[\n\\tilde{f} := f \\circ \\Phi \\,.\n\\] Explicitly, the above means \\[\n\\tilde{f}( \\tilde{u},\\tilde{v} ) = f (  \\Phi ( \\tilde{u},\\tilde{v}) ) \\,, \\quad \\forall \\,\\, (\\tilde{u},\\tilde{v} ) \\in\n\\widetilde{U} \\,.\n\\] We denote the components of \\(f, \\tilde{f}\\) and \\(\\Phi\\) by \\[\n\\tilde{f} = (\\tilde{f}^1, \\tilde{f}^2, \\tilde{f}^3) \\,, \\quad\nf = (f^1,f^2,f^3) \\,, \\quad\n\\Phi = (\\Phi^1, \\Phi^2) \\,.\n\\] The Jacobians are \\[\nJ \\tilde{f} = \\left(   \n\\begin{array}{cc}\n\\tilde{f}^1_{\\tilde u}  & \\tilde{f}^1_{\\tilde v}  \\\\\n\\tilde{f}^2_{\\tilde u}  & \\tilde{f}^2_{\\tilde v}  \\\\\n\\tilde{f}^3_{\\tilde u}  & \\tilde{f}^3_{\\tilde v}\n\\end{array}\n\\right) \\,, \\quad\nJ f = \\left(   \n\\begin{array}{cc}\n{f}^1_{u}  &  {f}^1_{v}  \\\\\n{f}^2_{u}  &  {f}^2_{v}  \\\\\n{f}^3_{u}  &  {f}^3_{v}\n\\end{array}\n\\right) \\,, \\quad\nJ \\Phi = \\left(   \n\\begin{array}{cc}\n{\\Phi}^1_{\\tilde u}  &  {\\Phi}^1_{\\tilde v}  \\\\\n{\\Phi}^2_{\\tilde u}  &  {\\Phi}^2_{\\tilde v}  \n\\end{array}\n\\right) \\,.\n\\]\nThe chain rule states that \\[\nJ \\tilde{f} (\\tilde u, \\tilde v) = Jf ( \\Phi (\\tilde u, \\tilde v) ) \\,\nJ\\Phi (\\tilde u, \\tilde v) \\,.\n\\] By expanding the above identity we obtain the chain rule in vectorial form \\[\\begin{align*}\n\\tilde{f}_{\\tilde{u}} (\\tilde{u}, \\tilde{v}) & =\nf_u ( \\Phi(\\tilde{u}, \\tilde{v}) ) \\Phi_{\\tilde{u}}^1 (\\tilde{u}, \\tilde{v}) + f_v ( \\Phi(\\tilde{u}, \\tilde{v}) ) \\Phi_{\\tilde{u}}^2 (\\tilde{u}, \\tilde{v}) \\\\\n\\tilde{f}_{\\tilde{v}} (\\tilde{u}, \\tilde{v}) & =\nf_u ( \\Phi(\\tilde{u}, \\tilde{v}) ) \\Phi_{\\tilde{v}}^1 (\\tilde{u}, \\tilde{v}) + f_v ( \\Phi(\\tilde{u}, \\tilde{v}) ) \\Phi_{\\tilde{v}}^2 (\\tilde{u}, \\tilde{v})\n\\end{align*}\\] As done previously, we introduce compact notation for reparametrizations and chain rule. Specifically, we denote the components of the diffeomorphism \\(\\Phi\\) by \\[\\begin{align*}\n\\Phi^1 \\quad & \\leadsto \\quad (\\tilde u, \\tilde v) \\mapsto u (\\tilde u, \\tilde v)  \\\\\n\\Phi^2 \\quad & \\leadsto \\quad (\\tilde u, \\tilde v) \\mapsto v (\\tilde u, \\tilde v)\n\\end{align*}\\] Accordingly, the Jacobian of \\(\\Phi\\) is denoted as: \\[\nJ \\Phi = \\left(   \n\\begin{array}{cc}\n{\\Phi}^1_{\\tilde u}  &  {\\Phi}^1_{\\tilde v}  \\\\\n{\\Phi}^2_{\\tilde u}  &  {\\Phi}^2_{\\tilde v}  \n\\end{array}\n\\right)   \\quad \\leadsto \\quad\n\\left(   \n\\begin{array}{cc}\n\\dfrac{\\partial u}{\\partial \\tilde u}  &  \\dfrac{\\partial u}{\\partial \\tilde v}  \\\\\n\\dfrac{\\partial v}{\\partial \\tilde u}  &  \\dfrac{\\partial v}{\\partial \\tilde v}\n\\end{array}\n\\right)  \\,.\n\\] Hence, the chain rule in vectorial form reads \\[\\begin{align*}\n\\tilde{f}_{\\tilde{u}}  & =\nf_u  \\frac{\\partial u}{\\partial \\tilde{u}} + f_v  \\frac{\\partial v}{\\partial \\tilde{u}} \\\\\n\\tilde{f}_{\\tilde{v}}  & =\nf_u  \\, \\frac{\\partial u}{\\partial \\tilde{v}}  + f_v  \\frac{\\partial v}{\\partial \\tilde{v}}\n\\end{align*}\\]\n\n\nWe will now prove that the reparametrization of a regular chart is regular.\n\nProposition 61Suppose that \\(U, \\widetilde{U} \\subseteq \\mathbb{R}^2\\) are open sets and \\[\n{\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\n\\] is a regular chart. Assume given a diffeomorphism \\[\n\\Phi \\colon \\widetilde{U} \\to U \\,.\n\\] The reparametrization \\(\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\mathbb{R}^3\\) defined by \\[\n\\widetilde{{\\pmb{\\sigma}}} = {\\pmb{\\sigma}}\\circ \\Phi\n\\] is a regular chart.\n\n\n\nProofSince \\({\\pmb{\\sigma}}\\) is a regular chart we have that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent. Hence \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\neq 0 \\,.\n\\] To see that \\(\\widetilde{{\\pmb{\\sigma}}}\\) is regular it is sufficient to prove that \\[\n\\widetilde{{\\pmb{\\sigma}}}_{\\tilde u} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde v} \\neq 0 \\,.\n\\tag{4.1}\\] By chain rule we have \\[\\begin{align*}\n\\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}}  & =\n{\\pmb{\\sigma}}_u  \\frac{\\partial u}{\\partial \\tilde{u}} + {\\pmb{\\sigma}}_v  \\frac{\\partial v}{\\partial \\tilde{u}} \\\\\n\\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}}  & =\n{\\pmb{\\sigma}}_u  \\, \\frac{\\partial u}{\\partial \\tilde{v}}  + {\\pmb{\\sigma}}_v  \\frac{\\partial v}{\\partial \\tilde{v}}\n\\end{align*}\\] By the properties of vector product we get \\[\\begin{align*}\n\\widetilde{{\\pmb{\\sigma}}}_{\\tilde u} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde v} & =\n\\left( {\\pmb{\\sigma}}_u  \\frac{\\partial u}{\\partial \\tilde{u}} + {\\pmb{\\sigma}}_v  \\frac{\\partial v}{\\partial \\tilde{u}}   \\right)\n\\times\n\\left( {\\pmb{\\sigma}}_u  \\, \\frac{\\partial u}{\\partial \\tilde{v}}  + {\\pmb{\\sigma}}_v  \\frac{\\partial v}{\\partial \\tilde{v}}\n\\right)  \\\\\n& =  \\frac{\\partial u}{\\partial \\tilde{u}} \\, \\frac{\\partial u}{\\partial \\tilde{v}}  \\, \\left(  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_u \\right) +\n  \\frac{\\partial u}{\\partial \\tilde{u}} \\, \\frac{\\partial v}{\\partial \\tilde{v}}  \\, \\left(  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right)  \\\\\n& + \\frac{\\partial v}{\\partial \\tilde{u}} \\, \\frac{\\partial u}{\\partial \\tilde{v}}  \\, \\left(  {\\pmb{\\sigma}}_v \\times {\\pmb{\\sigma}}_u \\right) +\n  \\frac{\\partial v}{\\partial \\tilde{u}} \\, \\frac{\\partial v}{\\partial \\tilde{v}}  \\, \\left(  {\\pmb{\\sigma}}_v \\times {\\pmb{\\sigma}}_v \\right) \\\\\n  & = \\left(   \\frac{\\partial u}{\\partial \\tilde{u}} \\, \\frac{\\partial v}{\\partial \\tilde{v}} - \\frac{\\partial v}{\\partial \\tilde{u}} \\, \\frac{\\partial u}{\\partial \\tilde{v}}         \\right)   \\, \\left( {{\\pmb{\\sigma}}}_{u}\\times {{\\pmb{\\sigma}}}_{v}\\right) \\\\\n  & = \\det \\left(\n\\begin{array}{cc}\n\\dfrac{\\partial u}{\\partial \\tilde u}  &  \\dfrac{\\partial u}{\\partial \\tilde v}  \\\\\n\\dfrac{\\partial v}{\\partial \\tilde u}  &  \\dfrac{\\partial v}{\\partial \\tilde v}\n\\end{array}\n\\right) \\,  \\left( {{\\pmb{\\sigma}}}_{u}\\times {{\\pmb{\\sigma}}}_{v}\\right) \\\\\n& = \\det  J \\Phi \\,  \\left( {{\\pmb{\\sigma}}}_{u}\\times {{\\pmb{\\sigma}}}_{v}\\right) \\,.\n\\end{align*}\\] Since \\(\\Phi\\) is a diffeomorphism, we have that \\[\n\\det J\\Phi \\neq 0 \\,,\n\\] from which we conclude (4.1).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#transition-maps",
    "href": "sections/chap_4.html#transition-maps",
    "title": "4  Surfaces",
    "section": "4.6 Transition maps",
    "text": "4.6 Transition maps\nConsider the situation in which two regular charts have overlapping image.\nIt is natural to ask wether these maps are reparametrizations of each other on the overlapping region, see Figure 4.5. If such reparametrization exists, it is called a transition map.\n\n\n\n\n\n\nFigure 4.5: If the two regular charts \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) have overlapping image, then they are reparametrization of each other, through a transition map \\(\\Phi\\).\n\n\n\n\nDefinition 62: Transition mapLet \\(\\mathcal{S}\\) be a regular surface and \\[\n{\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\,, \\quad\n\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\subseteq \\mathcal{S}\n\\] be regular charts. Assume that the images of \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) overlap, that is, \\[\nI := {\\pmb{\\sigma}}(U) \\cap \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\neq \\emptyset \\,.\n\\] The set \\(I\\) is open in \\(\\mathcal{S}\\), since it is intersection of open sets. Define the sets \\[\nV := {\\pmb{\\sigma}}^{-1}(I) \\subseteq U \\,, \\quad  \\widetilde{V} := \\widetilde{{\\pmb{\\sigma}}}^{-1} (I) \\subseteq \\widetilde{U} \\,,\n\\] The sets \\(V\\) and \\(\\widetilde{V}\\) are open and by construction \\[\n{\\pmb{\\sigma}}(V) = \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{V} ) = I \\,.\n\\] Therefore they are well defined the restrictions \\[\n{\\pmb{\\sigma}}|_{V} \\colon V \\to I \\,, \\quad\n\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}} \\colon \\widetilde{V} \\to I \\,,\n\\] which are homeomorphisms. The homeomorphism \\[\n\\Phi \\colon \\widetilde{V} \\to V \\,, \\quad \\Phi := {\\pmb{\\sigma}}^{-1} \\circ \\widetilde{{\\pmb{\\sigma}}}\n\\] is called a transition map from \\({\\pmb{\\sigma}}\\) to \\(\\widetilde{{\\pmb{\\sigma}}}\\).\n\n\nThe theorem below states that transition maps between regular charts are diffeomorphisms. The proof is slightly technical and is based on the Implicit Function Theorem. We decide to omit it. The interested reader can find a proof at Page 117 of (Pressley 2010).\n\nTheorem 63Let \\(\\mathcal{S}\\) be a regular surface. The transition maps between regular charts are diffeomorphisms.\n\n\nWe can now use Theorem 63 to show that transition maps are reparametrizations.\n\nProposition 64Let \\(\\mathcal{S}\\) be a regular surface and \\[\n{\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\,, \\quad\n\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\subseteq \\mathcal{S}\n\\] be regular charts. Assume that the images of \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) overlap, that is, \\[\n{\\pmb{\\sigma}}(U) \\cap \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\neq \\emptyset \\,.\n\\] Then there exist open sets \\[\nV \\subseteq U \\,, \\quad  \\widetilde{V} \\subseteq \\widetilde{U} \\,,\n\\] and a diffeomorphism \\[\n\\Phi \\colon \\widetilde{V} \\to V\n\\] such that \\(\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}}\\) is a reparametrization of \\({\\pmb{\\sigma}}|_{V}\\), that is, \\[\n\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}} = ({\\pmb{\\sigma}}|_{V}) \\circ \\Phi \\,.\n\\]\n\n\n\nProofDefine \\[\nI:={\\pmb{\\sigma}}(U) \\cap \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\neq \\emptyset \\,.\n\\] Note that this set is open in \\(\\mathcal{S}\\), being intersection of open sets. Set \\[\nV := {\\pmb{\\sigma}}^{-1} (  I  ) \\,, \\quad\n\\widetilde{V} := \\widetilde{{\\pmb{\\sigma}}}^{-1} (   I   ) \\,.\n\\] The sets \\(V\\) and \\(\\widetilde{V}\\) are open, since \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) are homeomorphisms, and hence are continuous. By construction we have \\[\n{\\pmb{\\sigma}}(V) = \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{V}) = I \\,.\n\\] Therefore they are well defined the restrictions \\[\n{\\pmb{\\sigma}}|_{V} \\colon V \\to I \\,, \\quad\n\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}} \\colon \\widetilde{V} \\to I \\,,\n\\] which are homeomorphisms. Consider the transition map \\[\n\\Phi \\colon \\widetilde{V} \\to V \\,, \\quad \\Phi := {\\pmb{\\sigma}}^{-1} \\circ \\widetilde{{\\pmb{\\sigma}}} \\,.\n\\] By Theorem 63 we know that \\(\\Phi\\) is a diffeomorphism. Hence \\[\n\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}} = ({\\pmb{\\sigma}}|_{V}) \\circ \\Phi \\,,\n\\] with \\(\\Phi\\) diffeomorphism, showing that \\(\\widetilde{{\\pmb{\\sigma}}} |_{\\widetilde{V}}\\) is a reparametrization of \\({\\pmb{\\sigma}}|_{V}\\).\n\n\n\nImportantProposition 64 allows us to define properties of surfaces using charts, as long as we check that the property in question does not depend on reparametrization.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#functions-between-surfaces",
    "href": "sections/chap_4.html#functions-between-surfaces",
    "title": "4  Surfaces",
    "section": "4.7 Functions between surfaces",
    "text": "4.7 Functions between surfaces\nWe would like to define a concept of smooth function \\[\nf \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2 \\,,\n\\] where \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) are regular surfaces. So far we know what a smooth function from \\(\\mathbb{R}^n\\) into \\(\\mathbb{R}^m\\) is. The idea is to use surface charts to define such \\(f\\).\n\nDefinition 65\nLet \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) be regular surfaces and let \\[\nf \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2\n\\] be a map. We say that:\n\n\\(f\\) is smooth at \\(\\mathbf{p}\\in \\mathcal{S}_1\\) if there exist charts \\({\\pmb{\\sigma}}_i \\colon U_i \\to \\mathcal{S}_i\\) for \\(i=1,2\\) such that \\[\n\\mathbf{p}\\in {\\pmb{\\sigma}}_1(U_1)\\,, \\quad f(\\mathbf{p}) \\in {\\pmb{\\sigma}}_2(U_2)\n\\] and \\[\n({\\pmb{\\sigma}}_2^{-1} \\circ f \\circ {\\pmb{\\sigma}}_1 )  \\colon U_1 \\to U_2\n\\] is smooth.\n\\(f\\) is smooth if it is smooth for each \\(\\mathbf{p}\\in \\mathcal{S}_1\\).\n\\(f\\) is a diffeomorphism if \\(f\\) is smooth and invertible, with smooth inverse.\n\n\n\n\n\n\nSketch function \\(f\\) smooth at \\(\\mathbf{p}\\) between the surfaces \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\).\n\n\n\nRemark 66\n\nDefinition 65 makes sense because \\({\\pmb{\\sigma}}_2^{-1}\\) exists.\nThe map \\({\\pmb{\\sigma}}_2^{-1} \\circ f \\circ {\\pmb{\\sigma}}_1\\) is only defined for \\(\\mathbf{x}\\in U_1\\) such that \\[\nf ( {\\pmb{\\sigma}}_1 (\\mathbf{x}) ) \\in {\\pmb{\\sigma}}_2 (U_2) \\,.\n\\]\nThe function \\({\\pmb{\\sigma}}_2^{-1} \\circ f \\circ {\\pmb{\\sigma}}_1\\) maps from \\(\\mathbb{R}^2\\) into \\(\\mathbb{R}^2\\), therefore differentiability is intended in the classical sense.\nDefinition 65 does not depend on the choice of charts \\({\\pmb{\\sigma}}_1\\) and \\({\\pmb{\\sigma}}_2\\)\n\n\nIndeed, suppose that \\(\\widetilde{{\\pmb{\\sigma}}}_{i} \\colon \\widetilde{U}_i \\to {\\mathcal{S}}_i\\) are charts such that \\[\n\\mathbf{p}\\in \\widetilde{{\\pmb{\\sigma}}}_1( \\widetilde{U}_1) \\,, \\quad  f(\\mathbf{p}) \\in \\widetilde{{\\pmb{\\sigma}}}_2(\\widetilde{U}_2) \\,.\n\\] In particular we have \\[\n{\\pmb{\\sigma}}_i(U_i) \\cap \\widetilde{{\\pmb{\\sigma}}}_i (\\widetilde{U}_i) \\neq \\emptyset \\,.\n\\] As \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) are regular surfaces, by Theorem 63 there exist open sets \\[\nV_i \\subseteq U_i \\,, \\quad \\widetilde{V}_i \\subseteq \\widetilde{U}_i \\,,\n\\] and transition maps \\[\n\\Phi_i \\colon \\widetilde{V}_i \\to V_i\n\\] which are diffeomorphisms and satisfy \\[\n\\widetilde{{\\pmb{\\sigma}}}_i = {\\pmb{\\sigma}}_i \\circ \\Phi_i \\,.\n\\] Hence \\[\\begin{align*}\n\\widetilde{{\\pmb{\\sigma}}}_2^{-1} \\circ f \\circ \\widetilde{{\\pmb{\\sigma}}}_1 & =\n\\widetilde{{\\pmb{\\sigma}}}_2^{-1} \\circ ( {\\pmb{\\sigma}}_2 \\circ {\\pmb{\\sigma}}_2^{-1} ) \\circ f \\circ  ( {\\pmb{\\sigma}}_1 \\circ {\\pmb{\\sigma}}_1^{-1} ) \\circ \\widetilde{{\\pmb{\\sigma}}}_1  \\\\\n& = ( \\widetilde{{\\pmb{\\sigma}}}_2^{-1} \\circ  {\\pmb{\\sigma}}_2 ) \\circ ( {\\pmb{\\sigma}}_2^{-1}  \\circ f \\circ   {\\pmb{\\sigma}}_1 ) \\circ ({\\pmb{\\sigma}}_1^{-1}  \\circ \\widetilde{{\\pmb{\\sigma}}}_1 )  \\\\\n& = \\Phi_2^{-1} \\circ ( {\\pmb{\\sigma}}_2^{-1}  \\circ f \\circ   {\\pmb{\\sigma}}_1 )  \\circ \\Phi_1^{-1} \\,.\n\\end{align*}\\] Since \\(\\Phi_i^{-1}\\) and \\({\\pmb{\\sigma}}_2^{-1}  \\circ f \\circ   {\\pmb{\\sigma}}_1\\) are smooth, we conclude that \\[\n\\widetilde{{\\pmb{\\sigma}}}_2^{-1} \\circ f \\circ \\widetilde{{\\pmb{\\sigma}}}_1\n\\] is smooth. Hence Definition 65 does not depend on the choice of charts.\n\n\n\n\nProposition 67If \\(f \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2\\) and \\(g \\colon \\mathcal{S}_2 \\to \\mathcal{S}_3\\) are smooth maps (resp. diffeomorphisms) between surfaces, then the composition \\[\n(g \\circ f) \\colon \\mathcal{S}_1 \\to \\mathcal{S}_3\n\\] is smooth (resp. a diffeomorphisms).\n\n\n\nProofFix \\(\\mathbf{p}\\in \\mathcal{S}_1\\) and choose charts \\[\n{\\pmb{\\sigma}}_i \\colon U_i \\to \\mathcal{S}_i\n\\] such that \\[\n\\mathbf{p}\\in {\\pmb{\\sigma}}_1 (U_1) \\,, \\quad\nf(\\mathbf{p}) \\in {\\pmb{\\sigma}}_2 (U_2) \\,, \\quad\ng(f(\\mathbf{p})) \\in {\\pmb{\\sigma}}_3 (U_3) \\,.\n\\] Since \\(f\\) and \\(g\\) are smooth we have that the maps \\[\n{\\pmb{\\sigma}}_2^{-1} \\circ f  \\circ {\\pmb{\\sigma}}_1 \\,, \\quad {\\pmb{\\sigma}}_3^{-1} \\circ  g \\circ {\\pmb{\\sigma}}_2  \\,,\n\\] are smooth. Hence \\[\n{\\pmb{\\sigma}}_3^{-1} \\circ ( g \\circ f ) \\circ {\\pmb{\\sigma}}_1 = ( {\\pmb{\\sigma}}_3^{-1} \\circ  g \\circ {\\pmb{\\sigma}}_2 ) \\circ ({\\pmb{\\sigma}}_2^{-1} \\circ f  \\circ {\\pmb{\\sigma}}_1)  \n\\] is smooth, ending the proof.\n\n\n\nDefinition 68Let \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) be regular surfaces. We say that \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) are diffeomorphic if there exists \\(f \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2\\) diffeomorphism.\n\n\nThe key ideas around diffeomorphisms are:\n\nTwo diffeomorphic surfaces are essentially the same. Indeed, it is immediate to show that being diffeomorphic is an equivalence relation on the set of regular surfaces.\nTwo diffeomorphic surfaces have essentially the same charts, as shown in the next proposition.\n\n\nProposition 69Let \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) be a diffeomorphism. If \\({\\pmb{\\sigma}}\\colon U \\to \\mathcal{S}\\) is a regular chart for \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\), then \\[\n\\widetilde{{\\pmb{\\sigma}}} := f \\circ {\\pmb{\\sigma}}\\colon U \\to \\widetilde{\\mathcal{S}}\n\\] is a regular chart for \\(\\widetilde{\\mathcal{S}}\\) at \\(f(\\mathbf{p})\\).\n\n\n\nProofLet \\({\\pmb{\\sigma}}_2 \\colon U_2 \\to \\widetilde{\\mathcal{S}}\\) be a regular chart for \\(\\widetilde{\\mathcal{S}}\\) at \\(f(\\mathbf{p})\\). By definition of diffeomorphism between surfaces, the map \\[\n\\Phi := {\\pmb{\\sigma}}_2^{-1} \\circ f \\circ {\\pmb{\\sigma}}\\colon U \\to U_2\n\\] is a diffeomorphism. Therfore \\[\n(f \\circ {\\pmb{\\sigma}}) (u,v) = {\\pmb{\\sigma}}_2  \\left( \\Phi(u,v) \\right)\n\\] with \\(\\Phi\\) diffeomorphism, meaning that \\(f \\circ {\\pmb{\\sigma}}\\) is a reparametrization of \\({\\pmb{\\sigma}}_2\\). Since \\({\\pmb{\\sigma}}_2\\) is regular, by Proposition 61 we deduce that \\(f \\circ {\\pmb{\\sigma}}\\) is regular.\n\n\nWe conclude with the definition of local diffeomorphism between surfaces.\n\nDefinition 70: Local diffeomorphismLet \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) be regular surfaces. A smooth map \\(f \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2\\) is called a local diffeomorphism if for each point \\(\\mathbf{p}\\in \\mathcal{S}_1\\) there exists an open set \\(V \\subseteq \\mathcal{S}_1\\) such that \\(f(V) \\subseteq \\mathcal{S}_2\\) is open and \\[\nf \\colon V \\to f(V)\n\\] is a diffeomorphism between surfaces.\n\n\nThe above definition is well posed since open subsets of surfaces are themselves surfaces.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#tangent-space",
    "href": "sections/chap_4.html#tangent-space",
    "title": "4  Surfaces",
    "section": "4.8 Tangent space",
    "text": "4.8 Tangent space\nWe have seen that tangent vectors to regular curves allow to define the Frenet Frame, curvature and torsion. Eventually, these quantities are sufficient to characterize a curve. The anolgue concept of tangent vector for surfaces is called the tangent space. To avoid clumsy terminology, we make the following assumption.\n\nAssumption 71From now on, all the surfaces will be regular and all the charts will be regular.\n\n\n\nDefinition 72: Tangent vectors and tangent spaceLet \\(\\mathcal{S}\\) be a surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). A tangent vector to \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is any vector \\(\\mathbf{v}\\in \\mathbb{R}^3\\) such that \\[\n\\mathbf{v}= \\dot{{\\pmb{\\gamma}}}(0) \\,,\n\\] where \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}^3\\) is a smooth curve such that \\[\n{\\pmb{\\gamma}}(-\\varepsilon, \\varepsilon) \\subseteq \\mathcal{S}\\,, \\quad {\\pmb{\\gamma}}(0) = \\mathbf{p}\\,,\n\\] where \\(\\varepsilon&gt;0\\). The tangent space of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is the set \\[\nT_{\\mathbf{p}} \\mathcal{S}:= \\{ \\mathbf{v}\\in \\mathbb{R}^3 \\, \\colon \\,\\mathbf{v}\\, \\mbox{ tangent vector of } \\, \\mathcal{S}\\, \\mbox{ at } \\, \\mathbf{p}\\} \\,.\n\\]\n\n\n\n\n\n\n\n\nFigure 4.6: Tangent space \\(T_{\\mathbf{p}} \\mathcal{S}\\) of surface \\(\\mathcal{S}\\) at the point \\(\\mathbf{p}\\). A tangent vector \\(\\mathbf{v}\\) coincides with \\(\\dot{{\\pmb{\\gamma}}}(0)\\) for some \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathcal{S}\\) such that \\({\\pmb{\\gamma}}(0)= \\mathbf{p}\\).\n\n\n\nLet us start with the most basic example: We want to compute the tangent space to an open set in \\(\\mathbb{R}^2\\).\n\nExample 73\nLet \\(U \\subseteq \\mathbb{R}^2\\) be open and \\(\\mathbf{p}\\in U\\). Then \\[\nT_{\\mathbf{p}} U = \\mathbb{R}^2 \\,.\n\\]\n\nProof. Let \\(\\mathbf{v}\\in T_{\\mathbf{p}} U\\). By definition there exists a smooth curve \\[\n\\gamma \\colon (-\\varepsilon,\\varepsilon) \\to U\n\\] such that \\({\\pmb{\\gamma}}(0) = \\mathbf{p}\\) and \\(\\dot{{\\pmb{\\gamma}}}(0)=\\mathbf{v}\\). Since \\(U \\subseteq \\mathbb{R}^2\\), it follows that \\({\\pmb{\\gamma}}\\) is a plane curve, so that \\[\n\\mathbf{v}= \\dot{{\\pmb{\\gamma}}}(0) \\in \\mathbb{R}^2 \\,.\n\\] Conversely, let \\(\\mathbf{v}\\in \\mathbb{R}^2\\). Since \\(\\mathbf{p}\\in U\\) and \\(U\\) is open, there exists \\(\\varepsilon&gt;0\\) such that \\(B_{\\varepsilon}(p) \\subseteq U\\). Define the curve \\[\n{\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}^3 \\,, \\quad {\\pmb{\\gamma}}(t):= \\mathbf{p}+ t \\mathbf{v}\\,.  \n\\] By construction \\[\n{\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq B_{\\varepsilon} (\\mathbf{p}) \\subseteq U \\,, \\quad {\\pmb{\\gamma}}(0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0)= \\mathbf{v}\\,,\n\\] showing that \\(\\mathbf{v}\\in T_{\\mathbf{p}} U\\).\n\n\n\nIn the above example we have seen that \\(T_{\\mathbf{p}} U = \\mathbb{R}^2\\). This property holds in general for \\(T_{\\mathbf{p}} \\mathcal{S}\\) with \\(\\mathcal{S}\\) regular surface. Before proving this fact, we need a lemma.\n\nLemma 74\nLet \\(\\mathcal{S}\\) be regular and \\(\\mathbf{p}\\in \\mathcal{S}\\). Let \\({\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\) be a regular chart at \\(\\mathbf{p}\\), with \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] We have:\n\nSuppose \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}^3\\) is a smooth curve such that \\[\n{\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq {\\pmb{\\sigma}}(U) \\,, \\quad {\\pmb{\\gamma}}(0) = \\mathbf{p}\\,.\n\\] Then there exist smooth functions \\[\nu , v \\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}\n\\] such that \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}( u(t), v(t) ) \\,, \\quad \\forall \\, t \\in (-\\varepsilon,\\varepsilon) \\,,\n\\] and \\[\nu(0)=u_0 \\,, \\quad v(0) = v_0 \\,.\n\\]\nConversely, assume \\(u , v \\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}\\) are smooth functions such that \\[\nu(0)=u_0 \\,, \\quad v(0) = v_0 \\,.\n\\] Then \\[\n{\\pmb{\\gamma}}(t):= {\\pmb{\\sigma}}(u(t),v(t))\n\\] is a smooth curve such that \\[\n{\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq \\mathcal{S}\\,, \\quad  {\\pmb{\\gamma}}(0)=\\mathbf{p}\\,.\n\\]\n\n\n\n\nProofDenote the coordinates of \\({\\pmb{\\sigma}}\\) by \\[\n{\\pmb{\\sigma}}(u,v) = (f(u,v), g(u,v), h(u, v)) \\,.\n\\] The differential of \\({\\pmb{\\sigma}}\\) is \\[\nd{\\pmb{\\sigma}}=\n\\left(   \n\\begin{array}{cc}\nf_u & f_v \\\\\ng_u & g_v \\\\\nh_u & h_v \\\\\n\\end{array}\n\\right) \\,.\n\\] Since \\({\\pmb{\\sigma}}\\) is regular, by definition \\(d{\\pmb{\\sigma}}\\) has rank-2 at \\((u_0,v_0)\\). This means that at least one of the 3 minors \\[\n\\left(   \n\\begin{array}{cc}\nf_u & f_v \\\\\ng_u & g_v\n\\end{array}\n\\right) \\,, \\quad\n\\left(   \n\\begin{array}{cc}\nf_u & f_v \\\\\nh_u & h_v \\\\\n\\end{array}\n\\right) \\,, \\quad\n\\left(   \n\\begin{array}{cc}\ng_u & g_v \\\\\nh_u & h_v \\\\\n\\end{array}\n\\right) \\,.\n\\] is invertible. WLOG assume the first is invertible (the proof in case the other two are invertible is similar.) Define the map \\[\nF \\colon U \\subseteq \\mathbb{R}^2 \\to \\mathbb{R}^2 \\,, \\quad F(u,v) = ( f(u,v), g(u,v) ) \\,.\n\\] We have \\[\ndF =\n\\left(   \n\\begin{array}{cc}\nf_u & f_v \\\\\ng_u & g_v\n\\end{array}\n\\right) \\,,\n\\] which is invertible at \\((u_0,v_0)\\) by assumption. Hence, by the Inverse Function Theorem, there exist\n\n\\(W \\subseteq U \\subseteq \\mathbb{R}^2\\) open set with \\((u_0,v_0) \\in W\\),\n\\(V \\subseteq \\mathbb{R}^2\\) open set with \\(F(u_0,v_0) \\in V\\),\n\nsuch that \\[\nF \\colon W \\to V\n\\] is a diffeomorphism. Hence \\[\nF^{-1} \\colon V \\to W\n\\] is smooth. Since \\({\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq {\\pmb{\\sigma}}(U)\\), it is well defined the composition \\[\nF^{-1} \\circ {\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to W \\subseteq U \\,.\n\\] Moreover such composition is smooth, being \\(F^{-1}\\) and \\({\\pmb{\\gamma}}\\) smooth. Therefore \\[\n(F^{-1} \\circ {\\pmb{\\gamma}}) (t) = (u(t),v(t))\n\\tag{4.2}\\] with \\(u,v\\) smooth. As \\({\\pmb{\\gamma}}(0)=\\mathbf{p}\\), by definition of \\(F\\) we have \\[\n(u(0),v(0)) = (F^{-1} \\circ {\\pmb{\\gamma}}) (0) = F^{-1}(\\mathbf{p}) =  (u_0,v_0) \\,,\n\\] showing that \\[\nu(0) = u_0 \\,, \\quad\nv(0) = v_0 \\,.\n\\] Moreover, applying \\({\\pmb{\\sigma}}\\) to both sides of (4.2) yields \\[\n{\\pmb{\\sigma}}(u(t),v(t)) = {\\pmb{\\sigma}}((F^{-1} \\circ {\\pmb{\\gamma}})) (t) = {\\pmb{\\gamma}}(t) \\,,\n\\] as we wanted to show.\nThe converse statement is trivial.\n\n\nWe are now ready to characterize \\(T_{\\mathbf{p}} \\mathcal{S}\\) when \\(\\mathcal{S}\\) is a regular surface.\n\nTheorem 75Let \\(\\mathcal{S}\\) be a (regular) surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). Let \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a chart at \\(\\mathbf{p}\\). Denote by \\((u_0,v_0) \\in U\\) a point such that \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] Then \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\} := \\{  \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\, \\colon \\,\\lambda,\\mu \\in \\mathbb{R}\\} \\,,\n\\] where \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are evaluated at \\((u_0,v_0)\\). In particular \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\mathbb{R}^2 \\,.\n\\]\n\n\n\nProofLet \\({\\pmb{\\sigma}}\\colon U \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\) be a chart at \\(p\\). If we show that \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\}\n\\] then we deduce \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\mathbb{R}^2 \\,,\n\\] since \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent.\nStep 1. Suppose \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). By definition there exists a smooth curve \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathcal{S}\\) such that \\[\n{\\pmb{\\gamma}}(0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0) = \\mathbf{v}\\,.\n\\] By continuity, we can take \\(\\varepsilon\\) small enough so that \\[\n{\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq {\\pmb{\\sigma}}(U) \\,.\n\\] By Lemma 74 there exist smooth functions \\(u , v \\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}\\) such that \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}( u(t), v(t) ) \\,, \\quad \\forall \\, t \\in (-\\varepsilon,\\varepsilon) \\,,\n\\] and \\[\nu(0)=u_0 \\,, \\quad v(0) = v_0 \\,.\n\\] Therefore, by chain rule, \\[\n\\dot{{\\pmb{\\gamma}}}(t) = {\\pmb{\\sigma}}_u ( u(t),v(t) ) \\, \\dot{u}(t) +  \n{\\pmb{\\sigma}}_v ( u(t),v(t) ) \\, \\dot{v}(t) \\,.\n\\] Evaluating the above at \\(t=0\\) yields \\[\\begin{align*}\n\\mathbf{v}& = \\dot{{\\pmb{\\gamma}}}(0) \\\\\n    & = {\\pmb{\\sigma}}_u ( u(0),v(0) ) \\, \\dot{u}(0) +  {\\pmb{\\sigma}}_v ( u(0),v(0) ) \\, \\dot{v}(0) \\\\\n    & = {\\pmb{\\sigma}}_u ( u_0,v_0 ) \\, \\dot{u}(0) +  {\\pmb{\\sigma}}_v ( u_0,v_0 ) \\, \\dot{v}(0)  \\,,\n\\end{align*}\\] which shows \\[\n\\mathbf{v}\\in \\operatorname{span} \\{  {\\pmb{\\sigma}}_u (u_0,v_0), {\\pmb{\\sigma}}_v(u_0,v_0) \\} \\,.\n\\]\nStep 2. Suppose that \\[\n\\mathbf{v}\\in \\operatorname{span} \\{  {\\pmb{\\sigma}}_u (u_0,v_0), {\\pmb{\\sigma}}_v(u_0,v_0) \\} \\,.\n\\] Then there exist \\(\\lambda,\\mu \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u (u_0,v_0) + \\mu {\\pmb{\\sigma}}_v (u_0,v_0) \\,.\n\\] Define the curve \\[\n{\\pmb{\\gamma}}(t) := {\\pmb{\\sigma}}(u_0 + \\lambda t, v_0 + \\mu t) \\,, \\quad t \\in (-\\varepsilon,\\varepsilon) \\,.\n\\] We have \\[\n{\\pmb{\\gamma}}(0) = {\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] Therefore, for \\(\\varepsilon\\) sufficiently small, we have \\[\n{\\pmb{\\gamma}}(-\\varepsilon,\\varepsilon) \\subseteq {\\pmb{\\sigma}}(U) \\,.\n\\] By chain rule \\[\n\\dot{{\\pmb{\\gamma}}}(t) = {\\pmb{\\sigma}}_u (u_0+ \\lambda t , v_0+ \\mu t ) \\lambda\n+ {\\pmb{\\sigma}}_v (u_0+ \\lambda t , v_0+ \\mu t ) \\mu \\,,\n\\] and therefore \\[\n\\dot{{\\pmb{\\gamma}}}(0) = {\\pmb{\\sigma}}_u (u_0 , v_0 ) \\lambda\n+ {\\pmb{\\sigma}}_v (u_0 ,v_0) \\mu = \\mathbf{v}\\,.\n\\] This proves that \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\), ending the proof.\n\n\nTherefore \\(T_{\\mathbf{p}} \\mathcal{S}\\) is always two-dimensional. This justifies the following definition.\n\nDefinition 76: Tangent planeLet \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). The set \\[\nT_{\\mathbf{p}} \\mathcal{S}\n\\] is called the tangent plane to \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\).\n\n\n\nRemark 77By definition \\(T_{\\mathbf{p}} \\mathcal{S}\\) is a vector subspace of \\(\\mathbb{R}^3\\). As such, it holds that \\[\n{\\pmb{0}}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nTo see this, take the curve \\({\\pmb{\\gamma}}(t) \\equiv \\mathbf{p}\\). Then \\({\\pmb{\\gamma}}(0) = \\mathbf{p}\\) and \\(\\dot{{\\pmb{\\gamma}}}(0) = {\\pmb{0}}\\), showing that \\({\\pmb{0}}\\in T_{\\mathbf{p}} \\mathcal{S}\\).\n\nTherefore \\(T_{\\mathbf{p}} \\mathcal{S}\\) is a plane through the origin, no matter where the point \\(\\mathbf{p}\\in \\mathcal{S}\\) is located. When we draw the tangent plane as a plane resting on the surface, see Figure 4.6, we are not drawing \\(T_{\\mathbf{p}} \\mathcal{S}\\), but rather the plane \\[\n\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] which is the affine tangent plane through \\(\\mathbf{p}\\in \\mathcal{S}\\).\n\n\nIt is possible to give a cartesian equation for the tangent plane \\[\nT_{\\mathbf{p}} \\mathcal{S}\n\\] and for the affine tangent plane \\[\n\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nProposition 78: Equation of tangent planeLet \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). Let \\({\\pmb{\\sigma}}\\) be a regular chart at \\(\\mathbf{p}\\), with \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}= (x_0,y_0,z_0) \\,.\n\\] Let \\[\n\\mathbf{n}:= {\\pmb{\\sigma}}_u (u_0,v_0) \\times {\\pmb{\\sigma}}_v (u_0,v_0) \\,.\n\\] The equation of the tangent plane \\(T_{\\mathbf{p}} \\mathcal{S}\\) is given by \\[\n{\\mathbf{n}}_1 x + {\\mathbf{n}}_2 y + {\\mathbf{n}}_3 z = 0 \\,, \\quad\n\\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,,\n\\] where \\(\\mathbf{n}= ({\\mathbf{n}}_1,{\\mathbf{n}}_2,{\\mathbf{n}}_3)\\). The equation of the affine tangent plane \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is given by \\[\n{\\mathbf{n}}_1 (x-x_0) + {\\mathbf{n}}_2 (y-x_0) + {\\mathbf{n}}_3 (z-z_0) = 0 \\,, \\quad\n\\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,.\n\\]\n\n\n\nProofBy Theorem 75 we know that \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{  {\\pmb{\\sigma}}_u (u_0,v_0), {\\pmb{\\sigma}}_v (u_0,v_0) \\} \\,.\n\\] By the properties of cross product, the vector \\(\\mathbf{n}\\) is orthogonal to both \\({\\pmb{\\sigma}}_u (u_0,v_0)\\) and \\({\\pmb{\\sigma}}_v (u_0,v_0)\\). Therefore it is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}\\). The equation for \\(T_{\\mathbf{p}} \\mathcal{S}\\) is then \\[\n(x,y,z) \\cdot \\mathbf{n}= 0 \\,, \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,.\n\\] In particular, the equation for the affine tangent plane \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is \\[\n(x,y,z) \\cdot \\mathbf{n}= k \\,, \\quad  \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,,\n\\] for some \\(k \\in \\mathbb{R}\\). To compute \\(k\\), it is sufficient to evaluate the above equation at \\(\\mathbf{p}\\), since \\(\\mathbf{p}\\) belongs to \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\). We obtain \\[\nk = \\mathbf{p}\\cdot \\mathbf{n}\\,.\n\\] Hence the equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is \\[\n(x-x_0,y-y_0,z-z_0) \\cdot \\mathbf{n}= 0 \\,, \\quad  \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,,\n\\] ending the proof.\n\n\n\nExample 79Consider the surface \\(\\mathcal{S}\\) defined by the chart \\[\n{\\pmb{\\sigma}}(u,v) := \\left(   \\sqrt{1-v} \\cos(u) , \\sqrt{1-v} \\sin(u), v        \\right) \\,.\n\\] We want to compute the equation for the tangent plane \\(T_{\\mathbf{p}} \\mathcal{S}\\), and for the affine tangent plane \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\).\nFirst, we need to check that \\({\\pmb{\\sigma}}\\) is regular. We have \\[\\begin{align*}\n{\\pmb{\\sigma}}_u & = \\left(  - \\sqrt{1-v} \\sin(u) , \\sqrt{1-v} \\cos(u), 0        \\right) \\\\\n{\\pmb{\\sigma}}_v & = \\left(    \\frac{1}{2} (1-v)^{-1/2}  \\cos(u) , \\frac{1}{2} (1-v)^{-1/2}   \\sin(u), 1        \\right)\n\\end{align*}\\] As the last component of \\({\\pmb{\\sigma}}_u\\) is \\(0\\) and the last component of \\({\\pmb{\\sigma}}_v\\) is \\(1\\), we conclude that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent. Thus \\({\\pmb{\\sigma}}\\) is regular.\nSuppose \\(\\mathbf{p}\\in \\mathcal{S}\\) is such that \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\n\\] for some \\((u_0,v_0) \\in \\mathbb{R}^2\\). By Theorem 75 we have \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u (u_0,v_0) , {\\pmb{\\sigma}}_v (u_0,v_0)  \\} \\,.\n\\] To find the equation of \\(T_{\\mathbf{p}} \\mathcal{S}\\) we compute: \\[\\begin{align*}\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v & =\n\\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n- \\sqrt{1-v} \\sin(u) & \\sqrt{1-v} \\cos(u) & 0 \\\\\n\\frac{1}{2} (1-v)^{-1/2}  \\cos(u) & \\frac{1}{2} (1-v)^{-1/2}   \\sin(u) & 1\n\\end{array}\n\\right| \\\\\n& = \\left(  \\sqrt{1-v} \\cos(u) , \\sqrt{1-v} \\sin(u), - \\frac12        \\right)\n\\end{align*}\\] For \\[\n(u_0,v_0) = \\left( \\frac{\\pi}{4}, 0 \\right)\n\\] we have \\[\n\\mathbf{p}= {\\pmb{\\sigma}}(u_0,v_0)  = \\left( \\frac{\\sqrt 2}{2}, \\frac{\\sqrt 2}{2}, 0  \\right) \\,,\n\\] and therefore \\[\n\\mathbf{n}= ({\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v)(u_0,v_0) =  \\left(  \\frac{\\sqrt 2}{2}, \\frac{\\sqrt 2}{2} , -\\frac{1}{2}   \\right) \\,.\n\\] The equation for \\(T_{\\mathbf{p}} \\mathcal{S}\\) is therefore \\[\n(x,y,z) \\cdot \\mathbf{n}= 0 \\,, \\quad \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,.\n\\] The above reads \\[\n\\frac{\\sqrt 2}{2} \\, x + \\frac{\\sqrt 2}{2} \\, y - \\frac{1}{2} \\, z = 0 \\,.\n\\] The equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is instead \\[\n\\frac{\\sqrt 2}{2} \\, x + \\frac{\\sqrt 2}{2} \\, y - \\frac{1}{2} \\, z = k \\,,\n\\] for some \\(k \\in \\mathbb{R}\\). To compute \\(k\\), note that \\(\\mathbf{p}\\in \\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\), and therefore \\[\n\\frac{\\sqrt 2}{2} \\, \\frac{\\sqrt 2}{2} + \\frac{\\sqrt 2}{2} \\, \\frac{\\sqrt 2}{2} = k \\quad \\implies \\quad k = 1 \\,.\n\\] The equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is then \\[\n\\frac{\\sqrt 2}{2} \\, x + \\frac{\\sqrt 2}{2} \\, y - \\frac{1}{2} \\, z = 1 \\,.\n\\]\n\n\n\nRemark 80: Tangent space and derivationsThe definition of tangent plane depends on the fact that \\(\\mathcal{S}\\) is contained in \\(\\mathbb{R}^3\\). This is a serious drawback in many applications, as the surface \\(\\mathcal{S}\\) does not necessarily need to be Euclidean. There is a way to get rid of such dependence, and give an intrinsic definition of tangent plane, depending only on the point \\(\\mathbf{p}\\) and the surface \\(\\mathcal{S}\\).\nThe basic idea is as follows: If \\(U \\subseteq \\mathbb{R}^2\\) is open and \\(\\mathbf{p}\\in U\\), then \\(T_{\\mathbf{p}} U = \\mathbb{R}^2\\). We can associate to any point \\(\\mathbf{v}\\in T_{\\mathbf{p}} U\\) a directional derivative acting on smooth functions \\(f \\colon U \\to \\mathbb{R}\\): \\[\n\\mathbf{v}= (v_1,v_2) \\mapsto \\left. \\frac{\\partial }{\\partial v} \\right|_p =\nv_1 \\, \\left. \\frac{\\partial }{\\partial x_1} \\right|_p +\nv_2 \\, \\left. \\frac{\\partial }{\\partial x_2} \\right|_p\n\\] The above directional derivative is called a derivation.\nThe point is that derivations do not need to be defined through vectors, but can be defined as follows: \\(D\\) is a derivation if\n\n\\(D \\colon C^{\\infty}(U) \\to \\mathbb{R}\\) is a linear operator, where \\(C^{\\infty}(U)\\) is the set of smooth functions \\(f \\colon U \\to \\mathbb{R}\\),\n\\(D\\) satisfies the Leibnitz rule \\[\nD(fg) = f(\\mathbf{p}) D(g) + g(\\mathbf{p}) D(f) \\,, \\quad \\forall \\, f,g \\in C^{\\infty}(U) \\,.\n\\]\n\nThe tangent plane at p can then be defined as \\[\nT_{\\mathbf{p}} U = \\{ D \\, \\mbox{ derivation at  } \\mathbf{p}\\} \\,.\n\\] Therefore \\[\nT_{\\mathbf{p}} U \\subseteq (C^{\\infty}(U))^* \\,,\n\\] the dual space of smooth functions.\nIt is possible to do such construction directly on \\(\\mathcal{S}\\), by introducing the concepts of:\n\ngerm of a function\nalgebra of derivations, acting on germs\n\nAn in depth discussion can be found in Chapter 3.4 of (Abate, Marco and Tovena, Francesca 2011).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#differential-of-smooth-functions",
    "href": "sections/chap_4.html#differential-of-smooth-functions",
    "title": "4  Surfaces",
    "section": "4.9 Differential of smooth functions",
    "text": "4.9 Differential of smooth functions\nLet \\(f \\colon U \\to V\\) with \\(U,V \\subseteq \\mathbb{R}^2\\) open. Suppose \\(f\\) is smooth. The differential of \\(f\\) at \\(\\mathbf{p}\\in U\\) is a linear map \\[\ndf_{\\mathbf{p}} \\colon \\mathbb{R}^2 \\to \\mathbb{R}^2 \\,.\n\\] We have seen that \\[\nT_{\\mathbf{p}} U = \\mathbb{R}^2\n\\] and therefore we can interpret \\(df_{\\mathbf{p}}\\) as a map between tangent planes: \\[\ndf_{\\mathbf{p}} \\colon \\mathbb{R}^2 \\to \\mathbb{R}^2 \\,.\n\\] Similarly, if \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) is a smooth map between surfaces, we can define its differential at \\(\\mathbf{p}\\in \\mathcal{S}\\) as a linear map \\[\ndf_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,.\n\\] To define such map, we need the following lemma.\n\nLemma 81Let \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) a smooth map. For \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\) let \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathcal{S}\\) be such that \\[\n{\\pmb{\\gamma}}(0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0) = \\mathbf{v}\\,.\n\\] Define \\[\n\\widetilde{{\\pmb{\\gamma}}}:= f \\circ {\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\widetilde{\\mathcal{S}} \\,.\n\\] Then \\(\\widetilde{{\\pmb{\\gamma}}}\\) is a smooth curve into \\(\\mathbb{R}^3\\) and \\[\n\\widetilde{\\mathbf{v}} \\in T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,, \\quad \\widetilde{\\mathbf{v}} := \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\,.\n\\]\n\n\n\nProofNote that \\[\n\\widetilde{{\\pmb{\\gamma}}}= i \\circ f \\circ {\\pmb{\\gamma}}\\,,\n\\] with \\(i \\colon \\widetilde{\\mathcal{S}} \\to \\mathbb{R}^3\\) inclusion map. Since \\(i,f,{\\pmb{\\gamma}}\\) are smooth, we conclude that \\(\\widetilde{{\\pmb{\\gamma}}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathbb{R}^3\\) is smooth. Moreover \\[\n\\widetilde{{\\pmb{\\gamma}}}(0) = f ({\\pmb{\\gamma}}(0)) = f(\\mathbf{p}) \\,,\n\\] and therefore \\[\n\\widetilde{\\mathbf{v}} := \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\in T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,,\n\\] by definition of tangent space.\n\n\n\nDefinition 82: Differential of smooth functionLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) a smooth map. The differential \\(df_{\\mathbf{p}}\\) of \\(f\\) at \\(\\mathbf{p}\\) is defined as the map \\[\ndf_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,,  \\quad df_{\\mathbf{p}}(\\mathbf{v}) := \\widetilde{\\mathbf{v}} \\,,\n\\] where \\(\\widetilde{\\mathbf{v}}\\) is as in Lemma 81.\n\n\nWe now show that \\(df_{\\mathbf{p}}\\) is well-defined and linear. Moreover we provide a representation of \\(df_{\\mathbf{p}}\\) as a matrix.\n\nProposition 83\nLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) a smooth map. Denote the differential of \\(f\\) by \\[\ndf_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,.\n\\] We have:\n\n\\(df_{\\mathbf{p}} (\\mathbf{v})\\) does not depend on the choice of \\({\\pmb{\\gamma}}\\).\n\\(df_{\\mathbf{p}}\\) is linear, that is, \\[\ndf_{\\mathbf{p}} (\\lambda \\mathbf{v}+ \\mu \\mathbf{w}) = \\lambda df_{\\mathbf{p}} (\\mathbf{v}) + \\mu df_{\\mathbf{p}} (\\mathbf{w}) \\,,\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\) and \\(\\lambda,\\mu \\in \\mathbb{R}\\).\nLet \\[\n{\\pmb{\\sigma}}\\colon U \\to \\mathcal{S}\\,, \\quad \\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\widetilde{\\mathcal{S}} \\,,\n\\] be regular charts at \\(\\mathbf{p}\\) and \\(f(\\mathbf{p})\\), respectively. Denote by \\[\n(u,v)  \\mapsto ( \\alpha(u,v), \\beta(u,v) )\n\\] the components of the smooth map \\[\n\\Psi := \\widetilde{{\\pmb{\\sigma}}}^{-1} \\circ f \\circ {\\pmb{\\sigma}}\\colon U \\to \\widetilde{U} \\,.\n\\] In particular \\[\n\\widetilde{{\\pmb{\\sigma}}} (  \\alpha(u,v) , \\beta(u,v) ) = f({\\pmb{\\sigma}}(u,v)) \\,,\n\\quad \\forall \\, (u,v) \\in U \\,.\n\\] The matrix of the linear map \\(df_{\\mathbf{p}}\\) with respect to the basis \\[\n\\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\} \\,\\, \\mbox{ on } \\,\\, T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad\n\\{ \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} , \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} \\} \\,\\, \\mbox{ on } \\,\\, T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,,\n\\] is given by the Jacobian of the map \\(\\Psi\\), that is, \\[\nd_{\\mathbf{p}} f = J\\Psi = \\left(\n\\begin{array}{cc}\n\\alpha_u & \\alpha_v \\\\\n\\beta_u & \\beta_v \\\\\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\nFor a proof, see the discussion at page \\(87\\) of (Pressley 2010).\n\nProposition 84\nThe following hold:\n\nIf \\(\\mathcal{S}\\) is a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\), the differential at \\(\\mathbf{p}\\) of the identity map \\[\nI \\colon \\mathcal{S}\\to \\mathcal{S}\\,, \\quad I(x):=x \\,,\n\\] is the identity map \\[\nI \\colon T_{\\mathbf{p}} (\\mathcal{S}) \\to T_{\\mathbf{p}} (\\mathcal{S}) \\,, \\quad I(v):=v \\,.\n\\]\nIf \\(\\mathcal{S}_1\\), \\(\\mathcal{S}_2\\) and \\(\\mathcal{S}_3\\) are regular surfaces and \\[\nf \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2 \\,, \\quad\ng \\colon \\mathcal{S}_2 \\to \\mathcal{S}_3 \\,,\n\\] are smooth maps, then \\[\nd_{\\mathbf{p}} ( g \\circ f ) = d_{f(\\mathbf{p})} g \\circ d_{\\mathbf{p}} f \\,,\n\\] for all \\(\\mathbf{p}\\in T_{\\mathbf{p}} \\mathcal{S}_1\\).\nIf \\(\\mathcal{S}_1\\), \\(\\mathcal{S}_2\\) are regular surfaces and \\[\nf \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2 \\,,\n\\] is a diffeomorphism, then the differential \\[\nd_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}_1 \\to T_{f(\\mathbf{p})} \\mathcal{S}_2\n\\] is invertible for all \\(\\mathbf{p}\\in \\mathcal{S}_1\\).\n\n\n\nFor a proof see Proposition 4.4.5 in (Pressley 2010). The above proposition says that the differential of diffeomorphism is invertible. The converse statement is true locally.\n\nTheorem 85\nLet \\(\\mathcal{S}_1\\) and \\(\\mathcal{S}_2\\) be regular surfaces. Suppose that \\[\nf \\colon \\mathcal{S}_1 \\to \\mathcal{S}_2\n\\] is smooth. They are equivalent:\n\n\\(f\\) is a local diffeomorphism.\nThe differential \\(d_{\\mathbf{p}} f \\colon T_{\\mathbf{p}} \\mathcal{S}_1 \\to T_{f(\\mathbf{p})} \\mathcal{S}_2\\) is invertible for all \\(\\mathbf{p}\\in \\mathcal{S}_1\\).\n\n\n\nThe proof is based on the Inverse Function Theorem, see Proposition 4.4.6 in (Pressley 2010).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#examples-of-surfaces",
    "href": "sections/chap_4.html#examples-of-surfaces",
    "title": "4  Surfaces",
    "section": "4.10 Examples of Surfaces",
    "text": "4.10 Examples of Surfaces\n\n4.10.1 Level surfaces\nWe have already seen level surfaces. Let us recall the defintion.\n\nDefinition 86: Level surfaceLet \\(V \\subseteq \\mathbb{R}^3\\) be an open set and \\(f \\colon V \\to \\mathbb{R}\\) be smooth. The level surface associated with \\(f\\) is the set \\[\n\\mathcal{S}_f := f^{-1}(0) = \\{ (x,y,z) \\in V \\, \\colon \\,f(x,y,z) = 0  \\} \\,.\n\\]\n\n\nThe following Theorem gives a sufficient condition for \\(\\mathcal{S}_f\\) to be a regular surface.\n\nTheorem 87Let \\(V \\subseteq \\mathbb{R}^3\\) be an open set and \\(f \\colon V \\to \\mathbb{R}\\) be smooth. Suppose that \\[\n\\nabla f (x,y,z) \\neq 0 \\,, \\quad \\forall \\, (x,y,z) \\in V \\,.\n\\] Then \\(\\mathcal{S}_f\\) is a regular surface.\n\n\nLet us give a characterization of the tangent plane to \\(\\mathcal{S}_f\\).\n\nProposition 88Let \\(V \\subseteq \\mathbb{R}^3\\) be an open set and \\(f \\colon V \\to \\mathbb{R}\\) be smooth. Suppose that \\[\n\\nabla f (x,y,z) \\neq 0 \\,, \\quad \\forall \\, (x,y,z) \\in V \\,.\n\\] Then \\(\\nabla f(\\mathbf{p})\\) is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}_f\\). In particular, the equation of \\(T_{\\mathbf{p}} \\mathcal{S}_f\\) is given by \\[\n\\partial_{x} f (\\mathbf{p}) x  + \\partial_{y} f (\\mathbf{p}) y    + \\partial_{z} f (\\mathbf{p}) z = 0 \\,, \\quad  \\forall \\, (x,y,z) \\in \\mathbb{R}^3\\,.   \n\\] The equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}_f\\) is given by \\[\n\\partial_{x} f (\\mathbf{p}) (x-x_0)  + \\partial_{y} f (\\mathbf{p}) (y-y_0)    + \\partial_{z} f (\\mathbf{p}) (z-z_0) = 0 \\,, \\forall \\, (x,y,z) \\in \\mathbb{R}^3\\,,   \n\\] where \\(\\mathbf{p}= (x_0,y_0,z_0)\\).\n\n\n\nProofLet \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}_f\\). By definition there exists a smooth curve \\[\n{\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathcal{S}_f \\subseteq \\mathbb{R}^3\n\\] such that \\[\n{\\pmb{\\gamma}}(0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0)=\\mathbf{v}\\,.\n\\] Since \\({\\pmb{\\gamma}}(t) \\in \\mathcal{S}_f\\), we have that \\[\nf({\\pmb{\\gamma}}(t)) = 0 \\,, \\quad \\forall \\, t \\in (-\\varepsilon,\\varepsilon) \\,.\n\\] By chain rule we get \\[\n\\nabla f ({\\pmb{\\gamma}}(t)) \\cdot \\dot{{\\pmb{\\gamma}}}(t) = 0 \\,, \\quad \\forall \\, t \\in (-\\varepsilon,\\varepsilon) \\,.\n\\] Evaluating the above at \\(t=0\\) yields \\[\n0 = \\nabla f ({\\pmb{\\gamma}}(0)) \\cdot \\dot{{\\pmb{\\gamma}}}(0) = \\nabla f (\\mathbf{p}) \\cdot \\mathbf{v}\\,,\n\\] showing that \\(\\mathbf{v}\\) is orthogonal to \\(\\nabla f (\\mathbf{p})\\). Since \\(\\mathbf{v}\\) is arbitrary, we conclude that \\(\\nabla f (\\mathbf{p})\\) is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}_f\\). In particular, the equation for \\(T_{\\mathbf{p}} \\mathcal{S}_f\\) is \\[\n\\nabla f(\\mathbf{p}) \\cdot (x,y,z) = 0 \\,, \\quad \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,.\n\\] Therefore the equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is given by \\[\n\\nabla f(\\mathbf{p}) \\cdot (x,y,z) = k \\,, \\quad \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,,\n\\] for some \\(k \\in \\mathbb{R}\\). Since \\(\\mathbf{p}\\in \\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\), we can substitute \\[\n(x,y,z)=(x_0,y_0,z_0) = \\mathbf{p}\n\\] in the above equation to obtain \\[\nk = \\nabla f(\\mathbf{p}) \\cdot (x_0,y_0,z_0) \\,.\n\\] Hence the equation for \\(\\mathbf{p}+ T_{\\mathbf{p}} \\mathcal{S}\\) is \\[\n\\nabla f(\\mathbf{p}) \\cdot (x-x_0,y-y_0,z-z_0) = 0 \\,, \\quad \\forall \\, (x,y,z) \\in \\mathbb{R}^3 \\,.\n\\]\n\n\n\n\n4.10.2 Quadrics\nQuadrics are level surfaces \\[\nS_f = \\left\\{  (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,f(x,y,z) = 0   \\right\\} \\,,\n\\] where \\[\\begin{align*}\nf(x,y,z)  = & a_1 x^2 + a_2 y^2 + a_3 z^2 + 2a_4 xy + 2a_5 xz + 2a_6 yz + \\\\\n          & + b_1 x + b_2 y + b_3 z + c  \\,,\n\\end{align*}\\] for some coefficients \\(a_i,b_i,c \\in \\mathbb{R}\\). Let \\[\nA =  \n\\left(\n\\begin{array}{ccc}\na_1 & a_4 & a_6 \\\\\na_4 & a_2 & a_5 \\\\\na_6 & a_5 & a_3\n\\end{array}\n\\right)  \\in \\mathbb{R}^{3 \\times 3} \\,,\n\\] and \\[\n\\mathbf{x}= (x,y,z)^T \\,, \\quad \\mathbf{b} = (b_1,b_2,b_3)^T \\,.\n\\] Then \\(f\\) can be represented by the quadratic form \\[\nf(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x}+ \\mathbf{b} \\cdot \\mathbf{x}+ c \\,.\n\\] The expression \\(f=0\\) is called a quadric equation.\nAs stated in the following theorem, there are \\(14\\) quadrics in total. Out of these:\n\n9 are interesting surfaces,\n3 are planes,\n1 is a line,\n1 is a point.\n\n\nTheorem 89\nSuppose \\(\\mathcal{S}\\) is a level surface defined by a quadric equation. Then, up to rigid motions, \\(\\mathcal{S}\\) can be described by one of the following equations:\n\nEllipsoid: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2} + \\dfrac{z^2}{r^2} = 1\\).\nHyperboloid of one sheet: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2} - \\dfrac{z^2}{r^2} = 1\\)\nHyperboloid of two sheets: \\(\\dfrac{x^2}{p^2} - \\dfrac{y^2}{q^2} - \\dfrac{z^2}{r^2} = 1\\)\nElliptic Paraboloid: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2}  = z\\)\nHyperbolic Paraboloid: \\(\\dfrac{x^2}{p^2} - \\dfrac{y^2}{q^2}  = z\\)\nQuadric Cone: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2} - \\dfrac{z^2}{r^2} = 0\\)\nElliptic Cylinder: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2}  = 1\\)\nHyperbolic Cylinder: \\(\\dfrac{x^2}{p^2} - \\dfrac{y^2}{q^2}  = 1\\)\nParabolic Cylinder: \\(\\dfrac{x^2}{p^2} = y\\)\nPlane: \\(x = 0\\)\nTwo parallel planes: \\(x^2 = p^2\\)\nTwo intersecting planes: \\(\\dfrac{x^2}{p^2} - \\dfrac{y^2}{q^2} = 0\\)\nStraight line: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2} = 0\\)\nSingle point: \\(\\dfrac{x^2}{p^2} + \\dfrac{y^2}{q^2} + \\dfrac{z^2}{r^2} = 0\\)\n\n\n\nThe proof of Theorem 89 follows by diagonalizing the symmetric matrix \\(A\\), and by studying the eigenvalues, see Theorem 5.5.2 in (Pressley 2010).\n\nExample 90The sphere is described by \\[\nS = \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,x^2 + y^2 + z^2 = 1 \\} \\,.\n\\] This is an ellipsoid with \\[\np = q = r = 1 \\,.\n\\] In particular we can write the sphere as the quadric equation: \\[\n\\mathbf{x}^T\n\\left(\n\\begin{array}{ccc}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1\n\\end{array}\n\\right)  \\mathbf{x}= 1 \\,.\n\\]\n\n\n\nExample 91Consider the level surface \\[\n\\mathcal{S}=   \\{ (x,y,z) \\in \\mathbb{R}^3 \\, \\colon \\,f(x,y,z) = 0 \\}\n\\] with \\[\nf(x,y,z) = x^2 + 2y^2 - 4z^2 + 2xy + yz - 6xz + 1 = 0 \\,.\n\\] Therefore \\(\\mathcal{S}\\) is a quadric. The matrix associated to \\(f\\) is \\[\nA =  \n\\left(\n\\begin{array}{ccc}\n1 & 1 & -3 \\\\\n1 & 2 & 1/2 \\\\\n-3 & 1/2 & -4\n\\end{array}\n\\right)  \\,.\n\\] Diagonalizing the matrix \\(A\\) we obtain \\(A=PDP^{-1}\\), with \\(P\\) matrix of eigenvectors and \\[\nD =  \n\\left(\n\\begin{array}{ccc}\n-5.51 & 0 & 0 \\\\\n0 & 1.55 & 0 \\\\\n0 & 0 & 2.96\n\\end{array}\n\\right)  \\,.\n\\] Therefore, up to changing basis via the matrix \\(P\\), \\(S\\) can be described by the quadric equation \\[\n5.51 \\widetilde{x}^2 - 1.55 \\widetilde{y}^2 - 2.96 \\widetilde{z}^2 = 1  \\,,\n\\] showing that \\(S\\) is a Hyperboloid of two sheets.\n\n\n\n\n4.10.3 Ruled surfaces\nA ruled surface is a surface obtained as union of straight lines, called the rulings of the surface. By using curves, ruled surfaces can be defined in the following way.\n\nDefinition 92: Ruled surface\nLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a smooth curve and \\(\\mathbf{a} \\colon (a,b) \\to \\mathbb{R}^3\\) a vector, such that \\(\\dot{{\\pmb{\\gamma}}}(t)\\) and \\(\\mathbf{a}(t)\\) are linearly independent for all \\(t \\in (a,b)\\). A ruled surface is a surface with chart \\[\n{\\pmb{\\sigma}}(u,v) = {\\pmb{\\gamma}}(u) + v \\mathbf{a}(u) \\,.\n\\] We say that:\n\n\\({\\pmb{\\gamma}}\\) is the base curve\nThe lines \\(v \\mapsto v \\mathbf{a}(u)\\) are the rulings\n\n\n\n\nProposition 93A ruled surface \\(\\mathcal{S}\\) is regular if \\(v\\) is sufficiently small.\n\n\n\nProofA chart for \\(\\mathcal{S}\\) is \\[\n{\\pmb{\\sigma}}_u = \\dot{{\\pmb{\\gamma}}}(u) + v \\dot{\\mathbf{a}}(u) \\,, \\quad\n{\\pmb{\\sigma}}_v = \\mathbf{a}(u) \\,,\n\\] with \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{a}\\) linerly independent. Thus \\(\\dot{{\\pmb{\\gamma}}}(u) + v \\dot{\\mathbf{a}}(u)\\) and \\(\\mathbf{a}\\) are linearly independent for \\(v\\) sufficiently small.\n\n\nThe same base curve can yield multiple ruled surfaces. For example, if \\({\\pmb{\\gamma}}\\) is a circle, we can obtain both the unit cylinder and the Möbius band.\n\nExample 94: Unit CylinderAs seen in Example 49, the cylinder is a surface with atlas \\(\\mathcal{A}=\\{{\\pmb{\\sigma}}_1,{\\pmb{\\sigma}}_2\\}\\), where \\({\\pmb{\\sigma}}_1\\) and \\({\\pmb{\\sigma}}_2\\) are suitable restriction of \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\cos(u),v ) \\,, \\quad (u,v) \\in [0,2\\pi) \\times \\mathbb{R}\\,.\n\\] We have \\[\n{\\pmb{\\sigma}}(u,v) = {\\pmb{\\gamma}}(u) + v \\mathbf{a}(u) \\,,\n\\] with \\[\n{\\pmb{\\gamma}}(u):= (\\cos(u), \\cos(u),0 ) \\,, \\quad \\mathbf{a} = (0,0,1) \\,.\n\\] Hence the unit cylinder is a ruled surface, see Figure 4.7.\n\n\n\n\n\n\n\n\nFigure 4.7: Unit cylinder is a ruled surface with base curve \\({\\pmb{\\gamma}}\\) and rulings given by vertical lines.\n\n\n\n\nExample 95: Möbius bandThe Möbius band is a ruled surface with chart \\[\n{\\pmb{\\sigma}}= {\\pmb{\\gamma}}(u) + v \\mathbf{a}(u) \\,, \\quad u \\in (0,2\\pi), \\, v \\in \\left( -\\frac12, \\frac12 \\right) \\,,\n\\] where \\[\n{\\pmb{\\gamma}}(u) = (\\cos(u), \\sin(u), 0)\n\\] is the unit circle and \\[\n\\mathbf{a} = \\left(   -\\sin \\left( \\frac{u}{2} \\right) \\cos(u),\n                  -\\sin \\left( \\frac{u}{2} \\right) \\sin(u),\n                   \\cos \\left( \\frac{u}{2} \\right)   \\right)\n\\] is a vector which does a full rotation while going around the unit circle \\({\\pmb{\\gamma}}\\). This is shown in Figure 4.8.\n\n\n\n\n\n\n\n\nFigure 4.8: The Möbius band is a ruled surface with base curve \\({\\pmb{\\gamma}}\\) and rulings given by rotating vertical lines.\n\n\n\n\n\n4.10.4 Surfaces of Revolution\nSurfaces of revolution are obtained by rotating a curve about the \\(z\\)-axis.\n\nDefinition 96: Surface of revolutionLet \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathbb{R}^3\\) be a smooth curve in the \\((x,z)\\)-plane, that is, \\[\n{\\pmb{\\gamma}}(u) = (f(u), 0 , g(u)) \\,.\n\\] Suppose that \\(f&gt;0\\). The surface obtained by rotating \\({\\pmb{\\gamma}}\\) about the \\(z\\)-axis is called surface of revolution. A chart for \\(\\mathcal{S}\\) is given by \\[\n{\\pmb{\\sigma}}(u,v) :=  (f(u) \\cos(v), f(u)\\sin(v), g(u)) \\,, \\,\\, u \\in (a,b) \\,, \\, v \\in [0,2\\pi) \\,.\n\\]\n\n\n\nProposition 97A surface of revolution is regular if and only if \\({\\pmb{\\gamma}}\\) is regular.\n\n\n\nProofWe have \\[\\begin{align*}\n{\\pmb{\\sigma}}_u & = \\left(\\dot{f}(u) \\cos(v), \\dot{f}(u) \\sin(v), \\dot{g}(u) \\right) \\,, \\\\\n{\\pmb{\\sigma}}_v & = \\left(-f(u)\\sin(v), f(u) \\cos(v), 0 \\right) \\,.\n\\end{align*}\\] Therefore \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v = \\left( f \\dot{g} \\cos(v), -\\dot{f} g \\sin(v), f \\dot{f} \\right)\n\\] and \\[\n\\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\|^2 = f^2 \\left( \\dot{f}^2 + \\dot{g}^2 \\right) = f^2 \\left\\| {\\pmb{\\gamma}} \\right\\|^2 \\,.\n\\] Recall that \\(f &gt; 0\\) by definition, so that \\(f^2 \\neq 0\\). Therefore \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent if and only if \\({\\pmb{\\gamma}}\\) is regular.\n\n\n\nExample 98: CatenoidThe catenoid is the surface of revolution obtained by rotating the catenary about the \\(z\\)-axis, see Figure 4.9. Recall that the catenary function is defined by \\[\nf(u) = \\cosh (u) \\,.  \n\\] Therefore the catenoid is obtained by rotating \\[\n{\\pmb{\\gamma}}(u) = \\left(  \\cosh (u), 0 , u \\right) \\,.\n\\] A chart for the catenoid is given by \\[\n{\\pmb{\\sigma}}(u,v) = (\\cosh (u) \\cos(v), \\cosh (u)\\sin(v), u) \\,,\n\\] where \\(u \\in \\mathbb{R}\\) and \\(v \\in [0,2\\pi)\\). Note that \\(f&gt;0\\) and \\[\n\\dot{{\\pmb{\\gamma}}}= \\left(  \\sinh (u), 0 , 1 \\right) \\,, \\quad\n\\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^2 = 1+ \\sinh(u)^2 \\geq 1 \\,.\n\\] Therefore \\({\\pmb{\\gamma}}\\) is regular. By Proposition 97 we conclude that the catenoid is a regular surface.\n\n\n\n\n\n\n\n\nFigure 4.9: The Catenoid is the surface of revolution obtained by rotating the catenary about the \\(z\\)-axis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#first-fundamental-form",
    "href": "sections/chap_4.html#first-fundamental-form",
    "title": "4  Surfaces",
    "section": "4.11 First fundamental form",
    "text": "4.11 First fundamental form\nIn this section we introduce the first fundamental form of a surface. This will allow us to compute:\n\nInner product between tangent vectors\nAngle between tangent vectors\nArea of surface regions\n\nMoreover we can compute\n\nLength of curves on a surface\nAngle between curves on a surface\n\n\n4.11.1 Length on surfaces\nLet \\(\\mathcal{S}\\) be a surface and consider two points \\(\\mathbf{p}, \\mathbf{q} \\in \\mathcal{S}\\). The euclidean distance between \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) is \\[\n\\left\\| \\mathbf{p}- \\mathbf{q} \\right\\| \\,.\n\\] However this measures the length of the straight segment which connects \\(\\mathbf{p}\\) to \\(\\mathbf{q}\\). We are interested in measuring the distance on \\(\\mathcal{S}\\). A way to measure such distance is the following: Suppose \\[\n{\\pmb{\\gamma}}\\colon (t_0,t_1) \\to \\mathcal{S}\n\\] is a smooth curve such that \\[\n{\\pmb{\\gamma}}(t_0) = \\mathbf{p}\\,, \\quad {\\pmb{\\gamma}}(t_1) = \\mathbf{q} \\,.\n\\] The distance between \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) on \\(\\mathcal{S}\\) is the length of \\({\\pmb{\\gamma}}\\), i.e., \\[\n\\int_{t_0}^{t_1} \\left\\|  \\dot{{\\pmb{\\gamma}}}(t)  \\right\\| \\, dt \\,.\n\\]\n\nQuestion 99How do we compute the above integral?\n\n\nSince \\({\\pmb{\\gamma}}(t) \\in \\mathcal{S}\\), by definition we have \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\in T_{\\mathbf{x}} S \\,, \\quad \\mathbf{x}:= {\\pmb{\\gamma}}(t) \\,.\n\\] Therefore, computing \\(\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|\\) is equivalent to computing the length of tangent vectors. This motivates the definition of first fundamental form.\n\nDefinition 100: First fundamental formLet \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). The first fundamental form of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is the bilinear symmetric map \\[\nI_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\times T_{\\mathbf{p}} \\mathcal{S}\\to \\mathbb{R}\\,, \\quad I_{\\mathbf{p}} (\\mathbf{v},\\mathbf{w}) := \\mathbf{v}\\cdot \\mathbf{w}\\,.\n\\]\n\n\nThree observations:\n\nThe first fundamental form of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is the map obtained by restricting the scalar product of \\(\\mathbb{R}^3\\) to \\(T_{\\mathbf{p}} \\mathcal{S}\\).\nNote that \\[\nI_{\\mathbf{p}} (\\mathbf{v},\\mathbf{v}) = \\| \\mathbf{v}\\|^2 \\,,\n\\] so that \\(I_{\\mathbf{p}}\\) can be used to compute the length of tangent vectors.\nThe definition of \\(I_{\\mathbf{p}}\\) does not depend on a chosen chart.\n\nTo use the first fundamental form in practice, we need to express \\(I_{\\mathbf{p}}\\) in terms of local charts. To this end, we first define the coordinates functions \\(du\\) and \\(dv\\) on \\(T_{\\mathbf{p}} S\\).\n\nDefinition 101: Coordinate functions on tangent planeLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart of \\(\\mathcal{S}\\). For each \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\) we have \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\} \\,,\n\\] where \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are evaluated at the point \\((u_0,v_0) \\in U\\) such that \\[\n{\\pmb{\\sigma}}(u_0,v_0)=\\mathbf{p}\\,.\n\\] Therefore, for each \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\), there exist \\(\\lambda,\\mu \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\,.\n\\] The coordinate functions on \\(T_{\\mathbf{p}} \\mathcal{S}\\) are the linear maps \\[\ndu, dv \\colon T_{\\mathbf{p}} \\mathcal{S}\\to \\mathbb{R}\\,, \\quad du(\\mathbf{v}) := \\lambda \\,,  \n\\quad dv(\\mathbf{v}) := \\mu \\,.\n\\]\n\n\n\nDefinition 102: First fundamental form of a chartLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart of \\(\\mathcal{S}\\). Define the functions \\[\nE , F , G \\colon U \\to \\mathbb{R}\n\\] by setting \\[\nE := {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u \\,, \\quad  F := {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\,, \\quad\nG := {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v \\,.\n\\] Let \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\) and denote by \\((u_0,v_0) \\in U\\) the point such that \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] The first fundamental form of \\({\\pmb{\\sigma}}\\) at \\(\\mathbf{p}\\) is the quadratic form \\[\n\\mathscr{F}_1 \\colon T_{\\mathbf{p}} \\mathcal{S}\\to \\mathbb{R}\n\\] defined by \\[\n\\mathscr{F}_1 (\\mathbf{v}) := E \\, du^2(\\mathbf{v}) + 2F \\, du(\\mathbf{v}) \\, dv (\\mathbf{v})+ G \\, dv^2 (\\mathbf{v}) \\,,\n\\tag{4.3}\\] for all \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\), where \\(E,F,G\\) are evaluated at \\((u_0,v_0)\\).\n\n\nWe usually omit the dependence on \\(\\mathbf{v}\\) in (4.3), and write \\[\n\\mathscr{F}_1 = E \\, du^2 + 2F \\, du \\, dv + G \\, dv^2 \\,.\n\\] The quadratic form \\(\\mathscr{F}_1\\) is related to \\(I_{\\mathbf{p}}\\) in the following way.\n\nProposition 103Let \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart of \\(\\mathcal{S}\\), and \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\). Then \\[\nI_{\\mathbf{p}} (\\mathbf{v},\\mathbf{w}) = (du (\\mathbf{v}), dv(\\mathbf{v}) )  \\,\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right) \\, (du(\\mathbf{w}) , dv(\\mathbf{w}))^T \\,,\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\). In particular, \\(\\mathscr{F}_1\\) is the quadratic form associated to the symmetric bilinear form \\(I_{\\mathbf{p}}\\), that is, \\[\n\\mathscr{F}_1 (\\mathbf{v}) = I_{\\mathbf{p}} (\\mathbf{v},\\mathbf{v}) \\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\n\n\nProofBy Theorem 75 we have \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u, {\\pmb{\\sigma}}_v \\} \\,.\n\\] Therefore, for \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\), there exist \\(\\lambda_1,\\lambda_2,\\mu_1,\\mu_2 \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= \\lambda_1 {\\pmb{\\sigma}}_u + \\mu_1 {\\pmb{\\sigma}}_v \\,, \\quad\n\\mathbf{w}= \\lambda_2 {\\pmb{\\sigma}}_u + \\mu_2 {\\pmb{\\sigma}}_v \\,.\n\\] We have \\[\\begin{align*}\nI_{\\mathbf{p}} (\\mathbf{v},\\mathbf{w}) & = \\mathbf{v}\\cdot \\mathbf{w}\\\\\n& = \\lambda_1 \\lambda_2 \\, {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v + ( \\lambda_1 \\mu_2 + \\lambda_2 \\mu_1 ) \\, {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v + \\mu_1 \\mu_2 \\, {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v \\\\\n& = E \\, du (\\mathbf{v}) du(\\mathbf{w})  + F \\, ( du(\\mathbf{v}) \\, dv(\\mathbf{w}) + du(\\mathbf{w}) dv(\\mathbf{v}) ) \\\\\n& \\qquad  + G \\,  dv(\\mathbf{v}) dv(\\mathbf{w}) \\\\\n& = (du (\\mathbf{v}), dv(\\mathbf{v}) )  \\,\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right) \\, (du(\\mathbf{w}) , dv(\\mathbf{w}))^T \\,.\n\\end{align*}\\] The fact that \\[\nI_{\\mathbf{p}}(\\mathbf{v},\\mathbf{v}) = \\mathscr{F}_1(\\mathbf{v})\n\\] follows from the first part of the statement and definition of \\(\\mathscr{F}_1\\).\n\n\n\nRemark 104: Linear algebra interpretationUsing linear algebra, Proposition 103 has a clear interpretation, as follows. \\(I_{\\mathbf{p}}\\) is a symmetric bilinear form on the vector space \\(T_{\\mathbf{p}} \\mathcal{S}\\). Fixing the basis \\(\\{ {\\pmb{\\sigma}}_u, {\\pmb{\\sigma}}_v \\}\\) for \\(T_{\\mathbf{p}} \\mathcal{S}\\), we can represent \\(I_{\\mathbf{p}}\\) via the matrix \\[\\begin{align*}\nM & :=\n\\left(\n\\begin{array}{cc}\nI_{\\mathbf{p}} ({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_u) & I_{\\mathbf{p}} ({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v) \\\\\nI_{\\mathbf{p}} ({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_u) & I_{\\mathbf{p}} ({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_v) \\\\\n\\end{array}\n\\right) \\\\\n& =\n\\left(\n\\begin{array}{cc}\n{\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u &  {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\\\\n{\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_u &  {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v \\\\\n\\end{array}\n\\right) \\\\\n& =\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G \\\\\n\\end{array}\n\\right) \\,,\n\\end{align*}\\] where we used that \\({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_u\\).\n\n\n\nNotationWith a little abuse of notation, we also denote by \\(\\mathscr{F}_1\\) the \\(2 \\times 2\\) matrix \\[\n\\mathscr{F}_1 :=\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\nRemark 105: First fundamental form and reparametrizations\nThe first fundamental form \\(I_{\\mathbf{p}}\\) depends only on the surface \\(\\mathcal{S}\\) and the point \\(\\mathbf{p}\\). Instead the representation of \\(I_{\\mathbf{p}}\\) \\[\n\\mathscr{F}_1 = E \\, du^2 + 2F \\, du dv + G \\, dv^2\n\\] depends on the choice of chart \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\). Indeed suppose that \\(\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\mathbb{R}^3\\) is a reparametrization of \\({\\pmb{\\sigma}}\\), that is, \\[\n\\widetilde{{\\pmb{\\sigma}}} = {\\pmb{\\sigma}}\\circ \\Phi \\,,\n\\] where \\(\\Phi \\colon \\widetilde{U} \\to U\\) is a diffeomorphism. Recall that we denote the components \\(\\Phi^1\\) and \\(\\Phi^2\\) of \\(\\Phi\\) by \\[\n(\\tilde{u}, \\tilde{v}) \\mapsto u (\\tilde{u}, \\tilde{v}) \\,, \\quad\n(\\tilde{u}, \\tilde{v}) \\mapsto v (\\tilde{u}, \\tilde{v}) \\,,\n\\] respectively. The Jacobian of \\(\\Phi\\) is then \\[\nJ\\Phi = \\left(   \n\\begin{array}{cc}\n\\dfrac{\\partial u}{\\partial \\tilde u}  &  \\dfrac{\\partial u}{\\partial \\tilde v}  \\\\\n\\dfrac{\\partial v}{\\partial \\tilde u}  &  \\dfrac{\\partial v}{\\partial \\tilde v}\n\\end{array}\n\\right) \\,.\n\\] Denote the first fundamental form of \\(\\widetilde{{\\pmb{\\sigma}}}\\) by \\[\n\\widetilde{\\mathscr{F}}_1 = \\widetilde{E} \\, d\\tilde{u}^2 + 2 \\widetilde{F} \\, d\\tilde{u} d\\tilde{v} + \\widetilde{G} \\, d\\tilde{v}^2 \\,.\n\\] The linear maps \\(du, dv\\) and \\(d\\tilde{u}, d\\tilde{v}\\) are related by \\[\ndu = \\frac{\\partial u}{\\partial \\tilde{u}} \\, d\\tilde{u} + \\frac{\\partial u}{\\partial \\tilde{v}} \\, d\\tilde{v} \\,, \\quad\ndv = \\frac{\\partial v}{\\partial \\tilde{u}} \\, d\\tilde{u} + \\frac{\\partial v}{\\partial \\tilde{v}} \\, d\\tilde{v}\n\\tag{4.4}\\] Moreover the matrices of \\(\\mathscr{F}_1\\) and \\(\\widetilde{\\mathscr{F}}_1\\) are related by \\[\n\\left(\n\\begin{array}{cc}\n\\widetilde{E} & \\widetilde{F} \\\\\n\\widetilde{F} & \\widetilde{G}\n\\end{array}\n\\right)  \n=\n(J \\Phi)^T \\,\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right)\n\\,\nJ \\Phi  \\,.\n\\tag{4.5}\\]\n\nThe proof of the above statements follows by basic linear algebra: The pairs \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_u\\}\\) and \\(\\{\\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} , \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} \\}\\) are bases for the vector space \\(T_{\\mathbf{p}} \\mathcal{S}\\). The change of basis matrix is given exactly by \\(J\\Phi\\). Therefore formulas (4.4) and (4.5) are consequence of change of basis results for linear maps and bilinear forms, respectively.\n\n\n\nLet us compute the first fundamental form of a plane and of a cylinder.\n\nExample 106: Plane\nLet \\(\\mathbf{a}, \\mathbf{p}, \\mathbf{q} \\in \\mathbb{R}^3\\). Suppose that \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) are orthonormal vectors, that is, \\[\n\\left\\| \\mathbf{p} \\right\\| = \\left\\| \\mathbf{q} \\right\\| = 1 \\,, \\quad \\mathbf{p}\\cdot \\mathbf{q} = 0 \\,.\n\\] Consider the plane with chart \\[\n{\\pmb{\\sigma}}(u,v) = \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\,, \\quad (u,v) \\in \\mathbb{R}^2 \\,.\n\\] Prove that the first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\]\n\nWe have \\[\n{\\pmb{\\sigma}}_u = \\mathbf{p}\\,, \\quad {\\pmb{\\sigma}}_v = \\mathbf{q}\n\\] and therefore \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u = \\left\\| \\mathbf{p} \\right\\|^2 = 1 \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = \\mathbf{p}\\cdot \\mathbf{q} = 0 \\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v = \\left\\| \\mathbf{q} \\right\\|^2 = 1 \\\\\n\\end{align*}\\] Then the first fundamental form is \\[\n\\mathscr{F}_1 = E \\, du^2 + 2 F\\, du \\, dv + G \\, dv^2 = du^2 + dv^2 \\,.  \n\\]\n\n\n\nTwo remarks concerning Example 106 :\n\nThe above example should not be surprising, since distances on a plane are the same as Euclidean distances, given that straight segments are contained in the plane.\nIf we drop the assumption of \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) being orthonormal, then \\[\n\\mathscr{F}_1 = \\left\\| \\mathbf{p} \\right\\|^2 \\, du^2 + \\mathbf{p}\\cdot \\mathbf{q} \\, du \\, dv + \\left\\| \\mathbf{q} \\right\\|^2 \\, dv^2 \\,.\n\\] Again, this is not surprising, due to Remark 105.\n\n\nExample 107: Unit cylinder\nConsider the unit cylinder with chart \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u),  v)  \\,, \\quad (u,v) \\in (0,2\\pi) \\times \\mathbb{R}\\,.\n\\] Prove that the first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\]\n\nWe have \\[\n{\\pmb{\\sigma}}_u = (-\\sin(u),\\cos(u), 0 )  \\,, \\quad {\\pmb{\\sigma}}_v = (0,0,1) \\,,\n\\] and therefore \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u = 1 \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = 0 \\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v = 1 \\\\\n\\end{align*}\\] Then the first fundamental form is \\[\n\\mathscr{F}_1 = E \\, du^2 + 2 F\\, du \\, dv + G \\, dv^2 = du^2 + dv^2 \\,.  \n\\]\n\n\n\n\nRemark 108We have seen that a plane and the unit cylinder have the same first fundamental form \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\] Therefore lengths are the same on the two surfaces.\n\n\n\n\n4.11.2 Length of curves\nLet us show how the first fundamental form allows to compute the length of curves with values on surfaces.\n\nProposition 109Let \\(\\mathcal{S}\\) be a regular surface with chart \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\). Suppose \\[\n{\\pmb{\\gamma}}\\colon (t_0,t_1) \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\n\\] is a smooth curve. Then \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}(u(t), v(t)) \\,,\n\\] for some smooth functions \\(u,v \\colon (t_0,t_1) \\to \\mathbb{R}\\) and \\[\n\\int_{t_0}^{t_1} \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt =\n\\int_{t_0}^{t_1} \\sqrt{  E \\dot{u}^2 + 2F \\dot u \\dot v + G \\dot{v}^2  } \\, dt \\,,\n\\] where \\(\\dot u, \\dot v\\) are computed at \\(t\\), and \\(E,F,G\\) are computed at \\((u(t),v(t))\\).\n\n\n\nProofSince \\({\\pmb{\\gamma}}\\) takes values into \\({\\pmb{\\sigma}}(U)\\), by Lemma 74 there exist smooth functions \\(u,v\\) such that \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}(u(t), v(t)) \\,, \\quad \\forall \\, t \\in (t_0,t_1) \\,.\n\\] By chain rule we have \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\dot u (t) {\\pmb{\\sigma}}_u( u(t),v(t) ) + \\dot v (t) {\\pmb{\\sigma}}_v( u(t),v(t) ) \\,.\n\\] The above means that the coefficients of \\(\\dot{{\\pmb{\\gamma}}}\\) with respect to the basis \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) are \\(\\dot u, \\dot v\\), i.e., \\[\ndu(dg) = \\dot u \\,, \\quad dv(\\dot{{\\pmb{\\gamma}}}) = \\dot v \\,.\n\\] By Proposition 103 we get \\[\\begin{align*}\n\\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2 & = \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}\\\\\n                & = I_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}, \\dot{{\\pmb{\\gamma}}}) \\\\\n                & = E \\, du(\\dot{{\\pmb{\\gamma}}})^2  + 2F \\, du(\\dot{{\\pmb{\\gamma}}}) dv({\\pmb{\\gamma}}) + G \\, dv(\\dot{{\\pmb{\\gamma}}})^2 \\\\\n                & = E \\, \\dot{u}^2  + 2F \\, \\dot{u} \\dot{v} + G \\, \\dot{v}^2\n                \\,,\n\\end{align*}\\] concluding the proof.\n\n\n\nExample 110: Cone\nConsider the cone with chart \\[\n{\\pmb{\\sigma}}(u,v)=(u \\cos(v), u \\sin (v), u) \\,,\n\\] where \\(u &gt; 0\\) and \\(v \\in [0,2\\pi]\\).\n\nProve that the first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1 = 2 \\, du^2 + u^2 \\, dv^2 \\,.\n\\]\nLet \\({\\pmb{\\gamma}}(t):= {\\pmb{\\sigma}}(t,t)\\). Show that \\[\n\\int_{\\pi/2}^{\\pi} \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt = \\int_{\\pi/2}^{\\pi} \\sqrt{  2 + t^2  } \\, dt  \\,.\n\\]\n\n\nWe have \\[\n{\\pmb{\\sigma}}_u = (\\cos(v), \\sin (v), 1) \\,, \\quad\n{\\pmb{\\sigma}}_v = (- u \\sin(v), u \\cos (v), 0) \\,.\n\\] Therefore \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u = \\cos^2(v) + \\sin^2 (v) + 1 = 2 \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = - u \\cos(v) \\sin(v) + u \\cos(v) \\sin(v) = 0 \\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v = u^2 \\sin^2(v) + u^2 \\cos^2(v) = u^2   \n\\end{align*}\\] The first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1 = 2 \\, du^2 + u^2 \\, dv^2 \\,.\n\\] Concering the curve \\({\\pmb{\\gamma}}\\), we have \\[\n{\\pmb{\\gamma}}(t) := {\\pmb{\\sigma}}(t,t) \\,,\n\\] so that \\[\nu(t) = t \\,, \\quad v(t) = t \\,.\n\\] In particular \\[\n\\dot u = 1\\,, \\quad \\dot v = 1\n\\] and \\[\\begin{align*}\nE(u(t),v(t)) & = E(t,t) = 2 \\\\\nF(u(t),v(t)) & = F(t,t) = 0 \\\\\nG(u(t),v(t)) & = G(t,t) = t^2  \\,.\n\\end{align*}\\] By Proposition 109 we have \\[\\begin{align*}\n\\int_{\\pi/2}^{\\pi} \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\| \\, dt & =\n\\int_{\\pi/2}^{\\pi} \\sqrt{  E \\dot{u}^2 + 2F \\dot u \\dot v + G \\dot{v}^2  } \\, dt \\\\\n& = \\int_{\\pi/2}^{\\pi} \\sqrt{  2 + t^2  } \\, dt   \\,.\n\\end{align*}\\]\n\n\n\n\n\n4.11.3 Local isometries\nWe have seen that a plane \\(\\pmb{\\pi}\\) and a cylinder \\(\\mathcal{C}\\) have the same first fundamental form. This means that scalar product on the two surfaces is the same, as is the length of curves. In this case we say that \\(\\pmb{\\pi}\\) and \\(\\mathcal{C}\\) are locally isometric. Let us give a general definition of such concept.\n\nDefinition 111: Local isometryLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces. A local diffeomorphism \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) is a local isometry if for all \\(\\mathbf{p}\\in \\mathcal{S}\\) the differential \\(d_{\\mathbf{p}}f \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}}\\) satisfies \\[\n\\mathbf{v}\\cdot \\mathbf{w}= d_{\\mathbf{p}}f (\\mathbf{v}) \\cdot d_{\\mathbf{p}}f (\\mathbf{w}) \\,, \\quad\n\\forall \\, \\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] We say that \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) are locally isometric if there exists a local isometry \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\).\n\n\n\n\n\nSketch of local isometry \\(f\\) between \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\). The scalar product between tangent vectors \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) is preserved by \\(d_{\\mathbf{p}}f\\).\n\n\n\nNotationFor brevity we denote \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle := \\mathbf{v}\\cdot \\mathbf{w}\\,, \\quad\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f := d_{\\mathbf{p}}f (\\mathbf{v}) \\cdot d_{\\mathbf{p}}f (\\mathbf{w}) \\,,\n\\] and also \\[\n\\| \\mathbf{v}\\| := \\sqrt{ \\left\\langle v,v \\right\\rangle } \\,, \\quad  \n\\| \\mathbf{v}\\|_f := \\sqrt{ \\left\\langle v,v \\right\\rangle_f } \\,.\n\\]\n\n\n\nRemark 112\nA local diffeomorphism \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) is a local isometry if and only if \\[\n\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle = \\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle_f  \\,, \\quad\n\\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nThe proof follows from the elementary identity \\[\n\\mathbf{v}\\cdot \\mathbf{w}= \\frac12 \\left(   (\\mathbf{v}+ \\mathbf{w}) \\cdot (\\mathbf{v}+ \\mathbf{w}) - \\mathbf{v}\\cdot \\mathbf{v}- \\mathbf{w}\\cdot \\mathbf{w}\\right) \\,,\n\\] which holds for all \\(\\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\) (and more in general in arbitrary vector spaces with inner product).\n\n\n\nLocal isometries preserve the length of curves, as shown in the following proposition.\n\nProposition 113\nLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) be a local diffeomorphism. They are equivalent:\n\n\\(f\\) is a local isometry\nLet \\({\\pmb{\\gamma}}\\) be a curve in \\(\\mathcal{S}\\) and consider the curve \\(\\widetilde{{\\pmb{\\gamma}}}= f \\circ {\\pmb{\\gamma}}\\) on \\(\\widetilde{\\mathcal{S}}\\). Then \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) have the same length.\n\n\n\n\nProofPart 1. Suppose \\({\\pmb{\\gamma}}\\colon (t_0,t_1) \\to \\mathcal{S}\\) is a smooth curve. Consider the smooth curve \\(\\widetilde{{\\pmb{\\gamma}}}:= f \\circ {\\pmb{\\gamma}}\\colon (t_0,t_1) \\to \\widetilde{\\mathcal{S}}\\). Setting \\(\\mathbf{p}:={\\pmb{\\gamma}}(t)\\), by definition of differential of a function between surfaces we have \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = df_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}(t)) \\,.\n\\] Hence \\[\\begin{align*}\n\\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\|^2 & = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\\\\n               & = df_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}(t)) \\cdot df_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}(t)) \\\\\n               & = \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t) \\\\\n               & = \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2\n\\end{align*}\\] where in the second last inequality we used that \\(f\\) is a local isometry. Therefore \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) have the same length: \\[\n\\int_{t_0}^{t_1} \\left\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\right\\|\\, dt\n= \\int_{t_0}^{t_1} \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|\\, dt \\,.\n\\]\nPart 2. Let \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Then there exists a curve \\({\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\mathcal{S}\\) such that \\[\n{\\pmb{\\gamma}}(0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0) = \\mathbf{v}\\,.\n\\] Define the curve \\(\\widetilde{{\\pmb{\\gamma}}}:= f \\circ {\\pmb{\\gamma}}\\colon (-\\varepsilon,\\varepsilon) \\to \\widetilde{\\mathcal{S}}\\). By assumption \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) have the same length, that is, \\[\n\\int_{-\\varepsilon}^{\\varepsilon} \\sqrt{ \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) }\\, dt\n= \\int_{-\\varepsilon}^{\\varepsilon} \\sqrt{ \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t) }\\, dt \\,.\n\\] Since the above is true for each \\(\\varepsilon&gt;0\\), we infer \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) = \\dot{{\\pmb{\\gamma}}}(0) \\cdot \\dot{{\\pmb{\\gamma}}}(0) \\,.\n\\] Recall that by definition of differential we have \\[\ndf_{\\mathbf{p}} (\\mathbf{v}) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\,.\n\\] Therefore \\[\\begin{align*}\ndf_{\\mathbf{p}} (\\mathbf{v}) \\cdot df_{\\mathbf{p}} (\\mathbf{v}) & = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) \\\\\n                                    & = \\dot{{\\pmb{\\gamma}}}(0) \\cdot \\dot{{\\pmb{\\gamma}}}(0) \\\\\n                                    & = \\mathbf{v}\\cdot \\mathbf{v}\\,.\n\\end{align*}\\] As \\(\\mathbf{v}\\) was arbitrary, we showed that \\[\ndf_{\\mathbf{p}} (\\mathbf{v}) \\cdot df_{\\mathbf{p}} (\\mathbf{v}) = \\mathbf{v}\\cdot \\mathbf{v}\\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}}(\\mathcal{S}) \\,.  \n\\] Thanks to Remark 112 we conclude that \\(f\\) is a local isometry.\n\n\nWe have seen that local isometries preserve the length of curves. It also happen that they preserve the first fundamental form.\n\nTheorem 114\nLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) be a local diffeomorphism. They are equivalent:\n\n\\(f\\) is a local isometry.\nLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathcal{S}\\) be a regular chart of \\(\\mathcal{S}\\) and consider the chart of \\(\\widetilde{\\mathcal{S}}\\) given by\n\\[\n\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\colon U \\to \\widetilde{\\mathcal{S}} \\,.\n\\] Then \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) have the same first fundamental form, that is, \\[\nE = \\widetilde{E} \\,, \\quad F = \\widetilde{F} \\,, \\quad G = \\widetilde{G} \\,,\n\\] where \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u \\,, \\quad\nF = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\,, \\quad\nG = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v \\,, \\\\\n\\widetilde{E} & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_u \\,, \\quad\n\\widetilde{F}  = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_v \\,, \\quad\n\\widetilde{G}  = \\widetilde{{\\pmb{\\sigma}}}_v \\cdot \\widetilde{{\\pmb{\\sigma}}}_v \\,.\n\\end{align*}\\]\n\n\n\n\nProofPart 1. Suppose that \\(f\\) is a local isometry, that is, \\[\n{\\mathbf{v}} \\cdot {\\mathbf{w}} = d_{\\mathbf{p}} f ({\\mathbf{v}}) \\cdot d_{\\mathbf{p}} f ({\\mathbf{w}}) \\,, \\quad \\forall \\, {\\mathbf{v}} , {\\mathbf{w}} \\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] Let \\({\\pmb{\\sigma}}\\) be a chart for \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). Define \\(\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\). By Proposition 69, \\(\\widetilde{{\\pmb{\\sigma}}}\\) is a regualar chart of \\(\\widetilde{\\mathcal{S}}\\) at \\(f(\\mathbf{p})\\). Now, recall the statement of Proposition 83: if \\[\n\\widetilde{{\\pmb{\\sigma}}} ( \\alpha(u,v), \\beta(u,v) ) = f ( {\\pmb{\\sigma}}(u,v) ) \\,,\n\\] for some smooth maps \\[\n\\alpha,\\beta \\colon U \\to \\widetilde{U} \\,,\n\\] then the matrix of \\(d_{\\mathbf{p}} f\\) with respect to the basis \\[\n\\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\} \\,\\,\\, \\mbox{ of } \\,\\,\\, T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad  \n\\{ \\widetilde{{\\pmb{\\sigma}}}_u , \\widetilde{{\\pmb{\\sigma}}}_v \\} \\,\\,\\, \\mbox{ of } \\,\\,\\, T_{f(\\mathbf{p})} \\widetilde{\\mathcal{S}} \\,,\n\\] is given by \\[\nd_{\\mathbf{p}} f =\n\\left(\n\\begin{array}{cc}\n\\alpha_u & \\alpha_v \\\\\n\\beta_u  & \\beta_v\n\\end{array}\n\\right) \\,.\n\\] In our case, we have \\(U = \\widetilde{U}\\) and \\[\n\\widetilde{{\\pmb{\\sigma}}} (u, v ) = f ( {\\pmb{\\sigma}}(u,v) )\\,,\n\\] so that \\[\n\\alpha(u,v) = u \\,, \\quad\n\\beta(u,v) = v \\,.\n\\] Therefore \\[\nd_{\\mathbf{p}} f =\n\\left(\n\\begin{array}{cc}\n\\alpha_u & \\alpha_v \\\\\n\\beta_u  & \\beta_v\n\\end{array}\n\\right)\n=\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0  & 1\n\\end{array}\n\\right) \\,,\n\\] which means that \\[\\begin{align*}\nd_{\\mathbf{p}} f({\\pmb{\\sigma}}_u)  & = 1 \\cdot \\widetilde{{\\pmb{\\sigma}}}_u + 0 \\cdot \\widetilde{{\\pmb{\\sigma}}}_v = \\widetilde{{\\pmb{\\sigma}}}_u \\\\\nd_{\\mathbf{p}} f({\\pmb{\\sigma}}_v)  & = 0 \\cdot \\widetilde{{\\pmb{\\sigma}}}_u + 1 \\cdot \\widetilde{{\\pmb{\\sigma}}}_v = \\widetilde{{\\pmb{\\sigma}}}_v \\\\\n\\end{align*}\\] Usingg that \\(f\\) is a local isometry we get To this end, note that \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u\n    = d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_u) \\cdot d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_u) \\\\\n  & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_u\n    = \\widetilde{E} \\,.\n\\end{align*}\\] Simlarly, we obtain also \\[\\begin{align*}\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v\n    = d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_u) \\cdot d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_v) \\\\\n  & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_v\n    = \\widetilde{F} \\,,\n\\end{align*}\\] and \\[\\begin{align*}\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v\n    = d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_v) \\cdot d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_v) \\\\\n  & = \\widetilde{{\\pmb{\\sigma}}}_v \\cdot \\widetilde{{\\pmb{\\sigma}}}_v\n    = \\widetilde{G} \\,,\n\\end{align*}\\] showing that \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) have the same first fundamental form.\nPart 2. Define \\(\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\) and suppose that \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) have the same first fundamental form. In particular they hold \\[\\begin{align*}\n{\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_u \\\\\n{\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_v \\\\\n{\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v & = \\widetilde{{\\pmb{\\sigma}}}_v \\cdot \\widetilde{{\\pmb{\\sigma}}}_v\n\\end{align*}\\] As discussed above, since \\(\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\), by Proposition 83 we get \\[\nd_{\\mathbf{p}} f({\\pmb{\\sigma}}_u)  = \\widetilde{{\\pmb{\\sigma}}}_u \\,, \\quad\nd_{\\mathbf{p}} f({\\pmb{\\sigma}}_v)  = \\widetilde{{\\pmb{\\sigma}}}_v \\,.\n\\] Let \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) is a basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\) we get \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v\n\\] for some \\(\\lambda,\\mu \\in \\mathbb{R}\\). Therefore \\[\\begin{align*}\nd_{\\mathbf{p}} f (\\mathbf{v}) & = d_{\\mathbf{p}} f(\\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v ) \\\\\n                & = \\lambda \\, d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_u) + \\mu \\, d_{\\mathbf{p}} f ({\\pmb{\\sigma}}_v)\\\\\n                & = \\lambda \\widetilde{{\\pmb{\\sigma}}}_u + \\mu \\widetilde{{\\pmb{\\sigma}}}_v \\,.\n\\end{align*}\\] Hence \\[\\begin{align*}\n\\mathbf{v}\\cdot \\mathbf{v}& = ( \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v ) \\cdot  (\\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v) \\\\\n              & = \\lambda^2 ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v) + 2 \\lambda\\mu ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v) + \\mu^2 ({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v) \\\\\n              & = \\lambda^2 ( \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_u) +\n              2\\lambda \\mu ( \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_v) +\n              \\mu^2 ( \\widetilde{{\\pmb{\\sigma}}}_v \\cdot \\widetilde{{\\pmb{\\sigma}}}_v) \\\\\n              & = (\\lambda \\widetilde{{\\pmb{\\sigma}}}_u + \\mu \\widetilde{{\\pmb{\\sigma}}}_v)\n              \\cdot (\\lambda \\widetilde{{\\pmb{\\sigma}}}_u + \\mu \\widetilde{{\\pmb{\\sigma}}}_v) \\\\\n              & = d_{\\mathbf{p}} f (\\mathbf{v}) \\cdot\n                  d_{\\mathbf{p}} f (\\mathbf{v}) \\,,\n\\end{align*}\\] showing that \\[\n\\mathbf{v}\\cdot \\mathbf{v}= d_{\\mathbf{p}} f (\\mathbf{v}) \\cdot d_{\\mathbf{p}} f (\\mathbf{v})  \\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] By Remark 112 we conclude that \\(f\\) is a local isometry.\n\n\n\n\n4.11.4 Angles on surfaces\nWe want to define the notion of angle between tangent vectors.\n\nDefinition 115: Angle between tangent vectorsLet \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). The angle between two vectors \\(\\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\) is defined as the number \\(\\theta\\) such that \\[\n\\cos(\\theta) = \\frac{ \\mathbf{v}\\cdot \\mathbf{w}}{ \\| \\mathbf{v}\\| \\,  \\| \\mathbf{w}\\| } \\,.\n\\]\n\n\n\n\n\nSketch of angle \\(\\theta\\) between two vectors \\(\\mathbf{v},\\mathbf{w}\\) in \\(T_{\\mathbf{p}} \\mathcal{S}\\).\n\n\nThe angle between tangent vectors can be computed in terms of local charts.\n\nProposition 116Let \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\sigma}}\\) a regular chart at \\(\\mathbf{p}\\). Let \\(\\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Then \\[\n\\cos(\\theta) = \\frac{ E  \\lambda \\tilde \\lambda + F (  \\lambda {\\tilde \\mu}+ \\tilde \\lambda \\mu) + G  \\mu \\tilde \\mu }{ (E  \\lambda^2 + 2 F  \\lambda \\mu + G \\mu^2 )^{1/2} (E  \\tilde{\\lambda}^2 + 2 F  {\\tilde{\\lambda}} {\\tilde{\\mu}} + G {\\tilde{\\mu}}^2 )^{1/2} } \\,,\n\\] where \\(\\lambda,\\mu,\\tilde{\\lambda},\\tilde{\\mu} \\in \\mathbb{R}\\) are such that \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\,, \\quad  \n\\mathbf{w}= \\tilde{\\lambda} {\\pmb{\\sigma}}_u + \\tilde{\\mu} {\\pmb{\\sigma}}_v \\,.\n\\]\n\n\n\nProofBy definition the angle between \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) is \\[\n\\cos(\\theta) = \\frac{ \\mathbf{v}\\cdot \\mathbf{w}}{ \\| \\mathbf{v}\\| \\,  \\| \\mathbf{w}\\| } \\,.\n\\tag{4.6}\\] The vectors \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) form a basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Therefore \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\,, \\quad  \n\\mathbf{w}= \\tilde{\\lambda} {\\pmb{\\sigma}}_u + \\tilde{\\mu} {\\pmb{\\sigma}}_v \\,.\n\\] for some \\(\\lambda,\\mu,\\tilde{\\lambda},\\tilde{\\mu} \\in \\mathbb{R}\\). Hence, the coordinates of \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) with respect to the basis \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) are \\[\n\\mathbf{v}= (\\lambda , \\mu ) \\,, \\quad\n\\mathbf{w}= ({\\tilde{\\lambda}}  , {\\tilde{\\mu}} ) \\,.\n\\] By Proposition 103 we get \\[\\begin{align*}\n\\mathbf{v}\\cdot \\mathbf{w}& = I_{\\mathbf{p}}(\\mathbf{v},\\mathbf{w}) \\\\\n               & = (\\lambda , \\mu)\n               \\left(\n               \\begin{array}{cc}\n               E & F \\\\\n               F & G\n               \\end{array}\n               \\right)\n               ( \\tilde{\\lambda}  , \\tilde{\\mu} )^T \\\\\n               & =  E  \\lambda \\tilde \\lambda + F (  \\lambda {\\tilde \\mu}+ {\\tilde{\\lambda}} \\mu ) + G  \\mu  \\tilde \\mu \\,.\n\\end{align*}\\] Similarly, we obtain \\[\\begin{align*}\n\\| \\mathbf{v}\\|^2 & = \\mathbf{v}\\cdot \\mathbf{v}= E  {\\lambda}^2 + 2 F  \\lambda \\mu + G \\mu^2  \\\\\n\\| \\mathbf{w}\\|^2 & = \\mathbf{w}\\cdot \\mathbf{w}= E  \\tilde{\\lambda}^2 + 2 F  \\tilde{\\lambda} \\tilde{\\mu}  + G  \\tilde{\\mu}^2 \\,.  \n\\end{align*}\\] Substituting in (4.6) we conclude.\n\n\n\n\n4.11.5 Angle between curves\nSince tangent vectors are derivatives of curves with values in \\(\\mathcal{S}\\), it also makes sense to define the angle between two intersecting curves.\n\nDefinition 117: Angle between curvesLet \\(\\mathcal{S}\\) be a regular surface and suppose to have two curves \\[\n{\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\,, \\quad \\widetilde{{\\pmb{\\gamma}}}\\colon (\\tilde{a},\\tilde{b}) \\to \\mathcal{S}\n\\] such that \\[\n{\\pmb{\\gamma}}(t_0) = \\mathbf{p}\\,, \\quad \\widetilde{{\\pmb{\\gamma}}}( \\tilde{t}_0 ) = \\mathbf{p}\\,.\n\\] Then \\[\n\\dot{{\\pmb{\\gamma}}}(t_0) \\,, \\, \\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\tilde{t}_0 )  \\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] The angle \\(\\theta\\) between \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) is the angle between \\(\\dot{{\\pmb{\\gamma}}}(t_0)\\) and \\(\\dot{\\widetilde{{\\pmb{\\gamma}}}}( \\tilde{t}_0 )\\), that is, \\[\n\\cos(\\theta) = \\frac{ \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}}{ \\| \\dot{{\\pmb{\\gamma}}}\\| \\,  \\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}\\| } \\,,\n\\] where \\(\\widetilde{{\\pmb{\\gamma}}}\\) is evaluated at \\(t_0\\) and \\(\\dot{\\widetilde{{\\pmb{\\gamma}}}}\\) at \\(\\tilde{t}_0\\).\n\n\n\n\n\nSketch of angle \\(\\theta\\) between two curves \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) on \\(\\mathcal{S}\\).\n\n\n\nProposition 118Let \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\sigma}}\\) a regular chart at \\(\\mathbf{p}\\). Suppose given two curves \\[\n{\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\,, \\quad \\widetilde{{\\pmb{\\gamma}}}\\colon (\\tilde{a},\\tilde{b}) \\to \\mathcal{S}\n\\] such that \\[\n{\\pmb{\\gamma}}(t_0) = \\mathbf{p}\\,, \\quad \\widetilde{{\\pmb{\\gamma}}}( \\tilde{t}_0 ) = \\mathbf{p}\\,.\n\\] The angle between \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) is \\[\n\\cos(\\theta) = \\frac{ E  \\dot u \\dot{\\tilde u} + F ( \\dot u \\dot{\\tilde v}+ \\dot{\\tilde{u}} \\dot v) + G \\dot v \\dot{\\tilde v} }{ (E  \\dot{u}^2 + 2 F  \\dot u \\dot v + G \\dot{v}^2 )^{1/2} (E  \\dot{\\tilde{u}}^2 + 2 F  \\dot{\\tilde{u}} \\dot{\\tilde{v}} + G \\dot{\\tilde{v}}^2 )^{1/2} } \\,,\n\\] where \\(u,v,\\tilde{u},\\tilde{v}\\) are smooth functions such that \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}(u(t),v(t)) \\,, \\quad\n\\widetilde{{\\pmb{\\gamma}}}(t) = {\\pmb{\\sigma}}(\\tilde{u}(t),\\tilde{v}(t)) \\,.\n\\]\n\n\n\nProofBy definition the angle between \\({\\pmb{\\gamma}}\\) and \\(\\widetilde{{\\pmb{\\gamma}}}\\) is \\[\n\\cos(\\theta) = \\frac{ \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}}{ \\| \\dot{{\\pmb{\\gamma}}}\\| \\,  \\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}\\| } \\,.\n\\tag{4.7}\\] As \\({\\pmb{\\gamma}}, \\widetilde{{\\pmb{\\gamma}}}\\) are smooth curves with values in \\(\\mathcal{S}\\), by Lemma 74 there exist smooth functions \\(u,v,\\tilde{u},\\tilde{v}\\) such that \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}(u(t),v(t)) \\,, \\quad\n\\widetilde{{\\pmb{\\gamma}}}(t) = {\\pmb{\\sigma}}(\\tilde{u}(t),\\tilde{v}(t)) \\,.\n\\] Differentiating the above expressions we obtain \\[\n\\dot{{\\pmb{\\gamma}}}= \\dot u {\\pmb{\\sigma}}_u + \\dot v {\\pmb{\\sigma}}_v \\,, \\quad\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}= \\dot{\\tilde{u}} {\\pmb{\\sigma}}_u + \\dot{\\tilde{v}} {\\pmb{\\sigma}}_v \\,.\n\\] Therefore the coordinates of \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\dot{\\widetilde{{\\pmb{\\gamma}}}}\\) with respect to the basis \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) of \\(T_{\\mathbf{p}} \\mathcal{S}\\) are \\[\n\\dot{{\\pmb{\\gamma}}}= (\\dot u , \\dot v) \\,, \\quad\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}= (\\dot{\\tilde{u}}  , \\dot{\\tilde{v}} ) \\,.\n\\] By Proposition 103 we get \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}\\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}& = I_{\\mathbf{p}}(\\dot{{\\pmb{\\gamma}}},\\dot{\\widetilde{{\\pmb{\\gamma}}}}) \\\\\n               & = (\\dot u , \\dot v)\n               \\left(\n               \\begin{array}{cc}\n               E & F \\\\\n               F & G\n               \\end{array}\n               \\right)\n               (\\dot{\\tilde{u}}  , \\dot{\\tilde{v}} )^T \\\\\n               & =  E  \\dot u \\dot{\\tilde u} + F ( \\dot u \\dot{\\tilde v}+ \\dot{\\tilde{u}} \\dot v) + G \\dot v \\dot{\\tilde v} \\,.\n\\end{align*}\\] Similarly, we obtain \\[\\begin{align*}\n\\| \\dot{{\\pmb{\\gamma}}}\\|^2 & = \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}= E  \\dot{u}^2 + 2 F  \\dot u \\dot v + G \\dot{v}^2  \\\\\n\\| \\dot{\\widetilde{{\\pmb{\\gamma}}}}\\|^2 & = \\dot{\\widetilde{{\\pmb{\\gamma}}}}\\cdot \\dot{\\widetilde{{\\pmb{\\gamma}}}}= E  \\dot{\\tilde{u}}^2 + 2 F  \\dot{\\tilde{u}} \\dot{\\tilde{v}}  + G \\dot{\\tilde{v}}^2 \\,.  \n\\end{align*}\\] Substituting in (4.7) we conclude.\n\n\n\n\n4.11.6 Conformal maps\nLocal isometries are maps which preserve the scalar product of tangent vectors. We want to consider maps which preserve the angle of tangent vectors. These will be called conformal maps.\n\nDefinition 119: Conformal mapLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces. A local diffeomorphism \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) is a conformal mapping if for all \\(\\mathbf{p}\\in \\mathcal{S}\\) and \\(\\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\) is holds \\[\n\\theta = \\tilde{\\theta} \\,,\n\\] with \\(\\theta\\), \\(\\tilde{\\theta}\\) the angles between \\(\\mathbf{v}, \\mathbf{w}\\) and \\(d_{\\mathbf{p}} f(\\mathbf{v})\\), \\(d_{\\mathbf{p}} f(\\mathbf{w})\\), respectively.\n\n\n\n\n\nSketch of conformal map \\(f\\) between \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\). The angles between tangent vectors are preserved by \\(d_{\\mathbf{p}} f\\).\n\n\n\nRemark 120\nWe have that \\(f\\) is a conformal map if and only if \\[\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle }{ \\| \\mathbf{v}\\| \\, \\| \\mathbf{w}\\| } =\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f  }{ \\| \\mathbf{v}\\|_f \\, \\| \\mathbf{w}\\|_f } \\,, \\quad \\forall \\, \\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nThis follows immediately by the definition of angle between tangent vectors.\n\n\n\n\nProposition 121Let \\(f\\) be a local isometry. Then \\(f\\) is a conformal map.\n\n\n\nProofBy definition of local isometry we have \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle =  \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f  \\,, \\quad \\forall \\, \\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] In particular we have \\[\n\\| \\mathbf{v}\\|^2  = \\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle\n             = \\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle_f\n             = \\| \\mathbf{v}\\|^2_f \\,,\n\\] for all \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Therefore \\[\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle }{ \\| \\mathbf{v}\\| \\, \\| \\mathbf{w}\\| } =\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f }{ \\| \\mathbf{v}\\|_f \\, \\| \\mathbf{w}\\|_f } \\,,\n\\] showing that \\(f\\) is a conformal map.\n\n\nTherefore every local isometry is a conformal map. The converse is false, as we will show in Example 124 below. Before giving the example, let us provide a characterization of conformal maps in terms of the first fundamental form.\n\nTheorem 122\nLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) a local diffeomorphism. They are equivalent:\n\n\\(f\\) is a conformal map.\nThere exists a function \\(\\lambda \\colon \\mathcal{S}\\to \\mathbb{R}\\) such that \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f =  \\lambda (\\mathbf{p}) \\, \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle \\,, \\quad \\forall \\, \\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\n\n\n\nProofStep 1. Suppose \\(f\\) is a conformal map, so that \\[\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle }{ \\| \\mathbf{v}\\| \\, \\| \\mathbf{w}\\| } =\n\\frac{ \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f }{ \\| \\mathbf{v}\\|_f \\, \\| \\mathbf{w}\\|_f } \\,, \\quad \\forall \\, \\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\tag{4.8}\\] Let \\(\\{\\pmb{\\alpha}_1,\\pmb{\\alpha}_2\\}\\) be an orthonormal basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\), that is, \\[\n\\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2 \\right\\rangle = 0 \\,, \\quad\n\\| \\pmb{\\alpha}_1  \\| = \\| \\pmb{\\alpha}_2 \\| = 1 \\,.\n\\] Define \\[\\begin{align*}\n\\lambda(\\mathbf{p}) & := \\left\\langle \\pmb{\\alpha_1},\\pmb{\\alpha_1} \\right\\rangle_f = \\| \\pmb{\\alpha_1} \\|_f^2 \\,, \\\\\n\\mu(\\mathbf{p}) & := \\left\\langle \\pmb{\\alpha_1},\\pmb{\\alpha_2} \\right\\rangle_f \\,, \\\\\n\\nu(\\mathbf{p}) & := \\left\\langle \\pmb{\\alpha_2},\\pmb{\\alpha_2} \\right\\rangle_f = \\| \\pmb{\\alpha_2} \\|_f^2   \\,.\n\\end{align*}\\] By (4.8) we have \\[\n\\frac{\\left\\langle \\pmb{\\alpha_1},\\pmb{\\alpha_2} \\right\\rangle}{ \\| \\pmb{\\alpha_1} \\| \\| \\pmb{\\alpha_2} \\|  } =\n\\frac{\\left\\langle \\pmb{\\alpha_1},\\pmb{\\alpha_2} \\right\\rangle_f}{ \\| \\pmb{\\alpha_1} \\|_f \\| \\pmb{\\alpha_2} \\|_f  } \\,.\n\\] Since \\(\\pmb{\\alpha}_1 \\cdot \\pmb{\\alpha}_2 = 0\\), from the above we get \\[\n\\mu (\\mathbf{p}) = \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2  \\right\\rangle_f = 0 \\,.\n\\] Moreover, since \\(\\pmb{\\alpha}_1\\) and \\(\\pmb{\\alpha}_2\\) are orthonormal, the angle between \\(\\pmb{\\alpha}_1\\) and \\(\\pmb{\\alpha}_1 + \\pmb{\\alpha}_2\\) is \\(\\theta = \\pi/4\\). By definition of angle between vectors, we infer \\[\n\\frac{\\sqrt{2}}{2} = \\cos (\\theta) = \\frac{ \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\right\\rangle  }{ \\| \\pmb{\\alpha}_1 \\| \\| \\pmb{\\alpha}_1 + \\pmb{\\alpha}_1 \\| } \\,.\n\\] On the other hand, using (4.8) we get \\[\n\\frac{ \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\right\\rangle  }{ \\| \\pmb{\\alpha}_1 \\| \\| \\pmb{\\alpha}_1 + \\pmb{\\alpha}_1 \\| } =\n\\frac{ \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\right\\rangle_f  }{ \\| \\pmb{\\alpha}_1 \\|_f \\| \\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\|_f } \\,.\n\\] The numerator of the right hand side satisfies \\[\\begin{align*}\n\\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\right\\rangle_f &\n=  \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1  \\right\\rangle_f +  \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2 \\right\\rangle_f  \\\\\n& = \\lambda(\\mathbf{p}) + \\mu (\\mathbf{p}) \\\\\n& = \\lambda(\\mathbf{p}) \\,,\n\\end{align*}\\] since \\(\\mu (\\mathbf{p}) = 0\\). Concerning the denominator, we have \\[\\begin{align*}\n\\| \\pmb{\\alpha}_1 + \\pmb{\\alpha}_2 \\|_f^2 & =\n\\| \\pmb{\\alpha}_1  \\|_f^2 + \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2 \\right\\rangle_f  +\n\\| \\pmb{\\alpha}_2 \\|_f^2 \\\\\n& = \\lambda(\\mathbf{p}) + \\mu(\\mathbf{p}) + \\nu (\\mathbf{p}) \\\\\n& = \\lambda(\\mathbf{p}) + \\nu (\\mathbf{p})  \\,,\n\\end{align*}\\] since \\(\\mu (\\mathbf{p}) = 0\\). Putting together the last 4 groups of equations, we obtain \\[\n\\frac{\\sqrt{2}}{2} = \\frac{ \\lambda }{ \\lambda^{1/2} (\\lambda + \\nu)^{1/2} } \\,.\n\\] Rearraging the above equation yields \\[\n\\lambda (\\mathbf{p}) = \\nu (\\mathbf{p}) \\,.\n\\] Now let \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\{ \\pmb{\\alpha}_1, \\pmb{\\alpha}_2\\}\\) is a basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\), there exist \\(v_1,v_2 \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= v_1 \\pmb{\\alpha}_1 + v_2 \\pmb{\\alpha}_2 \\,.\n\\] Therefore \\[\\begin{align*}\n\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle & = v_1^2 \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 \\right\\rangle +\n                2 v_1 v_2 \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2 \\right\\rangle +\n                v_2^2 \\left\\langle \\pmb{\\alpha}_2,\\pmb{\\alpha}_2 \\right\\rangle \\\\\n                & = v_1^2 + v_2^2 \\,,\n\\end{align*}\\] where we used that \\(\\pmb{\\alpha}_1\\) and \\(\\pmb{\\alpha}_2\\) are orthonormal. On the other hand, \\[\\begin{align*}\n\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle_f & = v_1^2 \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_1 \\right\\rangle_f +\n                2 v_1 v_2 \\left\\langle \\pmb{\\alpha}_1,\\pmb{\\alpha}_2 \\right\\rangle_f +\n                v_2^2 \\left\\langle \\pmb{\\alpha}_2,\\pmb{\\alpha}_2 \\right\\rangle_f \\\\\n               & = v_1^2 \\, \\lambda(\\mathbf{p}) +\n                2 v_1 v_2 \\, \\mu(\\mathbf{p}) +\n                v_2^2 \\, \\nu(\\mathbf{p}) \\\\\n                & =  \\lambda(\\mathbf{p}) \\, (v_1^2 + v_2^2) \\,,\n\\end{align*}\\] where we used that \\(\\lambda(\\mathbf{p}) = \\nu(\\mathbf{p})\\) and \\(\\mu (\\mathbf{p}) = 0\\). Thus \\[\n\\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle_f = \\lambda(\\mathbf{p}) \\, (v_1^2 + v_2^2) =\\lambda(\\mathbf{p}) \\, \\left\\langle \\mathbf{v},\\mathbf{v} \\right\\rangle \\,,\n\\] for all \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\left\\langle \\cdot,\\cdot \\right\\rangle\\) and \\(\\left\\langle \\cdot,\\cdot \\right\\rangle_f\\), by arguing as in Remark 112 we conclude that \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f = \\lambda(\\mathbf{p}) \\, \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle  \n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\).\nStep 2. Suppose that there exists a function \\(\\lambda \\colon \\mathcal{S}\\to \\mathbb{R}\\) such that \\[\n\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f =  \\lambda (\\mathbf{p}) \\, \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle \\,, \\quad \\forall \\, \\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] In particular, we have \\[\n\\| \\mathbf{v}\\|_f  = \\sqrt{\\lambda(\\mathbf{p})} \\| \\mathbf{v}\\| \\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] Then \\[\n\\frac{\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle_f}{ \\| \\mathbf{v}\\|_f  \\| \\mathbf{w}\\|_f } =\n\\frac{\\lambda (\\mathbf{p}) \\, \\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle}{  \\sqrt{\\lambda(\\mathbf{p})} \\| \\mathbf{v}\\|  \\sqrt{\\lambda(\\mathbf{p})} \\| \\mathbf{w}\\| }  =\n\\frac{\\left\\langle \\mathbf{v},\\mathbf{w} \\right\\rangle}{ \\| \\mathbf{v}\\|  \\| \\mathbf{w}\\| }  \\,,\n\\] showing that \\(f\\) is a conformal map.\n\n\n\nCorollary 123\nLet \\(\\mathcal{S}\\) and \\(\\widetilde{\\mathcal{S}}\\) be regular surfaces and \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) be a local diffeomorphism. They are equivalent:\n\n\\(f\\) is a conformal map.\nLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathcal{S}\\) be a regular chart of \\(\\mathcal{S}\\) and consider the chart of \\(\\widetilde{\\mathcal{S}}\\) given by \\[\n\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\colon U \\to \\widetilde{\\mathcal{S}} \\,.\n\\] There exists \\(\\lambda \\colon U \\to \\mathbb{R}\\) such that \\[\n\\widetilde{\\mathscr{F}}_1 = \\lambda (u,v) \\mathscr{F}_1 \\,, \\quad \\forall \\, (u,v) \\in U \\,,\n\\] where \\(\\mathscr{F}_1\\) and \\(\\widetilde{\\mathscr{F}}_1\\) are the first fundamental forms of \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\), respectively.\n\n\n\nThe follows by using Theorem 122, and by adapting the argument in the proof of Theorem 114.\n\nExample 124: Conformal maps are not local isometries\nConsider the plane \\(\\mathcal{S}\\) with chart \\[\n{\\pmb{\\sigma}}(u,v) := (u,v,0) \\,.\n\\] Let \\(\\widetilde{\\mathcal{S}}\\) be the sphere with parametrization \\[\n\\widetilde{{\\pmb{\\sigma}}}(u,v) := \\left(  \\mathop{\\mathrm{sech}}(u) \\cos(v), \\mathop{\\mathrm{sech}}(u) \\sin(v) , \\tanh (u) \\right) \\,.\n\\] We have \\[\n{\\pmb{\\sigma}}_u = (1,0,0) \\,, \\quad\n{\\pmb{\\sigma}}_v = (0,1,0) \\,,\n\\] so that \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u =  1 \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v =  0 \\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v =  1 \\\\\n\\end{align*}\\] Therefore the first fundamental form of \\(\\mathcal{S}\\) is \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\] Using the identitities \\[\\begin{align*}\n\\frac{d}{du} \\left( \\mathop{\\mathrm{sech}}(u)  \\right) & = - \\mathop{\\mathrm{sech}}(u) \\tanh (u) \\,, \\\\\n\\frac{d}{du} \\left( \\tanh (u) \\right)  & = {\\mathop{\\mathrm{sech}}}^2 (u) \\,,\n\\end{align*}\\] we obtain \\[\\begin{align*}\n\\widetilde{{\\pmb{\\sigma}}}_u & = ( -\\mathop{\\mathrm{sech}}(u) \\tanh(u) \\cos(v), -\\mathop{\\mathrm{sech}}(u) \\tanh(u) \\sin(v), {\\mathop{\\mathrm{sech}}}^2(u) ) \\\\\n\\widetilde{{\\pmb{\\sigma}}}_v & = ( -\\mathop{\\mathrm{sech}}(u) \\sin(v), \\mathop{\\mathrm{sech}}(u) \\cos(v), 0 )\n\\end{align*}\\] By recalling that \\[\n{\\mathop{\\mathrm{sech}}}^2 (u) + {\\tanh}^2 (u) = 1 \\,,\n\\] we compute \\[\\begin{align*}\n\\widetilde{E} & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_u = {\\mathop{\\mathrm{sech}}}^2(u) ({\\tanh}^2(u) + {\\mathop{\\mathrm{sech}}}^2(u)) = {\\mathop{\\mathrm{sech}}}^2(u) \\\\\n\\widetilde{F} & = \\widetilde{{\\pmb{\\sigma}}}_u \\cdot \\widetilde{{\\pmb{\\sigma}}}_v =  0 \\\\\n\\widetilde{G} & = \\widetilde{{\\pmb{\\sigma}}}_v \\cdot \\widetilde{{\\pmb{\\sigma}}}_v =  {\\mathop{\\mathrm{sech}}}^2(u) (\\cos^2(v) + \\sin^2(v)) = {\\mathop{\\mathrm{sech}}}^2(u) \\\\\n\\end{align*}\\] Hence the first fundamental form of \\(\\widetilde{\\mathcal{S}}\\) is \\[\n\\widetilde{\\mathscr{F}}_1 = {\\mathop{\\mathrm{sech}}}^2(u) \\, \\left(  du^2 + dv^2 \\right) \\,.\n\\] Now, consider the map \\(f \\colon \\mathcal{S}\\to \\widetilde{\\mathcal{S}}\\) defined by \\[\nf(u,v,0) = \\widetilde{{\\pmb{\\sigma}}} (u,v) \\,.\n\\] In particular \\(f\\) satisfies \\[\nf( {\\pmb{\\sigma}}( u,v) ) = \\widetilde{{\\pmb{\\sigma}}} (u,v) \\,.\n\\] We have:\n\n\\(f\\) is not a local isometry.\n\n\nIf \\(f\\) was a local isometry, by Theorem 114 we would conclude that \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\) have the same first fundamental form. However \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\neq {\\mathop{\\mathrm{sech}}}^2(u) \\, \\left(  du^2 + dv^2 \\right)\n= \\widetilde{\\mathscr{F}}_1  \\,.\n\\]\n\n\n\\(f\\) is a conformal map.\n\n\nThe first fundamental forms of \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}} = f \\circ {\\pmb{\\sigma}}\\) satisfy \\[\n\\widetilde{\\mathscr{F}}_1  = \\lambda(u,v) \\, \\mathscr{F}_1  \\,, \\quad\n\\lambda(u,v) := {\\mathop{\\mathrm{sech}}}(u) \\,.\n\\] Therefore \\(f\\) is a conformal map by Corollary 123.\n\n\n\n\n\n4.11.7 Conformal parametrizations\nWe conclude this section with the definition of conformally flat surface and conformal parametrization.\n\nDefinition 125: Conformally flat surface and conformal parametrizationLet \\(\\mathcal{S}\\) be a regular surface and \\[\n{\\pmb{\\sigma}}\\colon U  \\to  \\mathcal{S}\n\\] be a regular chart of \\(\\mathcal{S}\\). We say that \\(\\mathcal{S}\\) is conformally flat and \\({\\pmb{\\sigma}}\\) is a conformal parametrization if the first fundamental form of \\({\\pmb{\\sigma}}\\) satisfies \\[\n\\mathscr{F}_1 = \\lambda(u,v)  ( du^2 +  dv^2)\n\\] for some smooth function \\(\\lambda \\colon U \\to \\mathbb{R}\\).\n\n\nDefinition 125 is motivated by the following Theorem: It states that angles on conformally flat surfaces look like angles on a plane.\n\nTheorem 126\nLet \\(\\mathcal{S}\\) be a regular surface and \\[\n{\\pmb{\\sigma}}\\colon U  \\to  {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\n\\] be a regular chart of \\(\\mathcal{S}\\). Define the plane \\({\\pmb{\\pi}}\\) charted by \\[\n\\widetilde{{\\pmb{\\sigma}}} (u,v) = (u,v,0) \\,, \\quad \\forall \\, (u,v) \\in U \\,.\n\\]\n\nThey are equivalent:\n\n\\({\\pmb{\\sigma}}\\) is a conformal parametrization.\nThere exists a conformal map \\(f \\colon \\pi \\to {\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\).\n\nA conformal parametrization \\({\\pmb{\\sigma}}\\) preserves angles between vectors, in the following sense: Suppose \\({\\pmb{\\gamma}}_1, {\\pmb{\\gamma}}_2\\) are curves in \\(\\mathbb{R}^{2}\\) such that \\[\n{\\pmb{\\gamma}}_1 (t_0) = {\\pmb{\\gamma}}_2 (t_0) \\,.\n\\] Consider the corresponding curves on \\(\\mathcal{S}\\) given by \\[\n\\widetilde{{\\pmb{\\gamma}}}_1 := {\\pmb{\\sigma}}\\circ {\\pmb{\\gamma}}_1 \\,, \\quad \\widetilde{{\\pmb{\\gamma}}}_2 = {\\pmb{\\sigma}}\\circ {\\pmb{\\gamma}}_2 \\,.\n\\] If \\[\n\\dot{{\\pmb{\\gamma}}}_1 (t_0) \\,, \\dot{{\\pmb{\\gamma}}}_2(t_0) \\,\\, \\mbox{ form an angle } \\,\\, \\theta \\,,\n\\] then \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}_1 (t_0) \\,, \\dot{\\widetilde{{\\pmb{\\gamma}}}}_2(t_0) \\,\\, \\mbox{ form an angle } \\,\\, \\theta \\,.\n\\]\n\n\n\n\nProofProof of Point 1. Define the diffeomorphism \\(f \\colon {\\pmb{\\pi}}\\to \\mathcal{S}\\) by \\[\nf(u,v,0) = {\\pmb{\\sigma}}(u,v) \\,.\n\\] In particular \\[\nf( \\widetilde{{\\pmb{\\sigma}}}(u,v) ) = {\\pmb{\\sigma}}(u,v) \\,.\n\\] By Corollary 123 we have that \\(f\\) is a conformal map if and only if there exists \\(\\lambda \\colon {\\pmb{\\pi}}\\to \\mathbb{R}\\) such that \\[\n\\mathscr{F}_1 = \\lambda(u,v) \\widetilde{\\mathscr{F}}_1  \\,,\n\\] where \\(\\mathscr{F}_1\\) and \\(\\widetilde{\\mathscr{F}}_1\\) are the first fundamental forms of \\(\\mathcal{S}\\) and \\({\\pmb{\\pi}}\\), respectively. Since \\({\\pmb{\\pi}}\\) is a plane, the first fundamental form is given by \\[\n\\widetilde{\\mathscr{F}}_1 = du^2 + dv^2 \\,.\n\\] Therefore \\[\n\\mathscr{F}_1 = \\lambda(u,v) \\left(   du^2 + dv^2   \\right)\\,,\n\\] showing that \\({\\pmb{\\sigma}}\\) is a conformal parametrization.\nProof of Point 2. Suppose \\({\\pmb{\\sigma}}\\) is a conformal parametrization. By the proof of Point 1 we have that \\[\nf \\colon \\pi \\to \\mathcal{S}\\,, \\quad f(u,v,0) = {\\pmb{\\sigma}}(u,v) \\,,\n\\] is a conformal map. Since \\(T_{\\mathbf{p}} \\pi = \\mathbb{R}^2\\) and \\(f = {\\pmb{\\sigma}}\\), it follows by the definition of differential and \\(f\\) being conformal that the angle between \\({\\pmb{\\gamma}}_1\\) and \\({\\pmb{\\gamma}}_2\\) is the same as the angle between \\(\\widetilde{{\\pmb{\\gamma}}}_1\\) and \\(\\widetilde{{\\pmb{\\gamma}}}_2\\).\n\n\n\nExample 127: Unit cylinderThe cylinder \\(\\mathcal{S}\\) charted by \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u), v)\n\\] is conformally flat, since the first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\] Therefore \\({\\pmb{\\sigma}}\\) is a conformal parametrization of \\(\\mathcal{S}\\).\n\n\n\nExample 128: ShpereConsider the parametrization of the sphere \\[\n{\\pmb{\\sigma}}(u,v) = \\left(  \\mathop{\\mathrm{sech}}(u) \\cos(v), \\mathop{\\mathrm{sech}}(u) \\sin(v) , \\tanh (u) \\right) \\,.\n\\] In Example 124 we have seen that the first fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_1  = {\\mathop{\\mathrm{sech}}}(u) \\, ( du^2 + dv^2 )  \\,.\n\\] Therefore \\({\\pmb{\\sigma}}\\) is a conformal parametrization of the sphere.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#second-fudamental-form",
    "href": "sections/chap_4.html#second-fudamental-form",
    "title": "4  Surfaces",
    "section": "4.12 Second fudamental form",
    "text": "4.12 Second fudamental form\nThe first fundamental form allows to measure distances on a surface. However it does not give any information on how curved a surface is: For example, we saw that a plane and a cylinder have the same first fundamental form \\[\n\\mathscr{F}_1 = du^2 + dv^2 \\,.\n\\] However the plane is flat, while the cylinder curves. We would like to find a measure of curvature which allows us to tell these two surfaces apart.\n\n4.12.1 Unit normal and orientability\nBefore talking about curvatures, we need to clarify what we mean by normal vector to a surface and orientability. Let \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). The tangent plane \\(T_{\\mathbf{p}} \\mathcal{S}\\) passes through the origin. Therefore \\(T_{\\mathbf{p}} \\mathcal{S}\\) is completely determined by giving a unit vector \\(\\mathbf{N}\\) perpendicular to it: \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\{ \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\,\\mathbf{x}\\cdot \\mathbf{N}= 0 \\} \\,.\n\\] In this case we write \\[\n\\mathbf{N}\\perp T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] to denote that \\(\\mathbf{N}\\) is perpendicular to \\(T_{\\mathbf{p}} \\mathcal{S}\\). Clearly, also \\(-\\mathbf{N}\\) is a unit vector, and \\[\n(- \\mathbf{N}) \\perp T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nQuestion 129Which unit normal should we choose between \\(\\mathbf{N}\\) and \\(-\\mathbf{N}\\)?\n\n\nThere is no right answer to the above question. One way to proceed is the following.\n\nRemark 130Suppose that \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) is a regular chart for \\(\\mathcal{S}\\). Let \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\). Then \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\} \\,.\n\\] Therefore we can choose the unit normal to \\(T_{\\mathbf{p}} \\mathcal{S}\\) as \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} :=  \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\|  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } \\,.\n\\] Clearly \\(\\mathbf{N}_{{\\pmb{\\sigma}}}\\) has unit norm. Moreover \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} \\cdot {\\pmb{\\sigma}}_u = 0 \\,, \\quad \\mathbf{N}_{{\\pmb{\\sigma}}} \\cdot {\\pmb{\\sigma}}_v = 0\n\\] by the properties of cross product, showing that \\(\\mathbf{N}_{{\\pmb{\\sigma}}}\\) is perpendicular to \\(T_{\\mathbf{p}} \\mathcal{S}\\).\nThere is however an issue: \\(\\mathbf{N}_{{\\pmb{\\sigma}}}\\) is not independent on the choice of chart \\({\\pmb{\\sigma}}\\). Indeed, suppose that \\(\\widetilde{{\\pmb{\\sigma}}} \\colon  \\widetilde{U} \\to \\mathbb{R}^3\\) is a reparametrization of \\({\\pmb{\\sigma}}\\), that is, \\[\n\\widetilde{{\\pmb{\\sigma}}} = {\\pmb{\\sigma}}\\circ \\Phi \\,, \\quad \\Phi \\colon \\widetilde{U} \\to U \\,,\n\\] with \\(\\Phi\\) diffeomorphism. As shown in the proof of Proposition 61, we have \\[\n\\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}}\n= \\det (J\\Phi)  \\, {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\,.\n\\] Hence \\[\n\\mathbf{N}_{\\widetilde{{\\pmb{\\sigma}}}} = \\frac{ \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} }{\\left\\| \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} \\right\\|} = \\frac{\\det J\\Phi}{|\\det J\\Phi|} \\frac{{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v}{\\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\|} = \\pm \\mathbf{N}_{{\\pmb{\\sigma}}} \\,.\n\\] Therefore the sign on the right hand side depends on the sign of the Jacobian determinant of the transition map \\(\\Phi\\).\n\n\nThe above remark motivates the following definitions.\n\nDefinition 131: Standard unit normal of a chartLet \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) a regular chart. The standard unit normal of \\({\\pmb{\\sigma}}\\) is the smooth function \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} \\colon U \\to \\mathbb{R}^3 \\,, \\quad \\mathbf{N}_{{\\pmb{\\sigma}}} := \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| } \\,.\n\\]\n\n\n\nDefinition 132: Charts with same orientation\nLet \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\), \\(\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\mathbb{R}^3\\) regular charts such that \\[\n{\\pmb{\\sigma}}(U) \\cap \\widetilde{{\\pmb{\\sigma}}} (\\widetilde{U}) \\neq \\emptyset \\,.\n\\] Denote by \\(\\Phi\\) the transition map between \\(\\widetilde{{\\pmb{\\sigma}}}\\) and \\({\\pmb{\\sigma}}\\). We say that:\n\n\\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) determine the same orientation if \\[\n\\det J \\Phi &gt; 0 \\,,\n\\] where \\(\\Phi\\) is defined.\n\\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) determine opposite orientations if \\[\n\\det J \\Phi &lt; 0 \\,,\n\\] where \\(\\Phi\\) is defined.\n\n\n\n\nExample 133Let \\(\\mathbf{a} , \\mathbf{p},\\mathbf{q} \\in \\mathbb{R}^3\\) and suppose that \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) are linearly independent. The plane spanned by \\(\\mathbf{p},\\mathbf{q}\\) and passing through \\(\\mathbf{a}\\) can be parametrized by \\[\n{\\pmb{\\sigma}}(u,v):= \\mathbf{a} + \\mathbf{p}u + \\mathbf{q} v \\,, \\quad \\forall \\, (u,v) \\in \\mathbb{R}^2 \\,.\n\\] An alternative parametrization is given by \\[\n\\widetilde{{\\pmb{\\sigma}}} (u,v):= \\mathbf{a}  + \\mathbf{q} u + \\mathbf{p}v  \\,, \\quad \\forall \\, (u,v) \\in \\mathbb{R}^2 \\,.\n\\] We have \\[\n{\\pmb{\\sigma}}_u = \\mathbf{p}\\,, \\quad\n{\\pmb{\\sigma}}_v = \\mathbf{q} \\,, \\quad\n\\] and therefore \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} = \\frac{ \\mathbf{p}\\times \\mathbf{q}  }{ \\left\\|  \\mathbf{p}\\times \\mathbf{q}  \\right\\| } \\,.\n\\] Similarly, we have \\[\n\\mathbf{N}_{\\widetilde{{\\pmb{\\sigma}}}} = \\frac{ \\mathbf{q} \\times \\mathbf{p}}{ \\left\\|  \\mathbf{q} \\times \\mathbf{p} \\right\\| } =\n\\frac{ - \\mathbf{p}\\times \\mathbf{q}  }{ \\left\\|  \\mathbf{p}\\times \\mathbf{q}   \\right\\| } \\,,\n\\] showing that \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} = - \\mathbf{N}_{\\widetilde{{\\pmb{\\sigma}}}} \\,.\n\\] Hence \\({\\pmb{\\sigma}}\\) and \\(\\tilde{{\\pmb{\\sigma}}}\\) determine opposite orientations.\n\n\nIf a surface can be covered by charts with the same orientation, it is called orientable.\n\nDefinition 134: Orientable surface\nLet \\(\\mathcal{S}\\) be a regular surface. Then:\n\nAn atlas \\(\\mathcal{A} = \\{ {\\pmb{\\sigma}}_i \\}_{i \\in I}\\) is oriented if the following property holds: \\[\n{\\pmb{\\sigma}}_i (U_i) \\cap {\\pmb{\\sigma}}_j (U_j) \\neq \\emptyset \\quad \\implies \\quad\n\\det J \\Phi &gt; 0 \\,,\n\\] where \\(\\Phi\\) is the transition map between \\({\\pmb{\\sigma}}_i\\) and \\({\\pmb{\\sigma}}_j\\).\n\\(\\mathcal{S}\\) is orientable if there exists an oriented atlas \\(\\mathcal{A}\\).\nIf an oriented atlas \\(\\mathcal{A}\\) is assigned, we say that \\(\\mathcal{S}\\) is oriented by \\(\\mathcal{A}\\).\n\n\n\n\nExample 135All the surfaces we encountered in these Lecture Notes are orientable, except for the Möbius band in Example 95. Details about the non-orientability of the Möbius band can be found in Example 4.5.3 in (Pressley 2010).\n\n\n\nExample 136\nLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart. Then \\[\n\\mathcal{S}_{{\\pmb{\\sigma}}} := {\\pmb{\\sigma}}(U)\n\\] is a regular surface with atlas \\(\\mathcal{A}=\\{{\\pmb{\\sigma}}\\}\\). Therefore \\(\\mathcal{S}_{{\\pmb{\\sigma}}}\\) is orientable.\n\nThis is because we have only one chart. Therefore any transition map \\(\\Phi\\) will be the identity, so that \\(\\det J \\Phi = 1 &gt; 0\\).\n\n\n\n\nWarning: Orientability is a global propertyThe above example is saying that orientability is a global property: To determine wether a surface \\(\\mathcal{S}\\) is orientable, we need to examine the transition maps for the entire atlas \\(\\mathcal{A}\\). This is because a single local parametrization \\({\\pmb{\\sigma}}(U) \\subseteq \\mathcal{S}\\) is always orientable.\n\n\n\nRemark 137Let \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) be regular charts with transition map \\(\\Phi\\). We have seen in Remark 130 that \\[\n\\mathbf{N}_{\\widetilde{{\\pmb{\\sigma}}}} = \\frac{ \\det J \\Phi }{ |\\det J \\Phi| } \\, \\mathbf{N}_{{\\pmb{\\sigma}}} \\,.\n\\] If \\({\\pmb{\\sigma}}\\) and \\(\\widetilde{{\\pmb{\\sigma}}}\\) determine the same orientation, then \\[\n\\det J \\Phi &gt; 0 \\,,\n\\] which implies \\[\n\\mathbf{N}_{\\widetilde{{\\pmb{\\sigma}}}} =  \\mathbf{N}_{{\\pmb{\\sigma}}} \\,.\n\\] Hence, if \\(\\mathcal{S}\\) is an orientable surface, one can define a unit normal vector at each point of \\(\\mathcal{S}\\), without ambiguity.\n\n\n\nDefinition 138: Unit normal of a surfaceLet \\(\\mathcal{S}\\) be a regular surface. A unit normal of \\(\\mathcal{S}\\) is a smooth function \\(\\mathbf{N}\\colon \\mathcal{S}\\to \\mathbb{R}^3\\) such that \\[\n\\mathbf{N}(\\mathbf{p}) \\perp T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad \\| \\mathbf{N}(\\mathbf{p}) \\| = 1 \\,, \\quad \\forall \\, \\mathbf{p}\\in \\mathcal{S}\\, .\n\\]\n\n\n\nWarningWe require the function \\(\\mathbf{p}\\mapsto \\mathbf{N}(\\mathbf{p})\\) to be globally defined on \\(\\mathcal{S}\\) and smooth.\n\n\n\nProposition 139\nLet \\(\\mathcal{S}\\) be a regular surface. They are equivalent:\n\n\\(\\mathcal{S}\\) is orientable.\nThere exists a unit normal \\(\\mathbf{N}\\colon \\mathcal{S}\\to \\mathbb{R}^3\\).\n\n\n\nThe proof follows from the above arguments. For details, we refer the reader to Proposition 4.3.7 in (Abate, Marco and Tovena, Francesca 2011).\nIn view of the above propostion, for an oriented surface there is a natural choice of unit normal, which we call standard unit normal of \\(\\mathcal{S}\\).\n\nDefinition 140: Standard unit normal of a surfaceLet \\(\\mathcal{S}\\) be a regular surface oriented by the atlas \\(\\mathcal{A}\\). The standard unit normal to \\(\\mathcal{S}\\) is the map \\(\\mathbf{N}\\colon \\mathcal{S}\\to \\mathbb{R}^3\\) such that \\[\n\\mathbf{N}\\circ {\\pmb{\\sigma}}= \\mathbf{N}_{{\\pmb{\\sigma}}} \\,,\n\\] for each chart \\({\\pmb{\\sigma}}\\in \\mathcal{A}\\), where \\[\n\\mathbf{N}_{{\\pmb{\\sigma}}} \\colon U \\to \\mathbb{R}^3 \\,, \\quad  \\mathbf{N}_{{\\pmb{\\sigma}}} = \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| }\n\\] is the standard unit normal of \\({\\pmb{\\sigma}}\\).\n\n\n\nNotationIn the following we will denote by \\(\\mathbf{N}\\) both the standard unit normal of \\(\\mathcal{S}\\) and of a chart.\n\n\n\n\n4.12.2 Definition of Second fundamental form\nWe can now start our discussion about curvature of surfaces. We can make a similar argument to the one we made for curves: If \\({\\pmb{\\gamma}}\\) is a unit speed curve, the curvature of \\({\\pmb{\\gamma}}\\) is defined as \\[\n\\kappa (t) = \\left\\| \\ddot{{\\pmb{\\gamma}}}(t) \\right\\| \\,.\n\\] The quantity \\(\\kappa(t)\\) gave us a measure of how much \\({\\pmb{\\gamma}}\\) is deviating from a straight line. Similarly, we would like to quantify how much a surface \\(\\mathcal{S}\\) is deviating from the tangent plane \\(T_{\\mathbf{p}} \\mathcal{S}\\). Recall that \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v \\} \\,,\n\\] where \\({\\pmb{\\sigma}}\\) is a regular chart of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). The standard unit normal of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathbf{N}= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } \\,,\n\\] which is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}\\). Let \\((u_0,v_0) \\in \\mathbb{R}^2\\) be the point such that \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] As the scalar quantities \\(\\Delta u\\) and \\(\\Delta v\\) vary, the point \\[\n{\\pmb{\\sigma}}( u_0 + \\Delta u , v_0 + \\Delta v ) \\in \\mathcal{S}\n\\] deviates from the tangent plane \\(T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\mathbf{N}\\) is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}\\), the deviation is given by \\[\n\\delta := \\left[  {\\pmb{\\sigma}}(  u_0 + \\Delta u , v_0 + \\Delta v  ) - {\\pmb{\\sigma}}(u_0,v_0)    \\right] \\cdot \\mathbf{N}\\,,\n\\] as shown in Figure 4.10.\n\n\n\n\n\n\nFigure 4.10: The point \\({\\pmb{\\sigma}}(u_0 + \\Delta u, v_0 + \\Delta v)\\) on \\(\\mathcal{S}\\) deviates from \\(T_{\\mathbf{p}}\\mathcal{S}\\) by a quantity \\(\\delta\\).\n\n\n\nUsing Taylor’s formula we get \\[\\begin{align*}\n{\\pmb{\\sigma}}(u_0 + \\Delta u , v_0 + \\Delta v)  & = {\\pmb{\\sigma}}(u_0,v_0) +  {\\pmb{\\sigma}}_u (u_0,v_0) \\, \\Delta u +\n                                          {\\pmb{\\sigma}}_v (u_0,v_0) \\, \\Delta v  \\\\\n                                       & \\,\\, +  \\frac12 \\left(  {\\pmb{\\sigma}}_{uu}(u_0,v_0) (\\Delta u)^2 +  2 {\\pmb{\\sigma}}_{uv}(u_0,v_0) \\Delta u \\Delta v  +{{\\pmb{\\sigma}}}_{vv}(u_0,v_0) (\\Delta v)^2    \\right) \\\\\n                                       &  \\,\\, + R(\\Delta u , \\Delta v) \\,,\n\\end{align*}\\] where \\(R(\\Delta u , \\Delta v)\\) is a remainder such that \\[\n\\lim_{\\Delta \\to 0} \\, \\frac{R(\\Delta u , \\Delta v) }{\\Delta }  =  0 \\,, \\quad \\Delta := (\\Delta u)^2 + (\\Delta v)^2 \\,.\n\\] Since \\(\\mathbf{N}\\) is orthogonal to \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\), if we multiply the above Taylor expansion by \\(\\mathbf{N}\\), and ignore the remainder, we obtain \\[\n\\delta =  \\frac12 \\left(  L  (\\Delta u)^2 +  2 M \\Delta u \\Delta v  + N (\\Delta v)^2    \\right) \\,,\n\\] where we set \\[\nL := {\\pmb{\\sigma}}_{uu}  \\cdot \\mathbf{N}\\,, \\quad\nM := {\\pmb{\\sigma}}_{uv}  \\cdot \\mathbf{N}\\,, \\quad\nN := {\\pmb{\\sigma}}_{vv}  \\cdot \\mathbf{N}\\,.\n\\] The expression \\[\n\\mathscr{F}_2 :=  L \\, du^2 +  2 M  \\,du dv  + N \\, dv^2\n\\] is called the second fundamental form of \\(\\mathcal{S}\\). Therefore \\(\\mathscr{F}_2\\) measures how much the surface \\(\\mathcal{S}\\) deviates from being a plane. Let us make this definition precise.\n\nDefinition 141: Second fundamental form of a chartLet \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart of \\(\\mathcal{S}\\). Denote the standard unit normal of \\({\\pmb{\\sigma}}\\) by \\[\n\\mathbf{N}\\colon U \\to \\mathbb{R}^3 \\,, \\quad \\mathbf{N}= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } \\,.\n\\] Define the functions \\[\nL , M , N \\colon U \\to \\mathbb{R}\n\\] by setting \\[\nL := {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}\\,, \\quad  M := {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}\\,, \\quad\nN := {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}\\,.\n\\] Let \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\) and denote by \\((u_0,v_0) \\in U\\) the point such that \\[\n{\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,.\n\\] The second fundamental form of \\({\\pmb{\\sigma}}\\) at \\(\\mathbf{p}\\) is the quadratic form \\[\n\\mathscr{F}_2 \\colon T_{\\mathbf{p}} \\mathcal{S}\\to \\mathbb{R}\n\\] defined by \\[\n\\mathscr{F}_2 (\\mathbf{v}) := L \\, du^2(\\mathbf{v}) + 2M \\, du(\\mathbf{v}) \\, dv (\\mathbf{v})+ N \\, dv^2 (\\mathbf{v}) \\,,\n\\tag{4.9}\\] for all \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\). Here \\(L,M,N\\) are evaluated at \\((u_0,v_0)\\), and \\(du\\), \\(dv\\) are the coordinate functions as in Definition 101.\n\n\n\nNotationWith a little abuse of notation, we also denote by \\(\\mathscr{F}_2\\) the \\(2 \\times 2\\) matrix \\[\n\\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\nRemark 142: Second fundamental form and reparametrizations\nThe second fundamental form \\[\n\\mathscr{F}_2 = L \\, du^2 + 2M \\, du dv + N \\, dv^2\n\\] depends on the choice of chart \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\). Indeed, let us adopt the same notations as Remark 105. Suppose that \\(\\widetilde{{\\pmb{\\sigma}}} \\colon \\widetilde{U} \\to \\mathbb{R}^3\\) is a reparametrization of \\({\\pmb{\\sigma}}\\) with \\[\n\\widetilde{{\\pmb{\\sigma}}} = {\\pmb{\\sigma}}\\circ \\Phi \\,,\n\\] where \\(\\Phi \\colon \\widetilde{U} \\to U\\) is a diffeomorphism. Denote the second fundamental form of \\(\\widetilde{{\\pmb{\\sigma}}}\\) by \\[\n\\widetilde{\\mathscr{F}}_2 = \\widetilde{L} \\, d\\tilde{u}^2 + 2 \\widetilde{M} \\, d\\tilde{u} d\\tilde{v} + \\widetilde{N} \\, d\\tilde{v}^2 \\,.\n\\] The matrices of \\(\\mathscr{F}_2\\) and \\(\\widetilde{\\mathscr{F}}_2\\) are related by \\[\n\\left(\n\\begin{array}{cc}\n\\widetilde{L} & \\widetilde{M} \\\\\n\\widetilde{M} & \\widetilde{N}\n\\end{array}\n\\right)  \n=\n\\pm (J \\Phi)^T \\,\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right)\n\\,\nJ \\Phi  \\,,\n\\tag{4.10}\\] where (4.10) holds with \\(+\\) if \\(\\det J\\Phi &gt; 0\\) and \\(-\\) if \\(\\det J\\Phi &lt; 0\\).\n\nFormula (4.10) holds by a change of variable argument. The sign depends on the sign of \\(\\det J\\Phi\\) because \\[\n\\widetilde{\\mathbf{N}} = \\frac{ \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} }{\\left\\| \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{u}} \\times \\widetilde{{\\pmb{\\sigma}}}_{\\tilde{v}} \\right\\|} = \\frac{\\det J\\Phi}{|\\det J\\Phi|} \\frac{{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v}{\\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\|} = \\pm \\mathbf{N}\\,,\n\\] as shown in Remark 130.\n\n\n\nLet us show that a plane and a cylinder have different second fundamental forms.\n\nExample 143: Plane\nLet \\(\\mathbf{a}, \\mathbf{p}, \\mathbf{q} \\in \\mathbb{R}^3\\). Suppose that \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\) are orthonormal vectors, that is, \\[\n\\left\\| \\mathbf{p} \\right\\| = \\left\\| \\mathbf{q} \\right\\| = 1 \\,, \\quad \\mathbf{p}\\cdot \\mathbf{q} = 0 \\,.\n\\] Consider the plane with chart \\[\n{\\pmb{\\sigma}}(u,v) = \\mathbf{a} + u \\mathbf{p}+ v \\mathbf{q} \\,, \\quad (u,v) \\in \\mathbb{R}^2 \\,.\n\\] Prove that the second fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_2 = 0 \\,.\n\\] This reflects the intuition that a plane is flat, and therefore there is no curvature.\n\nWe have \\[\n{\\pmb{\\sigma}}_u = \\mathbf{p}\\,, \\quad {\\pmb{\\sigma}}_v = \\mathbf{q} \\,.\n\\] The principal unit normal is \\[\n\\mathbf{N}= \\frac{\\mathbf{p}\\times \\mathbf{q}}{\\left\\|  \\mathbf{p}\\times \\mathbf{q}  \\right\\|   } \\,,\n\\] while the second derivatives are \\[\n{\\pmb{\\sigma}}_{\\mathbf{u}} = {\\pmb{\\sigma}}_{\\mathbf{u}} = {\\pmb{\\sigma}}_{\\mathbf{u}} = {\\pmb{0}}\\,.\n\\] Therefore \\[\\begin{align*}\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}= 0 \\\\\nM & = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}= 0 \\\\\nN & = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}= 0 \\\\\n\\end{align*}\\] and the second fundamental form is \\[\n\\mathscr{F}_2 = L \\, du^2 + 2 M\\, du \\, dv + N \\, dv^2 = 0 \\,.  \n\\]\n\n\n\n\nExample 144: Unit cylinder\nConsider the unit cylinder with chart \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u),  v)  \\,, \\quad (u,v) \\in (0,2\\pi) \\times \\mathbb{R}\\,.\n\\] Prove that the second fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathscr{F}_2 = -  du^2 \\,.\n\\] This reflects the intuition that the cylinder curves only when moving in the \\(v\\)-direction. In such direction we are moving on a circle of radius \\(1\\), therefore we expect the curvature to be \\(-1\\).\n\nWe have \\[\n{\\pmb{\\sigma}}_u = (-\\sin(u),\\cos(u), 0 )  \\,, \\quad {\\pmb{\\sigma}}_v = (0,0,1) \\,,\n\\] and also \\[\n{\\pmb{\\sigma}}_{uu}  = (-\\cos(u), - \\sin(u), 0 ) \\,, \\quad {\\pmb{\\sigma}}_{uv} = {\\pmb{\\sigma}}_{vv} = {\\pmb{0}}\\,.\n\\] We have also \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  =\n\\left|  \n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n-\\sin(u) & \\cos(u) & 0 \\\\\n0 & 0 & 1\n\\end{array}\n\\right|\n= (\\cos(u), \\sin(u),0)\n\\] so that \\[\n\\left\\|  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| = \\sqrt{ \\cos^2(u) + \\sin^2(u)  } = 1 \\,.\n\\] The principal unit normal is \\[\n\\mathbf{N}= \\frac{{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v}{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| } = (\\cos(u), \\sin(u),0) \\,.\n\\] We finally compute \\[\\begin{align*}\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}\\\\\n& = (-\\cos(u), - \\sin(u), 0 ) \\cdot (\\cos(u), \\sin(u),0) \\\\\n& = - \\cos^2(u) - \\sin^2(u) = - 1 \\\\\nM & = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}= 0 \\\\\nN & = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}= 0 \\\\\n\\end{align*}\\] The second fundamental form is \\[\n\\mathscr{F}_2 = L \\, du^2 + 2 M\\, du \\, dv + N \\, dv^2 = - du^2  \\,.  \n\\]\n\n\n\n\nRemark 145We have seen that a plane and the unit cylinder have the same first fundamental form \\[\n\\mathscr{F}_1 = \\widetilde{\\mathscr{F}}_1 = du^2 + dv^2 \\,,\n\\] while their second fundamental forms differ: we have \\[\n\\mathscr{F}_2 = 0 \\,, \\quad \\widetilde{\\mathscr{F}}_2 = - du^2   \\,,\n\\] respectively.\n\n\n\n\n4.12.3 Gauss and Weingarten maps\nAnother way to quantify how much a surface \\(\\mathcal{S}\\) is curving is by examining the behavior of standard unit normal \\(\\mathbf{N}\\). If \\(\\mathcal{S}\\) is a plane spanned by vectors \\(\\mathbf{p}\\) and \\(\\mathbf{q}\\), then its standard unit normal is \\[\n\\mathbf{N}= \\frac{\\mathbf{p}\\times \\mathbf{q}}{ \\left\\| \\mathbf{p}\\times \\mathbf{q} \\right\\| } \\,,\n\\] which is constant across \\(\\mathcal{S}\\). If \\(\\mathcal{S}\\) is a general surface, measuring the variation of \\(\\mathbf{N}\\) will tell us how much \\(\\mathcal{S}\\) is deviating from being a plane. This is the idea behind the definition of the Gauss and Weingarten maps.\n\nRemark 146Let \\(\\mathcal{S}\\) be oriented and \\(\\mathbf{N}\\colon \\mathcal{S}\\to \\mathbb{R}^3\\) be the standard unit normal. In particular \\(\\mathbf{N}\\) is a smooth map and \\[\n\\mathbf{N}(\\mathbf{p}) \\perp T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad \\| \\mathbf{N}(\\mathbf{p}) \\| = 1 \\,, \\quad \\forall  \\, \\mathbf{p}\\in \\mathcal{S}\\,.\n\\] Since \\(T_{\\mathbf{p}} \\mathcal{S}\\) passes through the origin and \\(\\mathbf{N}\\) has norm \\(1\\), it follows that \\[\n\\mathbf{N}(\\mathbf{p}) \\in\n\\mathbb{S}^2 := \\{ \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\, \\| \\mathbf{x}\\| = 1 \\}  \\,,\n\\] where \\(\\mathbb{S}^2\\) is the unit sphere in \\(\\mathbb{R}^3\\). Thus \\(\\mathbf{N}\\colon \\mathcal{S}\\to \\mathbb{S}^2\\).\n\n\n\nDefinition 147: Gauss mapLet \\(\\mathcal{S}\\) be an oriented surface and \\(\\mathbf{N}\\) the standard unit normal to \\(\\mathcal{S}\\). The Gauss map of \\(\\mathcal{S}\\) is the map \\[\n{\\mathcal{G}}_{\\mathcal{S}} \\colon \\mathcal{S}\\to \\mathbb{S}^2 \\,, \\quad\n{\\mathcal{G}}_{\\mathcal{S}} (\\mathbf{p}):= \\mathbf{N}(\\mathbf{p}) \\,.\n\\]\n\n\n\n\n\nThe Gauss map \\({\\mathcal{G}}_{\\mathcal{S}}\\) of \\(\\mathcal{S}\\) is defined as \\({\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p}):= \\mathbf{N}(\\mathbf{p})\\). Note that \\({\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p}) \\in \\mathbb{S}^2\\).\n\n\n\nRemark 148The Gauss map of \\(\\mathcal{S}\\) is just the standard unit normal of \\(\\mathcal{S}\\). By definition of standard unit normal to \\(\\mathcal{S}\\) we obtain that \\[\n\\mathcal{G}_{\\mathcal{S}} \\circ {\\pmb{\\sigma}}= \\mathbf{N}\n\\] for all charts \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\), where \\(\\mathbf{N}= \\mathbf{N}_{{\\pmb{\\sigma}}}\\) is the standard unit normal to \\({\\pmb{\\sigma}}\\), that is, \\[\n\\mathbf{N}\\colon U \\to \\mathbb{R}^3 \\,, \\quad\n\\mathbf{N}:= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\|  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } \\,.\n\\]\n\n\n\nExample 149\n\nSuppose \\(\\mathcal{S}\\) is the unit sphere \\(\\mathbb{S}^2\\). Then \\({\\mathcal{G}}_{\\mathcal{S}} \\colon \\mathcal{S}\\to \\mathbb{S}^2\\) is the identity, see Figure 4.11.\nLet \\(\\mathbf{a} , \\mathbf{v},\\mathbf{w}\\in \\mathbb{R}^3\\) with \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) linearly independent. Let \\(\\mathcal{S}\\) be the plane \\[\n{\\pmb{\\sigma}}(u,v):= \\mathbf{a} + \\mathbf{v}u + \\mathbf{\\mathbf{w}} v \\,, \\quad \\forall \\, (u,v) \\in \\mathbb{R}^2 \\,.\n\\] The Gauss map of \\(\\mathcal{S}\\) is constant: \\[\n\\mathcal{G}_{\\mathcal{S}} (\\mathbf{p}) = \\frac{ \\mathbf{v}\\times \\mathbf{w}}{ \\| \\mathbf{v}\\times \\mathbf{w}\\| } \\,,\n\\] for all \\(\\mathbf{p}\\in \\mathcal{S}\\), see Figure 4.12.\nLet \\(\\mathcal{S}\\) be the unit cylinder \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u),  v)  \\,, \\quad (u,v) \\in (0,2\\pi) \\times \\mathbb{R}\\,.\n\\] Then \\[\n{\\pmb{\\sigma}}_u = (-\\sin(u),\\cos(u), 0 )  \\,, \\quad {\\pmb{\\sigma}}_v = (0,0,1) \\,,\n\\] and \\[\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v =\n\\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n-\\sin(u) & \\cos(u) & 0 \\\\\n0  &  0 &  1\n\\end{array}\n\\right|\n= (\\cos(u), \\sin(u), 0) \\,.\n\\] Therefore \\[\n\\left\\|  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| = 1 \\,,\n\\] and \\[\n\\mathbf{N}= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } = (\\cos(u), \\sin(u), 0) \\,.\n\\] The Gauss map of \\(\\mathcal{S}\\) is \\[\n\\mathcal{G}_{\\mathcal{S}} (\\mathbf{p}) = (\\cos(u_0), \\sin(u_0), 0) \\,,\n\\] where \\((u_0,v_0)\\) is such that \\({\\pmb{\\sigma}}(u_0,v_0)=\\mathbf{p}\\). Note that \\(\\mathcal{G}_{\\mathcal{S}}\\) maps \\(\\mathcal{S}\\) into the equator of \\(\\mathbb{S}^2\\), see Figure 4.13.\n\n\n\n\n\n\n\n\n\nFigure 4.11: The Gauss map \\({\\mathcal{G}}_{\\mathcal{S}}\\) of a sphere is the identity.\n\n\n\n\n\n\n\n\n\nFigure 4.12: The Gauss map \\({\\mathcal{G}}_{\\mathcal{S}}\\) of a plane is constant.\n\n\n\n\n\n\n\n\n\nFigure 4.13: If \\(\\mathcal{S}\\) is the unit cylinder, the Gauss map \\({\\mathcal{G}}_{\\mathcal{S}}\\) maps \\(\\mathcal{S}\\) into the equator of \\(\\mathbb{S}^2\\).\n\n\n\n\nRemark 150\nBy definition, the Gauss map is a smooth function between surfaces. Therefore the differential of \\(\\mathcal{G}_{\\mathcal{S}}\\) is well defined, and \\[\nd_{\\mathbf{p}} {\\mathcal{G}}_{\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2 \\,,\n\\] for all \\(\\mathbf{p}\\in \\mathcal{S}\\). We have that \\[\nT_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2 = T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\tag{4.11}\\] see Figure 4.14. Therefore \\[\nd_{\\mathbf{p}} {\\mathcal{G}}_{\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\nProof. The tangent plane \\(T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2\\) passes through the origin and \\[\n\\mathcal{G}(\\mathbf{p}) \\perp T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2 \\,.\n\\] By definition \\(\\mathcal{G}(\\mathbf{p}) = \\mathbf{N}(\\mathbf{p})\\), and thus \\[\n\\mathbf{N}(\\mathbf{p}) \\perp T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2 \\,.\n\\] Since by definition \\[\n\\mathbf{N}(\\mathbf{p}) \\perp T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] we infer (4.11).\n\n\n\n\n\n\n\n\n\nFigure 4.14: We ca identify \\(T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2\\) with \\(T_{\\mathbf{p}} \\mathcal{S}\\). This is because \\(\\mathcal{G}(\\mathbf{p}) \\perp T_{{\\mathcal{G}}_{\\mathcal{S}}(\\mathbf{p})} \\mathbb{S}^2\\) and \\(\\mathcal{G}(\\mathbf{p}) = \\mathbf{N}(\\mathbf{p})\\).\n\n\n\n\nDefinition 151: Weingarten mapLet \\(\\mathcal{S}\\) be an orientable surface and \\(\\mathcal{G} \\colon \\mathcal{S}\\to \\mathbb{S}^2\\) its Gauss map. The Weingarten map \\(\\mathcal{W}_{\\mathbf{p}, \\mathcal{S}}\\) of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is the negative differential of the Gauss map at \\(\\mathbf{p}\\), that is, \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}}\\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad  \\mathcal{W}_{\\mathbf{p},\\mathcal{S}}(\\mathbf{v}) := -d_{\\mathbf{p}} \\mathcal{G} (\\mathbf{v}) \\,,\n\\] for all \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\).\n\n\n\nImportantThe Gauss map encodes information on the standard unit normal \\(\\mathbf{N}\\) to \\(\\mathcal{S}\\). Hence its derivative, the Weingarten map, detects the rate of change of \\(\\mathbf{N}\\).\n\n\n\nRemark 152The minus sign in the definition of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) is a convention, just like we defined the torsion to be the scalar \\(\\tau\\) such that \\[\n\\dot{\\mathbf{b}} = - \\tau \\mathbf{n}\\,.\n\\]\n\n\nThe Weingarten map allows us to define a bilnear form on \\(T_{\\mathbf{p}} \\mathcal{S}\\). We call such bilinear form the second fundamental form of \\(\\mathcal{S}\\).\n\nDefinition 153: Second fundamental form of a surfaceLet \\(\\mathcal{S}\\) be an orientable surface and denote by \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\n\\] its Weingarten map at \\(\\mathbf{p}\\). The second fundamental form of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is the map \\[\nII_{\\mathbf{p}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\times T_{\\mathbf{p}} \\mathcal{S}\\to \\mathbb{R}\n\\] defined by \\[\nII_{\\mathbf{p}}(\\mathbf{v},\\mathbf{w}) := \\mathcal{W}_{\\mathbf{p}, \\mathcal{S}}(\\mathbf{v}) \\cdot \\mathbf{w}\\,, \\quad \\forall \\, \\mathbf{v}, \\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\n\n\nRemark 154\nThe second fudamental form \\(II_{\\mathbf{p}}\\) of \\(\\mathcal{S}\\) is bilinear.\n\nIndeed, \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) is linear, being the differential of a smooth map. Hence \\(II_{\\mathbf{p}}\\) is bilinear, given that the scalar product is bilinear.\n\n\n\n\nRemark 155: Matrix of the second fundamental formLet \\({\\pmb{\\sigma}}\\) be a chart at \\(\\mathbf{p}\\in \\mathcal{S}\\). Since \\(II_{\\mathbf{p}}\\) is a bilinear form on \\(T_{\\mathbf{p}} \\mathcal{S}\\), it can be represented by the \\(2 \\times 2\\) matrix \\[\nA =\n\\left(\n\\begin{array}{cc}\nII_{\\mathbf{p}} ({\\pmb{\\sigma}}_u, {\\pmb{\\sigma}}_u) & II_{\\mathbf{p}} ({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v) \\\\\nII_{\\mathbf{p}} ({\\pmb{\\sigma}}_v, {\\pmb{\\sigma}}_u) & II_{\\mathbf{p}} ({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_v)\n\\end{array}\n\\right)  \\,,\n\\] given that \\(\\{ {\\pmb{\\sigma}}_u, {\\pmb{\\sigma}}_v\\}\\) is a basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\). In a not so shocking turn of events, it happens that \\[\nA = \\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right)\n\\] where \\[\nL = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}\\,, \\quad\nM = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}\\,, \\quad\nN = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}\\,.\n\\] Therefore, the second fundamental form \\(II_{\\mathbf{p}}\\) coincides with the second fundamental form \\(\\mathscr{F}_{2}\\) of the chart \\({\\pmb{\\sigma}}\\). We prove this statement in the next theorem.\n\n\n\nTheorem 156\nLet \\(\\mathcal{S}\\) be an orientable surface and \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart. Let \\(\\mathbf{p}\\in {\\pmb{\\sigma}}(U)\\).\n\nThe second funamental form \\(II_{\\mathbf{p}}\\) is a symmetric bilinear map.\nIt holds \\[\nII_{\\mathbf{p}} (\\mathbf{v},\\mathbf{w}) = (du (\\mathbf{v}), dv(\\mathbf{v}) )  \\,\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right) \\, (du(\\mathbf{w}) , dv(\\mathbf{w}))^T \\,,\n\\] for all \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\), where \\[\nL = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}\\,, \\quad\nM = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}\\,, \\quad\nN = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}\\,.\n\\]\n\\(\\mathscr{F}_2\\) is the quadratic form associated to \\(II_{\\mathbf{p}}\\), that is, \\[\n\\mathscr{F}_2 (\\mathbf{v}) = {II}_{\\mathbf{p}} (\\mathbf{v},\\mathbf{v}) \\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\]\n\n\n\nTo prove Theorem 156 we use the following two Lemmas.\n\nLemma 157Let \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a regular chart with standard unit normal \\(\\mathbf{N}\\colon U \\to \\mathbb{R}^3\\). Then \\[\\begin{align*}\n\\mathbf{N}_{u} \\cdot {\\pmb{\\sigma}}_u & = - L \\,,\\\\\n\\mathbf{N}_{u} \\cdot {\\pmb{\\sigma}}_v & = \\mathbf{N}_{v} \\cdot {\\pmb{\\sigma}}_u = - M \\,, \\\\\n\\mathbf{N}_{v} \\cdot {\\pmb{\\sigma}}_v & = - N \\,.\n\\end{align*}\\]\n\n\n\nProofThe vectors \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) form a basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\mathbf{N}\\) is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}\\) by definition, it follows that \\[\n\\mathbf{N}\\cdot {\\pmb{\\sigma}}_u = 0 \\,, \\quad\n\\mathbf{N}\\cdot {\\pmb{\\sigma}}_v = 0 \\,.\n\\] Differentiating the above with respect to \\(u\\) and \\(v\\) yields the thesis. For example, we have \\[\n\\frac{\\partial}{\\partial u} (\\mathbf{N}\\cdot {\\pmb{\\sigma}}_u) = 0 \\,.\n\\] On the other hand, by chain rule, \\[\n\\frac{\\partial}{\\partial u} (\\mathbf{N}\\cdot {\\pmb{\\sigma}}_u) = \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u + \\mathbf{N}\\cdot {\\pmb{\\sigma}}_{uu} =\n\\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u + L \\,,\n\\] from which we infer \\[\n\\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u = - L \\,.\n\\] The rest of the proof follows similarly.\n\n\n\nLemma 158Let \\(\\mathcal{S}\\) be an orientable surface and \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\) be its Weingarten map at \\(\\mathbf{p}\\). Let \\({\\pmb{\\sigma}}\\) be a regular chart at \\(\\mathbf{p}\\), with \\({\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\). Then \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) = - \\mathbf{N}_u \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) = - \\mathbf{N}_v \\,,\n\\] where \\({\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v,\\mathbf{N}_u,\\mathbf{N}_v\\) are evaluated at \\((u_0,v_0)\\).\n\n\n\nProofSince \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) is defined as \\(- d_{\\mathbf{p}} \\mathcal{G}_{\\mathcal{S}}\\), we can compute \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u)\\) and \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v)\\) by using the definition of differential of a smooth function. To this end, consider the curve \\[\n{\\pmb{\\gamma}}(t) := {\\pmb{\\sigma}}( u_0 + t , v_0 ) \\,.\n\\] We have that \\({\\pmb{\\gamma}}\\) is a smooth curve in \\(\\mathcal{S}\\) and \\[\n\\dot{{\\pmb{\\gamma}}}(t) =  {\\pmb{\\sigma}}_u( u_0 + t, v_0 ) \\,.\n\\] Therefore \\[\n{\\pmb{\\gamma}}(0) = {\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\,, \\quad \\dot{{\\pmb{\\gamma}}}(0) = {\\pmb{\\sigma}}_u (u_0,v_0) \\,.\n\\] Define \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) := (\\mathcal{G}_{\\mathcal{S}} \\circ {\\pmb{\\gamma}})(t) \\,.\n\\] By Remark 148 \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) = \\mathcal{G}_{\\mathcal{S}} ({\\pmb{\\gamma}}(t)) = \\mathcal{G}_{\\mathcal{S}} ({\\pmb{\\sigma}}(u_0 + t , v_0)) = \\mathbf{N}(u_0 + t , v_0) \\,.\n\\] Thus \\[\n\\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) = \\mathbf{N}_u (u_0 + t , v_0) \\,, \\quad \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0) = \\mathbf{N}_u (u_0 , v_0) \\,.\n\\] By definition of differential, we have \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u)  = - d_{\\mathbf{p}} \\mathcal{G}_{\\mathcal{S}} ({\\pmb{\\sigma}}_u)\n                         = - \\dot{\\widetilde{{\\pmb{\\gamma}}}}(0)\n                         = - \\mathbf{N}_u (u_0,v_0) \\,,\n\\] as we wanted to prove. To show that \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) = - \\mathbf{N}_v (u_0,v_0) \\,,\n\\] it is sufficient to consider the curve \\[\n{\\pmb{\\gamma}}(t) := {\\pmb{\\sigma}}( u_0 , v_0 + t ) \\,,\n\\] and argue similarly. This is left as an exercise.\n\n\nWe can now prove Theorem 156\n\nProof: Proof of Theorem 156By Theorem 75 we have \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\operatorname{span} \\{ {\\pmb{\\sigma}}_u, {\\pmb{\\sigma}}_v \\} \\,.\n\\] Therefore, for \\(\\mathbf{v},\\mathbf{w}\\in T_{\\mathbf{p}} \\mathcal{S}\\), there exist \\(\\lambda_1,\\lambda_2,\\mu_1,\\mu_2 \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= \\lambda_1 {\\pmb{\\sigma}}_u + \\mu_1 {\\pmb{\\sigma}}_v \\,, \\quad\n\\mathbf{w}= \\lambda_2 {\\pmb{\\sigma}}_u + \\mu_2 {\\pmb{\\sigma}}_v \\,.\n\\] By bilinearity of \\(II_{\\mathbf{p}}\\) we infer \\[\\begin{align*}\n{II}_{\\mathbf{p}} (\\mathbf{v},\\mathbf{w}) & = \\lambda_1 \\lambda_2 \\, II_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_u)  +  \\lambda_1 \\mu_2 \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v) \\\\\n& \\,\\,\\,\\, + \\lambda_2 \\mu_1  \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_u)  + \\mu_1 \\mu_2 \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_v) \\\\\n& = du(\\mathbf{v}) du(\\mathbf{w}) \\, II_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_u)  +  du(\\mathbf{v}) dv(\\mathbf{w}) \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v) \\\\\n& \\,\\,\\,\\, + dv(\\mathbf{v}) du(\\mathbf{v})  \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_u)  + dv(\\mathbf{v}) dv(\\mathbf{w}) \\,  II_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_v) \\\\\n& = (du (\\mathbf{v}), dv(\\mathbf{v}) )  \\,\n\\left(\n\\begin{array}{cc}\nII_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_u) & II_{\\mathbf{p}}({\\pmb{\\sigma}}_u , {\\pmb{\\sigma}}_v) \\\\\nII_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_u) & II_{\\mathbf{p}}({\\pmb{\\sigma}}_v , {\\pmb{\\sigma}}_v)\n\\end{array}\n\\right) \\, (du(\\mathbf{w}) , dv(\\mathbf{w}))^T \\,.\n\\end{align*}\\] By Lemma 158 and Lemma 157 we have \\[\n\\mathcal{W}_{\\mathbf{p}, \\mathcal{S}} ({\\pmb{\\sigma}}_u) = - \\mathbf{N}_u \\,, \\quad L = - \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u \\,.\n\\] Therefore, using the above and the definition of \\(II_{\\mathbf{p}}\\), we get \\[\nII_{\\mathbf{p}} ({\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_u) = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) \\cdot {\\pmb{\\sigma}}_u = - \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u = L \\,.\n\\] With similar calculations we obtain \\[\nII_{\\mathbf{p}} ({\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v) = II_{\\mathbf{p}} ({\\pmb{\\sigma}}_v,{\\pmb{\\sigma}}_u) = M \\,, \\quad\nII_{\\mathbf{p}} ({\\pmb{\\sigma}}_v,{\\pmb{\\sigma}}_v) = N \\,,\n\\] concluding the proof of point 2. In particular this also proves that \\(II_{\\mathbf{p}}\\) is symmetric, which is Point 1 of the statement. The fact that \\[\nII_{\\mathbf{p}}(\\mathbf{v},\\mathbf{v}) = \\mathscr{F}_2(\\mathbf{v})\n\\] follows from Point 2 and definition of \\(\\mathscr{F}_2\\).\n\n\n\n\n4.12.4 Matrix of Weingarten map\nThe Weingarten map is a linear map \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] We would like to find a formula to compute \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\). This is easily done: Given a chart \\({\\pmb{\\sigma}}\\) at \\(\\mathbf{p}\\), we have that \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) is a basis for the vector space \\(T_{\\mathbf{p}} \\mathcal{S}\\). Therefore there exists a \\(2 \\times 2\\) matrix \\(A\\) which represents \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\), that is, \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}(\\mathbf{v}) = A \\mathbf{v}\\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\] It turns out that \\[\nA = \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\,,\n\\] where we recall that \\[\n\\mathscr{F}_1 =\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right)\\,, \\quad\n\\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right) \\,,\n\\] where \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u \\,, & F & =  {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\, , & G & =  {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v \\,,  \\\\\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}\\, ,  & M & =  {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}\\,, & N & =  {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}\\,,\n\\end{align*}\\] and \\[\n\\mathbf{N}= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\|  {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v  \\right\\| } \\,.\n\\] Let us prove this claim.\n\nTheorem 159: Matrix of Weingarten mapLet \\(\\mathcal{S}\\) be an orientable surface and \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\) be its Weingarten map at \\(\\mathbf{p}\\). Let \\({\\pmb{\\sigma}}\\) be a regular chart at \\(\\mathbf{p}\\), with \\({\\pmb{\\sigma}}(u_0,v_0) = \\mathbf{p}\\). Then \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) = \\mathscr{F}_1^{-1} \\mathscr{F}_2   \\left(\n\\begin{array}{c}\n\\lambda \\\\\n\\mu\n\\end{array}\n\\right)\\,, \\quad \\forall \\, v \\in T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] where \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\,,\n\\] with \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) evaluated at \\((u_0,v_0)\\).\n\n\n\nProofBy Theorem 75 we know that \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) is a basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Since \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} \\colon T_{\\mathbf{p}} \\mathcal{S}\\to T_{\\mathbf{p}} \\mathcal{S}\\) is linear, by standard linear algebra results there exist coefficients \\(a,b,c,d \\in \\mathbb{R}\\) such that \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) =\n\\left(\n\\begin{array}{cc}\na & b \\\\\nc & d\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{c}\n\\lambda \\\\\n\\mu\n\\end{array}\n\\right)\\, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] where \\[\n\\mathbf{v}= \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v \\,.\n\\] The coefficients \\(a,b,c,d \\in \\mathbb{R}\\) can be compute by solving the linear system \\[\\begin{align*}\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) & = a {\\pmb{\\sigma}}_u + b {\\pmb{\\sigma}}_v \\\\\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) & = c {\\pmb{\\sigma}}_u + d {\\pmb{\\sigma}}_v \\,.\n\\end{align*}\\] By Lemma 158 we have \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) = - \\mathbf{N}_u \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) = - \\mathbf{N}_v \\,,\n\\] so that we obtain \\[\\begin{align*}\n- \\mathbf{N}_u & = a {\\pmb{\\sigma}}_u + b {\\pmb{\\sigma}}_v \\\\\n- \\mathbf{N}_v & = c {\\pmb{\\sigma}}_u + d {\\pmb{\\sigma}}_v \\,.\n\\end{align*}\\] Taking the scalar product of the above equations with \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) we get \\[\\begin{align*}\n- \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u & = a ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u) + b ({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_u) \\\\\n- \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_v & = a ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v) + b ({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v) \\\\\n- \\mathbf{N}_v \\cdot {\\pmb{\\sigma}}_u & = c ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u) + d ({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_u) \\\\\n- \\mathbf{N}_v \\cdot {\\pmb{\\sigma}}_v & = c ({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v) + d ({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v)\n\\end{align*}\\] By Lemma 157 we have \\[\\begin{align*}\n\\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_u & = - L \\,,  & \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}_v & = - M \\,, \\\\\n\\mathbf{N}_v \\cdot {\\pmb{\\sigma}}_u & = - M \\,,  & \\mathbf{N}_v \\cdot {\\pmb{\\sigma}}_v & = - N \\,. \\\\\n\\end{align*}\\] If in addition we recall the definition of \\(E,F,G\\), we obtain \\[\\begin{align*}\nL & = a E + b F \\\\\nM & = a F + b G \\\\\nM & = c E + d F \\\\\nN & = c F + d G\n\\end{align*}\\] The above equations are equivalent to the matrix multiplication \\[\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right)\n=\n\\left(\n\\begin{array}{cc}\na & b \\\\\nc & d\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right) \\,,\n\\] which reads \\[\n\\mathscr{F}_1 A = \\mathscr{F}_2 \\,.\n\\] Now, notice that \\[\n\\det \\mathscr{F}_1 &gt; 0 \\,.\n\\]\n\nIndeed, recall Cauchy-Schwarz inequality: \\[\n\\mathbf{v}\\cdot \\mathbf{v}\\leq \\| \\mathbf{v}\\| \\| \\mathbf{w}\\| \\,, \\quad \\forall \\, \\mathbf{v}, \\mathbf{w}\\in\n\\mathbb{R}^3 \\,,\n\\] where the inequality is strict if and only if \\(\\mathbf{v}\\) and \\(\\mathbf{w}\\) are linearly independent. Since \\(\\mathcal{S}\\) is regular, we have that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent. Therefore by Cauchy-Schwarz we have \\[\n{\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v  &lt; \\left\\|  {\\pmb{\\sigma}}_u  \\right\\| \\left\\| {\\pmb{\\sigma}}_v \\right\\| \\,,\n\\] and so, squaring both sides, \\[\n\\left( {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\right)^2 &lt; \\left\\|  {\\pmb{\\sigma}}_u  \\right\\|^2 \\left\\| {\\pmb{\\sigma}}_v \\right\\|^2 \\,.\n\\] Hence \\[\\begin{align*}\n\\det (\\mathscr{F}_1) & = EG-F^2 \\\\\n& =  \\left({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u  \\right) \\left({\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v  \\right)  -  \\left({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\right)^2  \\\\\n& = \\left\\|  {\\pmb{\\sigma}}_u  \\right\\|^2 \\left\\| {\\pmb{\\sigma}}_v \\right\\|^2 - \\left({\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v \\right)^2 &gt; 0 \\,.\n\\end{align*}\\]\n\nIn particular the matrix \\(\\mathscr{F}_1\\) is invertible and thus \\[\nA = \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\,,\n\\] concluding the proof.\n\n\n\nImportantA matrix \\(A \\in \\mathbb{R}^{n \\times n}\\) is invertible if and only if \\(\\det (A) \\neq 0\\). In such case the inverse \\(A^{-1}\\) is computed via the formula \\[\nA^{-1} = \\frac{1}{\\det (A)} \\, \\operatorname{cof}(A)^T \\,,\n\\] where \\(\\operatorname{cof}(A)\\) is the cofactor matrix of \\(A\\). For \\(n=2\\) the above formula reads: \\[\n\\left(\n\\begin{array}{cc}\na & b \\\\\nc & d\n\\end{array}\n\\right)^{-1}\n=\n\\frac{1}{ad - bc}  \\,\n\\left(\n\\begin{array}{cc}\nd & -b \\\\\n-c & a\n\\end{array}\n\\right) \\,.\n\\] If the matrix is diagonal, then \\[\n\\left(\n\\begin{array}{cc}\n\\lambda & 0 \\\\\n0 & \\mu\n\\end{array}\n\\right)\n=\n\\left(\n\\begin{array}{cc}\n1/\\lambda & 0 \\\\\n0 & 1/\\mu\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\nNotationIn the following we denote the matrix of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) by the symbol \\(\\mathcal{W}\\).\n\n\n\nExample 160: Helicoid\nThe Helicoid is charted by \\[\n{\\pmb{\\sigma}}(u,v) = (u \\cos (v), u \\sin(v) , \\lambda v) \\,, \\quad u \\in [0,1] \\,, \\, v \\in [0,4\\pi) \\,,\n\\] where \\(\\lambda&gt;0\\) is a constant, see Figure 4.15. Prove that the matrix of the Weingarten map is \\[\n\\mathcal{W}=\n\\left(\n\\begin{array}{cc}\n0 & - \\dfrac{\\lambda}{(u^2 + \\lambda^2)^{1/2}} \\\\\n\\dfrac{\\lambda}{(u^2 + \\lambda^2)^{3/2}} & 0\n\\end{array}\n\\right) \\,.\n\\]\n\nSolution. We compute \\[\\begin{align*}\n{\\pmb{\\sigma}}_u & = ( \\cos(v), \\sin(v), 0  )  \\\\\n{\\pmb{\\sigma}}_v & = ( - u \\sin(v), u \\cos(v), \\lambda  )  \\\\\n{\\pmb{\\sigma}}_{uu} & = ( 0, 0, 0  )  \\\\\n{\\pmb{\\sigma}}_{uv} & = (- \\sin(v), \\cos(v), 0 ) \\\\\n{\\pmb{\\sigma}}_{vv} & = ( - u \\cos(v), - u \\sin(v), 0 ) \\\\\n\\end{align*}\\] from which \\[\\begin{align*}\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u = 1 \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = 0 \\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v = u^2 + \\lambda^2 \\,,\n\\end{align*}\\] so that the first fundamental form is \\[\n\\mathscr{F}_1 =\n\\left(\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right)\n=\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & u^2 + \\lambda^2\n\\end{array}\n\\right) \\,.\n\\] Since \\(\\mathscr{F}_1\\) is diagonal, the inverse is immediately computed \\[\n\\mathscr{F}_1^{-1}\n=\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & \\dfrac{1}{u^2 + \\lambda^2}\n\\end{array}\n\\right) \\,.\n\\] Moreover \\[\\begin{align*}\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v & =\n\\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n\\cos(v)  &  \\sin(v)  &  0 \\\\\n-u \\sin(v) & u \\cos(v) & \\lambda\n\\end{array}\n\\right| \\\\\n& =\n(\\lambda \\sin (v), - \\lambda \\cos(v), u)\n\\end{align*}\\] and so \\[\n\\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| = \\sqrt{u^2 + \\lambda^2} \\,.\n\\] The standard unit normal to \\({\\pmb{\\sigma}}\\) is \\[\n\\mathbf{N}= \\frac{ {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v }{ \\left\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\right\\| } =\n\\frac{1}{\\sqrt{u^2 + \\lambda^2}} \\, (\\lambda \\sin(v), -\\lambda \\cos(v), u) \\,.\n\\] Hence \\[\\begin{align*}\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}= 0 \\\\\nM & = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}= - \\frac{\\lambda}{\\sqrt{u^2 + \\lambda^2}} \\\\\nN & = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}= 0 \\\\\n\\end{align*}\\] and the second funamental form \\(\\mathscr{F}_2\\) is \\[\n\\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right)\n=\n\\left(\n\\begin{array}{cc}\n0 & - \\dfrac{\\lambda}{\\sqrt{u^2 + \\lambda^2}} \\\\\n- \\dfrac{\\lambda}{\\sqrt{u^2 + \\lambda^2}} & 0\n\\end{array}\n\\right) \\,.\n\\] Finally \\[\\begin{align*}\n\\mathcal{W}& = \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\\\\n& =\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & \\dfrac{1}{u^2 + \\lambda^2}\n\\end{array}\n\\right)    \n\\left(\n\\begin{array}{cc}\n0 & - \\dfrac{\\lambda}{\\sqrt{u^2 + \\lambda^2}} \\\\\n- \\dfrac{\\lambda}{\\sqrt{u^2 + \\lambda^2}} & 0\n\\end{array}\n\\right) \\\\\n& =\n\\left(\n\\begin{array}{cc}\n0 & - \\dfrac{\\lambda}{(u^2 + \\lambda^2)^{1/2}} \\\\\n\\dfrac{\\lambda}{(u^2 + \\lambda^2)^{3/2}} & 0\n\\end{array}\n\\right) \\,.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.15: Plot of Helicoid.\n\n\n\n\n\n\nExample 161\nFind the Weingarten matrix of the following surface chart \\[\n{\\pmb{\\sigma}}(u, v) = \\left(u-v, u+v, u^{2}+v^{2}\\right) \\,.\n\\]\n\nSolution. Start by computing the first fundamental form: \\[\\begin{align*}\n{\\pmb{\\sigma}}_{u} & =(1,1,2u) \\\\\n{\\pmb{\\sigma}}_{v} & =(-1,1,2v) \\\\  \nE & = {\\pmb{\\sigma}}_{u} \\cdot {\\pmb{\\sigma}}_u  = 2 (1+2u^2) \\\\\nF & = {\\pmb{\\sigma}}_{u} \\cdot {\\pmb{\\sigma}}_v  = 4uv \\\\\nG & = {\\pmb{\\sigma}}_{v} \\cdot {\\pmb{\\sigma}}_v  = 2 (1+2v^2)\n\\end{align*}\\] so that \\[\n\\mathscr{F}_{1}=\n\\left(\n\\begin{array}{ll}\nE & F \\\\\nF & G\n\\end{array}\n\\right)\n=\n\\left(\\begin{array}{ll}\n2(1 + 2u^2) & 4uv \\\\\n4uv & 2(1 + 2v^2)\n\\end{array}\\right)\n\\] The determinant of \\(\\mathscr{F}_1\\) is \\[\n\\det (\\mathscr{F}_1) = 4 (1+2u^2 + 2v^2)\n\\] and therefore \\[\\begin{align*}\n\\mathscr{F}_{1}^{-1} & = \\frac{1}{\\det (\\mathscr{F}_1)}\n\\left(\n\\begin{array}{ll}\nG & -F \\\\\n-F & E\n\\end{array}\n\\right) \\\\\n& = \\frac{1}{2(1 + 2u^2 + 2v^2)}\n\\,\\left(\\begin{array}{ll}\n1 + 2v^2 & -2uv \\\\\n- 2uv & 1 + 2u^2\n\\end{array}\\right) \\,.\n\\end{align*}\\] We now need to compute the second fundamental form \\[\\begin{align*}\n{\\pmb{\\sigma}}_{u u} & =(0,0,2) \\\\\n{\\pmb{\\sigma}}_{u v} & =(0,0,0) \\\\\n{\\pmb{\\sigma}}_{v v} & =(0,0,2) \\\\\n{\\pmb{\\sigma}}_{u} \\times {\\pmb{\\sigma}}_{v} & =\\left|\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n1 & 1 & 2 u \\\\\n-1 & 1 & 2 v\n\\end{array}\\right| \\\\\n& =2(v-u,-u-v, 1) \\\\\n\\left\\|{\\pmb{\\sigma}}_{u} \\times {\\pmb{\\sigma}}_{v}\\right\\| & =2\\left( 1 + 2u^2 + 2v^2\\right)^{\\frac{1}{2}} \\\\\n\\mathbf{N}& =\\frac{(v-u,-u-v, 1)}{ \\left( 1 + 2 u^2 + 2 v^2 \\right)^{\\frac{1}{2}}} \\\\\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}=\\frac{2}{\\left( 1 + 2u^{2}+ 2v^{2}\\right)^{\\frac{1}{2}}} \\\\\nM & = {\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}= 0 \\\\\nN & = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}= \\frac{2}{\\left(1 + 2u^{2}+ 2v^{2}\\right)^{\\frac{1}{2}}}\n\\end{align*}\\] so that \\[\\begin{align*}\n\\mathscr{F}_{2} & =\n\\left(\\begin{array}{ll}\nL & M \\\\\nM & N\n\\end{array}\\right) \\\\\n& =\n\\frac{2}{\\left( 1 + 2u^{2}+ 2v^{2}\\right)^{\\frac{1}{2}}} \\, \\left(\\begin{array}{ll}\n1 & 0 \\\\\n0 & 1\n\\end{array}\\right) \\,.\n\\end{align*}\\] The matrix of the Weingarten map is \\[\\begin{align*}\n\\mathcal{W}& = \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\\\\n& =\n\\frac{1}{(1 + 2u^2 + 2v^2)^{\\frac32}}\n\\,\\left(\\begin{array}{ll}\n1 + 2v^2 & -2uv \\\\\n- 2uv & 1 + 2u^2\n\\end{array}\\right) \\,.\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_4.html#curvatures",
    "href": "sections/chap_4.html#curvatures",
    "title": "4  Surfaces",
    "section": "4.13 Curvatures",
    "text": "4.13 Curvatures\nCurvatures of a surface \\(\\mathcal{S}\\) are scalars associated to the Weingarten map \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\). We will define:\n\nGaussian curvature\nMean curvature\nPrincipal curvatures\nNormal curvature\nGeodesic curvature\n\n\n4.13.1 Gaussian and mean curvature\nThe Weingarten map of \\(\\mathcal{S}\\) encodes the rate of change of the standard unit normal \\(\\mathbf{N}\\). We use this map to produce scalar values, which we call curvatures. The first two curvatures that we consider are called Gaussian and mean curvatures.\n\nDefinition 162: Gaussian and mean curvature\nLet \\(\\mathcal{S}\\) be an orientable surface and let \\(\\mathcal{W}\\) denote the matrix of the Weingarten map \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). We define:\n\nThe Gaussian curvature of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) as \\[\nK := \\det (\\mathcal{W}) \\,,\n\\]\nThe mean curvature of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) as \\[\nH := \\frac12 \\, \\operatorname{trace} (\\mathcal{W}) \\,,\n\\]\n\n\n\n\nNotation: Trace of a \\(2 \\times 2\\) matrixWe recall that the trace of a \\(2 \\times 2\\) matrix \\(A\\) is defined as the sum of the diagonal entries, that is, \\[\n\\operatorname{trace} A = a + d \\,, \\quad\nA =\n\\left(\n\\begin{array}{cc}\na & b \\\\\nc & d\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\nRemark 163\nThe Gaussian curvature and mean curvature do not depend on the choice of basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Indeed, if \\(\\widetilde{\\mathcal{W}}\\) is the matrix of the Weingarten map with respect to the basis \\(\\{\\widetilde{{\\pmb{\\sigma}}}_u,\\widetilde{{\\pmb{\\sigma}}}_v\\}\\) of \\(T_{\\mathbf{p}} \\mathcal{S}\\), then \\[\n\\det (\\mathcal{W}) = \\det (\\widetilde{\\mathcal{W}}) \\,, \\quad\n\\operatorname{trace} (\\mathcal{W}) = \\operatorname{trace} (\\widetilde{\\mathcal{W}}) \\,.\n\\]\n\nThe above is true by a general linear algebra result: The determinant and trace of a matrix are invariant under change of basis.\n\n\n\nSince we have shown that the matrix of the Weingarten map is \\[\n\\mathcal{W}= \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\,,\n\\] we can express \\(K\\) and \\(H\\) in terms of the first and second fundamental forms.\n\nProposition 164Let \\(\\mathcal{S}\\) be an orientable surface and \\({\\pmb{\\sigma}}\\) a regular chart at \\(\\mathbf{p}\\). Then \\[\nK =\n\\frac{ LN-M^2 }{ EG - F^2 } \\,, \\quad\nH =\n\\frac{LG - 2MF - NE}{2 (EG - F^2)} \\,.\n\\]\n\n\n\nProofBy Theorem 159 the matrix of the Weingarten map \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) is given by \\[\n\\mathcal{W}= \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\,.\n\\] We have \\[\\begin{align*}\n\\det (\\mathscr{F}_1) & =\n\\left|\n\\begin{array}{cc}\nE & F \\\\\nF & G\n\\end{array}\n\\right| = EF - G^2 \\,, \\\\\n\\det (\\mathscr{F}_2) & =\n\\left|\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right| = LN - M^2 \\,.\n\\end{align*}\\] By the properties of determinant we get \\[\n\\det (\\mathscr{F}_1^{-1}) = \\frac{1}{\\det (\\mathscr{F}_1)} = \\frac{1}{EF - G^2} \\,,\n\\] and therefore \\[\\begin{align*}\nK & = \\det (\\mathcal{W})  = \\det \\left( \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\right) \\\\\n  & =  \\det (\\mathscr{F}_1^{-1})  \\det (\\mathscr{F}_2)\n= \\frac{ LN-M^2 }{ EG - F^2 } \\, .\n\\end{align*}\\] To compute \\(H\\) we need to find the diagonal entries of \\(\\mathcal{W}\\). Since \\[\n\\mathscr{F}_1^{-1} =\n\\frac{1}{EG - F^2}\n\\left(\n\\begin{array}{cc}\nG & -F \\\\\n-F & E\n\\end{array}\n\\right)\n\\] we have \\[\n\\mathcal{W}= \\frac{1}{EG - F^2}\n\\left(\n\\begin{array}{cc}\nG & -F \\\\\n-F & E\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{cc}\nL & M \\\\\nM & N\n\\end{array}\n\\right) \\,.\n\\] From the above we compute \\[\\begin{align*}\nw_{11} & = \\frac{1}{EG - F^2} \\left( LG - MF  \\right) \\\\\nw_{22} & = \\frac{1}{EG - F^2} \\left( -MF + EN  \\right) \\\\\n\\end{align*}\\] Therefore \\[\\begin{align*}\nH & = \\frac12 \\operatorname{trace} \\mathcal{W}\\\\\n  & = \\frac12 \\left (w_{11} + w_{22} \\right) \\\\\n  & = \\frac{LG - 2MF + EN}{2 (EG - F^2)}  \\,.\n\\end{align*}\\]\n\n\n\nExample 165: PlaneConsider the plane charted by \\[\n{\\pmb{\\sigma}}(u,v) = \\mathbf{a} + \\mathbf{p}u + \\mathbf{q} v \\,, \\quad u \\in (0,2\\pi)\\,, \\, u, v \\in \\mathbb{R}\\,.\n\\] We have already computed in Example 106 and Example 143 that the first and second fundamental forms of \\({\\pmb{\\sigma}}\\) are \\[\n\\mathscr{F}_1 =\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & 1\n\\end{array}\n\\right) \\,, \\quad\n\\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\n0 & 0 \\\\\n0 & 0\n\\end{array}\n\\right) \\,.\n\\] Therefore the matrix of the Weingarten map is \\[\n\\mathcal{W}= \\mathscr{F}_1^{-1} \\mathscr{F}_2\n=\n\\left(\n\\begin{array}{cc}\n0 & 0 \\\\\n0 & 0\n\\end{array}\n\\right)  \\,.\n\\] Hence the Gaussian curvature is \\[\nK = \\det (\\mathcal{W}) = 0 \\,,\n\\] while the mean curvature is \\[\nH = \\frac12 \\, \\operatorname{trace} \\mathcal{W}=  0 \\,.\n\\]\n\n\n\nExample 166: Unit cylinderConsider the unit cylinder charted by \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u), v) \\,, \\quad u \\in (0,2\\pi)\\,, \\, v \\in \\mathbb{R}\\,.\n\\] We have already computed in Example 107 and Example 144 that the first and second fundamental forms of \\({\\pmb{\\sigma}}\\) are \\[\n\\mathscr{F}_1 =\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & 1\n\\end{array}\n\\right) \\,, \\quad\n\\mathscr{F}_2 =\n\\left(\n\\begin{array}{cc}\n-1 & 0 \\\\\n0 & 0\n\\end{array}\n\\right) \\,.\n\\] Therefore the matrix of the Weingarten map is \\[\\begin{align*}\n\\mathcal{W}& = \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\\\\n& =\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & 1\n\\end{array}\n\\right)\n\\left(\n\\begin{array}{cc}\n-1 & 0 \\\\\n0 & 0\n\\end{array}\n\\right)  \\\\\n& =\n\\left(\n\\begin{array}{cc}\n-1 & 0 \\\\\n0 & 0\n\\end{array}\n\\right)  \\,.\n\\end{align*}\\] Therefore the Gaussian curvature is \\[\nK = \\det (\\mathcal{W}) = 0 \\,,\n\\] while the mean curvature is \\[\nH = \\frac12 \\, \\operatorname{trace} \\mathcal{W}=  - \\frac12 \\,.\n\\]\n\n\n\n\n4.13.2 Principal curvatures\nLet \\(V\\) be a two-dimensional vector space. For a linear map \\(L \\colon V \\to V\\) we say that \\(\\lambda \\in \\mathbb{R}\\) is an eigenvalue of \\(L\\) with eigenvector \\(\\mathbf{v}\\in V\\) if \\[\nL(\\mathbf{v})  = \\lambda \\mathbf{v}\\,, \\quad \\mathbf{v}\\neq 0 \\,.\n\\] Suppose \\(A \\in \\mathbb{R}^{2 \\times 2}\\) is the matrix of \\(L\\) with respect to a basis \\(\\{\\mathbf{v}_1,\\mathbf{v}_2\\}\\) of \\(V\\). Denote by \\[\n\\mathbf{x}= (\\lambda,\\mu) \\,, \\quad\n\\mathbf{v}= \\lambda \\mathbf{w}_1 + \\mu \\mathbf{w}_2 \\,.\n\\] the vector of coordinates of \\(\\mathbf{v}\\). Then \\[\nA\\mathbf{v}= \\lambda \\mathbf{v}\\,,\n\\] meaning that \\(\\lambda\\) is an eigenvalue of \\(A\\) with eigenvector \\(\\mathbf{x}\\). The eigenvalues of \\(A\\) can be computed by solving the characteristic equation \\[\nP(\\lambda) = 0 \\,, \\quad P(\\lambda) := \\det \\left(  A - \\lambda I  \\right)  \\,,\n\\] where \\(P\\) is the characteristic polynomial of \\(A\\). Finally, we recall that \\(A \\in \\mathbb{R}^{2 \\times 2}\\) is diagonalizable if there exists a diagonal matrix \\(D\\) and an invertible matrix \\(P\\) such that \\[\nA = P^{-1} D P \\,.\n\\]\n\nTheorem 167Let \\(\\mathcal{S}\\) be an orientable surface and let \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) be the Weingarten map at \\(\\mathbf{p}\\). There exist scalars \\(\\kappa_1, \\kappa_2 \\in \\mathbb{R}\\) and an orthonormal basis \\(\\{\\mathbf{t}_1,\\mathbf{t}_2\\}\\) of \\(T_{\\mathbf{p}} \\mathcal{S}\\) such that \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) = \\kappa_1 \\mathbf{t}_1 \\,,\n\\quad \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) = \\kappa_2 \\mathbf{t}_2 \\,.\n\\]\n\n\n\nProofLet \\({\\pmb{\\sigma}}\\) be a chart for \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). Then \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) is a basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Let \\(\\mathcal{W}\\) be the matrix of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) with respect to such basis. By Theorem 159 we have \\[\n\\mathcal{W}= \\mathscr{F}_1^{-1} \\mathscr{F}_2 \\,.\n\\] Recall that \\[\n\\mathscr{F}_1^{-1} = \\frac{1}{EG - F^2 }\n\\left(\n\\begin{array}{cc}\nG & - F\\\\\n-F & E\n\\end{array}\n\\right)  \\,.\n\\] Thus \\(\\mathcal{F}_1^{-1}\\) is symmetric. Since \\(\\mathcal{F}_2\\) is symmetric, and the product of symmetric matrices is symmetric, we conclude that \\(\\mathcal{W}\\) is symmetric. Therefore \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) is self-adjoint, see Remark 15. The thesis now follows from the Spectral Theorem, see Theorem 13.\n\n\nThe matrix version of Theorem 167 is given in the following Corollary.\n\nCorollary 168\nLet \\(\\mathcal{S}\\) be orientable, and let \\(\\mathcal{W}\\) the matrix of the Weingarten map \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) with respect to the basis \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) of \\(T_{\\mathbf{p}}\\mathcal{S}\\), where \\({\\pmb{\\sigma}}\\) is a regular chart at \\(\\mathbf{p}\\). Let \\(\\kappa_1,\\kappa_2,\\mathbf{t}_1,\\mathbf{t}_2\\) be as in Theorem 167. Let \\(\\lambda_1, \\lambda_2, \\mu_1, \\mu_2 \\in \\mathbb{R}\\) be such that \\[\n\\mathbf{t}_1 = \\lambda_1 {\\pmb{\\sigma}}_u + \\mu_1 {\\pmb{\\sigma}}_v \\,, \\quad\n\\mathbf{t}_2 = \\lambda_2 {\\pmb{\\sigma}}_u + \\mu_2 {\\pmb{\\sigma}}_v \\,.\n\\] and denote \\[\n\\mathbf{x}_1 = (\\lambda_1,\\mu_1) \\,, \\quad\n\\mathbf{x}_2 = (\\lambda_2,\\mu_2) \\,.\n\\] They hold:\n\nThe scalars \\(\\kappa_1,\\kappa_2\\) are eingenvalues of \\(\\mathcal{W}\\) of eigenvectors \\(\\mathbf{x}_1\\) and \\(\\mathbf{x}_2\\), that is, \\[\n\\mathcal{W}\\mathbf{x}_1 = \\kappa_1 \\mathbf{x}_1 \\,, \\quad\n\\mathcal{W}\\mathbf{x}_2 = \\kappa_2 \\mathbf{x}_2 \\,.\n\\]\nThe matrix \\(\\mathcal{W}\\) is diagonalizable, with \\[\n\\mathcal{W}= P^{-1} D P \\,, \\quad\nD =\n\\left(\n\\begin{array}{cc}\n\\kappa_1 & 0 \\\\\n0   & \\kappa_2\n\\end{array}\n\\right) \\,, \\quad\nP =\n\\left(\n\\begin{array}{cc}\n\\lambda_1 & \\lambda_2 \\\\\n\\mu_1 & \\mu_2\n\\end{array}\n\\right) \\,.\n\\]\n\n\n\n\nProofRecall that \\(\\mathcal{W}\\) is the matrix of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) with respect to the basis \\(\\{{\\pmb{\\sigma}}_u,{\\pmb{\\sigma}}_v\\}\\) of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Therefore, by definition of \\(\\mathbf{x}_1\\), \\(\\mathbf{x}_2\\) we get \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) = \\mathcal{W}\\mathbf{x}_1 \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) = \\mathcal{W}\\mathbf{x}_2 \\,.\n\\] The thesis follows by Theorem 167 and the Spectral Theorem for matrices, see Theorem 19.\n\n\nThe eigenvalues and eigenvectors of the weingarten map have a name.\n\nDefinition 169: Principal curvatures and vectors\nLet \\(\\mathcal{S}\\) be an orientable surface and \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) be the Weingarten map of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). We define:\n\nThe principal curvatures of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) are the eigenvalues \\(\\kappa_1, \\kappa_2\\) of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\).\nThe principal vectors corresponding to \\(\\kappa_1\\) and \\(\\kappa_2\\) are the eigenvectors \\(\\mathbf{t_1}, \\mathbf{t}_2\\).\n\n\n\n\nRemark 170: Computing principal curvatures and vectors\nCorollary 168 gives an explicit way to compute the principal curvatures and vectors:\n\nCompute the eigenvalues of \\(\\mathcal{W}\\). This is done by solving for \\(\\kappa\\) the equation \\[\n\\det(\\mathcal{W}- \\kappa I) = 0 \\,.\n\\] This gives one of the principal curvatures \\[\n\\kappa_i = \\kappa\n\\]\nCompute the eigenvector(s) related to the eigenvalue \\(\\kappa\\). This is done by finding scalars \\(\\lambda\\), \\(\\mu\\) which solve the linear system \\[\n(\\mathcal{W}- \\kappa_i I)\n\\left(\n\\begin{array}{c}\n\\lambda \\\\\n\\mu\n\\end{array}\n\\right) = 0\n\\] This gives the eigenvector of \\(\\mathcal{W}\\) \\[\n\\mathbf{x}_i = (\\lambda,\\mu)\n\\]\nThe principal vector associated to \\(\\kappa_i\\) is\n\\[\n\\mathbf{t}_i = \\lambda {\\pmb{\\sigma}}_u + \\mu {\\pmb{\\sigma}}_v\n\\]\n\n\n\n\nRemark 171: Computing principal curvatures and vectorsIf the matrix of the Weingarten map has the form \\[\n\\mathcal{W}=\n\\left(\n\\begin{array}{cc}\n\\kappa_1 & 0 \\\\\n0        & \\kappa_2\n\\end{array}\n\\right)\n\\] then \\(\\mathcal{W}\\) is already diagonal. The eigenvalues of \\(\\mathcal{W}\\) are \\(\\kappa_1\\) and \\(\\kappa_2\\), with eigenvectors \\[\n\\mathbf{x}_1 = (1,0) \\,, \\quad\n\\mathbf{x}_2 = (0,1) \\,.\n\\] Therefore \\(\\kappa_1,\\kappa_2\\) are the principal curvatures, with principal vectors given by \\[\n\\mathbf{t}_1 = {\\pmb{\\sigma}}_u \\,, \\quad \\mathbf{t}_2 = {\\pmb{\\sigma}}_v \\,.\n\\]\n\n\nThe principal curvatures are related to the Gaussian and mean curvatures.\n\nProposition 172Let \\(\\mathcal{S}\\) be an orientable surface. Then \\[\nK = \\kappa_1 \\kappa_2 \\,, \\quad H = \\frac{\\kappa_1 + \\kappa_2}{2} \\,.\n\\]\n\n\n\nProofBy Corollary 168 we have \\[\n\\mathcal{W}= P^{-1} D P \\,, \\quad\nD =\n\\left(\n\\begin{array}{cc}\n\\kappa_1 & 0 \\\\\n0        & \\kappa_2\n\\end{array}\n\\right) \\,.\n\\] By the properties of determinant \\[\n\\det \\left(  A B \\right) = \\det (A) \\det (B) \\,, \\quad \\forall \\, A,B \\in \\mathbb{R}^{2 \\times 2} \\,.\n\\] By definition of Gaussian curvature and the above formula we infer \\[\\begin{align*}\nK & = \\det ( \\mathcal{W}) \\\\\n  & = \\det \\left( P^{-1} D P  \\right) \\\\\n  & = \\det (P^{-1}) \\det (D) \\det (P) \\\\\n  & = \\det (D) \\\\\n  & = \\kappa_1 \\kappa_2 \\,,\n\\end{align*}\\] where we also used that \\[\n\\det(P^{-1}) = \\frac{1}{\\det(P)}  \\,.\n\\] The trace satisfies \\[\n\\operatorname{trace} \\left(  A B \\right) = \\operatorname{trace} \\left( BA \\right) \\,, \\quad \\forall \\, A,B \\in \\mathbb{R}^{2 \\times 2} \\,.\n\\] By definition of mean curvature and the above formula we get \\[\\begin{align*}\nH & = \\frac12 \\operatorname{trace} (\\mathcal{W}) \\\\\n  & = \\frac12 \\operatorname{trace} \\left( P^{-1} D P  \\right) \\\\\n  & = \\frac12 \\operatorname{trace} \\left( P P^{-1} D  \\right) \\\\\n  & = \\frac12 \\operatorname{trace} \\left( D  \\right) \\\\\n  & = \\frac{1}{2} \\left( \\kappa_1  + \\kappa_2 \\right) \\,,\n\\end{align*}\\] concluding the proof.\n\n\n\nImportantIn general \\(\\kappa_1\\) and \\(\\kappa_2\\) are hard to compute, as they require solving a second order equation. Instead \\(K\\) and \\(H\\) are easier to compute, as they are directly expressed in terms of the first and second fundamental form coefficients.\n\n\n\nExample 173: Unit CylinderConsider the unit cylinder charted by \\[\n{\\pmb{\\sigma}}(u,v) = (\\cos(u), \\sin(u), v) \\,, \\quad u \\in (0,2\\pi)\\,, \\, v \\in \\mathbb{R}\\,.\n\\] We have already computed in Example 166 that the matrix of the Weingarten map is \\[\n\\mathcal{W}=\n\\left(\n\\begin{array}{cc}\n-1 & 0 \\\\\n0 & 0\n\\end{array}\n\\right)  \\,.\n\\] Since \\(\\mathcal{W}\\) is diagonal, the eigenvalues are the diagonal entries of \\(\\mathcal{W}\\) and eigenvectors are \\[\n\\mathbf{x}_1 = (1,0), \\quad \\mathbf{x}_2 = (0,1) \\,.\n\\] Therefore the principal curvatures are \\[\n\\kappa_1 = - 1 \\,, \\quad \\kappa_2 = 0\n\\] and the principal vectors are \\[\\begin{align*}\n\\mathbf{t}_1 & = {\\pmb{\\sigma}}_u = (-\\sin(u),\\cos(v),0) \\,,\\\\\n\\mathbf{t}_2 & = {\\pmb{\\sigma}}_v = (0,0,1)\\,,\n\\end{align*}\\] as shown in Figure 4.16.\n\n\n\n\n\n\n\n\nFigure 4.16: Principal vectors of the unit cylinder.\n\n\n\n\nExample 174: Sphere\nConsider the chart for the sphere \\[\n{\\pmb{\\sigma}}(u, v)=(\\cos (u) \\sin (v), \\sin (u) \\sin (v), \\cos (v))\n\\] Prove that \\[\n\\mathcal{F}_1 =\n\\mathcal{F}_2 =\n\\left(\n\\begin{array}{cc}\n\\sin^2(v) & 0 \\\\\n0         & 1\n\\end{array}\n\\right) \\,, \\quad\n\\mathcal{W}=\n\\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & 1\n\\end{array}\n\\right) \\,,\n\\] and \\[\nK = H = \\kappa_1 = \\kappa_2 =1 \\,, \\quad \\mathbf{t}_1 = {\\pmb{\\sigma}}_u \\,, \\quad\n\\mathbf{t}_2 = {\\pmb{\\sigma}}_v \\,.\n\\]\n\nSolution. We compute \\[\\begin{align*}\n{\\pmb{\\sigma}}_u & = (-\\sin(u)\\sin(v), \\cos(u)\\sin(v),0) \\\\\n{\\pmb{\\sigma}}_v & = (\\cos(u)\\cos(v), \\sin(u)\\cos(v), - \\sin(v)) \\\\\nE & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_u = \\sin^2(v) \\\\\nF & = {\\pmb{\\sigma}}_u \\cdot {\\pmb{\\sigma}}_v = 0\\\\\nG & = {\\pmb{\\sigma}}_v \\cdot {\\pmb{\\sigma}}_v = 1\n\\end{align*}\\] and therefore the first fundamental form is \\[\n\\mathcal{F}_1 =\n\\left(\n\\begin{array}{cc}\n\\sin^2(v) & 0 \\\\\n0         & 1\n\\end{array}\n\\right) \\,.\n\\] Moreover \\[\\begin{align*}\n{\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v & =\n\\left|\n\\begin{array}{ccc}\n\\mathbf{i}& \\mathbf{j}& \\mathbf{k}\\\\\n-\\sin(u)\\sin(v)  & \\cos(u)\\sin(v) & 0 \\\\\n\\cos(u)\\cos(v) & \\sin(u)\\cos(v) & - \\sin(v)\n\\end{array}\n\\right| \\\\\n& = (-\\cos(u)\\sin^2(v),\n-\\sin(u) \\sin^2(v),\n- \\cos(v)\\sin(v)) \\\\\n\\| {\\pmb{\\sigma}}_u \\times {\\pmb{\\sigma}}_v \\| & = |\\sin(v)| \\\\\n\\mathbf{N}& = (- \\cos(u) \\sin(v), -\\sin(u)\\sin(v), -\\cos(v) ) \\\\\n{\\pmb{\\sigma}}_{uu} & = (-\\cos(u)\\sin(v), -\\sin(u)\\sin(v), 0 ) \\\\\n{\\pmb{\\sigma}}_{uv} & = (-\\sin(u)\\cos(v), \\cos(u)\\cos(v), 0 ) \\\\\n{\\pmb{\\sigma}}_{vv} & = (-\\cos(u)\\sin(v), -\\sin(u)\\sin(v), -\\cos(v) ) \\\\\nL & = {\\pmb{\\sigma}}_{uu} \\cdot \\mathbf{N}= \\sin^{2}(v) \\\\\nM & ={\\pmb{\\sigma}}_{uv} \\cdot \\mathbf{N}= 0 \\\\\nN & = {\\pmb{\\sigma}}_{vv} \\cdot \\mathbf{N}= 1\n\\end{align*}\\] so that the second fundamental form is \\[\n\\mathcal{F}_2 =\n\\left(\n\\begin{array}{cc}\n\\sin^2(v) & 0 \\\\\n0         & 1\n\\end{array}\n\\right) \\,.\n\\] In particular the matrix of the Weingarten map is \\[\n\\mathcal{W}= \\mathcal{F}_1^{-1}\\mathcal{F}_2 = \\left(\n\\begin{array}{cc}\n1 & 0 \\\\\n0 & 1\n\\end{array}\n\\right)\n\\] Since \\(\\mathcal{W}\\) is diagonal, the principal curvatures are \\[\n\\kappa_1 = \\kappa_2 = 1\n\\] and the principal vectors \\[\n\\mathbf{t}_1 = {\\pmb{\\sigma}}_u \\,, \\quad\n\\mathbf{t}_2 = {\\pmb{\\sigma}}_v \\,.\n\\] Finally, we have that \\[\nH = \\frac{\\kappa_1 + \\kappa_2}{2} = 1 \\,, \\quad\nK= \\kappa_1 \\kappa_2 = 1 \\,.\n\\]\n\n\n\n\nExample 175: TorusConsider a circle \\(\\mathcal{C}\\) contained in the \\(xz\\)-plane, with center at distance \\(b&gt;0\\) from the \\(z\\)-axis and radius \\(a\\), with \\(0&lt;a&lt;b\\). The torus is obtained by rotating \\(\\mathcal{C}\\) around the \\(z\\)-axis. This surface is charted by \\[\n{\\pmb{\\sigma}}(\\theta,\\phi) = \\left( \\left(a+b \\cos(\\theta) \\right) \\cos(\\phi), \\left(a+b \\cos(\\theta) \\right) \\sin(\\phi), b\\sin(\\theta) \\right) \\,,\n\\] where \\(\\theta \\in (-\\pi/2,\\pi/2)\\) and \\(\\phi\\in (0,2\\pi)\\). One can compute that the first and second fundamental forms are \\[\\begin{align*}\n\\mathscr{F}_1 & =\n\\left(   \n\\begin{array}{cc}\nb^2  &    0   \\\\\n0   & \\left(a+b \\cos(\\theta) \\right)^2\n\\end{array}\n\\right)  \\\\\n\\mathscr{F}_2 & =\n\\left(   \n\\begin{array}{cc}\nb  &    0   \\\\\n0   & \\left(a+b \\cos(\\theta) \\right) \\cos(\\theta)\n\\end{array}\n\\right) \\,.\n\\end{align*}\\] Therefore the matrix of the Weingarten map is \\[\n\\mathcal{W}= \\mathscr{F}_1^{-1} \\mathscr{F}_2 =\n\\left(   \n\\begin{array}{cc}\n\\dfrac{1}{b}  &    0   \\\\\n0   & \\dfrac{\\cos(\\theta)}{ a + b \\cos(\\theta)}\n\\end{array}\n\\right) \\,.\n\\] Since \\(\\mathcal{W}\\) is diagonal, the principal curvatures are \\[\n\\kappa_1 = \\frac{1}{b} \\,, \\quad\n\\kappa_2 = \\dfrac{\\cos(\\theta)}{ a + b \\cos(\\theta)} \\,,\n\\] and the principal vectors \\[\n\\mathbf{t}_1 = {\\pmb{\\sigma}}_u \\,, \\quad\n\\mathbf{t}_2 = {\\pmb{\\sigma}}_v \\,.\n\\] The Gaussian and mean curvature are \\[\\begin{align*}\nK & = \\kappa_1 \\kappa_2 = \\dfrac{\\cos(\\theta)}{ b  \\left(a + b \\cos(\\theta)\\right)}  \\\\\nH & = \\frac{\\kappa_1 + \\kappa_2}{2} =\n\\dfrac{a + 2b \\cos(\\theta)}{2 b \\left(a + b \\cos(\\theta)\\right)}  \n\\end{align*}\\]\n\n\n\n\n4.13.3 Normal and geodesic curvatures\nLet \\(\\mathcal{S}\\) be a regular surface and consider all the curves \\({\\pmb{\\gamma}}\\) on \\(\\mathcal{S}\\) passing through the point \\(\\mathbf{p}\\in \\mathcal{S}\\).\n\nQuestion 176Which curves through \\(\\mathbf{p}\\) have greatest or lowest curvature?\n\n\nWe start our analysis with the following proposition.\n\nProposition 177Let \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\) be a unit speed curve. Then \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{N}, \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\}\n\\] is an orthornormal basis of \\(\\mathbb{R}^3\\) for all \\(t \\in (a,b)\\), where \\(\\mathbf{N}\\) is the standard unit normal to \\(\\mathcal{S}\\) evaluated at \\(\\mathbf{p}= {\\pmb{\\gamma}}(t)\\).\n\n\n\nProofBy definition \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\in T_{\\mathbf{p}} \\mathcal{S}\\,, \\quad \\mathbf{p}:= {\\pmb{\\gamma}}(t) \\,,\n\\] for all \\(t \\in (a,b)\\). This means \\(\\dot{{\\pmb{\\gamma}}}\\) is tangent to \\(\\mathcal{S}\\). Thus \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{N}= 0 \\,.\n\\] We have \\(\\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\| = 1\\) since \\({\\pmb{\\gamma}}\\) is unit speed. Moreover \\(\\left\\| \\mathbf{N} \\right\\|=1\\) by definition. Since \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{N}\\) are orthogonal, we also obtain \\[\n\\left\\| \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}} \\right\\| = \\left\\| \\mathbf{N} \\right\\| \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\| = 1 \\,,\n\\] by the properties of vector product. Finally \\[\n(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}) \\cdot \\mathbf{N}= 0 \\,, \\quad\n(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}) \\cdot \\dot{{\\pmb{\\gamma}}}= 0 \\,, \\quad\n\\] by the properties of vector product.\n\n\n\nImportantNotice that the basis \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{N}, \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\}\n\\] does not coincide with the Frenet frame of \\({\\pmb{\\gamma}}\\) in general.\n\n\n\nProposition 178Let \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\) be a unit speed curve. Then \\[\n\\ddot{{\\pmb{\\gamma}}}= \\kappa_n \\mathbf{N}+ \\kappa_g \\, \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) \\,,\n\\tag{4.12}\\] where \\(\\mathbf{N}\\) is evaluated at \\(\\mathbf{p}:={\\pmb{\\gamma}}(t)\\) and \\(\\kappa_n,\\kappa_g\\) are scalars depedent on \\(\\mathbf{p}\\). Moreover \\[\n\\kappa_n = \\ddot{{\\pmb{\\gamma}}}\\cdot \\mathbf{N}\\,, \\quad \\kappa_g = \\ddot{{\\pmb{\\gamma}}}\\cdot \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right)  \\,,\n\\tag{4.13}\\] \\[\n\\kappa^2 = \\kappa_n^2 + \\kappa_g^2 \\,,\n\\tag{4.14}\\] \\[\n\\kappa_n = \\kappa \\cos (\\phi) \\,, \\quad  \\kappa_g = \\pm \\kappa \\sin(\\phi) \\,,\n\\tag{4.15}\\] where \\(\\kappa\\) is the curvature of \\({\\pmb{\\gamma}}\\) and \\(\\phi\\) is the angle between \\(\\mathbf{N}\\) and \\(\\mathbf{n}\\), the principal unit normal of \\({\\pmb{\\gamma}}\\).\n\n\n\nProofPart 1. By Proposition 177 we know that \\[\n\\{ \\dot{{\\pmb{\\gamma}}}, \\mathbf{N}, \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\}\n\\] is an orthornormal basis of \\(\\mathbb{R}^3\\). Hence \\[\n\\ddot{{\\pmb{\\gamma}}}= a \\dot{{\\pmb{\\gamma}}}+ b \\mathbf{N}+ c \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) \\,,\n\\] for some coefficients \\(a,b,c \\in \\mathbb{R}\\). Since \\({\\pmb{\\gamma}}\\) is unit speed, we have that \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= 0 \\,.\n\\] On the other hand, \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\ddot{{\\pmb{\\gamma}}}= a  (\\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}) + b ( \\dot{{\\pmb{\\gamma}}}\\cdot \\mathbf{N}) +\nc \\dot{{\\pmb{\\gamma}}}\\cdot \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) = a \\,,\n\\] since \\(\\dot{{\\pmb{\\gamma}}}\\) is orthogonal to \\(\\mathbf{N}\\) and \\(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\), and \\[\n\\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}= \\left\\| \\dot{{\\pmb{\\gamma}}} \\right\\|^2 = 1 \\,.\n\\] Therefore \\(a = 0\\) and \\[\n\\ddot{{\\pmb{\\gamma}}}= b \\mathbf{N}+ c \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) \\,.\n\\] Setting \\(\\kappa_n := b\\) and \\(\\kappa_g := c\\) we conclude (4.12).\nPart 2. Taking the scalar product of (4.12) with \\(\\mathbf{N}\\) yields \\[\n\\ddot{{\\pmb{\\gamma}}}\\cdot \\mathbf{N}= \\kappa_n \\left\\| \\mathbf{N} \\right\\|^2 + \\kappa_g \\left( \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) \\cdot \\mathbf{N}= \\kappa_n \\,,\n\\] where we used that \\(\\mathbf{N}\\) and \\(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\) are orthonormal vectors. Similarly, taking the scalar product of (4.12) with \\(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\) yields the second equation in (4.13).\nPart 3. By (4.12) we infer \\[\\begin{align*}\n\\left\\| \\ddot{{\\pmb{\\gamma}}} \\right\\|^2 & = \\kappa_n^2 \\left\\| \\mathbf{N} \\right\\|^2 + 2 \\kappa_n \\kappa_g \\mathbf{N}\\cdot\n\\left(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\right) + \\kappa_g^2  \\left\\| \\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}} \\right\\|^2 \\\\\n              & = \\kappa_n^2 + \\kappa_g^2 \\,,\n\\end{align*}\\] where we used that \\(\\mathbf{N}\\) and \\(\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}}\\) are orthonormal. Since \\(\\kappa(t) = \\left\\| \\ddot{{\\pmb{\\gamma}}}(t) \\right\\|\\), we get (4.14).\nPart 4. Recalling that \\[\n\\ddot{{\\pmb{\\gamma}}}= \\kappa \\mathbf{n}\\,,\n\\] from the first equation in (4.13) we obtain \\[\\begin{align*}\n\\kappa_n & = \\ddot{{\\pmb{\\gamma}}}\\cdot \\mathbf{N}\\\\\n         & = \\kappa \\mathbf{n}\\cdot \\mathbf{N}\\\\\n         & = \\kappa \\| \\mathbf{n}\\|^2 \\| \\mathbf{N}\\|^2 \\cos(\\phi) \\\\\n         & = \\kappa \\cos(\\phi) \\,,\n\\end{align*}\\] where we used that \\(\\mathbf{n}\\) and \\(\\mathbf{N}\\) have unit norm. Hence the first equation in (4.15) is established. By (4.14) we get \\[\\begin{align*}\n\\kappa_g^2 & = \\kappa^2 - \\kappa_n^2 \\\\\n           & = \\kappa^2 \\cos^2(\\phi) -  \\kappa_n^2 \\\\\n           & = \\kappa^2 (\\cos^2(\\phi) - 1 ) \\\\\n           & = \\kappa^2 \\sin^2(\\phi) \\,,\n\\end{align*}\\] from which we obtain the second equation in (4.15).\n\n\nThe quantities \\(\\kappa_n\\) and \\(\\kappa_g\\) are the normal and geodesic curvatures of \\({\\pmb{\\gamma}}\\).\n\nDefinition 179: Normal and geodesic curvature\nLet \\(\\mathcal{S}\\) be regular and \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\) a unit speed curve. By (4.12) we have \\[\n\\ddot{{\\pmb{\\gamma}}}= \\kappa_{n} \\mathbf{N}+ \\kappa_{g} (\\mathbf{N}\\times \\dot{{\\pmb{\\gamma}}})\n\\] for \\(\\mathbf{N}\\) the standard unit normal to \\(\\mathcal{S}\\) and scalars \\(\\kappa_n , \\kappa_g \\in \\mathbb{R}\\). We call\n\n\\(\\kappa_{n}\\) the normal curvature of \\({\\pmb{\\gamma}}\\),\n\\(\\kappa_{g}\\) the geodesic curvature of \\({\\pmb{\\gamma}}\\).\n\n\n\nThe normal curvature \\(\\kappa_n\\) can be computed via the second fundamental form, as shown in the theorem below.\n\nTheorem 180\nLet \\(\\mathcal{S}\\) be a regular surface and \\({\\pmb{\\gamma}}\\colon (a,b) \\to \\mathcal{S}\\) a unit speed curve. Denote \\(\\mathbf{p}:= {\\pmb{\\gamma}}(t)\\). We have:\n\nThe normal curvature \\(\\kappa_n\\) satisfies \\[\n\\kappa_n = {II}_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}, \\dot{{\\pmb{\\gamma}}}) \\,.\n\\]\nLet \\({\\pmb{\\sigma}}\\) be a chart for \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). Then \\[\n{\\pmb{\\gamma}}(t)={\\pmb{\\sigma}}(u(t), v(t))\n\\] for some smooth functions \\(u,v \\colon (a,b) \\to \\mathbb{R}\\), and \\[\n\\kappa_{n}=L \\dot{u}^{2}+2 M \\dot{u} \\dot{v}+N \\dot{v}^{2} \\,.\n\\]\n\n\n\n\nProofPart 1. By definition we have \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\in T_{\\mathbf{p}} \\mathcal{S}\n\\] when \\(\\mathbf{p}= {\\pmb{\\gamma}}(t)\\). Set \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) := \\mathbf{N}( {\\pmb{\\gamma}}(t)) \\,.\n\\tag{4.16}\\] By definition of differential we have \\[\nd_{\\mathbf{p}} \\mathbf{N}(\\dot{{\\pmb{\\gamma}}}(t)) = \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t)  \\,.\n\\tag{4.17}\\] Note that \\[\n\\widetilde{{\\pmb{\\gamma}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t) = 0 \\,,\n\\] since \\(\\mathbf{N}\\) is normal to \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\) and \\(\\dot{{\\pmb{\\gamma}}}(t) \\in T_{\\mathbf{p}}(\\mathcal{S})\\). Differentiating the above expression we get \\[\\begin{align*}\n0 & = \\frac{d}{dt} \\left( \\widetilde{{\\pmb{\\gamma}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t) \\right) \\\\\n  & = \\widetilde{{\\pmb{\\gamma}}}(t) \\cdot \\ddot{{\\pmb{\\gamma}}}(t)  + \\dot{\\widetilde{{\\pmb{\\gamma}}}}(t) \\cdot \\dot{{\\pmb{\\gamma}}}(t)   \\\\\n  & = \\mathbf{N}({\\pmb{\\gamma}}(t)) \\cdot \\ddot{{\\pmb{\\gamma}}}(t)  + d_{\\mathbf{p}} \\mathbf{N}(\\dot{{\\pmb{\\gamma}}}(t)) \\cdot \\dot{{\\pmb{\\gamma}}}(t)  \n\\end{align*}\\] where in the last equation we used (4.16) and (4.17). Hence \\[\n- d_{\\mathbf{p}} \\mathbf{N}(\\dot{{\\pmb{\\gamma}}}(t)) \\cdot \\dot{{\\pmb{\\gamma}}}(t)  =\n\\mathbf{N}({\\pmb{\\gamma}}(t))  \\cdot  \\ddot{{\\pmb{\\gamma}}}(t)   \\,.\n\\tag{4.18}\\] By definition of Weingarten and Gauss map we get \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\dot{{\\pmb{\\gamma}}}(t)) = - d_{\\mathbf{p}} \\mathcal{G} (\\dot{{\\pmb{\\gamma}}}(t)) =  \n- d_{\\mathbf{p}} \\mathbf{N}(\\dot{{\\pmb{\\gamma}}}(t)) \\,.\n\\tag{4.19}\\] Therefore, using (4.18) and (4.19), we infer \\[\\begin{align*}\nII_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}(t) , \\dot{{\\pmb{\\gamma}}}(t) ) & = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\dot{{\\pmb{\\gamma}}}(t)) \\cdot \\dot{{\\pmb{\\gamma}}}(t) \\\\\n                            & = - d_{\\mathbf{p}} \\mathbf{N}(\\dot{{\\pmb{\\gamma}}}(t)) \\cdot \\dot{{\\pmb{\\gamma}}}(t) \\\\\n                            & = \\mathbf{N}({\\pmb{\\gamma}}(t))  \\cdot  \\ddot{{\\pmb{\\gamma}}}(t) \\\\\n                            & = \\kappa_n \\,,\n\\end{align*}\\] where in the last equality we used (4.13).\nPart 2. Let \\({\\pmb{\\sigma}}\\) be a chart at \\(\\mathbf{p}\\) and \\[\n{\\pmb{\\gamma}}(t) = {\\pmb{\\sigma}}(u(t),v(t)) \\,.\n\\] Differentiating the above expression we get \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\dot{u} {\\pmb{\\sigma}}_u + \\dot{v} {\\pmb{\\sigma}}_v \\,.\n\\] By definition of \\(du\\) and \\(dv\\), see Definition 101, we have \\[\ndu(\\dot{{\\pmb{\\gamma}}}(t)) = \\dot{u}(t) \\,, \\quad\ndv(\\dot{{\\pmb{\\gamma}}}(t)) = \\dot{v}(t) \\,.\n\\] Therefore, using Part 1 and Theorem 156, we obtain \\[\\begin{align*}\n\\kappa_n & = II_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}}(t) , \\dot{{\\pmb{\\gamma}}}(t) ) \\\\\n         & = L du(\\dot{{\\pmb{\\gamma}}}(t))^2 + 2M du(\\dot{{\\pmb{\\gamma}}}(t)) dv(\\dot{{\\pmb{\\gamma}}}(t)) + N dv(\\dot{{\\pmb{\\gamma}}}(t))^2 \\\\\n         & = L \\dot{u}^{2}+2 M \\dot{u} \\dot{v}+N \\dot{v}^{2} \\,.\n\\end{align*}\\]\n\n\n\nExample 181: Curves on the sphere\nConsider the chart for the sphere \\[\n{\\pmb{\\sigma}}(u, v)=(\\cos (u) \\sin (v), \\sin (u) \\sin (v), \\cos (v))\n\\] Show that \\[\n\\kappa_{n}(t)=1\n\\] for all unit speed curves on the sphere.\n\nSolution. We have computed in Example 174 that the second fundamental form of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathcal{F}_2 = \\sin^{2}(v) du^2 + dv^2\n\\] Let \\({\\pmb{\\gamma}}\\) be a unit speed curve on the sphere, that is, \\[\n{\\pmb{\\gamma}}(t)=\\sigma(u(t), v(t)) \\,.\n\\tag{4.20}\\] By Theorem 180 the normal curvature of \\({\\pmb{\\gamma}}\\) is \\[\n\\kappa_{n}=\\sin^{2}(v) \\dot{u}^{2}+\\dot{v}^{2} \\,.\n\\] Differentiating (4.20) we get \\[\\begin{align*}\n\\dot{{\\pmb{\\gamma}}}(t) & = \\frac{d}{dt} ( \\cos(u(t)) \\sin(v(t)), \\sin(u(t)) \\sin(v(t)), \\cos(v(t)) ) \\\\\n& = (-\\dot{u} \\sin (u) \\sin (v)+\\dot{v} \\cos (u) \\cos (v), \\dot{u} \\cos (u) \\sin (v)+ \\\\\n& \\qquad \\dot{v} \\sin (u) \\cos (v),-\\dot{v} \\sin (v))\n\\end{align*}\\] so that \\[\n\\| \\dot{{\\pmb{\\gamma}}}(t) \\|^2 =  \\sin^{2}(v) \\dot{u}^{2}+\\dot{v}^{2} \\,.\n\\] Since \\({\\pmb{\\gamma}}\\) is unit speed, we also get \\[\n\\|\\dot{{\\pmb{\\gamma}}}\\|^{2} = 1 \\,,\n\\] showing that \\[\n\\kappa_{n}=\\sin^{2}(v) \\dot{u}^{2}+\\dot{v}^{2} = 1 \\,,\n\\] as required.\n\n\n\nThe normal curvature \\(\\kappa_n\\) is related to the principal curvatures \\(\\kappa_1\\) and \\(\\kappa_2\\).\n\nTheorem 182: Euler’s TheoremLet \\(\\mathcal{S}\\) be a regular surface and denote by \\(\\kappa_1, \\kappa_2\\) the principal curvatures with principal vectors \\(\\mathbf{t}_1,\\mathbf{t}_2\\). Let \\({\\pmb{\\gamma}}\\) be a unit speed curve on \\(\\mathcal{S}\\). The normal curvature of \\({\\pmb{\\gamma}}\\) is given by \\[\n\\kappa_n = \\kappa_1 \\cos^2(\\theta) + \\kappa_2 \\sin^2(\\theta) \\,,\n\\] where \\(\\theta\\) is the angle between \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{t}_1\\).\n\n\n\nProofLet \\({\\pmb{\\gamma}}\\) be a unit speed curve on \\(\\mathcal{S}\\) and set \\[\n\\mathbf{p}:= {\\pmb{\\gamma}}(t) \\,.\n\\] By Theorem 167 the principal vectors \\(\\{ \\mathbf{t}_1, \\mathbf{t}_2 \\}\\) form an orthonormal basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Since by definition \\[\n\\dot{{\\pmb{\\gamma}}}(t) \\in T_{\\mathbf{p}} \\mathcal{S}\\,,\n\\] there exist scalars \\(\\lambda,\\mu \\in \\mathbb{R}\\) such that \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\lambda \\mathbf{t}_1 + \\mu \\mathbf{t}_2 \\,.\n\\] As \\({\\pmb{\\gamma}}\\) is unit speed and \\(\\mathbf{t}_1, \\mathbf{t}_2\\) orthonormal, we infer \\[\n1 = \\left\\| \\dot{{\\pmb{\\gamma}}}(t) \\right\\|^2 = \\dot{{\\pmb{\\gamma}}}\\cdot \\dot{{\\pmb{\\gamma}}}= \\lambda^2 + \\mu^2 \\,.\n\\] Therefore there exists \\(\\theta \\in [0,2\\pi]\\) such that \\[\n\\lambda = \\cos(\\theta), \\quad\n\\mu = \\sin(\\theta) \\,.\n\\] Hence \\[\n\\dot{{\\pmb{\\gamma}}}(t) = \\cos(\\theta) \\mathbf{t}_1 + \\sin(\\theta) \\mathbf{t}_2 \\,.\n\\tag{4.21}\\] In particular, we can take the scalar product of (4.21) with \\(\\mathbf{t}_1\\) to get \\[\n\\cos(\\theta) = \\lambda = \\dot{{\\pmb{\\gamma}}}(t) \\cdot \\mathbf{t}_1 \\,.\n\\] Since \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{t}_1\\) are unit vectors, from the above equation we conclude that \\(\\theta\\) is the angle between \\(\\dot{{\\pmb{\\gamma}}}\\) and \\(\\mathbf{t}_1\\). In addition, recall that \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) = \\kappa_1 \\mathbf{t}_1 \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) = \\kappa_2 \\mathbf{t}_2 \\,,\n\\] and \\(\\mathbf{t}_1\\), \\(\\mathbf{t}_2\\) are orthonormal. Thus \\[\\begin{align*}\nII_{\\mathbf{p}}(\\mathbf{t}_1 , \\mathbf{t}_1) & = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) \\cdot \\mathbf{t}_1 = \\kappa_1 \\left\\| \\mathbf{t}_1 \\right\\|^2 = \\kappa_1 \\\\\nII_{\\mathbf{p}}(\\mathbf{t}_1 , \\mathbf{t}_2) & = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) \\cdot \\mathbf{t}_2 = \\kappa_1  \\mathbf{t}_1 \\cdot \\mathbf{t}_2 = 0 \\\\\nII_{\\mathbf{p}}(\\mathbf{t}_2 , \\mathbf{t}_1) & = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) \\cdot \\mathbf{t}_1 = \\kappa_2  \\mathbf{t}_2 \\cdot \\mathbf{t}_1 = 0 \\\\\nII_{\\mathbf{p}}(\\mathbf{t}_2 , \\mathbf{t}_2) & = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) \\cdot \\mathbf{t}_2 = \\kappa_2 \\left\\| \\mathbf{t}_2 \\right\\|^2 = \\kappa_2 \\\\\n\\end{align*}\\] By Theorem 180, equation (4.21), and bilinearity of \\(II_{\\mathbf{p}}\\), we get \\[\\begin{align*}\n\\kappa_n & = {II}_{\\mathbf{p}} (\\dot{{\\pmb{\\gamma}}},\\dot{{\\pmb{\\gamma}}}) \\\\\n& = \\cos^2(\\theta) \\, II_{\\mathbf{p}}(\\mathbf{t}_1 , \\mathbf{t}_1)  +  \\cos(\\theta) \\sin(\\theta) \\,  II_{\\mathbf{p}}(\\mathbf{t}_1 , \\mathbf{t}_2) \\\\\n& \\,\\,\\,\\, + \\sin(\\theta)\\cos(\\theta)  \\,  II_{\\mathbf{p}}(\\mathbf{t}_2 , \\mathbf{t}_1)  + \\sin^2(\\theta)  \\,  II_{\\mathbf{p}}(\\mathbf{t}_2 , \\mathbf{t}_2)  \\\\\n& = \\cos^2(\\theta) \\kappa_1 + \\sin^2(\\theta) \\kappa_2\n\\end{align*}\\] ending the proof.\n\n\nAs an immediate corollary of the Euler’s Theorem we get the next statement.\n\nCorollary 183\nLet \\(\\mathcal{S}\\) be a regular surface and \\(\\kappa_1, \\kappa_2\\) its principal curvatures at \\(\\mathbf{p}\\) with principal vectors \\(\\mathbf{t}_1,\\mathbf{t}_2\\). Then:\n\n\\(\\kappa_{1}\\) and \\(\\kappa_{2}\\) are the minimum and maximum values of \\(\\kappa_{n}\\), for all unit speed curves on \\(\\mathcal{S}\\) passing through \\(\\mathbf{p}\\).\nThe directions of lowest and highest curvature on \\(\\mathcal{S}\\) are given by \\(\\mathbf{t}_1\\) and \\(\\mathbf{t}_2\\).\n\n\n\nIn Example 181 we have shown with a direct argument that \\[\n\\kappa_n = 1\n\\] for all unit speed curves on the sphere. Thanks to Euler’s Theorem we can obtain an immediate proof of this fact.\n\nExample 184: Curves on the sphereLet us consider again the chart for the sphere \\[\n{\\pmb{\\sigma}}(u, v)=(\\cos (u) \\sin (v), \\sin (u) \\sin (v), \\cos (v))\n\\] as seen in Example 181. By Example 174, the principal curvatures of \\({\\pmb{\\sigma}}\\) are \\[\n\\kappa_1 = \\kappa_2 =  1 \\,.\n\\] By Euler’s Theorem, for any curve \\({\\pmb{\\gamma}}\\) on the sphere we have \\[\n\\kappa_n = \\kappa_1 \\cos^2(\\theta) + \\kappa_2 \\sin^2(\\theta) = 1 \\,.\n\\]\n\n\n\n\n4.13.4 Local shape of a surface\nThe principal curvatures \\(\\kappa_1\\) and \\(\\kappa_2\\) determine the maximum and minimum curvature of a surface \\(\\mathcal{S}\\), see Corollary 183. Hence we can study the local shape of \\(\\mathcal{S}\\) in function of \\(\\kappa_1\\) and \\(\\kappa_2\\).\n\nTheorem 185: Local structure of surfacesLet \\(\\mathcal{S}\\) be a regular surface and \\(\\mathbf{p}\\in \\mathcal{S}\\). In the vicinity of \\(\\mathbf{p}\\) the surface \\(\\mathcal{S}\\) is approximated by the quadric surface of equation \\[\nz = \\frac12 \\left( x^2 \\kappa_1 (\\mathbf{p}) + y^2 \\kappa_2(\\mathbf{p}) \\right) \\,,\n\\tag{4.22}\\] where \\(\\kappa_1 (\\mathbf{p}),\\kappa_2 (\\mathbf{p})\\) are the principal curvatures of \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\).\n\n\n\nProofBy Theorem 167 the principal vectors \\(\\{ \\mathbf{t}_1, \\mathbf{t}_2 \\}\\) are an orthonormal basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Therefore the standard unit normal \\(\\mathbf{N}\\) at \\(\\mathbf{p}\\) is orthogonal to both \\(\\mathbf{t}_1\\) and \\(\\mathbf{t}_2\\). Up to rotations and translations, we can assume WLOG that \\(\\mathbf{p}= {\\pmb{0}}\\) and \\[\n\\mathbf{t}_1 = (1,0,0) \\,, \\quad\n\\mathbf{t}_2 = (0,1,0) \\,, \\quad\n\\mathbf{N}= (0,0,1) \\,.\n\\tag{4.23}\\] Let \\({\\pmb{\\sigma}}\\) be a chart for \\(\\mathcal{S}\\) at \\(\\mathbf{p}\\). Up to reparametrizing, we can assume that \\[\n{\\pmb{\\sigma}}(0,0)  = \\mathbf{p}= {\\pmb{0}}\\,.\n\\] As \\(\\mathbf{N}= (0,0,1)\\), it follows that \\(T_{\\mathbf{p}} \\mathcal{S}\\) is the \\(xy\\)-plane \\[\nT_{\\mathbf{p}} \\mathcal{S}= \\mathbb{R}^2 = \\{ (x,y,0) \\, \\colon \\,x, y \\in \\mathbb{R}\\} \\, .\n\\] Since \\(\\{{\\pmb{\\sigma}}_u ,{\\pmb{\\sigma}}_v\\}\\) is a basis for \\(T_{\\mathbf{p}} \\mathcal{S}\\), we have that for each \\((x,y) \\in \\mathbb{R}^2\\) there exist \\((s,t) \\in \\mathbb{R}^2\\) such that \\[\n(x,y,0) = s {\\pmb{\\sigma}}_u + t {\\pmb{\\sigma}}_v \\,,\n\\tag{4.24}\\] where \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are evaluated at \\((0,0)\\). The Taylor approximation of \\({\\pmb{\\sigma}}\\) at \\((0,0)\\) is \\[\\begin{align*}\n{\\pmb{\\sigma}}(s,t) & = {\\pmb{\\sigma}}(0,0) + s {\\pmb{\\sigma}}_u + t {\\pmb{\\sigma}}_v \\\\\n          & \\qquad + \\frac12 \\left(  s^2 {\\pmb{\\sigma}}_{uu} + 2st {\\pmb{\\sigma}}_{uv} + t^2 {\\pmb{\\sigma}}_{vv}   \\right) + R \\,, \\\\\n          & = (x,y,0) + \\frac12 \\left(  s^2 {\\pmb{\\sigma}}_{uu} + 2st {\\pmb{\\sigma}}_{uv} + t^2 {\\pmb{\\sigma}}_{vv}   \\right) + R\n\\end{align*}\\] where \\(R\\) is a remainder and the derivatives of \\({\\pmb{\\sigma}}\\) are evaluated at \\((0,0)\\). Hence, if \\(x,y\\) are small (and thus \\(s,t\\) are small), we have that \\[\n{\\pmb{\\sigma}}(s,t) \\approx  (x,y,z)\n\\] where \\[\\begin{align*}\nz & := \\frac12 \\left(  s^2 {\\pmb{\\sigma}}_{uu} + 2st {\\pmb{\\sigma}}_{uv} + t^2 {\\pmb{\\sigma}}_{vv}   \\right) \\cdot \\mathbf{N}\\\\\n  & = \\frac12 \\left( L s^2  + 2M st + N t^2   \\right) \\,,\n\\end{align*}\\] with \\(L,M,N\\) coefficients of the second fundamental form of \\({\\pmb{\\sigma}}\\) at \\((0,0)\\). Set \\[\n\\mathbf{v}:=  s {\\pmb{\\sigma}}_u + t {\\pmb{\\sigma}}_v  \\,.\n\\] By Theorem 156 we have \\[\nL s^2  + 2M st + N t^2  = II_{\\mathbf{p}} (\\mathbf{v},\\mathbf{v}) = \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) \\cdot \\mathbf{v}\\,.\n\\] On the other hand, using (4.23) and (4.24) we get \\[\n\\mathbf{v}= s {\\pmb{\\sigma}}_u + t {\\pmb{\\sigma}}_v  = (x,y,0) = x \\mathbf{t}_1 + y \\mathbf{t}_2 \\,.\n\\] Since the Weingarten map is linear we get \\[\\begin{align*}\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) & = x  \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_1) + y  \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) \\\\\n    & = x \\kappa_1 \\mathbf{t}_1 + y \\kappa_2 \\mathbf{t}_2 \\,,\n\\end{align*}\\] where we used that \\(\\mathbf{t}_1\\) and \\(\\mathbf{t}_2\\) are eigenvectors of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) with eigenvalues \\(\\kappa_1\\) and \\(\\kappa_2\\). Hence \\[\\begin{align*}\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) \\cdot \\mathbf{v}& =  x \\kappa_1 \\mathbf{t}_1 + y \\kappa_2 \\mathbf{t}_2 \\cdot ( x \\mathbf{t}_1 + y  \\mathbf{t}_2) \\\\\n                               & = x^2 \\kappa_1 + y^2 \\kappa_2  \n\\end{align*}\\] Therefore \\[\\begin{align*}\nz & = \\frac12 \\left( L s^2  + 2M st + N t^2   \\right) \\\\\n  & = \\frac12 \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) \\cdot \\mathbf{v}\\\\\n  & = \\frac12 \\left( x^2 \\kappa_1 + y^2 \\kappa_2  \\right) \\,,\n\\end{align*}\\] showing that \\[\n{\\pmb{\\sigma}}(t,s) \\approx \\left(x,y, \\frac12 \\left( x^2 \\kappa_1 + y^2 \\kappa_2  \\right)  \\right) \\,.\n\\]\n\n\nThanks to Theorem 185 we can distinguish between \\(4\\) approximating shapes.\n\nDefinition 186: Local shape types\nLet \\(\\mathcal{S}\\) be a regular surface and denote by \\(\\kappa_1(\\mathbf{p})\\) and \\(\\kappa_2(\\mathbf{p})\\) its principal curvatures at \\(\\mathbf{p}\\). The point \\(\\mathbf{p}\\) is\n\nElliptic if \\[\n\\kappa_1(\\mathbf{p}) &gt; 0 \\,, \\, \\kappa_2(\\mathbf{p}) &gt; 0 \\quad \\mbox{ or } \\quad  \\kappa_1(\\mathbf{p}) &lt; 0 \\,, \\, \\kappa_2(\\mathbf{p}) &lt; 0\n\\] Then (4.22) is the equation of an elliptic paraboloid.\nHyperbolic if \\[\n\\kappa_{1}(\\mathbf{p})&lt;0&lt;\\kappa_{2}(\\mathbf{p})  \\quad \\mbox{ or } \\quad  \\kappa_{2}(\\mathbf{p})&lt;0&lt; \\kappa_{1}(\\mathbf{p})\n\\] Then (4.22) is the equation of a hyperbolic paraboloid.\nParabolic if \\[\n\\kappa_{1}(\\mathbf{p})=0 \\, , \\, \\kappa_{2}(\\mathbf{p}) \\neq 0 \\quad \\mbox{ or } \\quad \\kappa_{2}(\\mathbf{p}) \\neq 0, \\, \\kappa_{1}(\\mathbf{p})=0\n\\] Then (4.22) is the equation of a parabolic cylinder.\nPlanar if \\[\n\\kappa_{1}(\\mathbf{p})=\\kappa_{2}(\\mathbf{p}) = 0\n\\] Then (4.22) is the equation of a plane.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.17: A surface \\(\\mathcal{S}\\) is locally approximated by one of the above quadrics, depending on the values of principal curvatures at \\(\\mathbf{p}\\).\n\n\n\n\nExample 187\nConsider the surface chart \\[\n{\\pmb{\\sigma}}(u, v) = \\left(u-v, u+v, u^{2}+v^{2}\\right) \\,.\n\\] Show that \\(\\mathbf{p}= {\\pmb{\\sigma}}(1,0)\\) is an elliptic point. Therefore \\({\\pmb{\\sigma}}\\) is approximated by an elliptic paraboiloid in the vicinity of \\(\\mathbf{p}\\).\n\nSolution. In Example 161 we have shown that the Weingarten matrix of \\({\\pmb{\\sigma}}\\) is \\[\n\\mathcal{W}\n=\n\\frac{1}{(1 + 2u^2 + 2v^2)^{\\frac32}}\n\\,\\left(\\begin{array}{ll}\n1 + 2v^2 & -2uv \\\\\n- 2uv & 1 + 2u^2\n\\end{array}\\right) \\,.\n\\] For \\(u=1\\) and \\(v=1\\) we obtain \\[\n\\mathcal{W}\n=\n\\frac{1}{3^{\\frac32}}\n\\,\\left(\\begin{array}{ll}\n1  & 0 \\\\\n0 &  3\n\\end{array}\\right)\n=\n\\left(\\begin{array}{ll}\n3^{-\\frac32}  & 0 \\\\\n0 &  3^{- \\frac12}\n\\end{array}\\right) \\,.\n\\] Therefore the principal curvatures at \\(\\mathbf{p}\\) are \\[\n\\kappa_1(\\mathbf{p}) = 3^{-\\frac32} \\,, \\quad\n\\kappa_2(\\mathbf{p}) = 3^{-\\frac12} \\,. \\quad\n\\] Since \\(\\kappa_1(\\mathbf{p}) &gt; 0\\) and \\(\\kappa_2(\\mathbf{p}) &gt; 0\\) we have that \\(\\mathbf{p}\\) is an elliptic point.\n\n\n\n\n\n4.13.5 Umbilical points\n\nDefinition 188: Umbilical pointLet \\(\\mathcal{S}\\) be a regular surface and denote by \\(\\kappa_1(\\mathbf{p})\\) and \\(\\kappa_2(\\mathbf{p})\\) its principal curvatures at \\(\\mathbf{p}\\). We say that \\(\\mathbf{p}\\) is an umbilic if \\[\n\\kappa_{1}(\\mathbf{p})=\\kappa_{2}(\\mathbf{p}) \\,.\n\\]\n\n\n\nRemark 189Umbilical points might be planar or elliptic.\n\n\nSuppose that \\(\\mathbf{p}\\) is an umbilic, that is, \\[\n\\kappa_1=\\kappa_2\n\\] at \\(\\mathbf{p}\\). Let \\(\\kappa_n\\) be the normal curvature of a unit speed curve \\({\\pmb{\\gamma}}\\) passing through \\(\\mathbf{p}\\). By Theorem 182 we have \\[\n\\kappa_n = \\kappa_1 \\cos^2(\\theta) + \\kappa_2 \\sin^2(\\theta) = \\kappa_1 \\,.\n\\] Therefore \\(\\kappa_n\\) does not depend on \\({\\pmb{\\gamma}}\\). Intuitively, this can only happen if in the vicinity of \\(\\mathbf{p}\\) the surface looks like a sphere or a plane. Indeed, the following theorem holds.\n\nTheorem 190Let \\(\\mathcal{S}\\) be a regular surface such that every point \\(\\mathbf{p}\\in \\mathcal{S}\\) is umbilic. Then \\(\\mathcal{S}\\) is an open subset of plane or a sphere.\n\n\n\nProof\nBy assumption we have \\[\n\\kappa_1 (\\mathbf{p}) = \\kappa_2 (\\mathbf{p}) = \\kappa (\\mathbf{p}) \\,, \\quad \\forall \\, \\mathbf{p}\\in \\mathcal{S}\\,.\n\\tag{4.25}\\]\nStep 1. \\(\\kappa\\) is constant.\nBy Theorem 167 the principal vectors \\(\\{\\mathbf{t}_1,\\mathbf{t}_2\\}\\) are an orthonormal basis of \\(T_{\\mathbf{p}} \\mathcal{S}\\). Hence, for each \\(\\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\) there exist \\(\\lambda,\\mu \\in \\mathbb{R}\\) such that \\[\n\\mathbf{v}= \\lambda \\mathbf{t}_1 + \\mu \\mathbf{t}_2 \\,.\n\\] Using the linearity of \\(\\mathcal{W}_{\\mathbf{p},\\mathcal{S}}\\) and (4.25) we obtain \\[\\begin{align*}\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) & = \\lambda \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ( \\mathbf{t}_1) + \\mu  \\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{t}_2) \\\\\n                     & = \\lambda \\kappa \\mathbf{t}_1 + \\mu \\kappa \\mathbf{t}_2 \\\\\n                     & = \\kappa \\mathbf{v}\\,,\n\\end{align*}\\] showing that \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} (\\mathbf{v}) = \\kappa \\mathbf{v}\\,, \\quad \\forall \\, \\mathbf{v}\\in T_{\\mathbf{p}} \\mathcal{S}\\,.\n\\tag{4.26}\\] Let \\({\\pmb{\\sigma}}\\colon U \\to \\mathbb{R}^3\\) be a chart of \\(\\mathcal{S}\\). Up to restricting \\({\\pmb{\\sigma}}\\), we can assume that \\(U\\) is connected. By Lemma 158 we have \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) = - \\mathbf{N}_{u} \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) = - \\mathbf{N}_{v} \\,.\n\\] On the other hand, by (4.26) we infer \\[\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_u) = \\kappa {\\pmb{\\sigma}}_u \\,, \\quad\n\\mathcal{W}_{\\mathbf{p},\\mathcal{S}} ({\\pmb{\\sigma}}_v) = \\kappa {\\pmb{\\sigma}}_v \\,,\n\\] from which \\[\n\\mathbf{N}_{u} = - \\kappa {\\pmb{\\sigma}}_u \\,, \\quad\n\\mathbf{N}_{v} = - \\kappa {\\pmb{\\sigma}}_v \\,.\n\\tag{4.27}\\] Thus \\[\n\\left( \\kappa {\\pmb{\\sigma}}_u \\right)_v = - \\left( \\mathbf{N}_u \\right)_v =\n- \\left( \\mathbf{N}_v \\right)_u = \\left( \\kappa {\\pmb{\\sigma}}_v \\right)_u \\,.\n\\] Moreover \\[\\begin{align*}\n\\left( \\kappa {\\pmb{\\sigma}}_u \\right)_v & = \\kappa_v {\\pmb{\\sigma}}_u + \\kappa {\\pmb{\\sigma}}_{uv} \\\\\n\\left( \\kappa {\\pmb{\\sigma}}_v \\right)_u & = \\kappa_u {\\pmb{\\sigma}}_v + \\kappa {\\pmb{\\sigma}}_{uv} \\,,\n\\end{align*}\\] so that \\[\n\\kappa_v {\\pmb{\\sigma}}_u = \\kappa_u {\\pmb{\\sigma}}_v \\,.\n\\tag{4.28}\\] Recall that \\({\\pmb{\\sigma}}_u\\) and \\({\\pmb{\\sigma}}_v\\) are linearly independent, being \\(\\mathcal{S}\\) regular. Hence the linear combination at (4.28) must be trivial, implying \\[\n\\kappa_u = \\kappa_v = 0 \\,.\n\\] Since \\(U\\) is connected, the above implies that \\(\\kappa\\) is constant.\nStep 2. We have the two cases \\(\\kappa = 0\\) and \\(\\kappa \\neq 0\\).\n\nAssume \\(\\kappa = 0\\). By (4.27) we get that \\[\n\\mathbf{N}_u = \\mathbf{N}_v = {\\pmb{0}}\\,,\n\\] which implies \\(\\mathbf{N}\\) is constant. Therefore \\[\n\\left( \\mathbf{N}\\cdot {\\pmb{\\sigma}}\\right)_u = \\mathbf{N}_u \\cdot {\\pmb{\\sigma}}+ \\mathbf{N}\\cdot {\\pmb{\\sigma}}_u = 0  \n\\] since \\(\\mathbf{N}_u = {\\pmb{0}}\\) and \\(\\mathbf{N}\\cdot {\\pmb{\\sigma}}_u = 0\\) because \\(\\mathbf{N}\\) is orthogonal to \\(T_{\\mathbf{p}} \\mathcal{S}\\). Similarly we get \\[\n\\left( \\mathbf{N}\\cdot {\\pmb{\\sigma}}\\right)_v = 0 \\,,\n\\] showing that \\(\\mathbf{N}\\cdot {\\pmb{\\sigma}}\\) is constant. Hence there exists \\(c \\in \\mathbb{R}\\) such that \\[\n\\mathbf{N}\\cdot {\\pmb{\\sigma}}(u,v) = c \\,, \\quad \\forall \\, (u,v) \\in U \\,.\n\\] This shows \\({\\pmb{\\sigma}}(U)\\) is contained in the plane \\[\n\\pi = \\{ \\mathbf{x}\\in \\mathbb{R}^3 \\, \\colon \\,\\mathbf{N}\\cdot \\mathbf{x}= c \\} \\,.\n\\]\nAssume \\(\\kappa \\neq 0\\). Condition (4.27) implies \\[\n\\mathbf{N}= -\\kappa {\\pmb{\\sigma}}+ \\mathbf{a}\n\\] for some \\(\\mathbf{a} \\in \\mathbb{R}^3\\) constant vector. Thus \\[\n\\left\\|  {\\pmb{\\sigma}}- \\frac{1}{\\kappa} \\mathbf{a}  \\right\\|^2 =\n\\left\\| - \\frac{1}{\\kappa}  \\mathbf{N}\\right\\|^2 = \\frac{1}{\\kappa^2} \\,,\n\\] given that \\(\\| \\mathbf{N}\\| = 1\\). Therefore \\({\\pmb{\\sigma}}(U)\\) is contained in the sphere of center \\(\\mathbf{a}/\\kappa\\) and radius \\(1/\\kappa\\).\n\n\n\n\n\n\n\nAbate, Marco, and Tovena, Francesca. 2011. Curves and Surfaces. Springer.\n\n\nPressley, Andrew. 2010. Elementary Differential Geometry. Second Edition. Springer.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Surfaces</span>"
    ]
  },
  {
    "objectID": "sections/chap_5.html",
    "href": "sections/chap_5.html",
    "title": "5  Plots with Python",
    "section": "",
    "text": "5.1 Curves in Python",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Plots with Python</span>"
    ]
  },
  {
    "objectID": "sections/chap_5.html#sec-plot-curves",
    "href": "sections/chap_5.html#sec-plot-curves",
    "title": "5  Plots with Python",
    "section": "",
    "text": "5.1.1 Curves in 2D\nSuppose we want to plot the parabola \\(y=t^2\\) for \\(t\\) in the interval \\([-3,3]\\). In our language, this is the two-dimensional curve \\[\n\\pmb{\\gamma}(t) = ( t, t^2 ) \\,, \\quad  t \\in [-3,3] \\,.\n\\] The two Python libraries we use to plot \\(\\pmb{\\gamma}\\) are numpy and matplotlib. In short, numpy handles multi-dimensional arrays and matrices, and can perform high-level mathematical functions on them. For any question you may have about numpy, answers can be found in the searchable documentation available here. Instead matplotlib is a plotting library, with documentation here. Python libraries need to be imported every time you want to use them. In our case we will import:\nimport numpy as np\nimport matplotlib.pyplot as plt\nThe above imports numpy and the module pyplot from matplotlib, and renames them to np and plt, respectively. These shorthands are standard in the literature, and they make code much more readable.\nThe function for plotting 2D graphs is called plot(x,y) and is contained in plt. As the syntax suggests, plot takes as arguments two arrays \\[\nx=[x_1, \\ldots, x_n]\\,, \\quad  y=[y_1,\\ldots,y_n]\\,.\n\\] As output it produces a graph which is the linear interpolation of the points \\((x_i,y_i)\\) in \\(\\mathbb{R}^2\\), that is, consecutive points \\((x_i,y_i)\\) and \\((x_{i+1},y_{i+1})\\) are connected by a segment. Using plot, we can graph the curve \\(\\pmb{\\gamma}(t)=(t,t^2)\\) like so:\n\n# Code for plotting gamma\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generating array t\nt = np.array([-3,-2,-1,0,1,2,3])\n\n# Computing array f\nf = t**2\n\n# Plotting the curve\nplt.plot(t,f)\n\n# Plotting dots\nplt.plot(t,f,\"ko\")\n\n# Showing the plot\nplt.show()\n\n\n\n\n\n\n\n\nLet us comment the above code. The variable t is a numpy array containing the ordered values \\[\nt = [-3,-2,-1,0,1,2,3]\\,.\n\\tag{5.1}\\] This array is then squared entry-by-entry via the operation \\(t\\ast\\!\\ast 2\\) and saved in the new numpy array f, that is, \\[\nf = [9,4,1,0,1,4,9] \\,.\n\\] The arrays t and f are then passed to plot(t,f), which produces the above linear interpolation, with t on the x-axis and f on the y-axis. The command plot(t,f,'ko') instead plots a black dot at each point \\((t_i,f_i)\\). The latter is clearly not needed to obtain a plot, and it was only included to highlight the fact that plot is actually producing a linear interpolation between points. Finally plt.show() displays the figure in the user window1.\nOf course one can refine the plot so that it resembles the continuous curve \\(\\pmb{\\gamma}(t)=(t,t^2)\\) that we all have in mind. This is achieved by generating a numpy array t with a finer stepsize, invoking the function np.linspace(a,b,n). Such call will return a numpy array which contains n evenly spaced points, starts at a, and ends in b. For example np.linspace(-3,3,7) returns our original array t at 5.1, as shown below\n\n# Displaying output of np.linspace\n\nimport numpy as np\n\n# Generates array t by dividing interval \n# (-3,3) in 7 parts\nt = np.linspace(-3,3, 7)\n\n# Prints array t\nprint(\"t =\", t)\n\nt = [-3. -2. -1.  0.  1.  2.  3.]\n\n\nIn order to have a more refined plot of \\(\\pmb{\\gamma}\\), we just need to increase \\(n\\).\n\n# Plotting gamma with finer step-size\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates array t by dividing interval \n# (-3,3) in 100 parts\nt = np.linspace(-3,3, 100)\n\n# Computes f\nf = t**2\n\n# Plotting\nplt.plot(t,f)\nplt.show()\n\n\n\n\n\n\n\n\nWe now want to plot a parametric curve \\(\\pmb{\\gamma} \\colon (a,b) \\to \\mathbb{R}^2\\) with \\[\n\\pmb{\\gamma}(t) = (x(t), y(t)) \\,.\n\\] Clearly we need to modify the above code. The variable t will still be a numpy array produced by linspace. We then need to introduce the arrays x and y which ecode the first and second components of \\(\\pmb{\\gamma}\\), respectively.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Divides time interval (a,b) in n parts\n# and saves output to numpy array t\nt = np.linspace(a, b, n)\n\n# Computes gamma from given functions x(y) and y(t)\nx = x(t)\ny = y(t)\n\n# Plots the curve\nplt.plot(x,y)\n\n# Shows the plot\nplt.show()\nWe use the above code to plot the 2D curve known as the Fermat’s spiral \\[\n\\pmb{\\gamma}(t) = ( \\sqrt{t}  \\cos(t) , \\sqrt{t}  \\sin(t) ) \\quad\n\\text{ for } \\quad t \\in [0,50] \\,.\n\\tag{5.2}\\]\n# Plotting Fermat's spiral\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Divides time interval (0,50) in 500 parts\nt = np.linspace(0, 50, 500)\n\n# Computes Fermat's Spiral\nx = np.sqrt(t) * np.cos(t)\ny = np.sqrt(t) * np.sin(t)\n\n# Plots the Spiral\nplt.plot(x,y)\nplt.show()\nBefore displaying the output of the above code, a few comments are in order. The array t has size 500, due to the behavior of linspace. You can also fact check this information by printing np.size(t), which is the numpy function that returns the size of an array. We then use the numpy function np.sqrt to compute the square root of the array t. The outcome is still an array with the same size of t, that is, \\[\nt=[t_1,\\ldots,t_n]   \\quad \\implies \\quad \\sqrt{t} = [\\sqrt{t_1}, \\ldots, \\sqrt{t_n}] \\,.\n\\] Similary, the call np.cos(t) returns the array \\[\n\\cos(t) = [\\cos(t_1), \\ldots, \\cos(t_n)] \\,.\n\\] The two arrays np.sqrt(t) and np.cos(t) are then multiplied, term-by-term, and saved in the array x. The array y is computed similarly. The command plt.plot(x,y) then yields the graph of the Fermat’s spiral:\n\n\n\n\n\nFermat’s spiral\n\n\n\n\nThe above plots can be styled a bit. For example we can give a title to the plot, label the axes, plot the spiral by means of green dots, and add a plot legend, as coded below:\n\n# Adding some style\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Computing Spiral\nt = np.linspace(0, 50, 500)\nx = np.sqrt(t) * np.cos(t)\ny = np.sqrt(t) * np.sin(t)\n\n# Generating figure\nplt.figure(1, figsize = (4,4))\n\n# Plotting the Spiral with some options\nplt.plot(x, y, '--', color = 'deeppink', linewidth = 1.5, label = 'Spiral')\n\n# Adding grid\nplt.grid(True, color = 'lightgray')\n\n# Adding title\nplt.title(\"Fermat's spiral for t between 0 and 50\")\n\n# Adding axes labels\nplt.xlabel(\"x-axis\", fontsize = 15)\nplt.ylabel(\"y-axis\", fontsize = 15)\n\n# Showing plot legend\nplt.legend()\n\n# Show the plot\nplt.show()\n\n\n\n\nAdding a bit of style\n\n\n\n\nLet us go over the novel part of the above code:\n\nplt.figure(): This command generates a figure object. If you are planning on plotting just one figure at a time, then this command is optional: a figure object is generated implicitly when calling plt.plot. Otherwise, if working with n figures, you need to generate a figure object with plt.figure(i) for each i between 1 and n. The number i uniquely identifies the i-th figure: whenever you call plt.figure(i), Python knows that the next commands will refer to the i-th figure. In our case we only have one figure, so we have used the identifier 1. The second argument figsize = (a,b) in plt.figure() specifies the size of figure 1 in inches. In this case we generated a figure 4 x 4 inches.\nplt.plot: This is plotting the arrays x and y, as usual. However we are adding a few aestethic touches: the curve is plotted in dashed style with --, in deep pink color and with a line width of 1.5. Finally this plot is labelled Spiral.\nplt.grid: This enables a grid in light gray color.\nplt.title: This gives a title to the figure, displayed on top.\nplt.xlabel and plt.ylabel: These assign labels to the axes, with font size 15 points.\nplt.legend(): This plots the legend, with all the labels assigned in the plt.plot call. In this case the only label is Spiral.\n\n\n\n\n\n\n\nMatplotlib styles\n\n\n\nThere are countless plot types and options you can specify in matplotlib, see for example the Matplotlib Gallery. Of course there is no need to remember every single command: a quick Google search can do wonders.\n\n\n\n\n\n\n\n\nGenerating arrays\n\n\n\nThere are several ways of generating evenly spaced arrays in Python. For example the function np.arange(a,b,s) returns an array with values within the half-open interval \\([a,b)\\), with spacing between values given by s. For example\n\nimport numpy as np\n\nt = np.arange(0,1, 0.2)\nprint(\"t =\",t)\n\nt = [0.  0.2 0.4 0.6 0.8]\n\n\n\n\n\n\n5.1.2 Implicit curves 2D\nA curve \\(\\pmb{\\gamma}\\) in \\(\\mathbb{R}^2\\) can also be defined as the set of points \\((x,y) \\in \\mathbb{R}^2\\) satisfying \\[\nf(x,y)=0\n\\] for some given \\(f \\colon \\mathbb{R}^2 \\to \\mathbb{R}\\). For example let us plot the curve \\(\\pmb{\\gamma}\\) implicitly defined by \\[\nf(x,y) =( 3 x^2 - y^2 )^2 \\ y^2  -  (x^2 + y^2 )^4\n\\] for \\(-1 \\leq x,y \\leq 1\\). First, we need a way to generate a grid in \\(\\mathbb{R}^2\\) so that we can evaluate \\(f\\) on such grid. To illustrate how to do this, let us generate a grid of spacing 1 in the 2D square \\([0,4]^2\\). The goal is to obtain the 5 x 5 matrix of coordinates \\[\nA = \\left(\n\\begin{matrix}\n(0,0) &  (1,0)  &  (2,0) & (3,0) & (4,0) \\\\\n(0,1) &  (1,1)  &  (2,1) & (3,1) & (4,1) \\\\\n(0,2) &  (1,2)  &  (2,2) & (2,3) & (2,4) \\\\\n(0,3) &  (1,3)  &  (2,3) & (3,3) & (3,4) \\\\\n(0,4) &  (1,4)  &  (2,4) & (3,4) & (4,4) \\\\\n\\end{matrix}\n\\right)    \n\\] which corresponds to the grid of points\n\n\n\n\n\n\n\n\nFigure 5.1: The 5 x 5 grid corresponding to the matrix A\n\n\n\n\n\nTo achieve this, first generate x and y coordinates using\nx = np.linspace(0, 4, 5)\ny = np.linspace(0, 4, 5)\nThis generates coordinates \\[\nx = [0, 1, 2, 3, 4] \\,, \\quad  y = [0, 1, 2, 3, 4] \\,.\n\\] We then need to obtain two matrices \\(X\\) and \\(Y\\): one for the \\(x\\) coordinates in \\(A\\), and one for the \\(y\\) coordinates in \\(A\\). This can be achieved with the code\nX[0,0] = 0 \nX[0,1] = 1\nX[0,2] = 2\nX[0,3] = 3\nX[0,4] = 4\nX[1,0] = 0\nX[1,1] = 1\n...\nx[4,3] = 3\nx[4,4] = 4\nand similarly for \\(Y\\). The output would be the two matrices \\(X\\) and \\(Y\\) \\[\nX = \\left(\n\\begin{matrix}\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 1 & 2 & 3 & 4 \\\\\n0 & 1 & 2 & 3 & 4 \\\\\n\\end{matrix}\n\\right)   \\,, \\quad\nY =\n\\left(\n\\begin{matrix}\n0 &  0 &  0 & 0 & 0 \\\\\n1 &  1 &  1 & 1 & 1 \\\\\n2 &  2 &  2 & 2 & 2 \\\\\n3 &  3 &  3 & 3 & 3 \\\\\n4 &  4 &  4 & 4 & 4 \\\\\n\\end{matrix}\n\\right)   \n\\]\nIf now we plot \\(X\\) against \\(Y\\) via the command\nplt.plot(X, Y, 'k.')\nwe obtain Figure 5.1. In the above command the style 'k.' represents black dots. This procedure would be impossible with large vectors. Thankfully there is a function in numpy doing exactly what we need: np.meshgrid.\n\n# Demonstrating np.meshgrid\n\nimport numpy as np\n\n# Generating x and y coordinates\nxlist = np.linspace(0, 4, 5)\nylist = np.linspace(0, 4, 5)\n\n# Generating grid X, Y\nX, Y = np.meshgrid(xlist, ylist)\n\n# Printing the matrices X and Y\n# np.array2string is only needed to align outputs\nprint('X =', np.array2string(X, prefix='X= '))\nprint('\\n')  \nprint('Y =', np.array2string(Y, prefix='Y= '))\n\nX = [[0. 1. 2. 3. 4.]\n    [0. 1. 2. 3. 4.]\n    [0. 1. 2. 3. 4.]\n    [0. 1. 2. 3. 4.]\n    [0. 1. 2. 3. 4.]]\n\n\nY = [[0. 0. 0. 0. 0.]\n    [1. 1. 1. 1. 1.]\n    [2. 2. 2. 2. 2.]\n    [3. 3. 3. 3. 3.]\n    [4. 4. 4. 4. 4.]]\n\n\nNow that we have our grid, we can evaluate the function \\(f\\) on it. This is simply done with the command\nZ =((3*(X**2) - Y**2)**2)*(Y**2) - (X**2 + Y**2)**4 \nThis will return the matrix \\(Z\\) containing the values \\(f(x_i,y_i)\\) for all \\((x_i,y_i)\\) in the grid \\([X,Y]\\). We are now interested in plotting the points in the grid \\([X,Y]\\) for which \\(Z\\) is zero. This is achieved with the command\nplt.contour(X, Y, Z, [0])\nPutting the above observations together, we have the code for plotting the curve \\(f=0\\) for \\(-1 \\leq x,y \\leq 1\\).\n\n# Plotting f=0\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Generates coordinates and grid\nxlist = np.linspace(-1, 1, 5000)\nylist = np.linspace(-1, 1, 5000)\nX, Y = np.meshgrid(xlist, ylist)\n\n# Computes f\nZ =((3*(X**2) - Y**2)**2)*(Y**2) - (X**2 + Y**2)**4 \n\n# Creates figure object\nplt.figure(figsize = (4,4))\n\n# Plots level set Z = 0\nplt.contour(X, Y, Z, [0])\n\n# Set axes labels\nplt.xlabel(\"x-axis\", fontsize = 15)\nplt.ylabel(\"y-axis\", fontsize = 15)\n\n# Shows plot\nplt.show()\n\n\n\n\nPlot of the curve defined by f=0\n\n\n\n\n\n\n5.1.3 Curves in 3D\nPlotting in 3D with matplotlib requires the mplot3d toolkit, see here for documentation. Therefore our first lines will always be\n# Packages for 3D plots\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\nWe can now generate empty 3D axes\n\n# Generates and plots empty 3D axes\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Creates figure object\nfig = plt.figure(figsize = (4,4))\n\n# Creates 3D axes object\nax = plt.axes(projection = '3d')\n\n# Shows the plot\nplt.show()\n\n\n\n\n\n\n\n\nIn the above code fig is a figure object, while ax is an axes object. In practice, the figure object contains the axes objects, and the actual plot information will be contained in axes. If you want multiple plots in the figure container, you should use the command\nax = fig.add_subplot(nrows = m, ncols = n, pos = k)\nThis generates an axes object ax in position k with respect to a m x n grid of plots in the container figure. For example we can create a 3 x 2 grid of empty 3D axes as follows\n\n# Generates 3 x 2 empty 3D axes\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Creates container figure object\nfig = plt.figure(figsize = (6,8))\n\n# Creates 6 empty 3D axes objects\nax1 = fig.add_subplot(3, 2, 1, projection = '3d')\nax2 = fig.add_subplot(3, 2, 2, projection = '3d')\nax3 = fig.add_subplot(3, 2, 3, projection = '3d')\nax4 = fig.add_subplot(3, 2, 4, projection = '3d')\nax5 = fig.add_subplot(3, 2, 5, projection = '3d')\nax6 = fig.add_subplot(3, 2, 6, projection = '3d')\n\n# Shows the plot\nplt.show()\n\n\n\n\n\n\n\n\nWe are now ready to plot a 3D parametric curve \\(\\pmb{\\gamma} \\colon (a,b) \\to \\mathbb{R}^3\\) of the form \\[\n\\pmb{\\gamma}(t) = (x(t), y(t), z(t))\n\\] with the code\n# Code to plot 3D curve\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure and 3D axes\nfig = plt.figure(figsize = (size1,size2))\nax = plt.axes(projection = '3d')\n\n# Plots grid\nax.grid(True)\n\n# Divides time interval (a,b)\n# into n parts and saves them in array t\nt = np.linspace(a, b, n)\n\n# Computes the curve gamma on array t\n# for given functions x(t), y(t), z(t)\nx = x(t) \ny = y(t)\nz = z(t)\n\n# Plots gamma\nax.plot3D(x, y, z)\n\n# Setting title for plot\nax.set_title('3D Plot of gamma')\n\n# Setting axes labels\nax.set_xlabel('x', labelpad = 'p')\nax.set_ylabel('y', labelpad = 'p')\nax.set_zlabel('z', labelpad = 'p')\n\n# Shows the plot\nplt.show()\nFor example we can use the above code to plot the Helix \\[\nx(t) = \\cos(t) \\,, \\quad\ny(t) = \\sin(t) \\,, \\quad\nz(t) = t\n\\tag{5.3}\\] for \\(t \\in [0,6\\pi]\\).\n\n# Plotting 3D Helix\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure and 3D axes\nfig = plt.figure(figsize = (4,4))\nax = plt.axes(projection = '3d')\n\n# Plots grid\nax.grid(True)\n\n# Divides time interval (0,6pi) in 100 parts \nt = np.linspace(0, 6*np.pi, 100)\n\n# Computes Helix\nx = np.cos(t) \ny = np.sin(t)\nz = t\n\n# Plots Helix - We added some styling\nax.plot3D(x, y, z, color = \"deeppink\", linewidth = 2)\n\n# Setting title for plot\nax.set_title('3D Plot of Helix')\n\n# Setting axes labels\nax.set_xlabel('x', labelpad = 20)\nax.set_ylabel('y', labelpad = 20)\nax.set_zlabel('z', labelpad = 20)\n\n# Shows the plot\nplt.show()\n\n\n\n\n\n\n\n\nWe can also change the viewing angle for a 3D plot store in ax. This is done via\nax.view_init(elev = e, azim = a)\nwhich displays the 3D axes with an elevation angle elev of e degrees and an azimuthal angle azim of a degrees. In other words, the 3D plot will be rotated by e degrees above the xy-plane and by a degrees around the z-axis. For example, let us plot the helix with 2 viewing angles. Note that we generate 2 sets of axes with the add_subplot command discussed above.\n\n# Plotting 3D Helix\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure object\nfig = plt.figure(figsize = (4,4))\n\n# Generates 2 sets of 3D axes\nax1 = fig.add_subplot(1, 2, 1, projection = '3d')\nax2 = fig.add_subplot(1, 2, 2, projection = '3d')\n\n# We will not show a grid this time\nax1.grid(False)\nax2.grid(False)\n\n# Divides time interval (0,6pi) in 100 parts \nt = np.linspace(0, 6*np.pi, 100)\n\n# Computes Helix\nx = np.cos(t) \ny = np.sin(t)\nz = t\n\n# Plots Helix on both axes\nax1.plot3D(x, y, z, color = \"deeppink\", linewidth = 1.5)\nax2.plot3D(x, y, z, color = \"deeppink\", linewidth = 1.5)\n\n# Setting title for plots\nax1.set_title('Helix from above')\nax2.set_title('Helix from side')\n\n# Changing viewing angle of ax1\n# View from above has elev = 90 and azim = 0\nax1.view_init(elev = 90, azim = 0)\n\n# Changing viewing angle of ax2\n# View from side has elev = 0 and azim = 0\nax2.view_init(elev = 0, azim = 0)\n\n# Shows the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n5.1.4 Interactive plots\nMatplotlib produces beautiful static plots; however it lacks built in interactivity. For this reason I would also like to show you how to plot curves with Plotly, a very popular Python graphic library which has built in interactivity. Documentation for Plotly and lots of examples can be found here.\n\n5.1.4.1 2D Plots\nSay we want to plot the 2D curve \\(\\pmb{\\gamma} \\colon (a,b) \\to \\mathbb{R}^2\\) parametrized by \\[\n\\pmb{\\gamma}(t) = ( x(t) , y(t) ) \\,.\n\\] The Plotly module needed is called graph_objects, usually imported as go. The function for line plots is called Scatter. For documentation and examples see link. The code for plotting \\(\\pmb{\\gamma}\\) is as follows.\n# Plotting gamma 2D\n\n# Import libraries\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Compute times grid by dividing (a,b) in \n# n equal parts\nt = np.linspace(a, b, n)\n\n# Compute the parametric curve gamma\n# for given functions x(t) and y(t)\nx = x(t)\ny = y(t)\n\n# Create empty figure object and saves \n# it in the variable \"fig\"\nfig = go.Figure()\n\n# Create the line plot object\ndata = go.Scatter(x = x, y = y, mode = 'lines', name = 'gamma')\n\n# Add \"data\" plot to the figure \"fig\"\nfig.add_trace(data)\n\n# Display the figure\nfig.show()\nSome comments about the functions called above:\n\ngo.Figure: generates an empty Plotly figure\ngo.Scatter: generates the actual plot. By default a scatter plot is produced. To obtain linear interpolation of the points, set mode = 'lines'. You can also label the plot with name = \"string\"\nadd_trace: adds a plot to a figure\nshow: displays a figure\n\nAs an example, let us plot the Fermat’s Spiral defined at 5.2. Compared to the above code, we also add a bit of styling.\n\n# Plotting Fermat's Spiral\n\n# Import libraries\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Compute times grid by dividing (0,50) in \n# 500 equal parts\nt = np.linspace(0, 50, 500)\n\n# Computes Fermat's Spiral\nx = np.sqrt(t) * np.cos(t)\ny = np.sqrt(t) * np.sin(t)\n\n# Create empty figure object and saves \n# it in the variable \"fig\"\nfig = go.Figure()\n\n# Create the line plot object\ndata = go.Scatter(x = x, y = y, mode = 'lines', name = 'gamma')\n\n# Add \"data\" plot to the figure \"fig\"\nfig.add_trace(data)\n\n# Here we start with the styling options\n# First we set a figure title\nfig.update_layout(title_text = \"Plotting Fermat's Spiral with Plotly\")\n\n# Adjust figure size\nfig.update_layout(autosize = False, width = 600, height = 600)\n\n# Change background canvas color\nfig.update_layout(paper_bgcolor = \"snow\")\n\n# Axes styling: adding title and ticks positions \nfig.update_layout(\nxaxis=dict(\n        title_text=\"X-axis Title\",\n        titlefont=dict(size=20),\n        tickvals=[-6,-4,-2,0,2,4,6],\n        ), \n\nyaxis=dict(\n        title_text=\"Y-axis Title\",\n        titlefont=dict(size=20),\n        tickvals=[-6,-4,-2,0,2,4,6],\n        )\n)\n\n# Display the figure\nfig.show()\n\n                                                \n\n\nAs you can examine by moving the mouse pointer, the above plot is interactive. Note that the style customizations could be listed in a single call of the function update_layout. There are also pretty buit-in themes available, see here. The layout can be specified with the command\nfig.update_layout(template = template_name)\nwhere template_name can be \"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white“.\n\n\n5.1.4.2 3D Plots\nWe now want to plot a 3D curve \\(\\pmb{\\gamma} \\colon (a,b) \\to \\mathbb{R}^3\\) parametrized by \\[\n\\pmb{\\gamma}(t) = ( x(t) , y(t) , z(t)) \\,.\n\\] Again we use the Plotly module graph_objects, imported as go. The function for 3D line plots is called Scatter3d, and documentation and examples can be found at link. The code for plotting \\(\\pmb{\\gamma}\\) is as follows.\n# Plotting gamma 3D\n\n# Import libraries\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Compute times grid by dividing (a,b) in \n# n equal parts\nt = np.linspace(a, b, n)\n\n# Compute the parametric curve gamma\n# for given functions x(t), y(t), z(t)\nx = x(t)\ny = y(t)\nz = z(t)\n\n# Create empty figure object and saves \n# it in the variable \"fig\"\nfig = go.Figure()\n\n# Create the line plot object\ndata = go.Scatter3d(x = x, y = y, z = z, mode = 'lines', name = 'gamma')\n\n# Add \"data\" plot to the figure \"fig\"\nfig.add_trace(data)\n\n# Display the figure\nfig.show()\nThe functions go.Figure, add_trace and show appearing above are described in the previous Section. The new addition is go.Scatter3d, which generates a 3D scatter plot of the points stored in the array [x,y,z]. Setting mode = 'lines' results in a linear interpolation of such points. As before, the curve can be labeled by setting name = \"string\".\nAs an example, we plot the 3D Helix defined at 5.3. We also add some styling. We can also use the same pre-defined templates descirbed for go.Scatter in the previous section, see here for official documentation.\n\n# Plotting 3D Helix\n\n# Import libraries\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Divides time interval (0,6pi) in 100 parts \nt = np.linspace(0, 6*np.pi, 100)\n\n# Computes Helix\nx = np.cos(t) \ny = np.sin(t)\nz = t\n\n# Create empty figure object and saves \n# it in the variable \"fig\"\nfig = go.Figure()\n\n# Create the line plot object\n# We add options for the line width and color\ndata = go.Scatter3d(\n    x = x, y = y, z = z, \n    mode = 'lines', name = 'gamma', \n    line = dict(width = 10, color = \"darkblue\")\n    )\n\n# Add \"data\" plot to the figure \"fig\"\nfig.add_trace(data)\n\n# Here we start with the styling options\n# First we set a figure title\nfig.update_layout(title_text = \"Plotting 3D Helix with Plotly\")\n\n# Adjust figure size\nfig.update_layout(\n    autosize = False, \n    width = 600, \n    height = 600\n    )\n\n# Set pre-defined template\nfig.update_layout(template = \"seaborn\")\n\n# Options for curve line style\n\n\n# Display the figure\nfig.show()\n\n                                                \n\n\nThe above plot is interactive: you can pan arond by dragging the pointer. Once again, the style customizations could be listed in a single call of the function update_layout.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Plots with Python</span>"
    ]
  },
  {
    "objectID": "sections/chap_5.html#surfaces-in-python",
    "href": "sections/chap_5.html#surfaces-in-python",
    "title": "5  Plots with Python",
    "section": "5.2 Surfaces in Python",
    "text": "5.2 Surfaces in Python\n\n5.2.1 Plots with Matplotlib\nI will take for granted all the commands explained in Section 5.1. Suppose we want to plot a surface \\(S\\) which is defined by the parametric equations \\[\nx = x(u,v) \\,, \\quad\ny = y(u,v) \\,, \\quad\nz = z(u,v)\n\\] for \\(u \\in (a,b)\\) and \\(v \\in (c,d)\\). This can be done via the function called plot_surface contained in the mplot3d Toolkit. This function works as follows: first we generate a mesh-grid \\([U,V]\\) from the coordinates \\((u,v)\\) via the command\n[U, V] = np.meshgrid(u, v)\nThen we compute the parametric surface on the mesh\nx = x (U, V)\ny = y (U, V)\nz = z (U, V)\nFinally we can plot the surface with the command\nplt.plot_surface(x, y, z)\nThe complete code looks as follows.\n# Plotting surface S\n\n# Importing numpy, matplotlib and mplot3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure object of size m x n\nfig = plt.figure(figsize = (m,n))\n\n# Generates 3D axes\nax = plt.axes(projection = '3d')\n\n# Shows axes grid\nax.grid(True)\n\n# Generates coordinates u and v\n# by dividing the interval (a,b) in n parts\n# and the interval (c,d) in m parts\nu = np.linspace(a, b, m)\nv = np.linspace(c, d, n)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Computes S given the functions x, y, z\n# on the grid [U,V]\nx = x(U,V)\ny = y(U,V)\nz = z(U,V)\n\n# Plots the surface S\nax.plot_surface(x, y, z)\n\n# Setting plot title \nax.set_title('The surface S')\n\n# Setting axes labels\nax.set_xlabel('x', labelpad=10)\nax.set_ylabel('y', labelpad=10)\nax.set_zlabel('z', labelpad=10)\n\n# Setting viewing angle\nax.view_init(elev = e, azim = a)\n\n# Showing the plot\nplt.show()\nFor example let us plot a cone described parametrically by: \\[\nx = u \\cos(v) \\,, \\quad\ny = u \\sin(v) \\,, \\quad\nz = u\n\\] for \\(u \\in (0,1)\\) and \\(v \\in (0,2\\pi)\\). We adapt the above code:\n\n# Plotting a cone\n\n# Importing numpy, matplotlib and mplot3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure object of size 4 x 4\nfig = plt.figure(figsize = (4,4))\n\n# Generates 3D axes\nax = plt.axes(projection = '3d')\n\n# Shows axes grid\nax.grid(True)\n\n# Generates coordinates u and v by dividing\n# the intervals (0,1) and (0,2pi) in 100 parts\nu = np.linspace(0, 1, 100)\nv = np.linspace(0, 2*np.pi, 100)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Computes the surface on grid [U,V]\nx = U * np.cos(V)\ny = U * np.sin(V)\nz = U\n\n# Plots the cone\nax.plot_surface(x, y, z)\n\n# Setting plot title \nax.set_title('Plot of a cone')\n\n# Setting axes labels\nax.set_xlabel('x', labelpad=10)\nax.set_ylabel('y', labelpad=10)\nax.set_zlabel('z', labelpad=10)\n\n# Setting viewing angle\nax.view_init(elev = 25, azim = 45)\n\n# Showing the plot\nplt.show()\n\n\n\n\n\n\n\n\nAs discussed in Section 5.1, we can have multiple plots in the same figure. For example let us plot the torus viewed from 2 angles. The parametric equations are: \\[\n\\begin{aligned}\nx & = (R + r \\cos(u)) \\cos(v)  \\\\\ny & = (R + r \\cos(u)) \\sin(v)  \\\\\nz & = r \\sin(u)\n\\end{aligned}\n\\] for \\(u, v \\in (0,2\\pi)\\) and with\n\n\\(R\\) distance from the center of the tube to the center of the torus\n\\(r\\) radius of the tube\n\n\n# Plotting torus seen from 2 angles\n\n# Importing numpy, matplotlib and mplot3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure object of size 9 x 5\nfig = plt.figure(figsize = (9,5))\n\n# Generates 2 sets of 3D axes\nax1 = fig.add_subplot(1, 2, 1, projection = '3d')\nax2 = fig.add_subplot(1, 2, 2, projection = '3d')\n\n# Shows axes grid\nax1.grid(True)\nax2.grid(True)\n\n# Generates coordinates u and v by dividing\n# the interval (0,2pi) in 100 parts\nu = np.linspace(0, 2*np.pi, 100)\nv = np.linspace(0, 2*np.pi, 100)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Computes the torus on grid [U,V]\n# with radii r = 1 and R = 2\nR = 2\nr = 1\n\nx = (R + r * np.cos(U)) * np.cos(V)\ny = (R + r * np.cos(U)) * np.sin(V)\nz = r * np.sin(U)\n\n# Plots the torus on both axes\nax1.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')\n\nax2.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')\n\n# Setting plot titles \nax1.set_title('Torus')\nax2.set_title('Torus from above')\n\n# Setting range for z axis in ax1\nax1.set_zlim(-3,3)\n\n# Setting viewing angles\nax1.view_init(elev = 35, azim = 45)\nax2.view_init(elev = 90, azim = 0)\n\n# Showing the plot\nplt.show()\n\n\n\n\n\n\n\n\nNotice that we have added some customization to the plot_surface command. Namely, we have set the color of the figure with color = 'dimgray' and of the edges with edgecolors = 'snow'. Moreover the commands rstride and cstride set the number of wires you see in the plot. More precisely, they set by how much the data in the mesh \\([U,V]\\) is downsampled in each direction, where rstride sets the row direction, and cstride sets the column direction. On the torus this is a bit difficult to visualize, due to the fact that \\([U,V]\\) represents angular coordinates. To appreciate the effect, we can plot for example the paraboiloid \\[\n\\begin{aligned}\nx & = u  \\\\\ny & = v  \\\\\nz & = - u^2 - v^2\n\\end{aligned}\n\\] for \\(u,v \\in [-1,1]\\).\n\n# Showing the effect of rstride and cstride\n\n# Importing numpy, matplotlib and mplot3d\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits import mplot3d\n\n# Generates figure object of size 6 x 6\nfig = plt.figure(figsize = (6,6))\n\n# Generates 2 sets of 3D axes\nax1 = fig.add_subplot(2, 2, 1, projection = '3d')\nax2 = fig.add_subplot(2, 2, 2, projection = '3d')\nax3 = fig.add_subplot(2, 2, 3, projection = '3d')\nax4 = fig.add_subplot(2, 2, 4, projection = '3d')\n\n# Generates coordinates u and v by dividing\n# the interval (-1,1) in 100 parts\nu = np.linspace(-1, 1, 100)\nv = np.linspace(-1, 1, 100)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Computes the paraboloid on grid [U,V]\nx = U\ny = V\nz = - U**2 - V**2\n\n# Plots the paraboloid on the 4 axes\n# but with different stride settings\nax1.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')\n\nax2.plot_surface(x, y, z, rstride = 5, cstride = 20, color = 'dimgray', edgecolors = 'snow')\n\nax3.plot_surface(x, y, z, rstride = 20, cstride = 5, color = 'dimgray', edgecolors = 'snow')\n\nax4.plot_surface(x, y, z, rstride = 10, cstride = 10, color = 'dimgray', edgecolors = 'snow')\n\n# Setting plot titles \nax1.set_title('rstride = 5, cstride = 5')\nax2.set_title('rstride = 5, cstride = 20')\nax3.set_title('rstride = 20, cstride = 5')\nax4.set_title('rstride = 10, cstride = 10')\n\n# We do not plot axes, to get cleaner pictures\nax1.axis('off')\nax2.axis('off')\nax3.axis('off')\nax4.axis('off')\n\n# Showing the plot\nplt.show()\n\n\n\n\n\n\n\n\nIn this case our mesh is 100 x 100, since u and v both have 100 components. Therefore setting rstride and cstride to 5 implies that each row and column of the mesh is sampled one time every 5 elements, for a total of \\[\n100/5 = 20\n\\] samples in each direction. This is why in the first picture you see a 20 x 20 grid. If instead one sets rstride and cstride to 10, then each row and column of the mesh is sampled one time every 10 elements, for a total of \\[\n100/10 = 10\n\\] samples in each direction. This is why in the fourth figure you see a 10x10 grid.\n\n\n5.2.2 Plots with Plotly\nAs done in Section 5.1.4, we now see how to use Plotly to generate an interactive 3D plot of a surface. This can be done by means of functions contained in the Plotly module graph_objects, usually imported as go. Specifically, we will use the function go.Surface. The code will look similar to the one used to plot surfaces with matplotlib:\n\ngenerate meshgrid on which to compute the parametric surface,\nstore such surface in the numpy array [x,y,z],\npass the array [x,y,z] to go.Surface to produce the plot.\n\nThe full code is below.\n\n# Plotting a Torus with Plotly\n\n# Import \"numpy\" and the \"graph_objects\" module from Plotly\nimport numpy as np\nimport plotly.graph_objects as go\n\n# Generates coordinates u and v by dividing\n# the interval (0,2pi) in 100 parts\nu = np.linspace(0, 2*np.pi, 100)\nv = np.linspace(0, 2*np.pi, 100)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Computes the torus on grid [U,V]\n# with radii r = 1 and R = 2\nR = 2\nr = 1\n\nx = (R + r * np.cos(U)) * np.cos(V)\ny = (R + r * np.cos(U)) * np.sin(V)\nz = r * np.sin(U)\n\n# Generate and empty figure object with Plotly\n# and saves it to the variable called \"fig\"\nfig = go.Figure()\n\n# Plot the torus with go.Surface and store it\n# in the variable \"data\". We also do now show the\n# plot scale, and set the color map to \"teal\"\ndata = go.Surface(\n    x = x , y = y, z = z, \n    showscale = False, \n    colorscale='teal'\n    )\n\n# Add the plot stored in \"data\" to the figure \"fig\"\n# This is done with the command add_trace\nfig.add_trace(data)\n\n# Set the title of the figure in \"fig\"\nfig.update_layout(title_text=\"Plotting a Torus with Plotly\")\n\n# Show the figure\nfig.show()\n\n                                                \n\n\nYou can rotate the above image by clicking on it and dragging the cursor. To further customize your plots, you can check out the documentation of go.Surface at this link. For example, note that we have set the colormap to teal: for all the pretty colorscales available in Plotly, see this page.\nOne could go even fancier and use the tri-surf plots in Plotly. This is done with the function create_trisurf contained in the module figure_factory of Plotly, usually imported as ff. The documentation can be found here. We also need to import the Python library scipy, which we use to generate a Delaunay triangulation for our plot. Let us for example plot the torus.\n\n# Plotting Torus with tri-surf\n\n# Importing libraries\nimport numpy as np\nimport plotly.figure_factory as ff\nfrom scipy.spatial import Delaunay\n\n# Generates coordinates u and v by dividing\n# the interval (0,2pi) in 100 parts\nu = np.linspace(0, 2*np.pi, 20)\nv = np.linspace(0, 2*np.pi, 20)\n\n# Generates grid [U,V] from the coordinates u, v\nU, V = np.meshgrid(u, v)\n\n# Collapse meshes to 1D array\n# This is needed for create_trisurf \nU = U.flatten()\nV = V.flatten()\n\n# Computes the torus on grid [U,V]\n# with radii r = 1 and R = 2\nR = 2\nr = 1\n\nx = (R + r * np.cos(U)) * np.cos(V)\ny = (R + r * np.cos(U)) * np.sin(V)\nz = r * np.sin(U)\n\n# Generate Delaunay triangulation\npoints2D = np.vstack([U,V]).T\ntri = Delaunay(points2D)\nsimplices = tri.simplices\n\n# Plot the Torus\nfig = ff.create_trisurf(\n    x=x, y=y, z=z,\n    colormap = \"Portland\",\n    simplices=simplices,\n    title=\"Torus with tri-surf\", \n    aspectratio=dict(x=1, y=1, z=0.3),\n    show_colorbar = False\n    )\n\n# Adjust figure size\nfig.update_layout(autosize = False, width = 700, height = 700)\n\n# Show the figure\nfig.show()\n\n                                                \n\n\nAgain, the above figure is interactive. Try rotating the torus with the pointer.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Plots with Python</span>"
    ]
  },
  {
    "objectID": "sections/chap_5.html#footnotes",
    "href": "sections/chap_5.html#footnotes",
    "title": "5  Plots with Python",
    "section": "",
    "text": "The command plt.show() can be omitted if working in Jupyter Notebook, as it is called by default.↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Plots with Python</span>"
    ]
  },
  {
    "objectID": "sections/license.html",
    "href": "sections/license.html",
    "title": "License",
    "section": "",
    "text": "Reuse\nThis work is licensed under CC-BY-NC-ND 4.0",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "sections/license.html#citation",
    "href": "sections/license.html#citation",
    "title": "License",
    "section": "Citation",
    "text": "Citation\nFor attribution, please cite this work as:\n\nFanzon, Silvio. (2024). Lecture Notes on Differential Geometry.\nhttps://www.silviofanzon.com/2024-Differential-Geometry-Notes/\n\nBibTex citation:\n@electronic{Fanzon-Diff-Geom-2024,\n    author = {Fanzon, Silvio},\n    title = {Lecture Notes on Differential Geometry},\n    url = {https://www.silviofanzon.com/2024-Differential-Geometry-Notes/},\n    year = {2024}}",
    "crumbs": [
      "License"
    ]
  },
  {
    "objectID": "sections/references.html",
    "href": "sections/references.html",
    "title": "References",
    "section": "",
    "text": "Abate, Marco, and Tovena, Francesca. 2011. Curves and Surfaces.\nSpringer.\n\n\ndo Carmo, Manfredo P. 2017. Differential Geometry of Curves and\nSurfaces. Second Edition. Dover Books on Mathematics.\n\n\nJohansson, Robert. 2019. Numerical Python. Scientific Computing and\nData Science Applications with Numpy, SciPy and Matplotlib. Second\nEdition. Apress.\n\n\nKong, Qingkai, Siauw, Timmy, and Bayen, Alexandre. 2020. Python\nProgramming and Numerical Methods. Academic Press.\n\n\nManetti, Marco. 2023. Topology. Second Edition. Springer.\n\n\nPressley, Andrew. 2010. Elementary Differential Geometry.\nSecond Edition. Springer.\n\n\nZorich, Vladimir A. 2015. Mathematical Analysis I.\nSecond Edition. Springer.\n\n\n———. 2016. Mathematical Analysis II. Second Edition. Springer.",
    "crumbs": [
      "References"
    ]
  }
]