::: {.content-hidden}
$$
{{< include macros.tex >}}
$$
:::






# Surfaces


Curves are 1D objects in $\R^3$, parametrized via functions $\g \colon (a,b) \to \R^3$. 
There is only one available direction in which to move on a curve:

- $t \mapsto \g(t)$ moves forward on the curve 
- $t \mapsto \g(-t)$ moves backward on the curve


![Sketch of a curve $\g$.](/images/curves_example.png){width=60%}


Surfaces are 2D objects in $\R^3$. There are two directions in which one can move on a surface. 


![Sketch of a surfaces: Sphere, Torus, MÃ¶bius band.](/images/surfaces_example.png){width=70%}



::: Question

How to dercribe a surface mathematically?

:::


A curve $\Gamma \subseteq \R^3$ can be described with one function $\g \colon (a,b) \to \Gamma$. The idea is that $\Gamma$ looks locally like $\R$.


![A curve $\Gamma$ can be described by a function $\g \colon (a,b) \to \Gamma$.](/images/curves_example_2.png){width=60%}


How do we represent a surface? Suppose given a function $\sss \colon U \to \R^3$, with $U \subseteq \R^2$ open set. Denote by $\SSS := \sss(U)$ the image of $U$ through $\sss$. We say that $\SSS$ is a surface and $\sss$ is a **chart**. Unofortunately, not all surfaces can be described with just one chart: in most cases one needs to piece together many local **charts** $\sss_i \colon U_i \to \SSS$, with $U_i \subseteq \R^2$ open. The charts $\sss_i$ represent $\SSS$ if they cover the whole surface:
$$
\SSS = \bigcup_{i} \sss_i (U_i) \,.
$$


![A surface $\SSS$ can be described by a family of charts $\sss_i \colon U_i \to \SSS$ with $U_i \subseteq \R^2$ open set.](/images/surfaces_example_2.png){width=60%}

Before proceeding with the formal definition of surface, we collect some preliminary definitions and results.


## Preliminaries


Before proceeding with the formal definition of surface, we need to establish
some basic notation and terminology regarding linear algebra, the topology of $\R^n$, and calculus for smooth maps from $\R^n$ into $\R^m$.




### Linear algebra



::: Definition
### Bilinear form

Let $V$ be a vector space and $B \colon V \times V \to \R$. 
We say that:

- $B$ is **bilinear** if
\begin{align*}
B(\lambda_1 \vv_1 + \lambda_2 \vv_2 , \ww) & = \lambda_1 B(\vv_1,\ww) + \lambda_2 B(\vv_2,\ww) \,, \\
B(\ww, \lambda_1 \vv_1 + \lambda_2 \vv_2 ) & = \lambda_1 B(\ww,\vv_1) + \lambda_2 B(\ww, \vv_2) \,. 
\end{align*}
for all $\vv_i,\ww \in V$, $\lambda_i \in \R$.

- $B$ is **symmetric** if 
$$
B(\vv,\ww) = B(\ww, \vv) 
$$
for all $\vv,\ww \in V$.


A bilinear map $B$ is called **bilinear form** on $V$.

:::



::: Notation

Let $V$ be a vector space with basis $\{\vv_1,\ldots,\vv_n\}$. Then, for 
a vector $\vv \in V$ there exist coefficients $\lambda_1, \ldots, \lambda_n$
such that
$$
\vv = \lambda_1 \vv_1 +  \ldots  +\lambda_n \vv_n \,.
$$
We denote the vector of coefficients of $\vv$ by the column vector
$$
\xx := (\lambda_1, \ldots, \lambda_n)^T \in \R^n \,.
$$
The coefficients of a vector $\ww$ are denoted by
$$
\yy := (\mu_1 , \ldots, \mu_n )^T \,. 
$$
Notice that we are using different letters to denote abstract vectors $\vv,\ww \in V$, and their components $\xx,\yy \in \R^n$.

:::


Bilinear forms can be represented by a matrix.



::: Remark
### Matrix representation for bilinear forms

Let $\{\vv_1, \ldots , \vv_n \}$ be a basis for the vector space $V$. 
Given a bilinear form $B \colon V \times V \to \R$ we define the matrix
$$
M := \left(  B(\vv_i,\vv_j) \right)_{i,j=1}^n \in \R^{n \times n} \,.
$$
Then 
$$
B(\vv,\ww) = \xx^T \,M \, \yy \,. 
$$

> *Proof.* We can write $\vv$ and $\ww$ in cordinates as
$$
\vv = \sum_{i=1}^n \lambda_i \vv_i \,, \quad 
\ww = \sum_{i=1}^n \mu_i \vv_i \,,
$$
for suitable coefficients $\lambda_i, \mu_i \in \R$. Using bilinearity of $B$
we get
\begin{align*}
B(\vv,\ww) & = B \left(  \sum_{i=1}^n \lambda_i \vv_i, \sum_{j=1}^n \mu_j \vv_j   \right) \\
           & = \sum_{i,j=1}^n \lambda_i \mu_j B(\vv_i,\vv_j) \\
           & = \xx^T M \yy \,.
\end{align*}

:::



::: Definition 
### Quadratic form

Let $V$ be a vector space and $B \colon V \times V \to \R$ be a bilinear form. The **quadratic** form associated to $B$ is the map 
$$
Q \colon V \to \R \,, \quad Q(\vv) := B(\vv, \vv) \,.
$$


:::


A symmetric bilinear form is uniquely determinded by its quadratic form, 
as stated in the following proposition.


::: Proposition

Let $B \colon V \times V \to \R$ be a symmetric bilinear form and 
$Q \colon V \to \R$ the associated quadratic form. Then
$$
B(u,v) = \frac12 \left(  Q(\vv + \ww) - Q(\vv) - Q(\ww)       \right) \,.
$$
for all $\vv,\ww \in V$.

:::

The proof is an easy check, and is left as an exercise.


::: Definition 
### Inner product

Let $V$ be a vector space. An inner product on $V$ is a symmetric bilinear form $\scp{\cdot}{\cdot} \colon V \times V \to \R$ such that
$$
\scp{\vv}{\vv} > 0 \,, \quad \forall \, \vv \in V \,.
$$
Moreover:

- The **length** of a vector $\vv \in V$ with respect to $B$ is defined as
$$
\| \vv \|  := \sqrt{\scp{\vv}{\vv}} \,.
$$

- Two vectors $\vv,\ww \in V$ are **orthogonal** if 
$$
\scp{\vv}{\ww} = 0 \,.
$$


:::


::: Example

Let $V = \R^n$ and consider the euclidean scalar product
$$
\vv \cdot \ww = \sum_{i=1}^n v_i w_i \,,
$$
where $\vv = (v_1,\ldots,v_n)$, $\ww = (w_1,\ldots,w_n)$. Then 
$$
\scp{\vv}{\ww} := \vv \cdot \ww
$$
is an inner product on $\R^n$.

:::


::: Proposition 

Let $V$ be a vector space and $\scp{\cdot}{\cdot}$ an inner product on $V$. There exists an **orthonormal** basis $\{\vv_1, \ldots, \vv_n\}$ of $V$, that is, such that 
$$
\scp{\vv_i}{\vv_j} = 
\begin{cases}
1 & \mbox{ if } \, i = j  \\
0 & \mbox{ if } \, i \neq j  \\
\end{cases}
$$
In particular, the matrix $M$ associated to $\scp{\cdot}{\cdot}$ is the identity.

:::



::: Definition
### Linear map

Let $V,W$ be vector spaces and $L \colon V \to W$. We say that $L$ is **linear** if 
$$
L(\lambda \vv + \mu \ww) = \lambda L(\vv) + \mu L(\ww) 
$$
for all $\vv,\ww \in V$ and $\lambda,\mu \in \R$. 
:::




::: Remark
### Matrix representation of linear maps


Let $V,W$ be vector spaces and $L \colon V \to W$ be a linear map.
Let $\{\vv_1, \ldots, \vv_n\}$ be a basis of $V$ and 
$\{ {\ww}_1 , \ldots, \ww_m\}$ be a basis of $W$. Then there exists a 
matrix $M \in \R^{m \times n}$ such that
$$
L \vv = M \xx \,, \quad \forall \, \vv \in V \,. 
$$
Specifically, $M \in \R^{n \times n}$ is called the matrix associated to 
$L$ with respect to the basis $\{\vv_1,\ldots,\vv_n\}$ of $V$ and $\{\ww_1 \ldots,\ww_m\}$ of $W$, and is defined by 
$$
M := \left(  
\begin{array}{ccc}
a_{11} & \ldots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{m1} & \ldots & a_{mn}
\end{array}
\right) \,,
$$
where the coefficients $a_{ij}$ are such that 
$$
L(\vv_j) = a_{1j} \ww_1 + \ldots + a_{mj} \ww_m = \sum_{i=1}^m a_{ij} \ww_i  \,.
$$
In other words, the columns of $M$ are given by the coordinates of the vectors $L(\vv_i)$ with respect to the basis $\{ \ww_1 , \ldots, \ww_m \}$.


:::






::: Definition
### Eigenvalues and eigenvectors

Let $V$ be a vector space and $L \colon V \to V$ a linear map.
We say that $\lambda \in \R$ is an eigenvalue of $L$ if
$$
L(\vv) = \lambda \vv 
$$
for some $\vv \in V$ with $\vv \neq 0$. Such $\vv$ is called **eigenvector** of $L$ associated to the eigenvalue $\lambda$.

:::




::: Definition
### Self-adjoint map

Let $V$ be a vector space, $\scp{\cdot}{\cdot}$ an inner product and $L \colon V \to V$ a linear map. We say that $L$ is **self-adjoint** if
$$
\scp{\vv}{L(\ww)} = \scp{L(\vv)}{\ww} \,, \quad \forall \, \vv , \, \ww \in V \,.
$$

:::






::: Theorem
### Spectral Theorem   {#theorem-spectral}

Let $V$ be a vector space, $\scp{\cdot}{\cdot}$ an inner product, and $L \colon V \to V$ a self-adjoint linear map. There exist an orthonormal 
basis of $V$
$$
\{ \vv_1, \ldots, \vv_n \} \,,
$$
where $\vv_i$ are eigenvectors of $L$, that is,
$$
L \vv_i = \lambda_i \vv_i
$$
for some eigevalue $\lambda_i \in \R$. In particular, the matrix of 
$L$ with respect to the basis $\{\vv_1,\ldots,\vv_n\}$ is diagonal:
$$
M = \operatorname{diag} (\lambda_1,\ldots, \lambda_n)  = 
\left(  
\begin{array}{cccc}
\lambda_1 &  0         & \ldots & 0 \\
    0     &  \lambda_2 & \ldots & 0 \\
  \vdots     &  \vdots & \ddots & \vdots \\
  0     &  0 & \ldots & \lambda_n \\
\end{array}
\right) \,.
$$


:::



There is also a matrix version of the spectral theorem. To state it,
we need to introduce some terminology.


::: Definition

Let $A \in \R^{n \times n}$ be a matrix. We say that:

- $A$ is **symmetric** if 
$$
A^T = A \,.
$$

- $A$ is **orthogonal** if 
$$
A^T A = I  \,,
$$
where $I$ is the identity matrix.

:::



::: {.Remark  #remark-self-adoint}

Let $L \colon V \to V$ be linear and $A \in \R^{n \times n}$ be the matrix
associated to $L$ with respect to any basis $\{\vv_1,\ldots,\vv_n\}$ of
$V$. They are equivalent:

- $L$ is self-adjoint,
- $A$ is symmetric.

:::




::: Definition
### Matrix eigenvalues

Let $A \in \R^{n \times n}$ be a matrix. An **eigenvalue** of $A$ is a number $\lambda \in \R$ such that 
$$
A \vv = \lambda \vv \,,
$$
for some $\vv \in \R^n$ with $\vv \neq 0$. The vector $\vv$ is called an **eigenvector** of $A$ with eigenvalue $\lambda$.

:::




::: Remark

Let $A \in \R^{n \times n}$. The eigenvalues of $\lambda$ of $A$ can be computed by
solving the **characteristic equation**
$$
P(\lambda) = 0 \,,
$$
where $P$ is the **characteristic polynomial** of $A$, defined by
$$
P(\lambda) := \det ( A - \lambda I  ) \,.
$$

:::



::: Remark 

Let $L \colon V \to V$ be a linear map and $A$ the associated matrix 
with respect to any basis of $V$. Then
$$
L(\vv) = A \xx \,, \quad \, \forall \, \vv \in V\,,
$$
where $\xx \in \R^n$ is the vector of coordinates of $\vv$.
They are equivalent:

- $\lambda$ is an eigenvalue of $L$ of eigenvector $\vv$,
- $\lambda$ is an eigenvalue of $A$ of eigenvector $\xx$.

:::




::: Theorem
### Spectral Theorem for matrices {#theorem-spectral-matrix}

Let $A \in \R^{n \times n}$ be a symmetric matrix. Consider $\R^n$ equipped with the euclidean scalar product. There exist an orthonormal 
basis of $V$
$$
\{ \vv_1, \ldots, \vv_n \} \,,
$$
where $\vv_i$ are eigenvectors of $A$, that is,
$$
A \vv_i = \lambda_i \vv_i
$$
for some eigevalue $\lambda_i \in \R$. Moreover
$$
A = P D P^T \,,
$$
where
\begin{align*}
P & := \left( \vv_1 \vert \ldots \vert \vv_n \right) \\
D & := \operatorname{diag} (\lambda_1,\ldots, \lambda_n)  = 
\left(  
\begin{array}{cccc}
\lambda_1 &  0         & \ldots & 0 \\
    0     &  \lambda_1 & \ldots & 0 \\
  \vdots     &  \vdots & \ddots & \vdots \\
  0     &  0 & \ldots & \lambda_n \\
\end{array}
\right) \,.
\end{align*}


:::



::: Remark

The corresponedence between Theorem \ref{theorem-spectral} and Theorem
\ref{theorem-spectral-matrix} is as follows. Let $A \in \R^{n \times n}$ be symmetric and $\{\ww_1, \ldots, \ww_n\}$ be any orthonormal basis
of the vector space $V$. Define the linear map $L \colon V \to V$
such that
$$
L(\vv_j) =  \sum_{i=1}^n a_{ij} \ww_i  \,, \quad \forall \, j =1 , \ldots , n \, .
$$
In this way $A$ is the matrix associated to $L$ with respect to the 
basis $\{\ww_1, \ldots, \ww_n\}$. Then 
$L$ is self-adjoint. Moreover $L$ and $A$ have the same eigenvalues. 
By the Spectral Theorem there exists an orthonormal basis $\{\vv_1,\ldots, \vv_n\}$ of $V$ such that the matrix of $L$ with respect to such basis, say $D$, is
diagonal. Then 
$$
A = P D P^T 
$$
where $P$ is the matrix of change of basis between $\{\ww_1, \ldots, \ww_n\}$
and $\{\vv_1, \ldots, \vv_n\}$, that is, $P = (p_{ij})$ where
$$
\ww_j = \sum_{i=1}^n p_{ij} \vv_i \,.
$$


:::









### Topology of $\R^n$


The Euclidean norm on $\R^n$ is denoted by 
$$
\| \xx \| := \sqrt{ \sum_{i=1}^n x_i^2 }\,, \quad \xx = (x_1 , \ldots, x_n) \in \R^n \,.
$$
The Euclidean norm induces the distance
$$
d(\xx,\yy) := \| \xx - \yy \| =   \sqrt{ \sum_{i=1}^n (x_i - y_i)^2 } \,.
$$


::: Definition
### Euclidean Topology 

The pair $(\R^n,d)$ is a metric space. The topology induced by the metric $d$ is called the Euclidean topology, denoted by $\TT$. In this chapter we will always assume that $\R^n$ is equipped with the Euclidean topology $\TT$.

:::


::: Definition 
### Open Sets

A set $U \subseteq \R^n$ is open if for all $\xx \in U$ there exists $\e>0$ such that $B_{\e}(\xx) \subseteq U$, where
$$
B_{\e}(\xx) := \{  \yy \in \R^n \divider \| \xx - \yy  \| < \e   \}
$$
is the open ball of radius $\e>0$ and centered at $\xx$. In this case we denote $U \in \TT$, with $\TT$ the Euclidean topology in $\R^n$.

:::



::: Definition 
### Closed Sets 

A set $V \subseteq \R^n$ is closed if $V^c := \R^n \smallsetminus U$ is open. 

:::




::: Example

- The $n$-dimensional unit sphere
$$
\sphere^n = \{ \xx \in \R^{n+1} \divider \| x \| = 1 \}
$$
is not open in $\R^{n+1}$, since for any $\xx \in \sphere^n$ we have
$$
B_{\e} (\xx) \not\subseteq \sphere^{n} \,. 
$$

- The $n$-dimensional unit cube 
$$
C := \{ \xx \in \R^n \divider |x_1| + \ldots + |x_n| <1  \}
$$
is open in $\R^n$, since one can always find $\e>0$ small enough so that
$$
B_{\e} (\xx) \not\subseteq C \,. 
$$

- The set 
$$
V := \{ \xx \in \R^n \divider |x_1| + \ldots + |x_n| \geq 1  \}
$$
is closed, since $V^c = C$ is the unit cube, which is open.

:::



::: Definition 
### Subspace Topology

Given a subset $A \subseteq \R^n$ the subspace topology on $A$ is the family of sets
$$
\TT_A := \{  U \subseteq A \divider \exists \,\, W \in \TT \st U = A \cap W  \} \,.
$$
If $U \in \TT_A$ we say that $U$ is open in $A$.

:::





### Smooth functions


We recall some basic facts about smooth functions from $\R^n$ into $\R^m$. For a vector valued function $f \colon \R^n \to \R^m$ we denote its components by 
$$
f = (f_1,\ldots,f_m) \,.
$$


::: Definition
### Continuous Function

Let $f \colon U \subseteq \R^n \to \R^m$ with $U$ open. We say that $f$ is continuous at $\xx \in U$ if $\forall \, \e>0$, \, $\exists \, \delta > 0$ such that 
$$
\|  \xx - \yy  \| < \delta \quad \implies \quad 
\| f(\xx) - f (\yy) \| < \e \,.
$$
We say that $f$ is continuous in $U$ if it is continuous for all $\xx \in U$.
:::


::: Remark

Let $f \colon U \subseteq \R^n \to V \subseteq \R^m$, with $U,V$ open. We have that $f$ is continuous if and only if $f^{-1}(A)$ is open in $U$, for all $A$ open in $V$.

:::


::: Definition
### Homeomorphism

Let $f \colon U \subseteq \R^n \to V \subseteq \R^m$ with $U,V$ open. We say that $f$ is a homeomorphism if $f$ is continuous and there exists inverse $f^{-1} \colon V \to U$ continuous.

:::



::: Definition
### Differentiable Function

Let $f \colon U \subseteq \R^n \to \R^m$ with $U$ open. We say that $f$ is differentiable at $\xx \in U$ if there exists a linear map $df_{\xx} \colon \R^n \to \R^m$ such that
$$
\lim_{\e \to 0} \   \frac{ f(\xx + \e \mathbf{h} )  - f(\xx) - \e \, df_{\xx}(\mathbf{h}) }{ \e } = 0 \,,
$$
for all $\mathbf{h} \in \R^n$, where the limit is taken in $\R^m$. The map $df_{\xx}$ is called the **differential** of $f$ at $\xx$. 

:::


We denote by $\{\ee_i\}_{i=1}^n$ the standard basis of $\R^n$.

::: Definition
### Partial Derivative

Let $f \colon U \subseteq \R^n \to \R^m$ with $U$ open be differentiable. The partial derivative of $f$ at $\xx \in U$ in direction $\ee_i$ is given by
$$
\frac{\partial f}{\partial x_i} := \lim_{\e \to 0}  \frac{ f( \xx + \e \ee_i ) - f(\xx) }{ \e } \,.
$$

:::



::: Definition
### Jacobian Matrix

The differential $df_{\xx} \colon \R^n \to \R^m$ is a linear map. As such, it must have a matrix representation with respect to the Euclidean basis. Such representation matrix is called **Jacobian**, and is given by:
$$
Jf(x):= \left( \frac{\partial f_i}{\partial x_j} \right)_{i,j}  \in \R^{m \times n} \,.
$$
If $m=n$ then $Jf \in \R^{n \times n}$ is a square matrix and we can compute its determinant, denoted by
$$
\det (Jf) \,.
$$
:::



::: Definition
### Multi-index notation

For a multi-index
$$
\alpha := (\alpha_1, \ldots , \alpha_n) \in \N^n
$$
we denote by 
$$
|\alpha|:= \sum_{i=1}^n   |\alpha_i|
$$
the length of the multi-index. 

:::




::: Definition
### Smooth Function

Let $f \colon U \subseteq \R^n \to \R^m$ with $U$ open. We say that $f$ is smooth if the derivatives 
$$
\frac{\partial^{|\alpha|} f}{d\xx^\alpha} :=  \frac{\partial^{\alpha_1}}{ \partial x_1^{\alpha_1}} \cdots \frac{\partial^{\alpha_n}}{ \partial x_n^{\alpha_n}} \, f
$$
exist for each multi-index $\alpha \in \N^n$. Note that in this case all the derivatives of $f$ are automatically continuous.

:::




::: Notation
### Gradient and partial derivatives

Let $f \colon U \subseteq \R^n \to \R$ be smooth. We denote the partial derivatives by 
$$
\partial_{x_i} f := \frac{\partial f}{\partial x_i} \,, \quad 
\partial_{x_i x_j} f := \frac{\partial^2 f}{\partial x_i \partial x_j} \,,
\quad 
\partial_{x_i x_j x_k} f := \frac{\partial^3 f}{\partial x_i \partial x_j \partial x_k} \,.
$$

For $f \colon U \subseteq \R^n \to \R$ smooth we denote the **gradient** by
$$
\nabla f (\xx) = \left(  f_{x_1}(\xx) , \ldots ,  f_{x_n}(\xx) \right) \,.
$$

:::



::: Example

The functions $f \colon \R^2 \to \R$ and $g \colon \R^2 \to \R^3$ defined by
$$
f(x,y) := \cos(x)y \,, \quad 
g(x,y) := (x^2,y^2,x-y)
$$
are both smooth.

:::



::: Definition
### Diffeomorphism

Let $f \colon U \to V$ with $U \subseteq \R^n$ and $V \subseteq \R^n$ open. We say that $f$ is a **diffeomorphism** between $U$ and $V$ if $f$ is smooth and there exists 
smooth inverse $f^{-1} \colon V \to U$.

:::



We recall, without proof, the Inverse Function Theorem. Please note that in the statement the function $f$ is defined from $\R^n$ into $\R^n$.



::: Theorem
### Inverse Function Theorem

Let $f \colon U \to \R^n$ with $U \subseteq \R^n$ open. Suppose $f$ is a smooth function and
$$
\det J f(\xx_0) \neq 0 \,,
$$
for some $\xx_0 \in U$. Then there exist open sets $U_0 , V \subseteq \R^n$ such that $\xx_0 \in U_0$, $f(\xx_0) \in V$ and $f \colon U_0 \to V$ is a diffeomorphism.


:::


::: Warning 

Even if 
$$
\det J f(\xx) \neq 0 \,,
$$
for all $\xx \in U$, it is not guaranteed that $f$ is a diffeomorphism between $U$ and $f(U)$.

:::


Non-vanishing Jacobian determinant is a necessary condition for being a diffeomorphism.



::: {.Proposition #proposition-jacobian-zero}

Let $f \colon U \to \R^n$ with $U \subseteq \R^n$ open. Suppose $f$ is a diffeomorphism on $U$. Then 
$$
\det Jf (\xx) \neq 0 \,, \quad   \forall \, \xx \in U \,.
$$

:::


::: Example

We have already encountered Proposition \ref{proposition-jacobian-zero} in the scalar case when we were studying curves. Indeed, if $f \colon U \subset \R \to \R$ is a diffeomorphism, then $Jf(x) = \dot{f}(x)$. Hence 
$$
\det Jf(x) = \dot{f}(x) \,,
$$
and we recover the familiar result
$$
\dot{f}(x) \neq 0 \,, \quad \forall \, x \in U \,.
$$

:::


::: Example

Define $f \colon \R^2 \to \R^2$ by
$$
f(x,y) := (\cos(x) \sin(y), \sin(x) \sin(y)) \,.
$$
Then 
$$
J f (x,y) = 
\left(
\begin{array}{cc}
 - \sin(x) \sin(y)  &   \cos(x) \cos(y) \\
 \cos(x) \sin(y)    &   \sin(x) \cos(y)
\end{array}
\right) \,.
$$
and 
\begin{align*}
\det Jf(x,y) & = - \sin^2(x) \cos(y) \sin(y) - \cos^2(x) \cos(y) \sin(y) \\
             & = - \sin(y) \cos(y) \\
             & = - \frac{1}{2} \sin(2y) \,.
\end{align*}
Therefore 
$$
\det Jf(x,y) \neq 0 \quad \iff \quad 
y \neq \frac{n \pi}{2} \,, \,\, n \in \N \,.
$$
Hence $f$ is a diffeomorphism away from the lines
$$
L_n := \left\{ \left(x, \frac{n \pi}{2} \right) \divider x \in \R \right\} \,.
$$

:::





## Definition of Surface


We give our main definition of surface in $\R^3$.


::: Definition
### Surface

Let $\SSS \subseteq \R^3$ be a connected set. We say that $\SSS$ is a **surface** if for every point $\pp \in \SSS$ there exist an open set  $U \subseteq \R^2$ and a smooth map
$$
\sss \colon U \to  \sss(U) \subseteq \SSS \,
$$
such that 

- $\pp \in \sss(U)$
- $\sss(U)$ is open in $\SSS$
- $\sss$ is a homeomorphism between $U$ and $\sss(U)$

The homeomorphism $\sss$ is called a **surface chart** at $\pp$.

:::



::: Remark

- A surface chart $\sss$ is a map 
$$
\sss \colon U  \to \R^3 \,,
$$
with $U \subseteq \R^2$ open.
Therefore smoothness of $\sss$ is intended in the classical sense.


- Given a chart $\sss \colon U \to \sss(U)$, the set $U$ is open in $\R^2$ while $\sss(U)$ is open in $\SSS$ with the subspace topology. This means that there exists $W \subseteq \R^3$ open such that
$$
\sss(U) = W \cap \SSS \,.
$$

- The omeomorphism condition is saying that $\sss(U) \subseteq \SSS$ looks locally (around $\pp$) like an open set $U \subseteq \R^2$.

:::



![Sketch of the surface $\SSS$ and chart $\sss \colon U \to \sss(U) \subseteq \SSS$. The set $U \subseteq \R^2$ is open in $\R^2$ and $\sss(U)$ is open in $\SSS$. This means there exists $W$ open in $\R^3$ such that $\sss(U) = \SSS \cap W$.](/images/surfaces_example_3.png){width=70%}


::: Notation

- Points in $U$ will be denoted with the pair $(u,v)$.

- Partial derivatives of a chart $\sss = \sss (u,v)$ will be denoted by
$$
\sss_u := \frac{\partial \sss }{\partial u} \,, \quad 
\sss_v := \frac{\partial \sss }{\partial v} \,.
$$
Similar notations are adopted for higher order derivatives, e.g.,
\begin{align*}
\sss_{uu} & := \frac{\partial^2 \sss }{\partial u^2} \,, 
& \sss_{uv} & :=  \frac{\partial^2 \sss }{\partial u \partial v} \,, \\
\sss_{vu} & := \frac{\partial^2 \sss }{\partial v  \partial u  } \,,  
& \sss_{vv} & :=  \frac{\partial^2 \sss }{\partial v^2 } \,, \\
\end{align*}

- Components of $\sss$ will be denoted by
$$
\sss = (\sigma^1, \sigma^2, \sigma^3) \,.
$$

:::




::: Definition
### Atlas of a surface

Let $\SSS$ be a surface. Assume there exists a collection of **charts** 
$$
\mathcal{A} = \{ \sss_i\}_{i \in I} \,, \qquad 
\sss_i  \colon U_i \to \sss(U_i) \subseteq \SSS \,,
$$
where $I$ is a suitable family of indices. The family $\mathcal{A}$ is an **atlas** of $\SSS$ if 
$$
\SSS = \bigcup_{i \in I} \sss_i(U_i)  \,.
$$

:::





::: Example
### 2D Plane in $\R^3$

Planes in $\R^3$ are surfaces with atlas made by one chart. This is because a plane
$\pi \subseteq \R^3$ is described by the equation
$$
\pi  = \{  \xx  \in \R^3 \divider \xx \cdot \ww = \lambda \} \,.
$$
Let

- $\pp,\mathbf{q} \in \R^3$ be linearly independent, and orthogonal to $\ww$.
- $\mathbf{a} \in \pi$ be any point in the plane.


If $\xx \in \pi$ then $\xx-\mathbf{a}$ is parallel to the plane. In particular $\xx-\mathbf{a}$ can be written as linear combination of the vectors $\pp$ and $\mathbf{q}$. Hence $\pi$ can be
equivalently represented as
$$
\pi = \{ \mathbf{a} + u \pp + v \mathbf{q} \divider u,v \in \R \} \,.
$$
Define the map
$$
\sss \colon \R^2 \to \pi \,, \quad \sss(u,v):= \mathbf{a} + u \pp + v \mathbf{q} \,.
$$
We have:

- $\sss$ is smooth.
- $\R^2$ is obviously open.
- $\sss(\R^2)$ is open in $\pi$, since $\sss(\R^2) = \pi$.
- The inverse of $\sss$ is 
$$
\sss^{-1} \colon \pi \to \R^2 \,, \quad 
\sss^{-1} (\xx) = ( (\xx - \mathbf{a}) \cdot \pp , (\xx - \mathbf{a}) \cdot \mathbf{q}  ) \,.
$$
- As $\sss^{-1}$ is continuous, then $\sss$ is a homeomorphism between $\R^2$ and $\pi$. 


Therefore $\sss$ is a chart for $\pi$. Since
$$
\sss(\R^2) = \pi \,,
$$
we have that $\{\sss\}$ is an atlas for $\pi$, and hence $\pi$ is a surface.

:::



![A plane $\pi$ is a surface with atlas containing a single chart $\sss \colon \R^2 \to \pi$.](/images/surface_plane.png){width=70%}




::: Example
### Unit cylinder

Consider the infinite unit cylinder
$$
\SSS  = \{  (x,y,z) \in \R^3 \divider x^2 + y^2 = 1 \} \,.
$$
$\SSS$ is a surface with an atlas consisting of two charts:
$$
\sss_i \colon U_i \to \R^3   \,, \quad 
\sss_i(u,v):= (\cos(u),\sin(u),v)
$$
for $i=1,2$, where
$$
U_1 := \left( 0,\frac{ 3 \pi}{2} \right) \times \R \,, \quad 
U_2 := \left( \pi,\frac{ 5 \pi}{2} \right) \times \R \,.
$$

> Indeed:
>
> - $\sss_i$ is smooth.
> - $U_i$ is clearly open in $\R^2$.
> - One can check that $\sss_i(U_i)$ is open in $\SSS$.
> - $\sss_i$ is a homeomorphism of $U_i$ in $\sss(U_i)$.
> - $\{\sss_1 , \sss_2\}$ is an atlas for $\SSS$, since 
$$
\SSS = \sss_1(U_1) \cup \sss_2(U_2) \,.
$$

:::


![Unit cylinder $\SSS$ is a surface with atlas $\mathcal{A} = \{\sss_1,\sss_2\}$. Depicted are the images $\sss_1(U_1)$ and $\sss_2(U_2)$. ](/images/surface_cylinder.png){width=70%}



::: Important


Consider again the unit cylinder 
$$
\SSS  = \{  (x,y,z) \in \R^3 \divider x^2 + y^2 = 1 \} \,.
$$
Define the map 
$$
\sss \colon U \to \R^3   \,, \quad 
\sss (u,v):= (\cos(u),\sin(u),v)
$$
where
$$
U:= [ 0, 2 \pi ] \times \R \,.
$$
Clearly we have 
$$
\sss(U) = \SSS \,.
$$
However $\{\sss\}$ is not an atlas for $\SSS$, since $\sss$ is not a chart. This is because $\sss$ is not invertible, as for example
$$
\sss(0,0) = \sss(2\pi,0) \,. 
$$
Therefore $\sss$ cannot be an omeomorphism between $U$ and $\SSS$.



:::




::: Example
### Graph of a function

Let $U \subseteq \R^2$ be open and $f \colon U \to \R$ be smooth. The graph of $f$ is the set
$$
\Gamma_f := \{ (u,v,f(u,v)) \divider (u,v) \in U  \}  \,.
$$
We have that $\Gamma_f$ is a surface with atlas given by
$$
\mathcal{A} = \{ \sss \}
$$
where $\sss \colon U \to \Gamma_f$ is
$$
\sss(u,v):=(u,v,f(u,v)) \,.
$$

> Let us check that $\Gamma_f$ is a surface:
>
> - $\sss$ is smooth since $f$ is smooth.
> - $U$ is open in $\R^2$ by assumption.
> - $\sss(U) = \Gamma_f$, and therefore $\sss(U)$ is open in $\Gamma_f$.
> - The inverse of $\sss$ is given by $\widetilde{\sss} \colon \Gamma_f \to U$ defined as
> $$
> \widetilde{\sss}(u,v,f(u,v)) := (u,v) \,.
> $$
> Clearly $\widetilde{\sss}$ is continuous.
> - Therefore $\sss$ is a homeomorphism of $U$ into $\Gamma_f$.
> - $\mathcal{A}=\{\sss\}$ is an atlas for $\Gamma_f$, since 
> $$
> \Gamma_f = \sss(U) \,.
> $$

:::



Let us conclude the section with an example of a set which is not 
a surface.



::: Example
### Circular cone

Consider the circular cone
$$
\SSS := \{ (x,y,z) \in \R^3 \divider x^2 + y^2 = z^2  \} \,.
$$
Then $\SSS$ is not a surface. This is essentially consequence of
the fact that
$$
\SSS \smallsetminus \{\zero\}
$$
is a disconnected set.


To see that $\SSS$ is not a surface, suppose there exists an 
atlas $\{\sss_i\}$ of $\SSS$
$$
\sss_i \colon U_i \to \sss_i(U_i) \subseteq \SSS \,.
$$
In particular there exists a chart $\sss$ such that 
$$
\zero \in \sss (U) \,.
$$
Let $\xx_0 \in U$ be the point such that
$$
\sss (\xx_0) = \zero \,.
$$
Since $U$ is open in $\R^2$, there exists $\e>0$ such that $B_{\e}(\xx_0) \subseteq U$. Since $\sss$ is a homeomorphism, we deduce that
$$
\sss (B_{\e}(\xx_0))
$$
is open in $\SSS$. Hence there exists an open set $W$ in $\R^3$ such that
$$
\sss(B_{\e}(\xx_0)) = \sss(U) \cap W \,.
$$
As $\zero \in \sss (B_{\e}(\xx_0))$, we conclude that $\zero \in W$. Since $W$ is open in $\R^3$, there exists $\delta > 0$ such that
$$
B_{\delta} (\zero) \subseteq W \,.
$$
In particular we deduce that
$$
B_{\delta} (\zero) \cap \sss(U) \subseteq  \sss(B_{\e}(\xx_0)) \,.
$$
Hence $\sss(B_{\e}(\xx_0))$ contains points of both $\SSS^-$ and $\SSS^+$, with
$$
\SSS^- := \SSS \cap \{ z < 0 \}   \,, \quad
\SSS^+ := \SSS \cap \{ z > 0 \}   \,.
$$
This implies that
$$
V := \sss (B_{\e}(\xx_0)) \smallsetminus \{\zero\}
$$
is disconnected, with disconnection given by
$$
V = ( V \cap \SSS^- ) \cup (V \cap \SSS^+) \,.
$$
However $V$ is homeomorphic to 
$$
B_{\e} (\xx_0) \smallsetminus \{ \xx_0 \} \,,
$$
which is instead connected. Contradiction. Hence $\SSS$ is not a surface.

:::




![The circular cone is not a surface. This is because $\SSS \smallsetminus \{\zero\}$ is disconnected.](/images/surface_cone.png){width=70%}






## Regular Surfaces


We have defined a regular curve to be a map $\g \colon (a,b) \to \R^n$ such that
$$
\norm{\g(t)} \neq 0 \,, \quad \forall \, t \in (a,b) \,.
$$
This allowed us to define tangent vectors and, eventually, Frenet frame.

We want to do something similar for surfaces: We look for a condition that eventually will allow us to define tangent planes. This is why we introduce **regular charts** and **regular surfaces**.



::: Definition
### Regular Chart

Let $U \subseteq \R^2$ be open. A map
$$
\sss = \sss(u,v)  \colon U \to \R^3
$$
is called a **regular chart** if the partial derivatives
$$
\sss_u(u,v) = \frac{d\sss}{du}(u,v) \,, \quad
\sss_v(u,v) = \frac{d\sss}{dv}(u,v) 
$$
are linearly independent vectors of $\R^3$ for all $(u,v) \in U$.
:::


The following gives more insight into the regularity condition.


::: Proposition

Let $U \subseteq \R^2$ be open and consider a map
$$
\sss  \colon U \to \R^3 \,.
$$
They are equivalent:

1. $\sss$ is a regular chart.
2. The differential $d\sss_{\xx} \colon \R^2 \to \R^3$ is injective for all $\xx \in U$.
3. The Jacobian matrix
$$
J\sss (u,v) = 
\left(
\begin{array}{ccc}
\sigma^1_{u}  &  \sigma^1_{v} \\
\sigma^2_{u}  &  \sigma^2_{v} \\
\sigma^3_{u}  &  \sigma^3_{v} \\
\end{array} 
\right)
$$
has rank $2$ for all $(u,v) \in U$.
4. It holds
$$
\sss_u \times \sss_v \neq 0 \, \quad  \forall \, (u,v) \in U \,.
$$


:::


::: Proof

*Part 1. Equivalence of Point 1 and Point 4.* 

By the properties of vector product, we have that
$$
\sss_u \times \sss_v \neq 0 \, \quad \, \forall (u,v) \in U 
$$
if and only if $\sss_u$ and $\sss_v$ are linearly independent for all $(u,v) \in U$.


*Part 2. Equivalence of Point 2 and Point 3.* 

The differential $d\sss_{\xx} \colon \R^2 \to \R^3$ is represented in matrix form by the Jacobian
$$
J\sss (u,v) = 
\left(
\begin{array}{ccc}
\sigma^1_{u}  &  \sigma^1_{v} \\
\sigma^2_{u}  &  \sigma^2_{v} \\
\sigma^3_{u}  &  \sigma^3_{v} \\
\end{array} 
\right)
$$
By standard linear algebra results, $J\sss$ has rank 2 if and only if $d\sss$ is injective. 

*Part 3. Equivalence of Point 1 and Point 3.*

A $3 \times 2$ matrix has rank 2 if and only if its columns are linearly independent. Since the columns of $J\sss$ are $\sss_u$ and $\sss_v$, we 
conclude that $\sss_u$ and $\sss_v$ are linearly independent.

:::



We are now ready to define regular surfaces.


::: Definition
### Regular surface

Let $\SSS$ be a surface. Let 
$$
\mathcal{A} = \{ \sss_i \}_{i \in I} \,,
$$
be an atlas for $\SSS$. We say that:

- $\mathcal{A}$ is a **regular atlas** if 
the map $\sss_i$ is a regular chart for all $i \in I$. 
- $\SSS$ is a **regular surface** if there exists a regular atlas for $\SSS$.

:::







::: Example
### 2D Plane in $\R^3$

Let $\mathbf{a}, \pp, \mathbf{q} \in \R^3$, with $\pp$ and $\mathbf{q}$ orthogonal. We have shown that the plane
$$
\pi = \{ \mathbf{a} + u \pp + v \mathbf{q} \divider u,v \in \R \} 
$$
is a surface with atlas $\mathcal{A} = \{\sss\}$, where
$$
\sss \colon \R^2 \to \pi \,, \quad \sss(u,v):= \mathbf{a} + u \pp + v \mathbf{q} \,.
$$
Then $\pi$ is a regular surface, because $\sss$ is a regular chart. To see this, compute
$$
\sss_u = \pp  \,, \quad \sss_v = \mathbf{q} \,.
$$
Since $\pp$ and $\mathbf{q}$ are orthogonal, then they are linearly independent. Thus $\sss_u$ and $\sss_v$ are linearly independent, and $\sss$ is a regular chart.

:::




::: Example
### Unit cylinder {#example-unit-cylinder}

Consider the infinite unit cylinder
$$
\SSS  = \{  (x,y,z) \in \R^3 \divider x^2 + y^2 = 1 \} \,.
$$
We have seen that $\SSS$ is a surface with atlas $\mathcal{A} = \{ \sss_1,\sss_2\}$ where we define
$$
\sss \colon \R^2 \to \R^3   \,, \quad 
\sss(u,v):= (\cos(u),\sin(u),v)
$$
and 
\begin{align*}
\sss_1 & := \sss |_{U_1} \,,   & \sss_2 & := \sss |_{U_2} \,, \\
U_1 & := \left( 0,\frac{ 3 \pi}{2} \right) \times \R \,, 
& U_2 & := \left( \pi,\frac{ 5 \pi}{2} \right) \times \R \,.
\end{align*}
We have that $\SSS$ is a regular surface, since the atlas $\mathcal{A}$ is regular. Indeed:
$$
\sss_u = (-\sin(u),\cos(u),0) \,, \quad 
\sss_v = (0,0,1) \,,
$$
and therefore
$$
\sss_u \times \sss_v = (\cos (u), \sin(u), 0)  \,, \quad \norm{\sss_u \times \sss_v} = 1 \,.
$$
This implies
$$
\sss_u \times \sss_v \neq 0 \,, \quad \forall \, (u,v) \in \R^2 \,,
$$
showing that $\sss_u$ and $\sss_v$ are linearly independent. Therefore
$\sss_1$ and $\sss_2$ are regular charts, being restrictions of $\sss$.

:::




::: Example
### Graph of a function

Let $U \subseteq \R^2$ be open and $f \colon U \to \R$ be smooth. The graph of $f$ is the set
$$
\Gamma_f := \{ (u,v,f(u,v)) \divider (u,v) \in U  \}  \,.
$$
We have seen that $\Gamma_f$ is surface with atlas given by
$\mathcal{A} = \{ \sss \}$, where $\sss \colon U \to \Gamma_f$ is
$$
\sss(u,v):=(u,v,f(u,v)) \,.
$$
We have that $\Gamma_f$ is regular, since $\mathcal{A}$ is a regular atlas.
Indeed, 
$$
\sss_u = (1,0,f_u) \,, \quad 
\sss_v = (0,1,f_v) \,,
$$
and so
$$
\sss_u \times \sss_v = (-f_u, - f_v, 1 ) \neq \zero \,,
$$
since the last component never vanishes. Therefore $\sss_u$ and $\sss_v$ are
linearly independent and $\sss$ is a regular chart.

:::




::: Example
### Unit sphere

Consider the unit sphere in $\R^3$
$$
\sphere^2 := \{  (x,y,z) \in \R^3 \divider x^2 + y^2 + z^2 = 1  \} \,.
$$
We have that $\sphere^2$ is a regular surface, with regular atlas
$$
\mathcal{A} = \{ \sss_i \}_{i=1}^6 \,,
$$
defined as follows: Let 
$$
U:= \{ (u,v) \in \R^2 \colon u^2 + v^2 < 1  \}
$$
be the unit open ball in $\R^2$ and define $\sss_i \colon U \to \R^3$ by
\begin{align*}
\sss_1 (u,v) & = \left(u,v,\sqrt{1-u^2-v^2}  \right) \\
\sss_2 (u,v) & = \left(u,v,-\sqrt{1-u^2-v^2}  \right) \\
\sss_3 (u,v) & = \left(u,\sqrt{1-u^2-v^2},v  \right) \\
\sss_4 (u,v) & = \left(u, -\sqrt{1-u^2-v^2}, v  \right) \\
\sss_5 (u,v) & = \left(\sqrt{1-u^2-v^2} , u ,v \right) \\
\sss_6 (u,v) & = \left(-\sqrt{1-u^2-v^2}, u,v,  \right) \\
\end{align*}

> Exercise: Check that $\sphere^2$ is a regular surface.

:::



::: Remark 
### Spherical coordinates

The equivalent of polar coordinates in dimension $3$ are spherical coordinates. A point $(x,y,z) \in \R^3 \smallsetminus \{\zero\}$ can
be represented in spherical coordinates by
\begin{align*}
x & = \rho \cos (\theta)  \cos(\phi)  \\
y & = \rho \cos (\theta)  \sin(\phi) \\
z & = \rho \sin (\theta) 
\end{align*}
where 
$$
\rho:=\sqrt{ x^2 + y^2 + z^2 } \,, \quad \f \in [0,2\pi] \,, \quad \theta \in \left[ -\frac{\pi}{2}, \frac{\pi}{2} \right] \,,
$$
with the angles $\f$ and $\theta$ as in Figure @fig-spherical-coordinates.

> It is clear that $z = \rho \sin(\theta)$, by basic trigonometry. To compute $x$ and $y$, we note
that the segment joining $\zero$ to $\pp$ has length 
$$
L = \rho \cos \theta \,.
$$
Therefore we get
\begin{align*}
x & = L \cos (\phi) = \rho \cos (\theta)  \cos(\phi) \\
y & = L \sin (\phi) = \rho \cos (\theta)  \sin(\phi) 
\end{align*}
concluding.

:::


![Spherical coordinates in $\R^3$.](/images/spherical_coordinates.png){#fig-spherical-coordinates width=80%}




::: Example
### Unit sphere in spherical coordinates

Consider again the unit sphere in $\R^3$
$$
\sphere^2 := \{  (x,y,z) \in \R^3 \divider x^2 + y^2 + z^2 = 1  \} \,.
$$
We want to give an alternative atlas for $\sphere^2$ based on spherical coordinates. To this end, define
$$
U := \left\{ (\theta,\phi)  \in \R^2 \divider -\frac{\pi}{2} < \theta < \frac{\pi}{2} \,, \,\, 
0< \phi < 2 \pi    \right\}
$$
and $\sss \colon U \to \R^3$ by
$$
\sss( \theta , \phi ) :=  ( \cos(\theta) \cos(\phi), \cos(\theta) \sin(\phi), \sin (\theta)  ) \,.
$$
We have:

- $\sss$ is smooth.

- $U$ is open in $\R^2$.

- Moreover
$$
\sss (U) = \sphere^2 \smallsetminus \{ (x,0,z) \in \R^3 \divider x \geq 0  \} \,,
$$
as seen also in the left picture in @fig-chart-sphere. 

- The set $\sss(U)$ is evidently open in $\sphere^2$. 

- It is easy to check that $\sss$ is invertible, with continuous inverse. 

- Thus $\sss$ is a homeomorphism from $U$ into $\sss(U)$.

Let us check that $\sss$ is a regular chart:
\begin{align*}
\sss_{\theta} & = (-\sin(\theta) \cos(\phi), -\sin(\theta) \sin(\phi), \cos(\theta) ) \\
 \sss_{\phi} & = ( - \cos(\theta) \sin(\phi), \cos(\theta) \cos(\phi), 0 )  \,.
\end{align*} 
Therefore 
$$
\sss_{\theta} \times \sss_{\phi} = 
( - \cos^2(\theta) \cos(\phi), - \cos^2(\theta) \sin(\phi), - \sin(\theta) \cos ( \theta ) ) \,,
$$
from which
$$
\norm{ \sss_{\theta} \times \sss_{\phi} } = |\cos (\theta)| \, .
$$
Since $(\theta,\phi)\in U$, we have $\theta \in ( -\pi/2, \pi/2 )$, and so
$$
\norm{ \sss_{\theta} \times \sss_{\phi} } = |\cos (\theta)| \neq 0 \,,
$$
showing that $\sss_{\theta}$ and $\sss_{\phi}$ are linearly independent, and
$\sss$ is regular.

Since $\sss(U) \neq \sphere^2$, the chart $\sss$ does not form an atlas. We need a second chart. An option is to define $\widetilde{\sss} \colon U \to \R^3$ by
$$
\widetilde{\sss} := ( - \cos(\theta) \cos (\phi), -\sin(\theta) , - \cos (\theta) \sin(\phi)) \,.
$$
Notice that $\widetilde{\sss}$ is obtained by rotating $\sss$ by $\pi$ about the $z$-axis and by $\pi/2$ about the $y$-axis, as seen in the right picture in @fig-chart-sphere. It is an exercise to check that $\widetilde{\sss}$ is a regular chart. 

Since we have
$$
\widetilde{\sss} (U) = \sphere^2 \smallsetminus \{ (x,y,0) \in \R^3 \divider x \leq 0  \} \,,
$$
it is immediate to see that
$$
\sphere^2 = \sss(U) \cup \widetilde{\sss}(U) \,.
$$
Hence
$$
\mathcal{A} := \{   \sss , \widetilde{\sss} \} 
$$
is a regular atlas for $\sphere^2$.


:::




```{python}
#| echo: false
#| fig-cap: "Image of the charts of the sphere from the above example."
#| label: fig-chart-sphere

# Importing numpy, matplotlib and mplot3d
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d


fig = plt.figure(figsize = (9,5))

# Generates 2 sets of 3D axes
ax1 = fig.add_subplot(1, 2, 1, projection = '3d')
ax2 = fig.add_subplot(1, 2, 2, projection = '3d')


# Shows axes grid
ax1.grid(True)
ax2.grid(True)

# Generates coordinates u and v by dividing
# the intervals (0,1) and (0,2pi) in 100 parts
u = np.linspace(- np.pi / 2, np.pi / 2, 100)
v = np.linspace(0+0.1, 2*np.pi- 0.1, 100)

# Generates grid [U,V] from the coordinates u, v
U, V = np.meshgrid(u, v)

# Computes the surface on grid [U,V]
x = np.cos(U) * np.cos(V)
y = np.cos(U) * np.sin(V)
z = np.sin(U)


X = - np.cos(U) * np.cos(V)
Y = - np.sin(U)
Z = - np.cos(U) * np.sin(V)

# Plots the cone
ax1.plot_surface(x, y, z, color = 'dimgray', edgecolors = 'snow')


ax2.plot_surface(X, Y, Z, color = 'dimgray', edgecolors = 'snow')



ax2.view_init(elev = 25, azim = -138)


# Setting axes labels
ax1.set_xlabel('x', labelpad=10)
ax1.set_ylabel('y', labelpad=10)
ax1.set_zlabel('z', labelpad=10)

ax2.set_xlabel('x', labelpad=10)
ax2.set_ylabel('y', labelpad=10)
ax2.set_zlabel('z', labelpad=10)


# Showing the plot
plt.show()
```




Let us make an example of a non-regular surface.


::: Example

The surface parametrized by 
$$
\sss(u,v) = (u,v^2,v^3) \,, \quad \forall (u,v) \in \R^2
$$
is not regular. This is because
$$
\sss_u = (1,0,0) \,, \quad
\sss_v = (0,2v,3v^2)
$$
and therefore 
$$
\sss_v(u,0) = (0,0,0) \,, 
$$
showing that $\sss_u$ and $\sss_v$ are linearly dependent along the line
$$
L = \{ (u,0) \divider u \in \R \} \,.
$$
Hence $\sss$ is not a regular chart.

Looking at Figure @fig-plot-cusp, it is clear that $\SSS$ is not regular, since $\SSS$ has a cusp along the line $\sss(L)$.

:::







```{python}
#| echo: false
#| fig-cap: "Example of non-regular surface."
#| label: fig-plot-cusp

# Importing numpy, matplotlib and mplot3d
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

# Generates figure object of size 4 x 4
fig = plt.figure(figsize = (4,4))

# Generates 3D axes
ax = plt.axes(projection = '3d')

# Shows axes grid
ax.grid(True)

# Generates coordinates u and v by dividing
# the intervals (0,1) and (0,2pi) in 100 parts
u = np.linspace(-1, 1, 100)
v = np.linspace(-1, 1, 100)

# Generates grid [U,V] from the coordinates u, v
U, V = np.meshgrid(u, v)

# Computes the surface on grid [U,V]
x = U 
y = V ** 2
z = V ** 3

# Plots the cone
ax.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')




# Setting axes labels
ax.set_xlabel('x', labelpad=10)
ax.set_ylabel('y', labelpad=10)
ax.set_zlabel('z', labelpad=10)

# Setting viewing angle
ax.view_init(elev = 26, azim = 35)

# Showing the plot
plt.show()
```





## Level surfaces



::: Definition
### Level surface

Let $V \subseteq \R^3$ be an open set and $f \colon V \to \R$ be smooth. The **level surface** associated with $f$ is the set
$$
\SSS_f := f^{-1}(0) = \{ (x,y,z) \in V \divider f(x,y,z) = 0  \} \,.
$$


:::


We now give a result concerning regularity of level surfaces. The proof, rather technical, is based on the Implicit Function Theorem and can be
found in Proposition 3.1.25 of [@abate-tovena]. We decide to omit it.


::: {.Theorem #theorem-level-surface}

Let $V \subseteq \R^3$ be an open set and $f \colon V \to \R$ be smooth. Consider the level surface
$$
\SSS_f = \{ (x,y,z) \in V \divider f(x,y,z) = 0  \} \,.
$$
Suppose that 
$$
\nabla f (x,y,z) \neq 0 \,, \quad \forall \, (x,y,z) \in V \,.
$$
Then $\SSS_f$ is a regular surface.

:::



::: Example

We want to determine if the set defined by the equation
$$
\SSS = \{ (x,y,z) \in \R^3 \divider x^2 + y^2 = 1 \}  
$$
is a regular surface. Note that $\SSS$ is a unit cylinder: From Example \ref{example-unit-cylinder} we already know that $\SSS$ is a regular surface.

Let us prove that $\SSS$ is regular by using Theorem \ref{theorem-level-surface}. To this end, define the open set
$$
V := \R^3 \smallsetminus \{ (0,0,z) \divider z \in \R \} \,.
$$
Note that $V$ is obtained by removing the $z$-axis from $\R^3$. Also define  the function $f \colon \R^3 \to \R$ by
$$
f(x,y,z) := x^2 + y^2 -1 \,.
$$
We have
$$
\nabla f (x,y,z) = ( 2x, 2y, 0 ) \neq 0  \,, \quad 
\forall \, (x,y,z) \in V \,.
$$
Since 
$$
\SSS = \SSS_f \,,
$$
by Theorem \ref{theorem-level-surface} we conclude that 
$\SSS$ is a regular surface.

:::




::: Example
### Circular cone

We saw that the circular cone
$$
\SSS := \{ (x,y,z) \in \R^3 \divider x^2 + y^2 = z^2  \} \,.
$$
is not a surface. However the positive sheet 
$$
\SSS^+ := \{ (x,y,z) \in \R^3 \divider x^2 + y^2 = z^2 \,, \,  z>0  \} \,.
$$
is a regular surface, see @fig-positive-cone Indeed, define the open set 
$$
V := \{ (x,y,z) \in \R^3 \divider z > 0 \} 
$$
and  the function $f \colon V \to \R$ by
$$
f(x,y,z) := x^2 + y^2 - z^2 \,.
$$
We have
$$
\nabla f (x,y,z) = ( 2x, 2y, -2z ) \neq 0  \,, \quad 
\forall \, (x,y,z) \in V \,.
$$
Since 
$$
\SSS^+ = \SSS_f \,,
$$
by Theorem \ref{theorem-level-surface} we conclude that 
$\SSS$ is a regular surface. 

As a side note, a regular atlas for $\SSS^+$ is given by $\mathcal{A} = \{\sss\}$ where $\sss \colon \R^2 \to \R^3$ is defined by
$$
\sss (u,v) := (u,v,\sqrt{u^2 + v^2}) \,.
$$

:::



```{python}
#| echo: false
#| fig-cap: "Positive sheet of circular cone."
#| label: fig-positive-cone

# Importing numpy, matplotlib and mplot3d
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

# Generates figure object of size 4 x 4
fig = plt.figure(figsize = (4,4))

# Generates 3D axes
ax = plt.axes(projection = '3d')

# Shows axes grid
ax.grid(True)

# Generates coordinates u and v by dividing
# the intervals (0,1) and (0,2pi) in 100 parts
u = np.linspace(-1, 1, 100)
v = np.linspace(-1, 1, 100)

# Generates grid [U,V] from the coordinates u, v
U, V = np.meshgrid(u, v)

# Computes the surface on grid [U,V]
x = U 
y = V
z = np.sqrt( U ** 2 + V ** 2)

# Plots the cone
ax.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')




# Setting axes labels
ax.set_xlabel('x', labelpad=10)
ax.set_ylabel('y', labelpad=10)
ax.set_zlabel('z', labelpad=10)

# Setting viewing angle
ax.view_init(elev = 26, azim = 35)

# Showing the plot
plt.show()
```






## Reparametrizations


We have defined the reparametrization of curves. In a similar way, one can reparametrize surface charts.


::: Definition

Suppose that $U, \widetilde{U} \subseteq \R^2$ are open sets and 
$$
\sss \colon U \to \R^3 \,, \quad 
\widetilde{\sss} \colon \widetilde{U} \to \R^3 \,,
$$ 
are surface charts. We say that $\widetilde{\sss}$ is a **reparametrization** of $\sss$ if there exists a diffeomorphism
$$
\Phi \colon \widetilde{U} \to U \,,
$$
such that 
$$
\widetilde{\sss} = \sss \circ \Phi \,,
$$
that is,
$$
\widetilde{\sss}( \tilde{u},\tilde{v} ) = \sss (  \Phi ( \tilde{u},\tilde{v}) ) \,, \quad \forall \,\, (\tilde{u},\tilde{v} ) \in 
\widetilde{U} \,.
$$
We call $\Phi$ a **reparametrization map**.
:::



![Schematic illustration of surface chart $\sss$ and reparametrization $\widetilde{\sss}$.](/images/surface_reparametrization.png){width=80%}


We will show that reparametrizations of regular charts are regular. To prove this, first we need to recall the chain rule for multivariable functions.

::: Remark
### Chain rule

Suppose that $U, \widetilde{U} \subseteq \R^2$ are open sets, 
$$
f \colon U \to \R^3 
$$
is smooth, and 
$$
\Phi \colon \widetilde{U} \to U
$$
is a diffeomorphism. Define $\tilde{f} \colon \widetilde{U} \to \R^3$ by composition:
$$
\tilde{f} := f \circ \Phi \,.
$$
Explicitly, the above means
$$
\tilde{f}( \tilde{u},\tilde{v} ) = f (  \Phi ( \tilde{u},\tilde{v}) ) \,, \quad \forall \,\, (\tilde{u},\tilde{v} ) \in 
\widetilde{U} \,.
$$
We denote the components of $f, \tilde{f}$ and $\Phi$ by
$$
\tilde{f} = (\tilde{f}^1, \tilde{f}^2, \tilde{f}^3) \,, \quad 
f = (f^1,f^2,f^3) \,, \quad 
\Phi = (\Phi^1, \Phi^2) \,. 
$$
The Jacobians are
$$
J \tilde{f} = \left(   
\begin{array}{cc}
 \tilde{f}^1_{\tilde u}  & \tilde{f}^1_{\tilde v}  \\
 \tilde{f}^2_{\tilde u}  & \tilde{f}^2_{\tilde v}  \\
 \tilde{f}^3_{\tilde u}  & \tilde{f}^3_{\tilde v}
\end{array}
\right) \,, \quad
J f = \left(   
\begin{array}{cc}
 {f}^1_{u}  &  {f}^1_{v}  \\
 {f}^2_{u}  &  {f}^2_{v}  \\
 {f}^3_{u}  &  {f}^3_{v}
\end{array}
\right) \,, \quad 
J \Phi = \left(   
\begin{array}{cc}
 {\Phi}^1_{\tilde u}  &  {\Phi}^1_{\tilde v}  \\
 {\Phi}^2_{\tilde u}  &  {\Phi}^2_{\tilde v}  
\end{array}
\right) \,.
$$

The chain rule states that
$$
J \tilde{f} (\tilde u, \tilde v) = Jf ( \Phi (\tilde u, \tilde v) ) \,
J\Phi (\tilde u, \tilde v) \,.
$$
By expanding the above identity we obtain the chain rule in vectorial form
\begin{align*}
\tilde{f}_{\tilde{u}} (\tilde{u}, \tilde{v}) & = 
f_u ( \Phi(\tilde{u}, \tilde{v}) ) \Phi_{\tilde{u}}^1 (\tilde{u}, \tilde{v}) + f_v ( \Phi(\tilde{u}, \tilde{v}) ) \Phi_{\tilde{u}}^2 (\tilde{u}, \tilde{v}) \\ 
\tilde{f}_{\tilde{v}} (\tilde{u}, \tilde{v}) & = 
f_u ( \Phi(\tilde{u}, \tilde{v}) ) \Phi_{\tilde{v}}^1 (\tilde{u}, \tilde{v}) + f_v ( \Phi(\tilde{u}, \tilde{v}) ) \Phi_{\tilde{v}}^2 (\tilde{u}, \tilde{v}) 
\end{align*}
The above is quite cumbersome. Hence we introduce compact notation for reparametrizations and chain rule. Specifically, we denote the components of the diffeomorphism $\Phi$ by
\begin{align*}
\Phi^1 \quad & \leadsto \quad (\tilde u, \tilde v) \mapsto u (\tilde u, \tilde v)  \\
\Phi^2 \quad & \leadsto \quad (\tilde u, \tilde v) \mapsto v (\tilde u, \tilde v) 
\end{align*}
Accordingly, the Jacobian of $\Phi$ is denoted as:
$$
J \Phi = \left(   
\begin{array}{cc}
 {\Phi}^1_{\tilde u}  &  {\Phi}^1_{\tilde v}  \\
 {\Phi}^2_{\tilde u}  &  {\Phi}^2_{\tilde v}  
\end{array}
\right)   \quad \leadsto \quad 
\left(   
\begin{array}{cc}
 \dfrac{\partial u}{\partial \tilde u}  &  \dfrac{\partial u}{\partial \tilde v}  \\
 \dfrac{\partial v}{\partial \tilde u}  &  \dfrac{\partial v}{\partial \tilde v}
\end{array}
\right)  \,.
$$
Hence, the chain rule in vectorial form reads
\begin{align*}
\tilde{f}_{\tilde{u}}  & = 
f_u  \frac{\partial u}{\partial \tilde{u}} + f_v  \frac{\partial v}{\partial \tilde{u}} \\ 
\tilde{f}_{\tilde{v}}  & = 
f_u  \, \frac{\partial u}{\partial \tilde{v}}  + f_v  \frac{\partial v}{\partial \tilde{v}} 
\end{align*}

:::




We will now prove that the reparametrization of a regular chart is regular.



::: {.Proposition  #proposition-transition-maps}

Suppose that $U, \widetilde{U} \subseteq \R^2$ are open sets and 
$$
\sss \colon U \to \R^3 
$$ 
is a regular chart. Assume given a diffeomorphism
$$
\Phi \colon \widetilde{U} \to U \,.
$$
The reparametrization $\widetilde{\sss} \colon \widetilde{U} \to \R^3$ defined by 
$$
\widetilde{\sss} = \sss \circ \Phi
$$
is a regular chart, and it holds
$$
 \widetilde{\sss}_{\tilde u} \times \widetilde{\sss}_{\tilde v} =\det  J \Phi \,  \left( \sssu \times \sssv  \right)
$$

:::


::: Proof

Since $\sss$ is a regular chart we have that $\sss_u$ and $\sss_v$ are linearly independent. Hence
$$
\sss_u \times \sss_v \neq 0 \,.
$$
To see that $\widetilde{\sss}$ is regular it is sufficient to prove that
$$
\widetilde{\sss}_{\tilde u} \times \widetilde{\sss}_{\tilde v} \neq 0 \,.
$${#eq-change-chart-1}
By chain rule we have
\begin{align*}
\widetilde{\sss}_{\tilde{u}}  & = 
\sss_u  \frac{\partial u}{\partial \tilde{u}} + \sss_v  \frac{\partial v}{\partial \tilde{u}} \\ 
\widetilde{\sss}_{\tilde{v}}  & = 
\sss_u  \, \frac{\partial u}{\partial \tilde{v}}  + \sss_v  \frac{\partial v}{\partial \tilde{v}} 
\end{align*}
By the properties of vector product we get
\begin{align*}
\widetilde{\sss}_{\tilde u} \times \widetilde{\sss}_{\tilde v} & = 
\left( \sss_u  \frac{\partial u}{\partial \tilde{u}} + \sss_v  \frac{\partial v}{\partial \tilde{u}}   \right) 
\times 
\left( \sss_u  \, \frac{\partial u}{\partial \tilde{v}}  + \sss_v  \frac{\partial v}{\partial \tilde{v}} 
 \right)  \\ 
 & =  \frac{\partial u}{\partial \tilde{u}} \, \frac{\partial u}{\partial \tilde{v}}  \, \left(  \sss_u \times \sss_u \right) +
  \frac{\partial u}{\partial \tilde{u}} \, \frac{\partial v}{\partial \tilde{v}}  \, \left(  \sss_u \times \sss_v \right)  \\
 & + \frac{\partial v}{\partial \tilde{u}} \, \frac{\partial u}{\partial \tilde{v}}  \, \left(  \sss_v \times \sss_u \right) +
  \frac{\partial v}{\partial \tilde{u}} \, \frac{\partial v}{\partial \tilde{v}}  \, \left(  \sss_v \times \sss_v \right) \\
  & = \left(   \frac{\partial u}{\partial \tilde{u}} \, \frac{\partial v}{\partial \tilde{v}} - \frac{\partial v}{\partial \tilde{u}} \, \frac{\partial u}{\partial \tilde{v}}         \right)   \, \left( \sssu \times \sssv  \right) \\
  & = \det \left( 
\begin{array}{cc}
 \dfrac{\partial u}{\partial \tilde u}  &  \dfrac{\partial u}{\partial \tilde v}  \\
 \dfrac{\partial v}{\partial \tilde u}  &  \dfrac{\partial v}{\partial \tilde v}
\end{array}
\right) \,  \left( \sssu \times \sssv  \right) \\
& = \det  J \Phi \,  \left( \sssu \times \sssv  \right) \,.
\end{align*}
Since $\Phi$ is a diffeomorphism, we have that 
$$
\det J\Phi \neq 0 \,,
$$
from which we conclude (@eq-change-chart-1).

:::





## Transition maps



Consider the situation in which two regular charts have overlapping image.  
It is natural to ask wether these maps are reparametrizations of each
other on the overlapping region, see @fig-transition-maps. If such reparametrization exists, it is called a transition map.



![If the two regular charts $\sss$ and $\widetilde{\sss}$ have overlapping image, then they are reparametrization of each other, through a transition map $\Phi$.](/images/surfaces_transition_map.png){#fig-transition-maps width=80%}



::: Definition
### Transition map

Let $\SSS$ be a regular surface and 
$$
\sss \colon U \to \sss(U) \subseteq \SSS \,, \quad
\widetilde{\sss} \colon \widetilde{U} \to \widetilde{\sss} (\widetilde{U}) \subseteq \SSS
$$
be regular charts. Assume that the images of $\sss$ and $\widetilde{\sss}$ overlap, that is,
$$
I := \sss (U) \cap \widetilde{\sss} (\widetilde{U}) \neq \emptyset \,.
$$
The set $I$ is open in $\SSS$, since it is intersection of open sets. Define the sets
$$
V := \sss^{-1}(I) \subseteq U \,, \quad  \widetilde{V} := \widetilde{\sss}^{-1} (I) \subseteq \widetilde{U} \,,
$$
The sets $V$ and $\widetilde{V}$ are open and by construction
$$
\sss(V) = \widetilde{\sss} (\widetilde{V} ) = I \,.
$$
Therefore they are well defined the restrictions
$$
\sss |_{V} \colon V \to I \,, \quad 
\widetilde{\sss} |_{\widetilde{V}} \colon \widetilde{V} \to I \,,
$$
which are homeomorphisms. The homeomorphism
$$
\Phi \colon \widetilde{V} \to V \,, \quad \Phi := \sss^{-1} \circ \widetilde{\sss}
$$
is called a **transition map** from $\sss$ to $\widetilde{\sss}$.

:::




The theorem below states that transition maps between regular charts are diffeomorphisms. The proof is slightly technical and is based on the Implicit Function Theorem. We decide to omit it. The interested reader can find a proof at Page 117 of [@pressley].


::: {.Theorem #theorem-transition-map}

Let $\SSS$ be a regular surface. The transition maps between regular charts are diffeomorphisms. 

:::


We can now use Theorem \ref{theorem-transition-map} to show that
transition maps are reparametrizations.


::: {.Proposition #proposition-transition-map}

Let $\SSS$ be a regular surface and 
$$
\sss \colon U \to \sss(U) \subseteq \SSS \,, \quad
\widetilde{\sss} \colon \widetilde{U} \to \widetilde{\sss} (\widetilde{U}) \subseteq \SSS
$$
be regular charts. Assume that the images of $\sss$ and $\widetilde{\sss}$ overlap, that is,
$$
\sss (U) \cap \widetilde{\sss} (\widetilde{U}) \neq \emptyset \,.
$$
Then there exist open sets 
$$
V \subseteq U \,, \quad  \widetilde{V} \subseteq \widetilde{U} \,,
$$
and a diffeomorphism 
$$
\Phi \colon \widetilde{V} \to V
$$
such that $\widetilde{\sss} |_{\widetilde{V}}$ is a reparametrization of $\sss |_{V}$, that is,
$$
\widetilde{\sss} |_{\widetilde{V}} = (\sss |_{V}) \circ \Phi \,.
$$

:::



::: Proof

Define
$$
I:=\sss (U) \cap \widetilde{\sss} (\widetilde{U}) \neq \emptyset \,.
$$
Note that this set is open in $\SSS$, being intersection of open sets.
Set 
$$
V := \sss^{-1} (  I  ) \,, \quad 
\widetilde{V} := \widetilde{\sss}^{-1} (   I   ) \,.
$$
The sets $V$ and $\widetilde{V}$ are open, since $\sss$ and $\widetilde{\sss}$ are homeomorphisms, and hence are continuous. By construction we have
$$
\sss(V) = \widetilde{\sss} (\widetilde{V}) = I \,.
$$
Therefore they are well defined the restrictions
$$
\sss |_{V} \colon V \to I \,, \quad 
\widetilde{\sss} |_{\widetilde{V}} \colon \widetilde{V} \to I \,,
$$
which are homeomorphisms. Consider the transition map
$$
\Phi \colon \widetilde{V} \to V \,, \quad \Phi := \sss^{-1} \circ \widetilde{\sss} \,.
$$
By Theorem \ref{theorem-transition-map} we know that $\Phi$ is a diffeomorphism. Hence 
$$
\widetilde{\sss} |_{\widetilde{V}} = (\sss |_{V}) \circ \Phi \,,
$$
with $\Phi$ diffeomorphism, showing that $\widetilde{\sss} |_{\widetilde{V}}$ is a reparametrization of $\sss |_{V}$.

:::




::: Important

Proposition \ref{proposition-transition-map} allows us to define properties of surfaces using charts, as long as we check that the property in question does not depend on reparametrization, and hence on the choice of chart.

:::





## Functions between surfaces


We would like to define a concept of smooth function 
$$
f \colon \SSS_1 \to \SSS_2 \,,
$$
where $\SSS_1$ and $\SSS_2$ are regular surfaces. So far, we only know how to define smooth functions from $\R^n$ into $\R^m$. The idea is to use surface charts to define smooth functions between surfaces.



::: {.Definition  #definition-smooth-map-surface}

Let $\SSS_1$ and $\SSS_2$ be regular surfaces and let 
$$
f \colon \SSS_1 \to \SSS_2 
$$
be a map. We say that:

- $f$ is smooth at $\pp \in \SSS_1$ if there exist charts $\sss_i \colon U_i \to \SSS_i$ for $i=1,2$ such that
$$
\pp \in \sss_1(U_1)\,, \quad f(\pp) \in \sss_2(U_2) 
$$
and 
$$
(\sss_2^{-1} \circ f \circ \sss_1 )  \colon U_1 \to U_2
$$
is smooth.

- $f$ is smooth if it is smooth for each $\pp \in \SSS_1$.

- $f$ is a diffeomorphism if $f$ is smooth and invertible, with smooth inverse.

:::




![Sketch function $f$ smooth at $\pp$ between the surfaces $\SSS_1$ and $\SSS_2$.](/images/surface_smooth_map.png){width=70%}





::: Remark

- Definition \ref{definition-smooth-map-surface} makes sense because $\sss_2^{-1}$ exists.

- The map $\sss_2^{-1} \circ f \circ \sss_1$ is only defined for $\xx \in U_1$ such that
$$
f ( \sss_1 (\xx) ) \in \sss_2 (U_2) \,.
$$

- The function $\sss_2^{-1} \circ f \circ \sss_1$ maps from $\R^2$ into $\R^2$, therefore differentiability is intended in the classical sense.

- Definition \ref{definition-smooth-map-surface} does not depend on the choice of charts $\sss_1$ and $\sss_2$  

    > Indeed, suppose that $\widetilde{\sss}_{i} \colon \widetilde{U}_i \to {\SSS}_i$ are charts such that 
    $$
    \pp \in \widetilde{\sss}_1( \widetilde{U}_1) \,, \quad  f(\pp) \in \widetilde{\sss}_2(\widetilde{U}_2) \,.
    $$
    In particular we have
    $$
    \sss_i(U_i) \cap \widetilde{\sss}_i (\widetilde{U}_i) \neq \emptyset \,.
    $$
    As $\SSS_1$ and $\SSS_2$ are regular surfaces, by Theorem \ref{theorem-transition-map} there exist open sets
    $$
    V_i \subseteq U_i \,, \quad \widetilde{V}_i \subseteq \widetilde{U}_i \,,
    $$
    and transition maps 
    $$
    \Phi_i \colon \widetilde{V}_i \to V_i
    $$
    which are diffeomorphisms and satisfy
    $$
    \widetilde{\sss}_i = \sss_i \circ \Phi_i \,.
    $$
    Hence
    \begin{align*}
    \widetilde{\sss}_2^{-1} \circ f \circ \widetilde{\sss}_1 & =
    \widetilde{\sss}_2^{-1} \circ ( \sss_2 \circ \sss_2^{-1} ) \circ f \circ  ( \sss_1 \circ \sss_1^{-1} ) \circ \widetilde{\sss}_1  \\
    & = ( \widetilde{\sss}_2^{-1} \circ  \sss_2 ) \circ ( \sss_2^{-1}  \circ f \circ   \sss_1 ) \circ (\sss_1^{-1}  \circ \widetilde{\sss}_1 )  \\
    & = \Phi_2^{-1} \circ ( \sss_2^{-1}  \circ f \circ   \sss_1 )  \circ \Phi_1^{-1} \,.
    \end{align*}
    Since $\Phi_i^{-1}$ and $\sss_2^{-1}  \circ f \circ   \sss_1$ are smooth, we conclude that
    $$
    \widetilde{\sss}_2^{-1} \circ f \circ \widetilde{\sss}_1
    $$
    is smooth. Hence Definition \ref{definition-smooth-map-surface} does not depend on the choice of charts.
:::




::: Proposition

If $f \colon \SSS_1 \to \SSS_2$ and $g \colon \SSS_2 \to \SSS_3$ are smooth maps (resp. diffeomorphisms) between surfaces, then the composition 
$$
(g \circ f) \colon \SSS_1 \to \SSS_3
$$
is smooth (resp. a diffeomorphisms).


:::


::: Proof

Fix $\pp \in \SSS_1$ and choose charts
$$
\sss_i \colon U_i \to \SSS_i 
$$
such that 
$$
\pp \in \sss_1 (U_1) \,, \quad
f(\pp) \in \sss_2 (U_2) \,, \quad
g(f(\pp)) \in \sss_3 (U_3) \,.
$$
Since $f$ and $g$ are smooth we have that the maps
$$
\sss_2^{-1} \circ f  \circ \sss_1 \,, \quad \sss_3^{-1} \circ  g \circ \sss_2  \,,
$$
are smooth. Hence
$$
\sss_3^{-1} \circ ( g \circ f ) \circ \sss_1 = ( \sss_3^{-1} \circ  g \circ \sss_2 ) \circ (\sss_2^{-1} \circ f  \circ \sss_1)  
$$
is smooth, ending the proof.
:::




::: Definition

Let $\SSS_1$ and $\SSS_2$ be regular surfaces. We say that $\SSS_1$ and $\SSS_2$ are diffeomorphic if there exists $f \colon \SSS_1 \to \SSS_2$ diffeomorphism.

:::


The key ideas around diffeomorphisms are:

1. Two diffeomorphic surfaces are essentially the same.  

    >Indeed, it is immediate to show that being diffeomorphic is an equivalence relation on the set of regular surfaces. 

2. Two diffeomorphic surfaces have essentially the same charts, as shown in the next proposition.


::: {.Proposition  #proposition-f-chart}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ be a diffeomorphism. If 
$\sss \colon U \to \SSS$ is a regular chart for $\SSS$ at $\pp$, then
$$
\widetilde{\sss} := f \circ \sss \colon U \to \widetilde{\SSS}
$$
is a regular chart for $\widetilde{\SSS}$ at $f(\pp)$.

:::


::: Proof

Let $\sss_2 \colon U_2 \to \widetilde{\SSS}$ be a regular chart for $\widetilde{\SSS}$ at $f(\pp)$. By definition of diffeomorphism between surfaces, the map
$$
\Phi := \sss_2^{-1} \circ f \circ \sss \colon U \to U_2
$$
is a diffeomorphism. Therfore 
$$
(f \circ \sss) (u,v) = \sss_2  \left( \Phi(u,v) \right)
$$
with $\Phi$ diffeomorphism, meaning that $f \circ \sss$ is a reparametrization of 
$\sss_2$. Since $\sss_2$ is regular, by Proposition \ref{proposition-transition-maps} we deduce
that $f \circ \sss$ is regular.

:::


We conclude with the definition of local diffeomorphism between surfaces.

::: Definition
### Local diffeomorphism

Let $\SSS_1$ and $\SSS_2$ be regular surfaces. A smooth map $f \colon \SSS_1 \to \SSS_2$ 
is called a **local diffeomorphism** if for each point $\pp \in \SSS_1$ there exists
an open set $V \subseteq \SSS_1$ with $\pp \in V$, such that $f(V) \subseteq \SSS_2$ is open and 
$$
f \colon V \to f(V)
$$
is a diffeomorphism between surfaces.

:::


The above definition is well posed since open subsets of surfaces are themselves surfaces.




## Tangent space


We have seen that tangent vectors to regular curves allow to define the Frenet Frame, curvature and torsion. Eventually, these quantities are sufficient to characterize a curve. It turns out that also regular surfaces admit tangent vectors. To avoid clumsy terminology, we 
make the following assumption.


::: Assumption

From now on, all the surfaces will be regular and all the charts will be regular.

:::


::: Definition
### Tangent vectors and tangent space

Let $\SSS$ be a surface and $\pp \in \SSS$. A **tangent vector** to $\SSS$ at 
$\pp$ is any vector $\vv \in \R^3$ such that
$$
\vv = \dg(0) \,,
$$
where $\g \colon (-\e,\e) \to \R^3$ is a smooth curve such that
$$
\g (-\e , \e) \subseteq \SSS \,, \quad \g(0) = \pp \,,
$$
where $\e>0$. The **tangent space** of $\SSS$ at $\pp$ is the set
$$
T_{\pp} \SSS := \{ \vv \in \R^3 \divider \vv \, \mbox{ tangent vector of } \, \SSS \, \mbox{ at } \, \pp \} \,.
$$


:::



![Tangent space $T_{\pp} \SSS$ of surface $\SSS$ at the point $\pp$. A tangent vector $\vv$ coincides with $\dg(0)$ for some $\g \colon (-\e,\e) \to \SSS$ such that $\g(0)= \pp$.](/images/tangent_space.png){#fig-tangent-plane width=80%}



Let us start with the most basic example: We want to compute the tangent space to an open set in $\R^2$. 


::: {.Example #example-tangent-open-set}

Let $U \subseteq \R^2$ be open and $\pp \in U$. Then 
$$
T_{\pp} U = \R^2 \,.
$$

> Proof. Let $\vv \in T_{\pp} U$. By definition there exists a smooth curve
$$
\gamma \colon (-\e,\e) \to U
$$
such that $\g(0) = \pp$ and $\dg(0)=\vv$. Since $U \subseteq \R^2$, it follows that $\g$ is a plane curve, so that 
$$
\vv = \dg (0) \in \R^2 \,.
$$
Conversely, let $\vv \in \R^2$. Since $\pp \in U$ and $U$ is open, there
exists $\e>0$ such that $B_{\e}(p) \subseteq U$. Define the curve
$$
\g \colon (-\e,\e) \to \R^3 \,, \quad \g(t):= \pp + t \vv \,.  
$$
By construction
$$
\g(-\e,\e) \subseteq B_{\e} (\pp) \subseteq U \,, \quad \g(0) = \pp \,, \quad \dg(0)= \vv \,,
$$
showing that $\vv \in T_{\pp} U$.

:::


In the above example we have seen that $T_{\pp} U = \R^2$. This property holds in general for $T_{\pp} \SSS$ with $\SSS$ regular surface. 
Before proving this fact, we need a lemma.


::: {.Lemma #lemma-curve-S}

Let $\SSS$ be regular and $\pp \in \SSS$. Let $\sss \colon U \to \sss(U) \subseteq \SSS$ be a regular chart at $\pp$, with
$$
\sss(u_0,v_0) = \pp \,.
$$
We have:

1. Suppose $\g \colon (-\e,\e) \to \R^3$ is a smooth curve such that
$$
\g(-\e,\e) \subseteq \sss(U) \,, \quad \g(0) = \pp \,.
$$
Then there exist smooth functions
$$
u , v \colon (-\e,\e) \to \R 
$$
such that
$$
\g(t) = \sss( u(t), v(t) ) \,, \quad \forall \, t \in (-\e,\e) \,,
$$
and 
$$
u(0)=u_0 \,, \quad v(0) = v_0 \,.
$$

2. Conversely, assume $u , v \colon (-\e,\e) \to \R$ are smooth functions such that
$$
u(0)=u_0 \,, \quad v(0) = v_0 \,.
$$
Then
$$
\g (t):= \sss (u(t),v(t))
$$
is a smooth curve such that 
$$
\g(-\e,\e) \subseteq \SSS \,, \quad  \g(0)=\pp \,.
$$


:::


::: Proof

Denote the coordinates of $\sss$ by
$$
\sss(u,v) = (f(u,v), g(u,v), h(u, v)) \,.
$$
The differential of $\sss$ is
$$
d\sss = 
\left(   
\begin{array}{cc}
f_u & f_v \\
g_u & g_v \\
h_u & h_v \\
\end{array}
\right) \,.
$$
Since $\sss$ is regular, by definition $d\sss$ has rank-2 at $(u_0,v_0)$. This means that at least one of the 3 minors
$$
\left(   
\begin{array}{cc}
f_u & f_v \\
g_u & g_v 
\end{array}
\right) \,, \quad 
\left(   
\begin{array}{cc}
f_u & f_v \\
h_u & h_v \\
\end{array}
\right) \,, \quad 
\left(   
\begin{array}{cc}
g_u & g_v \\
h_u & h_v \\
\end{array}
\right) \,.
$$
is invertible. WLOG assume the first is invertible (the proof in case the other two are invertible is similar.) Define the map 
$$
F \colon U \subseteq \R^2 \to \R^2 \,, \quad F(u,v) = ( f(u,v), g(u,v) ) \,.
$$
We have 
$$
dF = 
\left(   
\begin{array}{cc}
f_u & f_v \\
g_u & g_v 
\end{array}
\right) \,,
$$
which is invertible at $(u_0,v_0)$ by assumption. Hence, by the Inverse Function Theorem, there exist 

- $W \subseteq U \subseteq \R^2$ open set with $(u_0,v_0) \in W$,
- $V \subseteq \R^2$ open set with $F(u_0,v_0) \in V$,

such that 
$$
F \colon W \to V 
$$
is a diffeomorphism. Hence
$$
F^{-1} \colon V \to W
$$
is smooth. Since $\g(-\e,\e) \subseteq \sss(U)$, it is well defined the composition
$$
F^{-1} \circ \g \colon (-\e,\e) \to W \subseteq U \,.
$$
In particular, there exist two functions $u,v$ (the components of $F^{-1} \circ \g$) such that
$$
(F^{-1} \circ \g) (t) = (u(t),v(t))
$${#eq-lemma-curve-S}
Note that $u,v$ are smooth, since $F^{-1} \circ \g$ is smooth, being $F^{-1}$ and $\g$ smooth. As $\g(0)=\pp$, by definition of $F$ we have
$$
(u(0),v(0)) = (F^{-1} \circ \g) (0) = F^{-1}(\pp) =  (u_0,v_0) \,,
$$
showing that 
$$
u(0) = u_0 \,, \quad 
v(0) = v_0 \,.
$$
Moreover, applying $\sss$ to both sides of (@eq-lemma-curve-S) yields
$$
\sss(u(t),v(t)) = \sss ((F^{-1} \circ \g)) (t) = \g(t) \,,
$$
as we wanted to show.

The converse statement is trivial.

:::


We are now ready to characterize $T_{\pp} \SSS$ when $\SSS$ is a regular surface.


::: {.Theorem #theorem-tangent-plane}

Let $\SSS$ be a (regular) surface and $\pp \in \SSS$. 
Let $\sss \colon U \to \R^3$ be a chart at $\pp$. Denote by 
$(u_0,v_0) \in U$ a point such that
$$
\sss(u_0,v_0) = \pp \,.
$$
Then
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u , \sss_v \} := \{  \lambda \sss_u + \mu \sss_v \divider \lambda,\mu \in \R \} \,,
$$
where $\sss_u$ and $\sss_v$ are evaluated at $(u_0,v_0)$. In particular
$$
T_{\pp} \SSS = \R^2 \,.
$$

:::

::: Proof

Let $\sss \colon U \to \sss(U) \subseteq \SSS$ be a chart at $p$. If we show that
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u , \sss_v \}
$$
then we deduce 
$$
T_{\pp} \SSS = \R^2 \,,
$$
since $\sss_u$ and $\sss_v$ are linearly independent.


*Step 1.* Suppose $\vv \in T_{\pp} \SSS$. By definition there exists 
a smooth curve $\g \colon (-\e,\e) \to \SSS$ such that
$$
\g(0) = \pp \,, \quad \dg(0) = \vv \,.
$$
By continuity, we can take $\e$ small enough so that
$$
\g(-\e,\e) \subseteq \sss(U) \,.
$$
By Lemma \ref{lemma-curve-S} there exist smooth functions $u , v \colon (-\e,\e) \to \R$
such that
$$
\g(t) = \sss( u(t), v(t) ) \,, \quad \forall \, t \in (-\e,\e) \,,
$$
and 
$$
u(0)=u_0 \,, \quad v(0) = v_0 \,.
$$
Therefore, by chain rule,
$$
\dg(t) = \sss_u ( u(t),v(t) ) \, \dot{u}(t) +  
\sss_v ( u(t),v(t) ) \, \dot{v}(t) \,.
$$
Evaluating the above at $t=0$ yields
\begin{align*}
\vv & = \dg(0) \\
    & = \sss_u ( u(0),v(0) ) \, \dot{u}(0) +  \sss_v ( u(0),v(0) ) \, \dot{v}(0) \\
    & = \sss_u ( u_0,v_0 ) \, \dot{u}(0) +  \sss_v ( u_0,v_0 ) \, \dot{v}(0)  \,,
\end{align*}
which shows 
$$
\vv \in \operatorname{span} \{  \sss_u (u_0,v_0), \sss_v(u_0,v_0) \} \,.
$$

*Step 2.* Suppose that 
$$
\vv \in \operatorname{span} \{  \sss_u (u_0,v_0), \sss_v(u_0,v_0) \} \,.
$$
Then there exist $\lambda,\mu \in \R$ such that
$$
\vv = \lambda \sss_u (u_0,v_0) + \mu \sss_v (u_0,v_0) \,.
$$
Define the curve
$$
\g (t) := \sss (u_0 + \lambda t, v_0 + \mu t) \,, \quad t \in (-\e,\e) \,.
$$
We have
$$
\g(0) = \sss (u_0,v_0) = \pp \,.
$$
Therefore, for $\e$ sufficiently small, we have
$$
\g(-\e,\e) \subseteq \sss(U) \,.
$$
By chain rule
$$
\dg (t) = \sss_u (u_0+ \lambda t , v_0+ \mu t ) \lambda 
+ \sss_v (u_0+ \lambda t , v_0+ \mu t ) \mu \,,
$$
and therefore 
$$
\dg(0) = \sss_u (u_0 , v_0 ) \lambda 
+ \sss_v (u_0 ,v_0) \mu = \vv \,.
$$
This proves that $\vv \in T_{\pp} \SSS$, ending the proof.


:::



Therefore $T_{\pp} \SSS$ is always two-dimensional. This justifies the following definition.


::: Definition 
### Tangent plane

Let $\SSS$ be a regular surface and $\pp \in \SSS$. The set
$$
T_{\pp} \SSS
$$
is called the **tangent plane** to $\SSS$ at $\pp$.

:::




::: {.Remark  #remark-affine-plane}

By definition $T_{\pp} \SSS$ is a vector subspace of $\R^3$. 
As such, it holds that 
$$
\zero \in T_{\pp} \SSS \,.
$$

> To see this, take the curve $\g(t) \equiv \pp$. Then $\g(0) = \pp$ and $\dg(0) = \zero$, showing that $\zero \in T_{\pp} \SSS$.

Therefore $T_{\pp} \SSS$ is a plane through the origin, no matter where the point $\pp \in \SSS$ is located. In pictures, such as @fig-tangent-plane, we draw the tangent plane as if it was touching the surfaces at the point $\pp$, and still denote it by $T_{\pp}\SSS$. This is a slight abuse of notation: to be precise, the plane drawn is 
$$
\pp + T_{\pp} \SSS \,,
$$
which is the **affine tangent plane** through $\pp \in \SSS$.

:::


It is possible to give a cartesian equation for the tangent plane
$$
T_{\pp} \SSS
$$
and for the affine tangent plane
$$
\pp + T_{\pp} \SSS \,.
$$


::: Proposition
### Equation of tangent plane

Let $\SSS$ be a regular surface and $\pp \in \SSS$. Let $\sss$ be a regular chart at $\pp$, with
$$
\sss(u_0,v_0) = \pp = (x_0,y_0,z_0) \,.
$$
Let 
$$
\nn := \sss_u (u_0,v_0) \times \sss_v (u_0,v_0)
$$
We have:

1. The equation of the tangent plane $T_{\pp} \SSS$ is given by
$$
{\nn}_1 x + {\nn}_2 y + {\nn}_3 z = 0 \,, \quad 
\forall \, (x,y,z) \in \R^3 \,,
$$
where $\nn = ({\nn}_1,{\nn}_2,{\nn}_3)$.

2. The equation of the affine tangent plane $\pp + T_{\pp} \SSS$ is given by
$$
{\nn}_1 (x-x_0) + {\nn}_2 (y-x_0) + {\nn}_3 (z-z_0) = 0 \,, \quad 
\forall \, (x,y,z) \in \R^3 \,.
$$

:::


::: Proof

By Theorem \ref{theorem-tangent-plane} we know that
$$
T_{\pp} \SSS = \operatorname{span} \{  \sss_u (u_0,v_0), \sss_v (u_0,v_0) \} \,.
$$
By the properties of cross product, the vector $\nn$ is orthogonal to both
$\sss_u (u_0,v_0)$ and $\sss_v (u_0,v_0)$. Therefore it is orthogonal to
$T_{\pp} \SSS$. The equation for $T_{\pp} \SSS$ is then
$$
(x,y,z) \cdot \nn = 0 \,, \forall \, (x,y,z) \in \R^3 \,.
$$
In particular, the equation for the affine tangent plane $\pp + T_{\pp} \SSS$ is
$$
(x,y,z) \cdot \nn = k \,, \quad  \forall \, (x,y,z) \in \R^3 \,,
$$
for some $k \in \R$. To compute $k$, it is sufficient to evaluate the above equation at $\pp$, since $\pp$ belongs to $\pp + T_{\pp} \SSS$. We obtain
$$
k = \pp \cdot \nn  \,.
$$
Hence the equation for $\pp + T_{\pp} \SSS$ is
$$
(x-x_0,y-y_0,z-z_0) \cdot \nn = 0 \,, \quad  \forall \, (x,y,z) \in \R^3 \,,
$$
ending the proof.

:::




::: Example

Consider the surface $\SSS$ defined by the chart
$$
\sss (u,v) := \left(   \sqrt{1-v} \cos(u) , \sqrt{1-v} \sin(u), v        \right) \,.
$$
We want to compute the equation for the tangent plane $T_{\pp} \SSS$, and for the affine tangent plane $\pp + T_{\pp} \SSS$.

First, we need to check that $\sss$ is regular. We have
\begin{align*}
\sss_u & = \left(  - \sqrt{1-v} \sin(u) , \sqrt{1-v} \cos(u), 0        \right) \\
\sss_v & = \left(    \frac{1}{2} (1-v)^{-1/2}  \cos(u) , \frac{1}{2} (1-v)^{-1/2}   \sin(u), 1        \right) 
\end{align*}
As the last component of $\sss_u$ is $0$ and the last component of $\sss_v$ is $1$, we conclude that $\sss_u$ and $\sss_v$ are linearly independent. Thus $\sss$ is regular. 

Suppose $\pp \in \SSS$ is such that
$$
\sss(u_0,v_0) = \pp
$$
for some $(u_0,v_0) \in \R^2$. By Theorem \ref{theorem-tangent-plane} we have
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u (u_0,v_0) , \sss_v (u_0,v_0)  \} \,.
$$
To find the equation of $T_{\pp} \SSS$ we compute:
\begin{align*}
\sss_u \times \sss_v & = 
\left| 
\begin{array}{ccc}
\ii & \jj & \kk \\
- \sqrt{1-v} \sin(u) & \sqrt{1-v} \cos(u) & 0 \\
\frac{1}{2} (1-v)^{-1/2}  \cos(u) & \frac{1}{2} (1-v)^{-1/2}   \sin(u) & 1
\end{array}
\right| \\
& = \left(  \sqrt{1-v} \cos(u) , \sqrt{1-v} \sin(u), - \frac12        \right) 
\end{align*}
For 
$$
(u_0,v_0) = \left( \frac{\pi}{4}, 0 \right) 
$$
we have
$$
\pp = \sss (u_0,v_0)  = \left( \frac{\sqrt 2}{2}, \frac{\sqrt 2}{2}, 0  \right) \,,
$$
and therefore 
$$
\nn = (\sss_u \times \sss_v)(u_0,v_0) =  \left(  \frac{\sqrt 2}{2}, \frac{\sqrt 2}{2} , -\frac{1}{2}   \right) \,.
$$
The equation for $T_{\pp} \SSS$ is therefore
$$
(x,y,z) \cdot \nn = 0 \,, \quad \forall \, (x,y,z) \in \R^3 \,.
$$
The above reads
$$
\frac{\sqrt 2}{2} \, x + \frac{\sqrt 2}{2} \, y - \frac{1}{2} \, z = 0 \,.
$$
The equation for $\pp + T_{\pp} \SSS$ is instead
$$
\frac{\sqrt 2}{2} \, x + \frac{\sqrt 2}{2} \, y - \frac{1}{2} \, z = k \,,
$$
for some $k \in \R$. To compute $k$, note that $\pp \in \pp + T_{\pp} \SSS$, and therefore 
$$
\frac{\sqrt 2}{2} \, \frac{\sqrt 2}{2} + \frac{\sqrt 2}{2} \, \frac{\sqrt 2}{2} = k \quad \implies \quad k = 1 \,.
$$
The equation for $\pp + T_{\pp} \SSS$ is then
$$
\frac{\sqrt 2}{2} \, x + \frac{\sqrt 2}{2} \, y - \frac{1}{2} \, z = 1 \,.
$$

:::




::: Remark
### Tangent space and derivations

The definition of tangent plane depends on the fact that $\SSS$ is contained in $\R^3$. This is a serious drawback in many applications, as the surface $\SSS$ does not necessarily need to be Euclidean. There is a way to get rid of such dependence, and give an *intrinsic* definition of tangent plane, depending only on the point $\pp$ and the surface $\SSS$. 

The basic idea is as follows: If $U \subseteq \R^2$ is open and $\pp \in U$, then $T_{\pp} U = \R^2$. We can associate to any point $\vv \in T_{\pp} U$ a directional derivative acting on smooth functions $f \colon U \to \R$:
$$
\vv = (v_1,v_2) \mapsto \left. \frac{\partial }{\partial v} \right|_p =
v_1 \, \left. \frac{\partial }{\partial x_1} \right|_p +
v_2 \, \left. \frac{\partial }{\partial x_2} \right|_p 
$$
The above directional derivative is called a **derivation**.

The point is that derivations do not need to be defined through vectors, but can be defined as follows: $D$ is a **derivation** if 

- $D \colon C^{\infty}(U) \to \R$ is a linear operator, where $C^{\infty}(U)$ is the set of smooth functions $f \colon U \to \R$,
- $D$ satisfies the Leibnitz rule
$$
D(fg) = f(\pp) D(g) + g(\pp) D(f) \,, \quad \forall \, f,g \in C^{\infty}(U) \,. 
$$

The tangent plane at p can then be defined as
$$
T_{\pp} U = \{ D \, \mbox{ derivation at  } \pp \} \,.
$$
Therefore 
$$
T_{\pp} U \subseteq (C^{\infty}(U))^* \,,
$$ 
the dual space of smooth functions. 

It is possible to do such construction directly on $\SSS$, by introducing the concepts of: 

- **germ** of a function 
- **algebra** of derivations, acting on germs

An in depth discussion can be found in Chapter 3.4 of [@abate-tovena].


:::




## Unit normal and orientability

Let $\SSS$ be a regular surface and $\pp \in \SSS$. The tangent plane $T_{\pp} \SSS$ passes through the origin. Therefore $T_{\pp} \SSS$ is completely determined by giving a unit vector $\NN$ perpendicular to it:
$$
T_{\pp} \SSS = \{ \xx \in \R^3 \divider \xx \cdot \NN = 0 \} \,.
$$
In this case we write
$$
\NN \perp T_{\pp} \SSS \,,
$$
to denote that $\NN$ is **perpendicular** to $T_{\pp} \SSS$. Clearly, also $-\NN$ is a unit vector, and
$$
(- \NN) \perp T_{\pp} \SSS \,. 
$$


::: Question 

Which unit normal should we choose between $\NN$ and $-\NN$?

:::

There is no right answer to the above question. One way to proceed is the following.


::: {.Remark   #remark-normal-chart}

Suppose that $\sss \colon U \to \R^3$ is a regular chart for $\SSS$. Let $\pp \in \sss(U)$. Then
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u , \sss_v \} \,.
$$
Therefore we can choose the unit normal to $T_{\pp} \SSS$ as 
$$
\NN_{\sss} :=  \frac{ \sss_u \times \sss_v }{ \norm{ \sss_u \times \sss_v } } \,.
$$
Clearly $\NN_{\sss}$ has unit norm. Moreover 
$$
\NN_{\sss} \cdot \sss_u = 0 \,, \quad \NN_{\sss} \cdot \sss_v = 0
$$
by the properties of cross product, showing that $\NN_{\sss}$ is perpendicular to $T_{\pp} \SSS$.

There is however an issue: $\NN_{\sss}$ is not independent on the choice of chart $\sss$. Indeed, suppose that $\widetilde{\sss} \colon  \widetilde{U} \to \R^3$ is a reparametrization of $\sss$, that is, 
$$
\widetilde{\sss} = \sss \circ \Phi \,, \quad \Phi \colon \widetilde{U} \to U \,,
$$
with $\Phi$ diffeomorphism. As shown in the proof of Proposition \ref{proposition-transition-maps}, we have
$$
\widetilde{\sss}_{\tilde{u}} \times \widetilde{\sss}_{\tilde{v}}
= \det (J\Phi)  \, \sss_u \times \sss_v \,.
$$
Hence
$$
\NN_{\widetilde{\sss}} = \frac{ \widetilde{\sss}_{\tilde{u}} \times \widetilde{\sss}_{\tilde{v}} }{\norm{\widetilde{\sss}_{\tilde{u}} \times \widetilde{\sss}_{\tilde{v}}}} = \frac{\det J\Phi}{|\det J\Phi|} \frac{\sss_u \times \sss_v}{\norm{\sss_u \times \sss_v}} = \pm \NN_{\sss} \,.
$$
Therefore the sign on the right hand side depends on the sign of the Jacobian determinant of the transition map $\Phi$.

:::


The above remark motivates the following definitions.



::: Definition
### Standard unit normal of a chart

Let $\SSS$ be a regular surface and $\sss \colon U \to \R^3$ a regular chart. The **standard unit normal** of $\sss$ is the smooth function
$$
\NN_{\sss} \colon U \to \R^3 \,, \quad \NN_{\sss} := \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v} } \,. 
$$

:::



::: Definition
### Charts with same orientation

Let $\SSS$ be a regular surface and $\sss \colon U \to \R^3$, $\widetilde{\sss} \colon \widetilde{U} \to \R^3$ regular charts such that 
$$
\sss(U) \cap \widetilde{\sss} (\widetilde{U}) \neq \emptyset \,.
$$
Denote by $\Phi$ the transition map between $\widetilde{\sss}$ and $\sss$. We say that: 

1. $\sss$ and $\widetilde{\sss}$ determine the **same orientation** if 
$$
\det J \Phi > 0 \,,
$$
where $\Phi$ is defined.

2. $\sss$ and $\widetilde{\sss}$ determine **opposite orientations** if 
$$
\det J \Phi < 0 \,,
$$
where $\Phi$ is defined.

:::



::: Example

Let $\mathbf{a} , \pp ,\mathbf{q} \in \R^3$ and suppose that $\pp$ and $\mathbf{q}$ are linearly independent.
The plane spanned by $\pp ,\mathbf{q}$ and passing through $\mathbf{a}$ can be parametrized by 
$$
\sss (u,v):= \mathbf{a} + \pp u + \mathbf{q} v \,, \quad \forall \, (u,v) \in \R^2 \,.
$$
An alternative parametrization is given by
$$
\widetilde{\sss} (u,v):= \mathbf{a}  + \mathbf{q} u + \pp v  \,, \quad \forall \, (u,v) \in \R^2 \,.
$$
We have
$$
\sss_u = \pp \,, \quad 
\sss_v = \mathbf{q} \,, \quad 
$$
and therefore
$$
\NN_{\sss} = \frac{ \pp \times \mathbf{q}  }{ \norm{ \pp \times \mathbf{q} } } \,.
$$
Similarly, we have
$$
\NN_{\widetilde{\sss}} = \frac{ \mathbf{q} \times \pp   }{ \norm{ \mathbf{q} \times \pp } } =
 \frac{ - \pp \times \mathbf{q}  }{ \norm{ \pp \times \mathbf{q}  } } \,,
$$
showing that
$$
\NN_{\sss} = - \NN_{\widetilde{\sss}} \,.
$$
Hence $\sss$ and $\tilde{\sss}$ determine opposite orientations.

:::





If a surface can be covered by charts with the same orientation, it is called orientable.


::: Definition
### Orientable surface

Let $\SSS$ be a regular surface. Then:

1. An atlas $\mathcal{A} = \{ \sss_i \}_{i \in I}$ is **oriented** if the following property holds: 
$$
\sss_i (U_i) \cap \sss_j (U_j) \neq \emptyset \quad \implies \quad 
\det J \Phi > 0 \,,
$$
where $\Phi$ is the transition map between $\sss_i$ and $\sss_j$.

2. $\SSS$ is **orientable** if there exists an oriented atlas $\mathcal{A}$.

3. If an oriented atlas $\mathcal{A}$ is assigned, we say that $\SSS$ is **oriented** by $\mathcal{A}$.

:::



::: Example
### MÃ¶bius strip

The classical example of non orientable surface is the MÃ¶bius strip, see @fig-mobius-ruled. We will discuss this example in more details when we introduce ruled srufaces, see Example \ref{example-mobius}.

:::


::: Example

Let $\sss \colon U \to \R^3$ be a regular chart. Then 
$$
\SSS_{\sss} := \sss(U)
$$ 
is a regular surface with atlas $\mathcal{A}=\{\sss\}$. Therefore $\SSS_{\sss}$ is orientable.

> This is because we have only one chart. Therefore any transition map $\Phi$ will be the identity,
so that $\det J \Phi = 1 > 0$.

:::


::: Warning
### Orientability is a global property

The above example is saying that orientability is a global property: To determine wether 
a surface $\SSS$ is orientable, we need to examine the transition maps for the entire atlas 
$\mathcal{A}$. This is because a single local parametrization $\sss(U) \subseteq \SSS$ is always orientable.

:::




::: Remark

Let $\sss$ and $\widetilde{\sss}$ be regular charts with transition map $\Phi$. We have seen in 
Remark \ref{remark-normal-chart} that
$$
\NN_{\widetilde{\sss}} = \frac{ \det J \Phi }{ |\det J \Phi| } \, \NN_{\sss} \,.
$$ 
If $\sss$ and $\widetilde{\sss}$ determine the same orientation, then 
$$
\det J \Phi > 0 \,,
$$
which implies
$$
\NN_{\widetilde{\sss}} =  \NN_{\sss} \,.
$$
Hence, if $\SSS$ is an orientable surface, one can define a unit normal vector at each point of 
$\SSS$, without ambiguity.

:::




::: Definition
### Unit normal of a surface

Let $\SSS$ be a regular surface. A **unit normal** of $\SSS$ is a smooth function
$\NN \colon \SSS \to \R^3$ such that
$$
\NN (\pp) \perp T_{\pp} \SSS \,, \quad \| \NN (\pp) \| = 1 \,, \quad \forall \, \pp \in \SSS \, .
$$

:::


::: Warning 

We require the function $\pp \mapsto \NN(\pp)$ to be globally defined on $\SSS$ and smooth.  

:::




::: Proposition

Let $\SSS$ be a regular surface. They are equivalent:

1. $\SSS$ is orientable.

2. There exists a unit normal $\NN \colon \SSS \to \R^3$.

:::

The proof follows from the above arguments. For details, we refer the reader to Proposition 4.3.7 in [@abate-tovena].



In view of the above propostion, for an oriented surface there is a natural choice of unit normal, 
which we call **standard unit normal** of $\SSS$. 


::: Definition
### Standard unit normal of a surface

Let $\SSS$ be a regular surface oriented by the atlas $\mathcal{A}$. The **standard unit normal**
to $\SSS$ is the map $\NN \colon \SSS \to \R^3$ such that
$$
\NN \circ \sss = \NN_{\sss} \,,
$$
for each chart $\sss \in \mathcal{A}$, where 
$$
\NN_{\sss} \colon U \to \R^3 \,, \quad  \NN_{\sss} = \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v} }
$$
is the standard unit normal of $\sss$.

:::




::: Notation

In the following we will denote by $\NN$ both the standard unit normal of $\SSS$ and of a chart. 

:::









## Differential of smooth functions


Let $f \colon U \to V$ with $U,V \subseteq \R^2$ open. Suppose $f$ is smooth. By definition, the differential of $f$ at $\pp \in U$ is a linear map 
$$
df_{\pp} \colon \R^2 \to \R^2 
$$
which approximates $f$ locally at $\pp$. 
We have seen in Example \ref{example-tangent-open-set} that
$$
T_{\pp} U = \R^2 
$$
Therefore we can interpret $df_{\pp}$ as a map between tangent planes:
$$
df_{\pp} \colon T_{\pp} U \to T_{\pp} U \,.
$$
This reasoning suggests how to define the differential of a smooth map between surfaces: If $f \colon \SSS \to \widetilde{\SSS}$ is smooth, we could define its differential at $\pp \in \SSS$ as a linear map
$$
df_{\pp} \colon T_{\pp} \SSS \to T_{f(\pp)} \widetilde{\SSS} \,.
$$
How is the above map defined explicitly? To answer this question, we need a lemma.


::: {.Lemma  #lemma-derivative}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ a smooth map.
For $\vv \in T_{\pp} \SSS$, let $\g \colon (-\e,\e) \to \SSS$ be such that
$$
\g(0) = \pp \,, \quad \dg(0) = \vv \,.
$$
Define
$$
\tg := f \circ \g \colon (-\e,\e) \to \widetilde{\SSS} \,. 
$$
Then $\tg$ is a smooth curve into $\R^3$ and 
$$
\widetilde{\vv} \in T_{f(\pp)} \widetilde{\SSS} \,, \quad \widetilde{\vv} := \dtg (0) \,.
$$

:::



::: Proof

Note that 
$$
\tg = i \circ f \circ \g \,, 
$$
with $i \colon \widetilde{\SSS} \to \R^3$ inclusion map. Since $i,f,\g$ are smooth, we conclude that $\tg \colon (-\e,\e) \to \R^3$ is smooth. Moreover 
$$
\tg(0) = f (\g(0)) = f(\pp) \,,
$$
and therefore 
$$
 \widetilde{\vv} := \dtg (0) \in T_{f(\pp)} \widetilde{\SSS} \,,
$$
by definition of tangent space. 

:::




::: Definition
### Differential of smooth function

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ a smooth map. 
The differential $df_{\pp}$ of $f$ at $\pp$ is defined as the map
$$
df_{\pp} \colon T_{\pp} \SSS \to T_{f(\pp)} \widetilde{\SSS} \,,  \quad df_{\pp}(\vv) := \widetilde{\vv} \,,
$$
where $\widetilde{\vv}$ is as in Lemma \ref{lemma-derivative}.

:::


::: Remark
### Computing $d_{\pp} f$

The differential of $f$ can be computed using the definition. Specifically, let $\vv \in T_{\pp} \SSS$ and let $\g$ be a curve on $\SSS$ such that 
$$
\g(0) = \pp \,, \quad \dg(0) = \vv
$$
Then 
$$
d_{\pp} f (\vv) = (f \circ \gamma)'(0)
$$
The problem with this calculation is that one has to produce a curve $\g$ with $\dg(0) = \vv$, in order to compute $d_{\pp} f$ at $\vv$. As you can imagine, finding one curve for each vector is far from ideal.

:::



::: Example

Let $\SSS = (0,2\pi) \times \R$ and 
$$
\widetilde{\SSS} = \{ (x,y,z) \in \R^3 \, \colon \, x^2 + y^2 = 1 \} 
$$
Note that $\SSS$ is a subset of $\R^2$ (and in particular a regular surface), while $\widetilde{\SSS}$ is a unit cylinder. Define the map 
$$
f \colon S \to \widetilde{\SSS} \,, \quad 
f(u,v) := (\cos u , \sin u, v)
$$
Clearly $f \in \widetilde{\SSS}$ since $\cos^2 u + \sin^2 u = 1$. We want to compute the differential of $f$
$$
d_{\pp} f \colon T_{\pp} \SSS \to T_{f(\pp)} \widetilde{\SSS}
$$
Since $\SSS$ is a subset of $\R^2$, we have that $T_{\pp} \SSS$ is just $\R^2$. Let $\vv = (a,b) \in \R^2$. We need to find a curve $\g \colon (-\e,\e) \to \SSS$ such that
$$
\g(0) = \pp \,, \quad \dg(0) = \vv = (a,b)
$${#eq-example-differential}
Since $\SSS$ is a subset of $\R^2$, $\g$ can be chosen as the straight line through $\pp$ of direction $\vv$, e.g.,
$$
\g(t) := \pp + t \vv = (u_0 + t a, v_0 + tb)\,,
$$
where we denoted $\pp = (u_0,v_0)$. Clearly $\g$ satisfies (@eq-example-differential). We have
\begin{align*}
(f \circ \g) (t) & = f(u_0 + t a, v_0 + tb) \\
                 & = ( \cos(u_0 + ta), \sin(u_0 + ta),v_0 + tb  ) \\
(f \circ \g)' (t) & = (- a \sin (u_0 + ta), a \cos (u_0 + ta), b)
\end{align*}
Therefore the differential at $\pp$ is
$$
d_{\pp} f (\vv) = (f \circ \g)' (0) =  (- a \sin (u_0), a \cos (u_0), b) \,.
$$

:::

We need to show that the definition of differential is well-posed, i.e., that $d_{\pp} f (\vv)$ depends only on $\pp$, $f$, $\vv$: This is because there are infinitely many curves $\g$ passing trough $\pp$ and such that $\dg(0) = \vv$, and a priori $d_{\pp} f (\vv)$ could depend on which curve is chosen.

We prove well-posedness of $df_{\pp}$ in the next Proposition. We also show that the map $df_{\pp}$ is linear, and we provide the matrix representation of $df_{\pp}$. The matrix representation, in particular, allows to compute $d_{\pp} f$ without the need to construct suitable curves.


::: {.Proposition #proposition-differential-smooth}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ a smooth map. Denote the differential of $f$ by
$$
df_{\pp} \colon T_{\pp} \SSS \to T_{f(\pp)} \widetilde{\SSS} \,.
$$
We have:

1. $df_{\pp} (\vv)$ does not depend on the choice of $\g$, but rather only on $f, \pp,\vv$.

2. $df_{\pp}$ is linear, that is,
$$
df_{\pp} (\lambda \vv + \mu \ww) = \lambda df_{\pp} (\vv) + \mu df_{\pp} (\ww) \,, 
$$
for all $\vv,\ww \in T_{\pp} \SSS$ and $\lambda,\mu \in \R$.
3. Let 
$$
\sss \colon U \to \SSS \,, \quad \widetilde{\sss} \colon \widetilde{U} \to \widetilde{\SSS} \,,
$$
be regular charts at $\pp$ and $f(\pp)$, respectively. Denote by 
$$
(u,v)  \mapsto ( \alpha(u,v), \beta(u,v) ) 
$$
the components of the smooth map
$$
\Psi := \widetilde{\sss}^{-1} \circ f \circ \sss \colon U \to \widetilde{U} \,.
$$
In particular it holds
$$
\widetilde{\sss} (  \alpha(u,v) , \beta(u,v) ) = f(\sss (u,v)) \,, 
\quad \forall \, (u,v) \in U \,.
$$
The matrix of the linear map $df_{\pp}$ with respect to the basis 
$$
\{ \sss_u , \sss_v \} \,\, \mbox{ on } \,\, T_{\pp} \SSS \,, \quad
\{ \widetilde{\sss}_{\tilde{u}} , \widetilde{\sss}_{\tilde{v}} \} \,\, \mbox{ on } \,\, T_{f(\pp)} \widetilde{\SSS} \,,
$$
is given by the Jacobian of the map $\Psi$, that is,
$$
d_{\pp} f = J\Psi = \left(
\begin{array}{cc}
\alpha_u & \alpha_v \\
\beta_u & \beta_v \\
\end{array}
\right) \,.
$$


:::


Point 3 in the above proposition seems complicated, but it is saying something really simple:

1. Let $f \colon \SSS \to \widetilde{\SSS}$ be a smooth function between surfaces. Consider local charts $\sss$ at $\pp$ and $\widetilde{\sss}$ at $f(\pp)$. By definition of smooth map, the real map
$$
\Psi \colon \R^2 \to \R^2 \,, \qquad \Psi := \widetilde{\sss}^{-1} \circ f \circ \sss
$$
is smooth.

2. The matrix of the differential $d_{\pp}f$ with respect to the basis
$$
\{ \sss_u , \sss_v \} \,\, \mbox{ on } \,\, T_{\pp} \SSS \,, \quad
\{ \widetilde{\sss}_{\tilde{u}} , \widetilde{\sss}_{\tilde{v}} \} \,\, \mbox{ on } \,\, T_{f(\pp)} \widetilde{\SSS} \,,
$$
is just the Jacobian of $\Psi$. 



::: Proof

Let $\pp \in \SSS$ and $\vv \in T_{\pp} \SSS$ be fixed. In order to prove the thesis, we need compute $d_{\pp} f$. To this end, let $\sss \colon U \to \SSS$ be a chart at $\pp$. Denote by $(u_0,v_0) \in U$ the point such that
$$
\sss(u_0,v_0) = \pp \,.
$$
Let $\widetilde{\sss} \colon \widetilde{U} \to \widetilde{\SSS}$ a chart at $f(\pp)$. Since $f$ is smooth, the map
$$
\Psi \colon U \to \widetilde{U} \,, \quad \Psi := \widetilde{\sss}^{-1} \circ f \circ \sss
$$
is smooth. Denote by 
$$
(u,v)  \mapsto ( \alpha(u,v), \beta(u,v) ) 
$$
the smooth components of $\Psi$. By definition of $\Psi$ it holds
$$
\widetilde{\sss} (  \alpha(u,v) , \beta(u,v) ) = f(\sss (u,v)) \,, 
\quad \forall \, (u,v) \in U \,.
$${#eq-function-transition}
Denote by
$$
\vv = (\lambda,\mu)
$$
the components of $\vv$ with respect to the basis $\{\sssu,\sssv\}$ of $T_{\pp} \SSS$. Define the scalar functions
$$
u(t):= u_0 +\lambda t \,, \quad 
v(t):= v_0 +\mu t \,,
$$
and the curve
$$
\g(t) := \sss(u(t), v(t)) \,.
$$
Clearly $\g$ is a regular curve on $\SSS$, and it holds
$$
\g(0) = \sss(u_0, v_0) = \pp  \,, \quad 
\dg(0) = (\lambda,\mu) = \vv
$$
By (@eq-function-transition) we have
\begin{align*}
(f \circ \g)(t) & = f(\g(t)) \\
                & = f( \sss(u(t), v(t)) ) \\
                & = \widetilde{\sss} ( \alpha(u(t),v(t)), \beta(u(t),v(t))  )
\end{align*}
By chain rule we obtain
\begin{align*}
(f \circ \g)'(t) & = \widetilde{\sss}_{\tilde{u}} \frac{d}{dt}  \alpha(u(t),v(t)) +
\widetilde{\sss}_{\tilde{v}} \frac{d}{dt}  \beta(u(t),v(t))   \\
& = \widetilde{\sss}_{\tilde{u}} [ \alpha_u \dot{u}(t) + \alpha_v \dot{v}(t)  ] + 
\widetilde{\sss}_{\tilde{v}} [ \beta_u \dot{u}(t) + \beta_v \dot{v}(t)  ]
\end{align*}
Recalling that $\dot{u}(0) = \lambda$ and $\dot{v}(0) = \mu$, we get
$$
(f \circ \g)'(t) = 
\widetilde{\sss}_{\tilde{u}} [ \lambda \alpha_u + \mu \alpha_v  ] + 
\widetilde{\sss}_{\tilde{v}} [ \lambda  \beta_u + \mu \beta_v]
$$
As by definition of differential
$$
d_{\pp} f (\vv)  = ( f \circ \g )' (0)
$$
we have obtained 
$$
d_{\pp} f (\vv) = \widetilde{\sss}_{\tilde{u}} [ \lambda \alpha_u + \mu \alpha_v  ] + 
\widetilde{\sss}_{\tilde{v}} [ \lambda  \beta_u + \mu \beta_v]
$${#eq-function-transition-1}
We can now draw our 3 conclusions:

1. The RHS of (@eq-function-transition-1) depends only on $\lambda,\mu$ (the components of $\vv$), $f$ (via the components $\alpha,\beta$ of $\Psi$), and the point $\pp$. In particular $d_{\pp}f(\vv)$ does not depend on the choice of $\g$, and the definition is well-posed.

2. The RHS of (@eq-function-transition-1) is linear in the components $\lambda,\mu$ of $\vv$. In particular $d_{\pp}f(\vv)$ is linear in $\vv$.

3. The coordinates of $\sssu$ with respect to the basis $\{\sssu,\sssv\}$ are $(\lambda,\mu) = (1,0)$. Using (@eq-function-transition-1), we get
$$
d_{\pp}f(\sssu) = \widetilde{\sss}_{\tilde{u}}\alpha_u + 
\widetilde{\sss}_{\tilde{v}} \beta_u 
$$
Similarly, the coordinates of $\sssv$ with respect to the basis $\{\sssu,\sssv\}$ are $(\lambda,\mu) = (0,1)$. Therefore
$$
d_{\pp}f(\sssv) = \widetilde{\sss}_{\tilde{u}}\alpha_v + 
\widetilde{\sss}_{\tilde{v}} \beta_v 
$$ 
This shows that the matrix of the linear application $d_{\pp}f$ with respect to the basis $\{\sssu,\sssv\}$ on $T_{\pp} \SSS$ and the basis $\{\widetilde{\sss}_{\tilde{u}} , \widetilde{\sss}_{\tilde{v}}\}$ on $T_{f(\pp)} \widetilde{\SSS}$ is
$$
\left(
\begin{array}{cc}
\alpha_u & \alpha_v \\
\beta_u & \beta_v \\
\end{array}
\right) = J\Psi  \,.
$$
:::


::: Example
### Computing the matrix of $d_{\pp}f$

Consider the unit cylinder 
$$
\SSS = \{ (x,y,z) \in \R^3 \, \colon \, x^2 + y^2 = 1 \} \,.
$$
and the map
$$
f \colon \SSS \to \R^2 \,, \quad 
f(x,y,z) = (y,xz,0)
$$
We want to compute the matrix of $d_{\pp}f$. To this end, a chart of $\SSS$ is given by 
$$
\sss(u,v) = (\cos u, \sin u, v) \,, \quad (u,v) \in U := (0,2\pi) \times \R \,.
$$
A chart of $\widetilde{\SSS} = \R^2$ is given by 
$$
\widetilde{\sss}(\tilde{u},\tilde{v}) = (\tilde{u},\tilde{v},0) \,, \quad (\tilde{u},\tilde{v}) \in \tilde{U} = \R^2 \,.
$$
We need to compute the map
$$
\Psi \colon U \to \widetilde{U} \,, \quad \Psi := \widetilde{\sss}^{-1} \circ f \circ \sss \,.
$$
Clearly we have
$$
\widetilde{\sss}^{-1} (\tilde{u},\tilde{v},0) =(\tilde{u},\tilde{v}) \,.
$$
Therefore
\begin{align*}
\Psi(u,v) & = \widetilde{\sss}^{-1} \left( f(\sss(u,v))    \right) \\
          & = \widetilde{\sss}^{-1} \left( f(\cos u, \sin u, v )    \right) \\
          & =  \widetilde{\sss}^{-1} \left( \sin (u), \cos (u) v, 0    \right) \\
          & = \left( \sin (u), \cos (u) v    \right)
\end{align*}
Therefore 
\begin{align*}
\partial_u \Psi^1 & = \cos (u) \,, & \partial_v & \Psi^1 = 0 \\
\partial_u \Psi^2 & = -\sin (u) v \,,  & \partial_v & \Psi^2 = \cos(u) 
\end{align*}
The matrix of $d_{\pp}f$ is hence
$$
d_{\pp}f = J\Psi = 
\left(
\begin{array}{cc}
\cos (u) & 0 \\
-\sin (u) v  & \cos(u) \\
\end{array}
\right) \,.
$$

:::


The differential satisfies the following useful properties.


::: Proposition

The following hold:

1. If $\SSS$ is a regular surface and $\pp \in \SSS$, the differential at $\pp$ of the identity map 
$$
I \colon \SSS \to \SSS \,, \quad I(x):=x \,,
$$
is the identity map
$$
I \colon T_{\pp} (\SSS) \to T_{\pp} (\SSS) \,, \quad I(v):=v \,.
$$

2. If $\SSS_1$, $\SSS_2$ and $\SSS_3$ are regular surfaces and 
$$
f \colon \SSS_1 \to \SSS_2 \,, \quad 
g \colon \SSS_2 \to \SSS_3 \,,
$$
are smooth maps, then 
$$
d_{\pp} ( g \circ f ) = d_{f(\pp)} g \circ d_{\pp} f \,,
$$
for all $\pp \in T_{\pp} \SSS_1$.

3. If $\SSS_1$, $\SSS_2$ are regular surfaces and 
$$
f \colon \SSS_1 \to \SSS_2 \,,
$$
is a diffeomorphism, then the differential
$$
d_{\pp} \colon T_{\pp} \SSS_1 \to T_{f(\pp)} \SSS_2
$$
is invertible for all $\pp \in \SSS_1$.

:::

For a proof see Proposition 4.4.5 in [@pressley]. The above proposition says that the differential of diffeomorphism is invertible. The converse statement is true locally.


::: Theorem

Let $\SSS_1$ and $\SSS_2$ be regular surfaces. Suppose that 
$$
f \colon \SSS_1 \to \SSS_2 
$$
is smooth. They are equivalent:

1. $f$ is a local diffeomorphism.
2. The differential $d_{\pp} f \colon T_{\pp} \SSS_1 \to T_{f(\pp)} \SSS_2$ is invertible for all $\pp \in \SSS_1$.


:::

The proof is based on the Inverse Function Theorem, see Proposition 4.4.6 in
[@pressley].








## Examples of Surfaces


### Level surfaces

We have already seen level surfaces. Let us recall the defintion.

::: Definition
### Level surface

Let $V \subseteq \R^3$ be an open set and $f \colon V \to \R$ be smooth. The **level surface** associated with $f$ is the set
$$
\SSS_f := f^{-1}(0) = \{ (x,y,z) \in V \divider f(x,y,z) = 0  \} \,.
$$

:::


The following Theorem gives a sufficient condition for $\SSS_f$ to be
a regular surface. 



::: {.Theorem #theorem-level-surface-bis}

Let $V \subseteq \R^3$ be an open set and $f \colon V \to \R$ be smooth. 
Suppose that 
$$
\nabla f (x,y,z) \neq 0 \,, \quad \forall \, (x,y,z) \in V \,.
$$
Then $\SSS_f$ is a regular surface.

:::


Let us give a characterization of the tangent plane to $\SSS_f$.


::: Proposition

Let $V \subseteq \R^3$ be an open set and $f \colon V \to \R$ be smooth. 
Suppose that 
$$
\nabla f (x,y,z) \neq 0 \,, \quad \forall \, (x,y,z) \in V \,.
$$
Then $\nabla f(\pp)$ is orthogonal to $T_{\pp} \SSS_f$. In particular,
the equation of $T_{\pp} \SSS_f$ is given by
$$
\partial_{x} f (\pp) x  + \partial_{y} f (\pp) y    + \partial_{z} f (\pp) z = 0 \,, \quad  \forall \, (x,y,z) \in \R^3\,.   
$$
The equation for $\pp + T_{\pp} \SSS_f$ is given by
$$
\partial_{x} f (\pp) (x-x_0)  + \partial_{y} f (\pp) (y-y_0)    + \partial_{z} f (\pp) (z-z_0) = 0 \,, \forall \, (x,y,z) \in \R^3\,,   
$$
where $\pp = (x_0,y_0,z_0)$.

:::

::: Proof

Let $\vv \in T_{\pp} \SSS_f$. By definition there exists a smooth curve 
$$
\g \colon (-\e,\e) \to \SSS_f \subseteq \R^3 
$$
such that
$$
\g(0) = \pp \,, \quad \dg(0)=\vv \,.
$$
Since $\g(t) \in \SSS_f$, we have that
$$
f(\g(t)) = 0 \,, \quad \forall \, t \in (-\e,\e) \,.
$$
By chain rule we get
$$
\nabla f (\g(t)) \cdot \dg(t) = 0 \,, \quad \forall \, t \in (-\e,\e) \,.
$$
Evaluating the above at $t=0$ yields
$$
0 = \nabla f (\g(0)) \cdot \dg(0) = \nabla f (\pp) \cdot \vv \,,
$$
showing that $\vv$ is orthogonal to $\nabla f (\pp)$. Since $\vv$ is arbitrary, we conclude that $\nabla f (\pp)$ is orthogonal to $T_{\pp} \SSS_f$. In particular, the equation for $T_{\pp} \SSS_f$ is
$$
\nabla f(\pp) \cdot (x,y,z) = 0 \,, \quad \forall \, (x,y,z) \in \R^3 \,.
$$
Therefore the equation for $\pp + T_{\pp} \SSS$ is given by
$$
\nabla f(\pp) \cdot (x,y,z) = k \,, \quad \forall \, (x,y,z) \in \R^3 \,,
$$
for some $k \in \R$. Since $\pp \in \pp + T_{\pp} \SSS$, we can substitute 
$$
(x,y,z)=(x_0,y_0,z_0) = \pp 
$$
in the above equation to obtain
$$
k = \nabla f(\pp) \cdot (x_0,y_0,z_0) \,.
$$
Hence the equation for $\pp + T_{\pp} \SSS$ is
$$
\nabla f(\pp) \cdot (x-x_0,y-y_0,z-z_0) = 0 \,, \quad \forall \, (x,y,z) \in \R^3 \,.
$$

:::





### Quadrics


Quadrics are level surfaces
$$
S_f = \left\{  (x,y,z) \in \R^3 \divider f(x,y,z) = 0   \right\} \,,
$$
where
\begin{align*}
f(x,y,z)  = & a_1 x^2 + a_2 y^2 + a_3 z^2 + 2a_4 xy + 2a_5 xz + 2a_6 yz + \\
          & + b_1 x + b_2 y + b_3 z + c  \,,
\end{align*}
for some coefficients $a_i,b_i,c \in \R$. Let
$$
A =  
\left( 
\begin{array}{ccc}
a_1 & a_4 & a_6 \\
a_4 & a_2 & a_5 \\
a_6 & a_5 & a_3 
\end{array}
\right)  \in \R^{3 \times 3} \,,
$$
and
$$
\xx = (x,y,z)^T \,, \quad \mathbf{b} = (b_1,b_2,b_3)^T \,.
$$
Then $f$ can be represented by the quadratic form
$$
f(\xx) = \xx^T A \xx + \mathbf{b} \cdot \xx + c \,.
$$
The expression $f=0$ is called a **quadric equation**.


As stated in the following theorem, there are $14$ quadrics in total. Out of these:

- 9 are *interesting* surfaces, 
- 3 are planes,
- 1 is a line,
- 1 is a point.



::: {.Theorem #theorem-quadrics}

Suppose $\SSS$ is a level surface defined by a quadric equation. 
Then, up to rigid motions, $\SSS$ can be described by one of the following equations:

1. Ellipsoid: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2} + \dfrac{z^2}{r^2} = 1$.

2. Hyperboloid of one sheet: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2} - \dfrac{z^2}{r^2} = 1$

3. Hyperboloid of two sheets: $\dfrac{x^2}{p^2} - \dfrac{y^2}{q^2} - \dfrac{z^2}{r^2} = 1$

4. Elliptic Paraboloid: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2}  = z$

5. Hyperbolic Paraboloid: $\dfrac{x^2}{p^2} - \dfrac{y^2}{q^2}  = z$

6. Quadric Cone: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2} - \dfrac{z^2}{r^2} = 0$

7. Elliptic Cylinder: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2}  = 1$

8. Hyperbolic Cylinder: $\dfrac{x^2}{p^2} - \dfrac{y^2}{q^2}  = 1$

9. Parabolic Cylinder: $\dfrac{x^2}{p^2} = y$

10. Plane: $x = 0$

11. Two parallel planes: $x^2 = p^2$

12. Two intersecting planes: $\dfrac{x^2}{p^2} - \dfrac{y^2}{q^2} = 0$

13. Straight line: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2} = 0$

14. Single point: $\dfrac{x^2}{p^2} + \dfrac{y^2}{q^2} + \dfrac{z^2}{r^2} = 0$

:::


The proof of Theorem \ref{theorem-quadrics} follows by diagonalizing 
the symmetric matrix $A$, and by studying the eigenvalues, see Theorem 5.5.2 in [@pressley].



::: Example

The sphere is described by
$$
S = \{ (x,y,z) \in \R^3 \divider x^2 + y^2 + z^2 = 1 \} \,.
$$
This is an ellipsoid with 
$$
p = q = r = 1 \,.
$$
In particular we can write the sphere as the quadric equation:
$$
\xx^T 
\left( 
\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 
\end{array}
\right)  \xx = 1 \,.
$$

:::


::: Example

Consider the level surface
$$
\SSS =   \{ (x,y,z) \in \R^3 \divider f(x,y,z) = 0 \}
$$
with 
$$
f(x,y,z) = x^2 + 2y^2 - 4z^2 + 2xy + yz - 6xz + 1 = 0 \,.
$$
Therefore $\SSS$ is a quadric. The matrix associated to $f$ is
$$
A =  
\left( 
\begin{array}{ccc}
1 & 1 & -3 \\
1 & 2 & 1/2 \\
-3 & 1/2 & -4 
\end{array}
\right)  \,.
$$
Diagonalizing the matrix $A$ we obtain $A=PDP^{-1}$, with $P$ matrix of
eigenvectors and 
$$
D =  
\left( 
\begin{array}{ccc}
-5.51 & 0 & 0 \\
0 & 1.55 & 0 \\
0 & 0 & 2.96 
\end{array}
\right)  \,.
$$
Therefore, up to changing basis via the matrix $P$, $S$ can be described 
by the quadric equation
$$
5.51 \widetilde{x}^2 - 1.55 \widetilde{y}^2 - 2.96 \widetilde{z}^2 = 1  \,,
$$
showing that $S$ is a Hyperboloid of two sheets.

:::



### Ruled surfaces


A ruled surface is a surface obtained as union of straight lines, called the rulings of the surface. By using curves, ruled surfaces can be defined
in the following way.


::: Definition
### Ruled surface

Let $\g \colon (a,b) \to \R^3$ be a smooth curve and $\mathbf{a} \colon (a,b) \to \R^3$ a vector, such that $\dg(t)$ and $\mathbf{a}(t)$ are linearly independent for all $t \in (a,b)$. A **ruled surface** is a surface with 
chart
$$
\sss(u,v) = \g(u) + v \mathbf{a}(u) \,.
$$
We say that:

- $\g$ is the **base curve**
- The lines $v \mapsto v \mathbf{a}(u)$ are the **rulings**

:::


::: Proposition

A ruled surface $\SSS$ is regular if $v$ is sufficiently small.

:::

::: Proof

A chart for $\SSS$ is
$$
\sss_u = \dg(u) + v \dot{\mathbf{a}}(u) \,, \quad
\sss_v = \mathbf{a}(u) \,,
$$
with $\dg$ and $\mathbf{a}$ linerly independent. Thus $\dg(u) + v \dot{\mathbf{a}}(u)$ and $\mathbf{a}$ are linearly independent for
$v$ sufficiently small. 

:::


The same base curve can yield multiple ruled surfaces.
For example, if $\g$ is a circle, we can obtain both the unit cylinder
and the MÃ¶bius band. 


::: Example
### Unit Cylinder

As seen in Example \ref{example-unit-cylinder}, the cylinder is a surface with atlas $\mathcal{A}=\{\sss_1,\sss_2\}$, where $\sss_1$ and $\sss_2$ are suitable restriction of
$$
\sss (u,v) = (\cos(u), \cos(u),v ) \,, \quad (u,v) \in [0,2\pi) \times \R \,.
$$
We have
$$
\sss(u,v) = \g(u) + v \mathbf{a}(u) \,,
$$
with
$$
\g(u):= (\cos(u), \cos(u),0 ) \,, \quad \mathbf{a} = (0,0,1) \,.
$$
Hence the unit cylinder is a ruled surface, see @fig-cylinder-ruled.

:::


![Unit cylinder is a ruled surface with base curve $\g$ and rulings given by vertical lines.](/images/surfaces_ruled.png){#fig-cylinder-ruled width=70%}


::: Example
### MÃ¶bius band  {#example-mobius}

The MÃ¶bius band is a ruled surface with chart
$$
\sss = \g(u) + v \mathbf{a}(u) \,, \quad u \in (0,2\pi), \, v \in \left( -\frac12, \frac12 \right) \,,
$$
where 
$$
\g(u) = (\cos(u), \sin(u), 0) 
$$
is the unit circle and
$$
\mathbf{a} = \left(   -\sin \left( \frac{u}{2} \right) \cos(u),
                  -\sin \left( \frac{u}{2} \right) \sin(u),
                   \cos \left( \frac{u}{2} \right)   \right) 
$$
is a vector which does a full rotation while going around the unit
circle $\g$. This is shown in @fig-mobius-ruled. In particular 
$$
\sss (u,v) =  \left(   
  \left[ 1 - v \sin \left( \frac{u}{2} \right) \right] \cos(u),
  \left[ 1 - v \sin \left( \frac{u}{2} \right) \right] \sin(u),
  v \cos \left( \frac{u}{2} \right)   \right) \,.
$$

We want to prove that $\SSS$ is **non orientable**. From the above formula for $\sss$, it is easy to compute that 
$$
\sssu \times \sssv = \left( - \cos(u) \cos \left(  \frac{u}{2} \right),   - \sin(u) \cos \left(  \frac{u}{2} \right) , - \sin \left(  \frac{u}{2} \right) \right) \,.
$$
It is also immediate to check that $\norm{\sssu \times \sssv} = 1$, and therefore the principal unit normal of $\sss$ is
$$
\NN_{\sss} = \sss_u \times \sssv \,.
$$
Suppose by contradiction that $\SSS$ is orientable. This means there exists a globally defined principal unit normal vector
$$
\NN \colon \SSS \to \R^3 \,.
$$
By definition of principal normal, we have either 
$$
\NN \circ \sss = \NN_{\sss} \quad \text{ or } \quad
\NN \circ \sss = - \NN_{\sss} \,.
$$
Without loss of generality assume that 
$$
\NN \circ \sss = \NN_{\sss} \,.
$$
Consider the point $\pp = (1,0,0)$ on $\SSS$. Notice that, by continuity, $\pp$ can be obtained via $\sss$ through the limits
$$
\pp = \lim_{u \to 0^+} \sss(u,0) = \lim_{u \to 2\pi^-} \sss(u,0) \,.
$$
Since $\NN$ is continuous, the above implies
$$
\NN(\pp) = \lim_{u \to 0^+} \NN \circ \sss(u,0) = \lim_{u \to 2\pi^-} \NN \circ \sss(u,0) \,.
$${#eq-mobius-not-orientable}
However, by direct calculation:
\begin{align*}
\lim_{u \to 0^+} \NN \circ \sss(u,0) & =
\lim_{u \to 0^+} \NN_{\sss} (u,0) = (-1,0,0) \\
\lim_{u \to 2\pi^-} \NN \circ \sss(u,0) & =
\lim_{u \to 2\pi^-} \NN_{\sss} (u,0) = (1,0,0)
\end{align*}
This clearly contradicts (@eq-mobius-not-orientable). Therefore $\NN$ cannot exist, and $\SSS$ is not orientable.


:::



![The MÃ¶bius band is a ruled surface with base curve $\g$ and rulings given by rotating vertical lines.](/images/surfaces_ruled_2.png){#fig-mobius-ruled width=70%}





### Surfaces of Revolution


Surfaces of revolution are obtained by rotating a curve about the $z$-axis.


::: Definition
### Surface of revolution

Let $\g \colon (a,b) \to \R^3$ be a smooth curve in the $(x,z)$-plane, that is,
$$
\g(u) = (f(u), 0 , g(u)) \,.
$$
Suppose that $f>0$. The surface obtained by rotating $\g$ about the $z$-axis is called **surface of revolution**. A chart for $\SSS$ is given by
$$
\sss (u,v) :=  (f(u) \cos(v), f(u)\sin(v), g(u)) \,, \,\, u \in (a,b) \,, \, v \in [0,2\pi) \,.
$$

:::


::: {.Proposition #proposition-revolution}

A surface of revolution is regular if and only if $\g$ is regular.

:::


::: Proof

We have
\begin{align*}
\sss_u & = \left(\dot{f}(u) \cos(v), \dot{f}(u) \sin(v), \dot{g}(u) \right) \,, \\
\sss_v & = \left(-f(u)\sin(v), f(u) \cos(v), 0 \right) \,.
\end{align*}
Therefore
$$
\sss_u \times \sss_v = \left( f \dot{g} \cos(v), -\dot{f} g \sin(v), f \dot{f} \right)
$$
and 
$$
\norm{\sss_u \times \sss_v}^2 = f^2 \left( \dot{f}^2 + \dot{g}^2 \right) = f^2 \norm{\g}^2 \,.
$$
Recall that $f > 0$ by definition, so that $f^2 \neq 0$. 
Therefore $\sss_u$ and $\sss_v$ are linearly independent if and only if $\g$ is regular.

:::



::: Example
### Catenoid

The catenoid is the surface of revolution obtained by rotating the catenary about the $z$-axis, see @fig-catenoid. Recall that the catenary function is defined by
$$
f(u) = \cosh (u) \,.  
$$
Therefore the catenoid is obtained by rotating 
$$
\g(u) = \left(  \cosh (u), 0 , u \right) \,.
$$
A chart for the catenoid is given by
$$
\sss (u,v) = (\cosh (u) \cos(v), \cosh (u)\sin(v), u) \,, 
$$
where $u \in \R$ and  $v \in [0,2\pi)$. Note that $f>0$ and 
$$
\dg = \left(  \sinh (u), 0 , 1 \right) \,, \quad 
\norm{\dg}^2 = 1+ \sinh(u)^2 \geq 1 \,.
$$
Therefore $\g$ is regular. By Proposition \ref{proposition-revolution} we  conclude that the catenoid is a regular surface.


:::


![The Catenoid is the surface of revolution obtained by rotating the catenary about the $z$-axis.](/images/surface_catenoid.png){#fig-catenoid width=70%}








## First fundamental form


In this section we introduce the first **fundamental form** of a surface. This will allow us to compute:

- Angle between tangent vectors
- Lengths of tangent vectors
- Area of surface regions





### Length and angles between tangent vectors

Let $\SSS$ be a surface and consider two points $\pp, \mathbf{q} \in \SSS$. The euclidean distance between $\pp$ and $\mathbf{q}$ is 
$$
\norm{\pp - \mathbf{q}} \,.
$$
However this measures the length of the straight segment which connects $\pp$ to $\mathbf{q}$. We are interested in measuring the distance of $\pp$ and $\mathbf{q}$ on $\SSS$.
A way to measure such distance is the following: Suppose 
$$
\g \colon (t_0,t_1) \to \SSS
$$ 
is a smooth curve such that
$$
\g(t_0) = \pp\,, \quad \g(t_1) = \mathbf{q} \,.
$$
The distance between $\pp$ and $\mathbf{q}$ on $\SSS$ is the length of $\g$, i.e.,
$$
\int_{t_0}^{t_1} \norm{ \dg (t) } \, dt \,.
$$
Since $\g(t) \in \SSS$, by definition
we have
$$
\dg(t) \in T_{\xx} S \,, \quad \xx := \g(t) \,.
$$
Therefore, computing $\norm{\dg(t)}$ is equivalent
to computing the length of tangent vectors to $\SSS$. This motivates the definition of first fundamental form.


::: Definition
### First fundamental form

Let $\SSS$ be a regular surface and $\pp \in \SSS$. The 
**first fundamental form** of $\SSS$ at $\pp$ is the bilinear symmetric map
$$
I_{\pp} \colon T_{\pp} \SSS \times T_{\pp} \SSS \to \R \,, \quad I_{\pp} (\vv,\ww) := \vv \cdot \ww \,.
$$


:::


Three observations:

1. The first fundamental form of $\SSS$ at $\pp$ is the map obtained by restricting the scalar product of $\R^3$ to $T_{\pp} \SSS$.

2. Note that 
$$
I_{\pp} (\vv,\vv) = \| \vv \|^2 \,,
$$
so that $I_{\pp}$ can be used to compute the length of tangent vectors.

3. The definition of $I_{\pp}$ does not depend on a chosen chart, since $T_{\pp}\SSS$ can be defined without using charts.


To use the first fundamental form in practice, we need to express $I_{\pp}$ in terms of local
charts. To this end, we first define the coordinates functions $du$ and $dv$ on $T_{\pp} S$.


::: Definition
### Coordinate functions on tangent plane  {#definition-coordinate-functions}

Let $\sss \colon U \to \R^3$ be a regular chart of $\SSS$. 
For each $\pp \in \sss(U)$ we have
$$
T_{\pp} \SSS = \operatorname{span} \{\sss_u,\sss_v\} \,,
$$
where $\sss_u$ and $\sss_v$ are evaluated at the point $(u_0,v_0) \in U$ such that 
$$
\sss(u_0,v_0)=\pp \,.
$$
Therefore, for each $\vv \in T_{\pp} \SSS$, there exist $\lambda,\mu \in \R$ such that
$$
\vv = \lambda \sss_u + \mu \sss_v \,.
$$
The **coordinate functions** on $T_{\pp} \SSS$ are the linear maps
$$
du, dv \colon T_{\pp} \SSS \to \R \,, \quad du(\vv) := \lambda \,,  
\quad dv(\vv) := \mu \,.
$$

:::


::: Definition
### First fundamental form of a chart

Let $\sss \colon U \to \R^3$ be a regular chart of $\SSS$. Define the functions
$$
E , F , G \colon U \to \R 
$$
by setting
$$
E := \sss_u \cdot \sss_u \,, \quad  F := \sss_u \cdot \sss_v \,, \quad 
G := \sss_v \cdot \sss_v \,.
$$
Let $\pp \in \sss(U)$ and denote by $(u_0,v_0) \in U$ the point such that
$$
\sss(u_0,v_0) = \pp \,.
$$
The **first fundamental form** of $\sss$ at $\pp$ is the quadratic form
$$
\mathscr{F}_1 \colon T_{\pp} \SSS \to \R
$$
defined by
$$
\mathscr{F}_1 (\vv) := E \, du^2(\vv) + 2F \, du(\vv) \, dv (\vv)+ G \, dv^2 (\vv) \,,
$${#eq-fff-chart}
for all $\vv \in T_{\pp} \SSS$, where $E,F,G$ are evaluated at $(u_0,v_0)$.

:::


We usually omit the dependence on $\vv$ in (@eq-fff-chart), and write
$$
\mathscr{F}_1 = E \, du^2 + 2F \, du \, dv + G \, dv^2 \,. 
$$
The quadratic form $\mathscr{F}_1$ is related to $I_{\pp}$ in the following way.




::: {.Proposition  #proposition-fff-quadratic}

Let $\sss \colon U \to \R^3$ be a regular chart of $\SSS$, and $\pp \in \sss(U)$. Then
$$
I_{\pp} (\vv,\ww) = (du (\vv), dv(\vv) )  \, 
\left( 
\begin{array}{cc}
E & F \\
F & G 
\end{array}
\right) \, (du(\ww) , dv(\ww))^T \,,
$$
for all $\vv,\ww \in T_{\pp} \SSS$. In particular, $\mathscr{F}_1$ is the quadratic form associated to the symmetric bilinear form $I_{\pp}$, that is,
$$
\mathscr{F}_1 (\vv) = I_{\pp} (\vv,\vv) \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$$


:::

::: Proof

By Theorem \ref{theorem-tangent-plane} we have
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u, \sss_v \} \,.
$$
Therefore, for $\vv,\ww \in T_{\pp} \SSS$, there exist $\lambda_1,\lambda_2,\mu_1,\mu_2 \in \R$ such that 
$$
\vv = \lambda_1 \sss_u + \mu_1 \sss_v \,, \quad 
\ww = \lambda_2 \sss_u + \mu_2 \sss_v \,.
$$
We have
\begin{align*}
I_{\pp} (\vv,\ww) & = \vv \cdot \ww \\
& = \lambda_1 \lambda_2 \, \sss_u \cdot \sss_v + ( \lambda_1 \mu_2 + \lambda_2 \mu_1 ) \, \sss_u \cdot \sss_v + \mu_1 \mu_2 \, \sss_v \cdot \sss_v \\
& = E \, du (\vv) du(\ww)  + F \, ( du(\vv) \, dv(\ww) + du(\ww) dv(\vv) ) \\
& \qquad  + G \,  dv(\vv) dv(\ww) \\
& = (du (\vv), dv(\vv) )  \, 
\left( 
\begin{array}{cc}
E & F \\
F & G 
\end{array}
\right) \, (du(\ww) , dv(\ww))^T \,.
\end{align*}
The fact that 
$$
I_{\pp}(\vv,\vv) = \mathscr{F}_1(\vv)
$$ 
follows from the first part of the 
statement and definition of $\mathscr{F}_1$.

:::



::: Remark
### Linear algebra interpretation 

Using linear algebra, Proposition \ref{proposition-fff-quadratic} has a clear interpretation, as follows. $I_{\pp}$ is a symmetric bilinear form on the vector space $T_{\pp} \SSS$. 
Fixing the basis $\{ \sss_u, \sss_v \}$ for $T_{\pp} \SSS$, we can represent $I_{\pp}$ via the matrix
\begin{align*}
M & := 
\left(
\begin{array}{cc}
I_{\pp} (\sss_u , \sss_u) & I_{\pp} (\sss_u , \sss_v) \\
I_{\pp} (\sss_v , \sss_u) & I_{\pp} (\sss_v , \sss_v) \\
\end{array}
\right) \\
& =
\left(
\begin{array}{cc}
\sss_u \cdot \sss_u &  \sss_u \cdot \sss_v \\
\sss_v \cdot \sss_u &  \sss_v \cdot \sss_v \\
\end{array}
\right) \\
& =
\left(
\begin{array}{cc}
E & F \\
F & G \\
\end{array}
\right) \,,
\end{align*}
where we used that $\sss_u \cdot \sss_v = \sss_v \cdot \sss_u$. 

:::


::: Notation

With a little abuse of notation, we also denote by $\mathscr{F}_1$ the $2 \times 2$ matrix
$$
\mathscr{F}_1 := 
\left(
\begin{array}{cc}
E & F \\
F & G
\end{array}
\right) \,.
$$

:::



::: Remark
### First fundamental form and reparametrizations  {#remark-fff-reparametrization}

The first fundamental form $I_{\pp}$ depends only on the surface $\SSS$ and the point $\pp$. 
Instead the representation of $I_{\pp}$
$$
\mathscr{F}_1 = E \, du^2 + 2F \, du dv + G \, dv^2
$$
depends on the choice of chart $\sss \colon U \to \R^3$. Indeed suppose that $\widetilde{\sss} \colon \widetilde{U} \to \R^3$ is a reparametrization of $\sss$, that is, 
$$
\widetilde{\sss} = \sss \circ \Phi \,,
$$
where $\Phi \colon \widetilde{U} \to U$ is a diffeomorphism. Recall that we denote the components
$\Phi^1$ and $\Phi^2$ of $\Phi$ by
$$
(\tilde{u}, \tilde{v}) \mapsto u (\tilde{u}, \tilde{v}) \,, \quad 
(\tilde{u}, \tilde{v}) \mapsto v (\tilde{u}, \tilde{v}) \,,
$$
respectively. The Jacobian of $\Phi$ is then
$$
J\Phi = \left(   
\begin{array}{cc}
 \dfrac{\partial u}{\partial \tilde u}  &  \dfrac{\partial u}{\partial \tilde v}  \\
 \dfrac{\partial v}{\partial \tilde u}  &  \dfrac{\partial v}{\partial \tilde v}
\end{array}
\right) \,.
$$
Denote the first fundamental form of $\widetilde{\sss}$ by
$$
\widetilde{\mathscr{F}}_1 = \widetilde{E} \, d\tilde{u}^2 + 2 \widetilde{F} \, d\tilde{u} d\tilde{v} + \widetilde{G} \, d\tilde{v}^2 \,.
$$
The linear maps $du, dv$ and $d\tilde{u}, d\tilde{v}$ are related by
$$
du = \frac{\partial u}{\partial \tilde{u}} \, d\tilde{u} + \frac{\partial u}{\partial \tilde{v}} \, d\tilde{v} \,, \quad 
dv = \frac{\partial v}{\partial \tilde{u}} \, d\tilde{u} + \frac{\partial v}{\partial \tilde{v}} \, d\tilde{v} 
$${#eq-fff-change-basis-1}
Moreover the matrices of $\mathscr{F}_1$ and $\widetilde{\mathscr{F}}_1$ are related by
$$
\left(
\begin{array}{cc}
\widetilde{E} & \widetilde{F} \\
\widetilde{F} & \widetilde{G}
\end{array}
\right)  
= 
(J \Phi)^T \,
\left(
\begin{array}{cc}
E & F \\
F & G
\end{array}
\right)
\, 
J \Phi  \,.
$${#eq-fff-change-basis-2}

> The proof of the above statements follows by basic linear algebra: The pairs $\{\sss_u,\sss_u\}$ and $\{\widetilde{\sss}_{\tilde{u}} , \widetilde{\sss}_{\tilde{v}} \}$ are bases for the vector space $T_{\pp} \SSS$. The change of basis matrix is given exactly by $J\Phi$. Therefore formulas (@eq-fff-change-basis-1) and (@eq-fff-change-basis-2) are consequence of change of basis results for linear maps and bilinear forms, respectively.


:::


Let us compute the first fundamental form of a plane and of a cylinder.


::: Example
### Plane   {#example-fff-plane}

Let $\mathbf{a}, \pp, \mathbf{q} \in \R^3$. Suppose that $\pp$ and $\mathbf{q}$ are orthonormal vectors, that is,
$$
\norm{\pp} = \norm{\mathbf{q}} = 1 \,, \quad \pp \cdot \mathbf{q} = 0 \,. 
$$
Consider the plane with chart
$$
\sss(u,v) = \mathbf{a} + u \pp + v \mathbf{q} \,, \quad (u,v) \in \R^2 \,.
$$
The first fundamental form of $\sss$ is
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$

> We have
$$
\sss_u = \pp \,, \quad \sss_v = \mathbf{q}
$$
and therefore 
\begin{align*}
E & = \sss_u \cdot \sss_u = \norm{\pp}^2 = 1 \\
F & = \sss_u \cdot \sss_v = \pp \cdot \mathbf{q} = 0 \\
G & = \sss_v \cdot \sss_v = \norm{\mathbf{q}}^2 = 1 \\
\end{align*}
Then the first fundamental form is
$$
\mathscr{F}_1 = E \, du^2 + 2 F\, du \, dv + G \, dv^2 = du^2 + dv^2 \,.  
$$

:::


Two remarks concerning Example \ref{example-fff-plane} :

- The above example should not be surprising, since distances on a plane are the same as Euclidean distances, given that straight segments are contained in the plane.
- If we drop the assumption of $\pp$ and $\mathbf{q}$ being orthonormal, then 
$$
\mathscr{F}_1 = \norm{\pp}^2 \, du^2 + \pp \cdot \mathbf{q} \, du \, dv + \norm{\mathbf{q}}^2 \, dv^2 \,.
$$
Again, this is not surprising, due to Remark \ref{remark-fff-reparametrization}.


::: Example
### Unit cylinder  {#example-cylinder-fff}

Consider the unit cylinder with chart
$$
\sss(u,v) = (\cos(u), \sin(u),  v)  \,, \quad (u,v) \in (0,2\pi) \times \R \,.
$$
The first fundamental form of $\sss$ is
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$

> We have
$$
\sss_u = (-\sin(u),\cos(u), 0 )  \,, \quad \sss_v = (0,0,1) \,, 
$$
and therefore 
\begin{align*}
E & = \sss_u \cdot \sss_u = 1 \\
F & = \sss_u \cdot \sss_v = 0 \\
G & = \sss_v \cdot \sss_v = 1 \\
\end{align*}
Then the first fundamental form is
$$
\mathscr{F}_1 = E \, du^2 + 2 F\, du \, dv + G \, dv^2 = du^2 + dv^2 \,.  
$$

:::


::: Remark

We have seen that a plane and the unit cylinder have the same first fundamental form 
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$
Therefore lengths and angles are the same on the two surfaces.

:::






### Length of curves


Let us show how the first fundamental form allows to compute the
length of curves with values on surfaces.


::: {.Proposition  #proposition-fff-length}

Let $\SSS$ be a regular surface with chart $\sss \colon U \to \R^3$. Suppose
$$
\g \colon (t_0,t_1) \to \sss(U) \subseteq \SSS 
$$
is a smooth curve. Then
$$
\g(t) = \sss (u(t), v(t)) \,,
$$
for some smooth functions $u,v \colon (t_0,t_1) \to \R$ and 
$$
\int_{t_0}^{t_1} \norm{\dg(t)} \, dt =
\int_{t_0}^{t_1} \sqrt{  E \dot{u}^2 + 2F \dot u \dot v + G \dot{v}^2  } \, dt \,,
$$
where $\dot u, \dot v$ are computed at $t$, and $E,F,G$ are computed at $(u(t),v(t))$.

:::


::: Proof 

Since $\g$ takes values into $\sss(U)$, by Lemma \ref{lemma-curve-S} there exist smooth functions $u,v$ such that 
$$
\g(t) = \sss (u(t), v(t)) \,, \quad \forall \, t \in (t_0,t_1) \,.
$$
By chain rule we have
$$
\dg(t) = \dot u (t) \sss_u( u(t),v(t) ) + \dot v (t) \sss_v( u(t),v(t) ) \,.
$$
The above means that the coefficients of $\dg$ with respect to the basis $\{\sss_u,\sss_v\}$ of $T_{\pp} \SSS$ are $\dot u$ and $\dot v$, respectively. Then
$$
du(\dg) = \dot u \,, \quad dv(\dg) = \dot v \,.
$$
Since $\dg$ is a tagent vector, by Proposition \ref{proposition-fff-quadratic} we get
\begin{align*}
\norm{\dg(t)}^2 & = \dg \cdot \dg \\
                & = I_{\pp} (\dg , \dg ) \\
                & = E \, du(\dg)^2  + 2F \, du(\dg) dv(\g) + G \, dv(\dg)^2 \\ 
                & = E \, \dot{u}^2  + 2F \, \dot{u} \dot{v} + G \, \dot{v}^2 
                \,,
\end{align*}
concluding the proof.


:::





::: Example
### Cone

Consider the cone with chart
$$
\sss (u,v)=(u \cos(v), u \sin (v), u) \,, 
$$
where $u > 0$ and $v \in [0,2\pi]$.

1. The first fundamental form of $\sss$ is
$$
\mathscr{F}_1 = 2 \, du^2 + u^2 \, dv^2 \,.
$$

2. Let $\g (t):= \sss(t,t)$. The length of $\g$ is
$$
\int_{\pi/2}^{\pi} \norm{\dg(t)} \, dt = \int_{\pi/2}^{\pi} \sqrt{  2 + t^2  } \, dt  \,.
$$

> We have
$$
\sss_u = (\cos(v), \sin (v), 1) \,, \quad 
\sss_v = (- u \sin(v), u \cos (v), 0) \,.
$$
Therefore
\begin{align*}
E & = \sss_u \cdot \sss_u = \cos^2(v) + \sin^2 (v) + 1 = 2 \\
F & = \sss_u \cdot \sss_v = - u \cos(v) \sin(v) + u \cos(v) \sin(v) = 0 \\
G & = \sss_v \cdot \sss_v = u^2 \sin^2(v) + u^2 \cos^2(v) = u^2   
\end{align*}
The first fundamental form of $\sss$ is 
$$
\mathscr{F}_1 = 2 \, du^2 + u^2 \, dv^2 \,.
$$
Concering the curve $\g$, by definition we have
$$
\g(t) := \sss(t,t) \,,
$$
so that 
$$
u(t) = t \,, \quad v(t) = t \,.
$$
In particular
$$
\dot u = 1\,, \quad \dot v = 1
$$ 
and 
\begin{align*}
E(u(t),v(t)) & = E(t,t) = 2 \\
F(u(t),v(t)) & = F(t,t) = 0 \\
G(u(t),v(t)) & = G(t,t) = t^2  \,.
\end{align*}
By Proposition \ref{proposition-fff-length} we have
\begin{align*}
\int_{\pi/2}^{\pi} \norm{\dg(t)} \, dt & = 
\int_{\pi/2}^{\pi} \sqrt{  E \dot{u}^2 + 2F \dot u \dot v + G \dot{v}^2  } \, dt \\
& = \int_{\pi/2}^{\pi} \sqrt{  2 + t^2  } \, dt   \,.
\end{align*}

:::







### Local isometries


We have seen that a plane $\pmb{\pi}$ and a cylinder $\mathcal{C}$ have the same first fundamental form. This means that scalar product on the two surfaces is the same, as is the length of curves. In this case we say that 
$\pmb{\pi}$ and $\mathcal{C}$ are locally isometric. Let us give a general definition of such concept.



::: Definition 
### Local isometry

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces. A local diffeomorphism 
$f \colon \SSS \to \widetilde{\SSS}$ is a **local isometry** if for all $\pp \in \SSS$ the 
differential $d_{\pp}f \colon T_{\pp} \SSS \to T_{f(\pp)} \widetilde{\SSS}$ satisfies
$$
\vv \cdot \ww  = d_{\pp}f (\vv) \cdot d_{\pp}f (\ww) \,, \quad 
\forall \, \vv, \ww \in T_{\pp} \SSS \,. 
$$
We say that $\SSS$ and $\widetilde{\SSS}$ are **locally isometric** if 
there exists a local isometry $f \colon \SSS \to \widetilde{\SSS}$.

:::


![Sketch of local isometry $f$ between $\SSS$ and $\widetilde{\SSS}$. The scalar product between tangent vectors $\vv$ and $\ww$ is preserved by $d_{\pp}f$.](/images/fff_local_isometry.png){width=70%}


::: Notation

For brevity we denote 
$$
\scp{\vv}{\ww} := \vv \cdot \ww  \,, \quad 
\scp{\vv}{\ww}_f := d_{\pp}f (\vv) \cdot d_{\pp}f (\ww) \,,
$$
and also
$$
\| \vv \| := \sqrt{ \scp{v}{v} } \,, \quad  
\| \vv \|_f := \sqrt{ \scp{v}{v}_f } \,.
$$

:::


::: {.Remark #remark-local-isometry}

A local diffeomorphism $f \colon \SSS \to \widetilde{\SSS}$ is a local isometry if and only 
if 
$$
\scp{\vv}{\vv} = \scp{\vv}{\vv}_f  \,, \quad 
\forall \, \vv \in T_{\pp} \SSS \,. 
$$

> The proof follows from the elementary identity
$$
\vv \cdot \ww = \frac12 \left(   (\vv + \ww ) \cdot (\vv + \ww ) - \vv \cdot \vv - \ww \cdot \ww       \right) \,, 
$$
which holds for all $\vv, \ww \in T_{\pp} \SSS$ (and more in general in arbitrary vector spaces with inner product).

:::


Local isometries preserve the length of curves, as shown in the following proposition.


::: Proposition

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ be a local diffeomorphism. They are equivalent:

1. $f$ is a local isometry.
2. Let $\g$ be a curve in $\SSS$ and consider the curve $\tg = f \circ \g$ on $\widetilde{\SSS}$. Then $\g$ and $\tg$ have the same length.

:::


::: Proof

*Part 1.* Suppose $\g \colon (t_0,t_1) \to \SSS$ is a smooth curve. 
Consider the smooth curve $\tg := f \circ \g \colon (t_0,t_1) \to \widetilde{\SSS}$. Set $\pp :=\g(t)$. By definition of differential of a function between surfaces, we have
$$
\dtg(t) = df_{\pp} (\dg(t)) \,.
$$
Using that $f$ is a local isometry gives:
\begin{align*}
\norm{\dtg(t)}^2 & = \dtg(t) \cdot \dtg(t) \\
               & = df_{\pp} (\dg(t)) \cdot df_{\pp} (\dg(t)) \\
               & = \dg(t) \cdot \dg(t) \\
               & = \norm{\dg(t)}^2
\end{align*}
Therefore $\g$ and $\tg$ have the same length:
$$
\int_{t_0}^{t_1} \norm{\dtg(t)}\, dt 
= \int_{t_0}^{t_1} \norm{\dg(t)}\, dt \,.
$$

*Part 2.* 
We need to prove that $f$ is a local isometry. Thanks to Remark \ref{remark-local-isometry}, it is sufficient to show that
$$
df_{\pp} (\vv) \cdot df_{\pp} (\vv) = \vv \cdot \vv \,, \quad \forall \, \vv \in T_{\pp}(\SSS) \,.  
$${#eq-proof-loc-iso}
Therefore, let $\vv \in T_{\pp} \SSS$ be arbitrary. By definition of tangent plane, there exists a curve $\g \colon (-\e,\e) \to \SSS$ such that
$$
\g(0) = \pp \,, \quad \dg(0) = \vv \,.
$$
Define the curve $\tg := f \circ \g \colon (-\e,\e) \to \widetilde{\SSS}$. By assumption $\g$ and $\tg$ have the same length, that is,
$$
\int_{-\e}^{\e} \sqrt{ \dtg(t) \cdot \dtg(t) }\, dt 
= \int_{-\e}^{\e} \sqrt{ \dg(t) \cdot \dg(t) }\, dt \,.
$$
Since the above is true for each $\e>0$, and the functions integrated are continuous, we infer
$$
\dtg(0) \cdot \dtg(0) = \dg(0) \cdot \dg(0) \,.
$$
Recall that by definition of differential we have
$$
df_{\pp} (\vv) = \dtg(0) \,.
$$
Therefore 
\begin{align*}
df_{\pp} (\vv) \cdot df_{\pp} (\vv) & = \dtg(0) \cdot \dtg(0) \\
                                    & = \dg(0) \cdot \dg(0) \\
                                    & = \vv \cdot \vv \,.
\end{align*}
As $\vv$ was arbitrary, we conclude (@eq-proof-loc-iso).

:::



We have seen that local isometries preserve the length of curves. Recall that the first fundamental form of $\SSS$ is defined by
$$
I_{\pp} (\vv, \ww) = \vv \cdot  \ww \,, \quad \vv, \ww \in T_{\pp} \SSS \,.
$$
A natural question is how the first fundamental form changes under local isometries. The result is that local isometries preserve the first fundamental form.


::: {.Theorem  #theorem-local-isometry}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ be a local diffeomorphism. They are equivalent:

1. $f$ is a local isometry.
2. Let $\sss \colon U \to \SSS$ be a regular chart of $\SSS$ and consider the chart of $\widetilde{\SSS}$ given by  
$$
\widetilde{\sss} = f \circ \sss \colon U \to \widetilde{\SSS} \,.
$$
Then $\sss$ and $\widetilde{\sss}$ have the same first fundamental form, that is, 
$$
E = \widetilde{E} \,, \quad F = \widetilde{F} \,, \quad G = \widetilde{G} \,,
$$
where 
\begin{align*}
E & = \sss_u \cdot \sss_u \,, \quad
F = \sss_u \cdot \sss_v \,, \quad
G = \sss_v \cdot \sss_v \,, \\
\widetilde{E} & = \widetilde{\sss}_u \cdot \widetilde{\sss}_u \,, \quad
\widetilde{F}  = \widetilde{\sss}_u \cdot \widetilde{\sss}_v \,, \quad
\widetilde{G}  = \widetilde{\sss}_v \cdot \widetilde{\sss}_v \,.
\end{align*}

> Note that $E,F,G$ and $\widetilde{E},\widetilde{F},\widetilde{G}$ are defined on the same set $U$. Therefore equality is intended pointwise.

:::


::: Proof

*Part 1.* Suppose that $f$ is a local isometry, that is,
$$
{\vv} \cdot {\ww} = d_{\pp} f ({\vv}) \cdot d_{\pp} f ({\ww}) \,, \quad \forall \, {\vv} , {\ww} \in T_{\pp} \SSS \,.
$$
Let $\sss$ be a chart for $\SSS$ at $\pp$. Define $\widetilde{\sss} = f \circ \sss$. By Proposition \ref{proposition-f-chart}, $\widetilde{\sss}$ is a regualar chart of $\widetilde{\SSS}$ at $f(\pp)$. Now, recall the statement of Proposition \ref{proposition-differential-smooth}: if
$$
\widetilde{\sss} ( \alpha(u,v), \beta(u,v) ) = f ( \sss (u,v) ) \,,
$$
for some smooth maps 
$$
\alpha,\beta \colon U \to \widetilde{U} \,,
$$
then the matrix of $d_{\pp} f$ with respect to the basis 
$$
\{ \sss_u , \sss_v \} \,\,\, \mbox{ of } \,\,\, T_{\pp} \SSS \,, \quad  
\{ \widetilde{\sss}_u , \widetilde{\sss}_v \} \,\,\, \mbox{ of } \,\,\, T_{f(\pp)} \widetilde{\SSS} \,,
$$
is given by
$$
d_{\pp} f = 
\left(
\begin{array}{cc}
\alpha_u & \alpha_v \\
\beta_u  & \beta_v
\end{array}
\right) \,.
$$
In our case, we have $U = \widetilde{U}$ and
$$
\widetilde{\sss} (u, v ) = f ( \sss (u,v) )\,,
$$
so that 
$$
\alpha(u,v) = u \,, \quad 
\beta(u,v) = v \,.
$$
Therefore 
$$
d_{\pp} f = 
\left(
\begin{array}{cc}
\alpha_u & \alpha_v \\
\beta_u  & \beta_v
\end{array}
\right) 
=
\left(
\begin{array}{cc}
1 & 0 \\
0  & 1
\end{array}
\right) \,,
$$
which means that 
\begin{align*}
d_{\pp} f(\sss_u)  & = 1 \cdot \widetilde{\sss}_u + 0 \cdot \widetilde{\sss}_v = \widetilde{\sss}_u \\
d_{\pp} f(\sss_v)  & = 0 \cdot \widetilde{\sss}_u + 1 \cdot \widetilde{\sss}_v = \widetilde{\sss}_v \\
\end{align*}
Using that $f$ is a local isometry gives
\begin{align*}
E & = \sss_u \cdot \sss_u 
    = d_{\pp} f (\sss_u) \cdot d_{\pp} f (\sss_u) \\
  & = \widetilde{\sss}_u \cdot \widetilde{\sss}_u 
    = \widetilde{E} \,.
\end{align*}
Simlarly, we obtain also
\begin{align*}
F & = \sss_u \cdot \sss_v 
    = d_{\pp} f (\sss_u) \cdot d_{\pp} f (\sss_v) \\
  & = \widetilde{\sss}_u \cdot \widetilde{\sss}_v 
    = \widetilde{F} \,,
\end{align*}
and
\begin{align*}
G & = \sss_v \cdot \sss_v 
    = d_{\pp} f (\sss_v) \cdot d_{\pp} f (\sss_v) \\
  & = \widetilde{\sss}_v \cdot \widetilde{\sss}_v 
    = \widetilde{G} \,,
\end{align*}
showing that $\sss$ and $\widetilde{\sss}$ have the same first fundamental form.



*Part 2.* Define $\widetilde{\sss} = f \circ \sss$ and suppose that $\sss$ and $\widetilde{\sss}$ have the same first fundamental form. In particular they hold
\begin{align*}
\sss_u \cdot \sss_u & = \widetilde{\sss}_u \cdot \widetilde{\sss}_u \\
\sss_u \cdot \sss_v & = \widetilde{\sss}_u \cdot \widetilde{\sss}_v \\
\sss_v \cdot \sss_v & = \widetilde{\sss}_v \cdot \widetilde{\sss}_v 
\end{align*}
As discussed above, since $\widetilde{\sss} = f \circ \sss$, by Proposition \ref{proposition-differential-smooth} we get
$$
d_{\pp} f(\sss_u)  = \widetilde{\sss}_u \,, \quad 
d_{\pp} f(\sss_v)  = \widetilde{\sss}_v \,.
$$
Let $\vv \in T_{\pp} \SSS$. Since $\{\sss_u,\sss_v\}$ is a basis for $T_{\pp} \SSS$ we get
$$
\vv = \lambda \sss_u + \mu \sss_v 
$$
for some $\lambda,\mu \in \R$. Therefore
\begin{align*}
d_{\pp} f (\vv) & = d_{\pp} f(\lambda \sss_u + \mu \sss_v ) \\
                & = \lambda \, d_{\pp} f (\sss_u) + \mu \, d_{\pp} f (\sss_v)\\
                & = \lambda \widetilde{\sss}_u + \mu \widetilde{\sss}_v \,.
\end{align*}
Hence
\begin{align*}
\vv \cdot \vv & = ( \lambda \sss_u + \mu \sss_v ) \cdot  (\lambda \sss_u + \mu \sss_v) \\
              & = \lambda^2 (\sss_u \cdot \sss_v) + 2 \lambda\mu (\sss_u \cdot \sss_v) + \mu^2 (\sss_v \cdot \sss_v) \\ 
              & = \lambda^2 ( \widetilde{\sss}_u \cdot \widetilde{\sss}_u) +
              2\lambda \mu ( \widetilde{\sss}_u \cdot \widetilde{\sss}_v) + 
              \mu^2 ( \widetilde{\sss}_v \cdot \widetilde{\sss}_v) \\
              & = (\lambda \widetilde{\sss}_u + \mu \widetilde{\sss}_v) 
              \cdot (\lambda \widetilde{\sss}_u + \mu \widetilde{\sss}_v) \\
              & = d_{\pp} f (\vv) \cdot 
                  d_{\pp} f (\vv) \,, 
\end{align*}
showing that 
$$
\vv \cdot \vv = d_{\pp} f (\vv) \cdot d_{\pp} f (\vv)  \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$$
By Remark \ref{remark-local-isometry} we conclude that $f$ is a local isometry.

:::




### Angles on surfaces


We want to define the notion of angle between tangent vectors.


::: Definition
### Angle between tangent vectors

Let $\SSS$ be a regular surface and $\pp \in \SSS$. The angle between
two vectors $\vv , \ww \in T_{\pp} \SSS$ is defined as the number $\theta$ such that
$$
\cos(\theta) = \frac{ \vv \cdot \ww }{ \| \vv \| \,  \| \ww \| } \,.
$$

:::


![Sketch of angle $\theta$ between two vectors $\vv,\ww$ in $T_{\pp} \SSS$.](/images/fff_angle_vectors.png){width=70%}



The angle between tangent vectors can be computed in terms of local charts.


::: Proposition

Let $\SSS$ be a regular surface and $\sss$ a regular chart at $\pp$. 
Let $\vv, \ww \in T_{\pp} \SSS$. Then 
$$
\cos(\theta) = \frac{ E  \lambda \tilde \lambda + F (  \lambda {\tilde \mu}+ \tilde \lambda \mu) + G  \mu \tilde \mu }{ (E  \lambda^2 + 2 F  \lambda \mu + G \mu^2 )^{1/2} (E  \tilde{\lambda}^2 + 2 F  {\tilde{\lambda}} {\tilde{\mu}} + G {\tilde{\mu}}^2 )^{1/2} } \,,
$$
where $\lambda,\mu,\tilde{\lambda},\tilde{\mu} \in \R$ are such that 
$$
\vv = \lambda \sss_u + \mu \sss_v \,, \quad  
\ww = \tilde{\lambda} \sss_u + \tilde{\mu} \sss_v \,.
$$

:::


::: Proof

By definition the angle between $\vv$ and $\ww$ is
$$
\cos(\theta) = \frac{ \vv \cdot \ww }{ \| \vv \| \,  \| \ww \| } \,.
$${#eq-angle-proof}
The vectors $\{\sss_u,\sss_v\}$ form a basis of $T_{\pp} \SSS$. Therefore 
$$
\vv = \lambda \sss_u + \mu \sss_v \,, \quad  
\ww = \tilde{\lambda} \sss_u + \tilde{\mu} \sss_v \,.
$$
for some $\lambda,\mu,\tilde{\lambda},\tilde{\mu} \in \R$. Hence, the coordinates of $\vv$ and $\ww$ with respect to the basis
$\{\sss_u,\sss_v\}$ are
$$
\vv = (\lambda , \mu ) \,, \quad 
\ww = ({\tilde{\lambda}}  , {\tilde{\mu}} ) \,.
$$
By Proposition \ref{proposition-fff-quadratic} we get
\begin{align*}
\vv \cdot \ww & = I_{\pp}(\vv,\ww) \\
               & = (\lambda , \mu) 
               \left(
               \begin{array}{cc}
               E & F \\
               F & G
               \end{array}
               \right)
               ( \tilde{\lambda}  , \tilde{\mu} )^T \\
               & =  E  \lambda \tilde \lambda + F (  \lambda {\tilde \mu}+ {\tilde{\lambda}} \mu ) + G  \mu  \tilde \mu \,.
\end{align*}
Similarly, we obtain
\begin{align*}
\| \vv \|^2 & = \vv \cdot \vv = E  {\lambda}^2 + 2 F  \lambda \mu + G \mu^2  \\
\| \ww \|^2 & = \ww \cdot \ww = E  \tilde{\lambda}^2 + 2 F  \tilde{\lambda} \tilde{\mu}  + G  \tilde{\mu}^2 \,.  
\end{align*}
Substituting in (@eq-angle-proof) we conclude.

:::





### Angle between curves

Since tangent vectors are derivatives of curves with values in $\SSS$, it also makes sense to define the angle between two intersecting curves.



::: Definition
### Angle between curves

Let $\SSS$ be a regular surface and suppose to have two curves
$$
\g \colon (a,b) \to \SSS \,, \quad \tg \colon (\tilde{a},\tilde{b}) \to \SSS
$$
such that 
$$
\g(t_0) = \pp \,, \quad \tg( \tilde{t}_0 ) = \pp \,.
$$
Then 
$$
\dg(t_0) \,, \, \dtg( \tilde{t}_0 )  \in T_{\pp} \SSS \,.
$$
The angle $\theta$ between $\g$ and $\tg$ is the angle between $\dg(t_0)$ and $\dtg( \tilde{t}_0 )$, that is,
$$
\cos(\theta) = \frac{ \dg \cdot \dtg }{ \| \dg \| \,  \| \dtg \| } \,,
$$
where $\tg$ is evaluated at $t_0$ and $\dtg$ at $\tilde{t}_0$.

:::



![Sketch of angle $\theta$ between two curves $\g$ and $\tg$ on $\SSS$.](/images/fff_angle_curves.png){width=70%}



::: Proposition

Let $\SSS$ be a regular surface and $\sss$ a regular chart at $\pp$. 
Suppose given two curves
$$
\g \colon (a,b) \to \SSS \,, \quad \tg \colon (\tilde{a},\tilde{b}) \to \SSS
$$
such that 
$$
\g(t_0) = \pp \,, \quad \tg( \tilde{t}_0 ) = \pp \,.
$$
The angle between $\g$ and $\tg$ is
$$
\cos(\theta) = \frac{ E  \dot u \dot{\tilde u} + F ( \dot u \dot{\tilde v}+ \dot{\tilde{u}} \dot v) + G \dot v \dot{\tilde v} }{ (E  \dot{u}^2 + 2 F  \dot u \dot v + G \dot{v}^2 )^{1/2} (E  \dot{\tilde{u}}^2 + 2 F  \dot{\tilde{u}} \dot{\tilde{v}} + G \dot{\tilde{v}}^2 )^{1/2} } \,,
$$
where $u,v,\tilde{u},\tilde{v}$ are smooth functions such that
$$
\g(t) = \sss (u(t),v(t)) \,, \quad 
\tg(t) = \sss (\tilde{u}(t),\tilde{v}(t)) \,.
$$

:::


::: Proof

By definition the angle between $\g$ and $\tg$ is
$$
\cos(\theta) = \frac{ \dg \cdot \dtg }{ \| \dg \| \,  \| \dtg \| } \,.
$${#eq-angle-curves-proof}
As $\g, \tg$ are smooth curves with values in $\SSS$, by Lemma \ref{lemma-curve-S} there exist smooth functions $u,v,\tilde{u},\tilde{v}$ such that
$$
\g(t) = \sss (u(t),v(t)) \,, \quad 
\tg(t) = \sss (\tilde{u}(t),\tilde{v}(t)) \,.
$$
Differentiating the above expressions we obtain
$$
\dg = \dot u \sss_u + \dot v \sss_v \,, \quad 
\dtg = \dot{\tilde{u}} \sss_u + \dot{\tilde{v}} \sss_v \,.
$$
Therefore the coordinates of $\dg$ and $\dtg$ with respect to the basis
$\{\sss_u,\sss_v\}$ of $T_{\pp} \SSS$ are
$$
\dg = (\dot u , \dot v) \,, \quad 
\dtg = (\dot{\tilde{u}}  , \dot{\tilde{v}} ) \,.
$$
By Proposition \ref{proposition-fff-quadratic} we get
\begin{align*}
\dg \cdot \dtg & = I_{\pp}(\dg,\dtg) \\
               & = (\dot u , \dot v) 
               \left(
               \begin{array}{cc}
               E & F \\
               F & G
               \end{array}
               \right)
               (\dot{\tilde{u}}  , \dot{\tilde{v}} )^T \\
               & =  E  \dot u \dot{\tilde u} + F ( \dot u \dot{\tilde v}+ \dot{\tilde{u}} \dot v) + G \dot v \dot{\tilde v} \,.
\end{align*}
Similarly, we obtain
\begin{align*}
\| \dg \|^2 & = \dg \cdot \dg = E  \dot{u}^2 + 2 F  \dot u \dot v + G \dot{v}^2  \\
\| \dtg \|^2 & = \dtg \cdot \dtg = E  \dot{\tilde{u}}^2 + 2 F  \dot{\tilde{u}} \dot{\tilde{v}}  + G \dot{\tilde{v}}^2 \,.  
\end{align*}
Substituting in (@eq-angle-curves-proof) we conclude.

:::




### Conformal maps


Local isometries are maps which preserve the **scalar product** between tangent vectors. We want to consider maps which preserve the **angle** between tangent
vectors. These will be called **conformal maps**.


::: Definition
### Conformal map

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces. A local diffeomorphism $f \colon \SSS \to \widetilde{\SSS}$ is a **conformal mapping** if for all $\pp \in \SSS$ and $\vv , \ww \in T_{\pp} \SSS$ is holds
$$
\theta = \tilde{\theta} \,,
$$
with $\theta$, $\tilde{\theta}$ the angles between $\vv, \ww$ and $d_{\pp} f(\vv)$, $d_{\pp} f(\ww)$, respectively.


:::


![Sketch of conformal map $f$ between $\SSS$ and $\widetilde{\SSS}$. The angles between tangent vectors are preserved by $d_{\pp} f$.](/images/fff_conformal_map.png){width=70%}



::: Remark

We have that $f$ is a conformal map if and only if
$$
\frac{ \scp{\vv}{\ww} }{ \| \vv \| \, \| \ww \| } = 
\frac{ \scp{\vv}{\ww}_f  }{ \| \vv \|_f \, \| \ww \|_f } \,, \quad \forall \, \vv , \ww \in T_{\pp} \SSS \,.
$$


> This follows immediately by the definition of angle between tangent vectors.

:::




::: Proposition

Let $f$ be a local isometry. Then $f$ is a conformal map.

:::


::: Proof


By definition of local isometry we have
$$
\scp{\vv}{\ww} =  \scp{\vv}{\ww}_f  \,, \quad \forall \, \vv , \ww \in T_{\pp} \SSS \,.
$$
In particular we have
$$
\| \vv \|^2  = \scp{\vv}{\vv} 
             = \scp{\vv}{\vv}_f 
             = \| \vv \|^2_f \,,
$$
for all $\vv \in T_{\pp} \SSS$. Therefore 
$$
\frac{ \scp{\vv}{\ww} }{ \| \vv \| \, \| \ww \| } = 
\frac{ \scp{\vv}{\ww}_f }{ \| \vv \|_f \, \| \ww \|_f } \,,
$$
showing that $f$ is a conformal map.


:::


Therefore every local isometry is a conformal map. The converse is false,
as we will show in Example \ref{example-conformal} below. 
Before giving the example, let us provide a characterization of conformal
maps in terms of the first fundamental form.


::: {.Theorem #theorem-conformal}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ a local diffeomorphism. They are equivalent:

1. $f$ is a conformal map.
2. There exists a function $\lambda \colon \SSS \to \R$ such that 
$$
\scp{\vv}{\ww}_f =  \lambda (\pp) \, \scp{\vv}{\ww} \,, \quad \forall \, \vv,\ww \in T_{\pp} \SSS \,.
$$

:::


::: Proof

*Step 1.* Suppose $f$ is a conformal map, so that 
$$
\frac{ \scp{\vv}{\ww} }{ \| \vv \| \, \| \ww \| } = 
\frac{ \scp{\vv}{\ww}_f }{ \| \vv \|_f \, \| \ww \|_f } \,, \quad \forall \, \vv , \ww \in T_{\pp} \SSS \,.
$${#eq-theorem-conformal-proof}
Let $\{\pmb{\alpha}_1,\pmb{\alpha}_2\}$ be an orthonormal basis for $T_{\pp} \SSS$, that is, 
$$
\scp{\pmb{\alpha}_1}{\pmb{\alpha}_2} = 0 \,, \quad
\| \pmb{\alpha}_1  \| = \| \pmb{\alpha}_2 \| = 1 \,.
$$
Define 
\begin{align*}
\lambda(\pp) & := \scp{\pmb{\alpha_1}}{\pmb{\alpha_1}}_f = \| \pmb{\alpha_1} \|_f^2 \,, \\
\mu(\pp) & := \scp{\pmb{\alpha_1}}{\pmb{\alpha_2}}_f \,, \\
\nu(\pp) & := \scp{\pmb{\alpha_2}}{\pmb{\alpha_2}}_f = \| \pmb{\alpha_2} \|_f^2   \,.
\end{align*}
By (@eq-theorem-conformal-proof) we have
$$
\frac{\scp{\pmb{\alpha_1}}{\pmb{\alpha_2}}}{ \| \pmb{\alpha_1} \| \| \pmb{\alpha_2} \|  } = 
\frac{\scp{\pmb{\alpha_1}}{\pmb{\alpha_2}}_f}{ \| \pmb{\alpha_1} \|_f \| \pmb{\alpha_2} \|_f  } \,.
$$
Since $\pmb{\alpha}_1 \cdot \pmb{\alpha}_2 = 0$, from the above we get
$$
\mu (\pp) = \scp{\pmb{\alpha}_1}{\pmb{\alpha}_2 }_f = 0 \,.
$$
Moreover, since $\pmb{\alpha}_1$ and $\pmb{\alpha}_2$ are orthonormal, 
the angle between $\pmb{\alpha}_1$ and $\pmb{\alpha}_1 + \pmb{\alpha}_2$ is
$\theta = \pi/4$. By definition of angle between vectors, we infer
$$
\frac{\sqrt{2}}{2} = \cos (\theta) = \frac{ \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1 + \pmb{\alpha}_2}  }{ \| \pmb{\alpha}_1 \| \| \pmb{\alpha}_1 + \pmb{\alpha}_1 \| } \,. 
$$
On the other hand, using (@eq-theorem-conformal-proof) we get
$$
\frac{ \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1 + \pmb{\alpha}_2}  }{ \| \pmb{\alpha}_1 \| \| \pmb{\alpha}_1 + \pmb{\alpha}_1 \| } =
\frac{ \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1 + \pmb{\alpha}_2}_f  }{ \| \pmb{\alpha}_1 \|_f \| \pmb{\alpha}_1 + \pmb{\alpha}_2 \|_f } \,. 
$$
The numerator of the right hand side satisfies
\begin{align*}
 \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1 + \pmb{\alpha}_2}_f & 
 =  \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1 }_f +  \scp{\pmb{\alpha}_1}{\pmb{\alpha}_2}_f  \\
 & = \lambda(\pp) + \mu (\pp) \\
 & = \lambda(\pp) \,,
\end{align*}
since $\mu (\pp) = 0$. Concerning the denominator, we have
\begin{align*}
\| \pmb{\alpha}_1 + \pmb{\alpha}_2 \|_f^2 & = 
\| \pmb{\alpha}_1  \|_f^2 + \scp{\pmb{\alpha}_1}{\pmb{\alpha}_2}_f  + 
\| \pmb{\alpha}_2 \|_f^2 \\
& = \lambda(\pp) + \mu(\pp) + \nu (\pp) \\
& = \lambda(\pp) + \nu (\pp)  \,,
\end{align*}
since $\mu (\pp) = 0$. Putting together the last 4 groups of equations, we obtain
$$
\frac{\sqrt{2}}{2} = \frac{ \lambda }{ \lambda^{1/2} (\lambda + \nu)^{1/2} } \,.
$$
Rearraging the above equation yields
$$
\lambda (\pp) = \nu (\pp) \,.
$$
Now let $\vv \in T_{\pp} \SSS$. Since $\{ \pmb{\alpha}_1, \pmb{\alpha}_2\}$ is a basis for $T_{\pp} \SSS$, there exist $v_1,v_2 \in \R$ such that
$$
\vv = v_1 \pmb{\alpha}_1 + v_2 \pmb{\alpha}_2 \,.
$$
Therefore 
\begin{align*}
\scp{\vv}{\vv} & = v_1^2 \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1} + 
                2 v_1 v_2 \scp{\pmb{\alpha}_1}{\pmb{\alpha}_2} +
                v_2^2 \scp{\pmb{\alpha}_2}{\pmb{\alpha}_2} \\
                & = v_1^2 + v_2^2 \,, 
\end{align*}
where we used that $\pmb{\alpha}_1$ and $\pmb{\alpha}_2$ are orthonormal.
On the other hand,
\begin{align*}
\scp{\vv}{\vv}_f & = v_1^2 \scp{\pmb{\alpha}_1}{\pmb{\alpha}_1}_f + 
                2 v_1 v_2 \scp{\pmb{\alpha}_1}{\pmb{\alpha}_2}_f +
                v_2^2 \scp{\pmb{\alpha}_2}{\pmb{\alpha}_2}_f \\
               & = v_1^2 \, \lambda(\pp) + 
                2 v_1 v_2 \, \mu(\pp) +
                v_2^2 \, \nu(\pp) \\
                & =  \lambda(\pp) \, (v_1^2 + v_2^2) \,,
\end{align*}
where we used that $\lambda(\pp) = \nu(\pp)$ and $\mu (\pp) = 0$. Thus
$$
\scp{\vv}{\vv}_f = \lambda(\pp) \, (v_1^2 + v_2^2) =\lambda(\pp) \, \scp{\vv}{\vv} \,, 
$$
for all $\vv \in T_{\pp} \SSS$. Since $\scp{\cdot}{\cdot}$ and 
$\scp{\cdot}{\cdot}_f$, by arguing as in Remark \ref{remark-local-isometry} we conclude that 
$$
\scp{\vv}{\ww}_f = \lambda(\pp) \, \scp{\vv}{\ww}  
$$
for all $\vv,\ww \in T_{\pp} \SSS$.


*Step 2.* Suppose that there exists a function $\lambda \colon \SSS \to \R$ such that 
$$
\scp{\vv}{\ww}_f =  \lambda (\pp) \, \scp{\vv}{\ww} \,, \quad \forall \, \vv,\ww \in T_{\pp} \SSS \,.
$$
In particular, we have
$$
\| \vv \|_f  = \sqrt{\lambda(\pp)} \| \vv \| \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$$
Then 
$$
\frac{\scp{\vv}{\ww}_f}{ \| \vv \|_f  \| \ww \|_f } = 
\frac{\lambda (\pp) \, \scp{\vv}{\ww}}{  \sqrt{\lambda(\pp)} \| \vv \|  \sqrt{\lambda(\pp)} \| \ww \| }  = 
\frac{\scp{\vv}{\ww}}{ \| \vv \|  \| \ww \| }  \,,
$$
showing that $f$ is a conformal map.

:::



::: {.Corollary #corollary-conformal}

Let $\SSS$ and $\widetilde{\SSS}$ be regular surfaces and $f \colon \SSS \to \widetilde{\SSS}$ be a local diffeomorphism. They are equivalent:

1. $f$ is a conformal map.
2. Let $\sss \colon U \to \SSS$ be a regular chart of $\SSS$ and consider the chart of $\widetilde{\SSS}$ given by 
$$
\widetilde{\sss} = f \circ \sss \colon U \to \widetilde{\SSS} \,.
$$ 
There exists $\lambda \colon U \to \R$ such that 
$$
\widetilde{\mathscr{F}}_1 = \lambda (u,v) \mathscr{F}_1 \,, \quad \forall \, (u,v) \in U \,,
$$
where $\mathscr{F}_1$ and $\widetilde{\mathscr{F}}_1$ are the first fundamental forms of $\sss$ and $\widetilde{\sss}$, respectively.

:::


The follows by using Theorem \ref{theorem-conformal}, and by adapting the
argument in the proof of Theorem \ref{theorem-local-isometry}.


::: Example 
### Conformal maps are not local isometries {#example-conformal}

Consider the plane $\SSS$ with chart 
$$
\sss(u,v) := (u,v,0) \,.
$$
Let $\widetilde{\SSS}$ be the sphere with parametrization
$$
\widetilde{\sss}(u,v) := \left(  \sech(u) \cos(v), \sech(u) \sin(v) , \tanh (u) \right) \,.
$$
We have
$$
\sss_u = (1,0,0) \,, \quad 
\sss_v = (0,1,0) \,,
$$
so that 
\begin{align*}
E & = \sss_u \cdot \sss_u =  1 \\ 
F & = \sss_u \cdot \sss_v =  0 \\ 
G & = \sss_v \cdot \sss_v =  1 \\ 
\end{align*}
Therefore the first fundamental form of $\SSS$ is
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$
Using the identitities
\begin{align*}
\frac{d}{du} \left( \sech (u)  \right) & = - \sech (u) \tanh (u) \,, \\
\frac{d}{du} \left( \tanh (u) \right)  & = {\sech}^2 (u) \,,
\end{align*}
we obtain
\begin{align*}
\widetilde{\sss}_u & = ( -\sech(u) \tanh(u) \cos(v), -\sech(u) \tanh(u) \sin(v), {\sech}^2(u) ) \\
\widetilde{\sss}_v & = ( -\sech(u) \sin(v), \sech(u) \cos(v), 0 ) 
\end{align*}
By recalling that
$$
{\sech}^2 (u) + {\tanh}^2 (u) = 1 \,,
$$
we compute
\begin{align*}
\widetilde{E} & = \widetilde{\sss}_u \cdot \widetilde{\sss}_u = {\sech}^2(u) ({\tanh}^2(u) + {\sech}^2(u)) = {\sech}^2(u) \\ 
\widetilde{F} & = \widetilde{\sss}_u \cdot \widetilde{\sss}_v =  0 \\ 
\widetilde{G} & = \widetilde{\sss}_v \cdot \widetilde{\sss}_v =  {\sech}^2(u) (\cos^2(v) + \sin^2(v)) = {\sech}^2(u) \\ 
\end{align*}
Hence the first fundamental form of $\widetilde{\SSS}$ is
$$
\widetilde{\mathscr{F}}_1 = {\sech}^2(u) \, \left(  du^2 + dv^2 \right) \,.
$$
Now, consider the map $f \colon \SSS \to \widetilde{\SSS}$ defined by
$$
f(u,v,0) = \widetilde{\sss} (u,v) \,.
$$
In particular $f$ satisfies
$$
f( \sss( u,v) ) = \widetilde{\sss} (u,v) \,.
$$
We have:

1. $f$ is not a local isometry.
2. $f$ is a conformal map.

*Proof.*

1. If $f$ was a local isometry, by Theorem \ref{theorem-local-isometry} we would conclude that $\sss$ and $\widetilde{\sss} = f \circ \sss$ have the same first fundamental form. However 
$$
\mathscr{F}_1 = du^2 + dv^2 \neq {\sech}^2(u) \, \left(  du^2 + dv^2 \right) 
= \widetilde{\mathscr{F}}_1  \,.
$$

2. The first fundamental forms of $\sss$ and $\widetilde{\sss} = f \circ \sss$ satisfy
$$
\widetilde{\mathscr{F}}_1  = \lambda(u,v) \, \mathscr{F}_1  \,, \quad 
\lambda(u,v) := {\sech}(u) \,.
$$
Therefore $f$ is a conformal map by Corollary \ref{corollary-conformal}.


:::




### Conformal parametrizations


In the previous section we defined conformal maps between surfaces
$$
f \colon \SSS \to \widetilde{\SSS}\,.
$$
As a special case, consider a surface chart
$$
\sss \colon U \to \SSS \,.
$$
The open set $U$ of $\R^2$ can be interpreted as a surface, parametrized by 
$$
(u,v) \to (u,v,0) \,.
$$
Hence $\sss$ can be seen as a map between surfaces, and it makes sense to discuss whether it is conformal or not.


::: Definition
### Conformal parametrization {#definition-conformal-parametrization}

Let $\SSS$ be a regular surface and 
$$
\sss \colon U  \to  \SSS
$$ 
be a regular chart of $\SSS$. We say that $\sss$ is a **conformal parametrization** if the first fundamental form of $\sss$ satisfies
$$
\mathscr{F}_1 = \lambda(u,v)  ( du^2 +  dv^2)
$$
for some smooth function $\lambda \colon U \to \R$. 


:::


The following Theorem states that, if $\sss$ is a conformal parametrization of $\SSS$, then angles on $\SSS$ look like angles on a plane.


::: Theorem

Let $\SSS$ be a regular surface and
$$
\sss \colon U  \to  \sss(U) \subseteq \SSS
$$ 
be a regular chart of $\SSS$. Define the plane $\p$ charted by
$$
\widetilde{\sss} (u,v) = (u,v,0) \,, \quad \forall \, (u,v) \in U \,.
$$

1. They are equivalent:

    - $\sss$ is a conformal parametrization.

    - There exists a conformal map $f \colon \p \to \sss(U) \subseteq \SSS$.

2. Angles on $\SSS$ look like angles on the plane, 
in the following sense: Suppose $\g_1, \g_2$ are curves in $\mathbb{R}^{2}$ such that
$$
\g_1 (t_0) = \g_2 (t_0) \,.
$$
Consider the corresponding curves on $\SSS$ given by 
$$
\tg_1 := \sss \circ \g_1 \,, \quad \tg_2 = \sss \circ \g_2 \,.
$$
Then 
$$
\theta = \widetilde{\theta}
$$
where $\theta$ is the angle between 
$\dg_1 (t_0), \dg_2(t_0)$ and $\widetilde{\theta}$ the angle between $\dtg_1 (t_0), \dtg_2(t_0)$


:::



::: Proof

*Proof of Point 1.*
Define the diffeomorphism $f \colon \p \to \SSS$ by
$$
f(u,v,0) = \sss(u,v) \,.
$$
In particular 
$$
f( \widetilde{\sss}(u,v) ) = \sss(u,v) \,.
$$
By Corollary \ref{corollary-conformal} we have that $f$ is a conformal map
if and only if there exists $\lambda \colon \p \to \R$ such that 
$$
\mathscr{F}_1 = \lambda(u,v) \widetilde{\mathscr{F}}_1  \,,
$$
where $\mathscr{F}_1$ and $\widetilde{\mathscr{F}}_1$ are the first fundamental forms of $\SSS$ and $\p$, respectively. Since $\p$ is a plane,
the first fundamental form is given by 
$$
\widetilde{\mathscr{F}}_1 = du^2 + dv^2 \,.
$$
Therefore 
$$
\mathscr{F}_1 = \lambda(u,v) \left(   du^2 + dv^2   \right)\,,
$$
showing that $\sss$ is a conformal parametrization. 


*Proof of Point 2.*
Suppose $\sss$ is a conformal parametrization. By the proof of Point 1 we have that 
$$
f \colon \p \to \SSS  \,, \quad f(u,v,0) = \sss(u,v) \,,
$$
is a conformal map. Since $T_{\pp} \p = \R^2$ and $f = \sss$, it follows by the definition of
differential and $f$ being conformal that the angle between $\g_1$ and $\g_2$ is the same as 
the angle between $\tg_1$ and $\tg_2$.

:::





::: Example
### Unit cylinder

Consider the unit cylinder $\SSS$ charted by
$$
\sss (u,v) = (\cos(u), \sin(u), v) \,.
$$
We have proven that the first fundamental form of $\sss$ is
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$
Therefore $\sss$ is a conformal parametrization of $\SSS$.

:::




::: Example
### Sphere

Consider the parametrization of the sphere
$$
\sss(u,v) = \left(  \sech(u) \cos(v), \sech(u) \sin(v) , \tanh (u) \right) \,.
$$
In Example \ref{example-conformal} we have seen that the first fundamental form of $\sss$ is
$$
\mathscr{F}_1  = {\sech}(u) \, ( du^2 + dv^2 )  \,.
$$
Therefore $\sss$ is a conformal parametrization of the sphere.


:::




### Equiareal maps




![The area of a small region $R$ on a surface $\SSS$ can be approximated by the area of the rectangle of sides $\sss_u$ and $\sss_v$. Such area is $\| \sss_u \times \sss_v \|$.](/images/fff_area.png){width=70%}




![Sketch of equiareal map $f$ between the surfaces $\SSS$ and $\widetilde{\SSS}$. The area of the region $R$ is the same of the area of $f(R)$.](/images/fff_equiareal.png){width=70%}




### Summary

Let us conclude with a summary for this section. We have introduced the 
**first fundamental form** as the restriction of the euclidean scalar product to the tangent space. The first fundamental form allows to compute:

- Inner product between tangent vectors
- Angle between tangent vectors
- Area of surface regions


In particular we can use the first fundamental form to compute:

- Length of curves on a surface
- Angle between curves on a surface


We have also introduced maps preserving certain quantities:

- Local isometries: They preserve scalar product of tangent vectors, and length of curves
- Conformal maps: They preserve the angle between tangent vectors, and between curves
- Equiareal maps: They preserve areas of surface regions

We have also shown that:

- Conformal maps are local isometries
- Local isometries are not conformal (in general)



### Application: Cartography

Consider the unit sphere
$$
\sphere^2 = \{ (x,y,z) \in \R^3 \, \colon \, x^2 + y^2 + z^2 = 1 \} \,.
$$
To make a map of the Earth one has to define a projection map
$$
\pi \colon \sphere^2 \to \R^2 \,.
$$
As we will see in the next section, the curvatures of $\sphere^2$ and $\R^2$ are different. Consequently each map $\pi$ will induce some *distorsion* in either

- Length
- Angles
- Shapes
- Area 

These types of distorsion can all be present at the same time. There are 2 main types of Earth maps

1. **Conformal projections:** These preserve angles and shapes but change areas. The main examples are
    - Stereographic projection (@fig-stereographic)
    - Mercator projection (@fig-mercator)
    
  
2. **Equiareal projections:** These preserve areas but change angles and shapes. For example:
    - Lambert cylindrical projection (@fig-lambert)


The above mentioned projections admit explicit formulations, and one can actually prove that the corresponding maps are/are not conformal/equi-areal. We will discuss these 3 projections below. Details are left as an exercise. 


::: Example
### Stereographic Projection

Denote the unit sphere by 
$$
\sphere^2 = \{ (x,y,z) \in \R^3 \, \colon \, x^2 + y^2 + z^2 = 1 \} \,.
$$
We will call the points 
$$
N = (0,0,1) \,, \quad S  = (0,0,-1)
$$
the north and south pole, respectively. The plane $\{z=0\}$ slices through the equator of the sphere. Let $P=(x,y,z)$ be any point on $\sphere^2$ except the north pole. The line joining the north pole to $P$ intersects the plane $\{z=0\}$ at the point $P'$, see @fig-stereographic-4. The point $P'$ defines the *Stereographic Projection* map 
$$
\pi \colon \sphere^2 \smallsetminus \{N\} \to \R^2 \,,
$$
where
$$
\pi(x,y,z) = \left( \frac{x}{1-z},\frac{y}{1-z}  \right) \,.
$$
Notice that $\pi$ is slightly different from the map described in @fig-stereographic: there the projection is done onto the plane $\{z=-1\}$, while in this example we project on the plane $\{z=0\}$. This is just because calculations are more convenient when projecting on $\{z=0\}$. It is not difficult to prove that $\pi$ is invertible, with inverse given by 
$$
\sss(u,v) =\left( \frac{2u}{u^2+v^2+1},  \frac{2v}{u^2+v^2+1} , 1-\frac{2}{u^2+v^2+1}\right) \,.
$$
We have that $\sss$ is a regular chart for $\sphere^2 \smallsetminus \{N\}$. It can be computed that the coefficients of the first fundamental form associated of $\sss$ are
$$
E = G = \lambda(u,v) := \frac{4}{(u^2+v^2+1)^2} \,, \qquad F = 0 \,.
$$
In particualar the fisrt fundamental form is of type
$$
\mathscr{F}_1 = \lambda(u,v) (du^2 + dv^2)
$$
showing that $\sss$ is a conformal parametrization of the sphere. 

However, $\sss$ is not equi-areal. Indeed, recall that the first fundamental form of the plane is $du^2 + dv^2$. Therefore the area element of the plane is $1$. 
The area element for $\sss$ is
$$
EG - F^2 =  \frac{16}{(u^2+v^2+1)^4} \neq 1 \,,
$$
showing that $\sss$ is not equi-areal. 

:::


![Stereographic projection map from the North pole $N = (0,0,1)$. Let $P \in \sphere^2$. The line through $N$ and $P$ intersects the plane $\{z=0\}$ at the point $P'$.](/images/stereographic_4.png){#fig-stereographic-4 width=70%}





::: Example
### Lambert cylindrical projection

Consider the unit sphere
$$
\sphere^2 = \{ (x,y,z) \in \R^3 \, \colon \, x^2 + y^2 + z^2 = 1 \} \,,
$$
and the unit cylinder of equation
$$
x^2 + y^2 = 1 \,.
$$
The sphere is contained inside the cylinder, and the two surfaces touch along the circle $x^2 + y^2 = 1$ in the $\{z=0\}$ plane. Let $P \in \sphere^2$ except for north or south pole. Draw the line through $P$ and the $z$-axis which is parallel to the plane $\{z=0\}$. This line intersects the cylinder in 2 points. Denote by $P'$ the intersection point which is closest to $P$, see @fig-archimedes. To write the projection map explicitly, denote the coordinates of $P$ and $P'$ by
$$
P = (x,y,z) \,, \quad P' = (X,Y,Z) \,.
$$
Since the line through $P$ and $P'$ is parallel to the plane $\{z=0\}$, we have
$$
Z = z \,, \quad (X,Y) = \lambda (x,y)
$$
for some scalar $\lambda$. Using that $P'$ belongs to the cylinder, we get
$$
1 = X^2 + Y^2 = \lambda^2 (x^2 + y^2)
$$
from which we deduce that 
$$
\lambda = \pm \frac{1}{(x^2 + y^2)^{1/2}} \,.
$$ 
Therefore 
$$
X = \lambda x = \pm \frac{x}{(x^2 + y^2)^{1/2}} \,, 
\quad 
Y = \lambda y = \pm \frac{y}{(x^2 + y^2)^{1/2}} \,.
$$
Taking the $+$ sign gives the point
$$
P' = (X,Y,Z) = \left( \frac{x}{(x^2 + y^2)^{1/2}}, \frac{y}{(x^2 + y^2)^{1/2}} ,   z \right) \,.
$$


Consider the chart for the sphere
$$
\sss(u, v)=(\cos (u) \sin (v), \sin (u) \sin (v), \cos (v))
$$


The full calculation will be carried out in Example \ref{example-sphere-principal} below. 


:::


![Lambert projection map: Let $P \in \sphere^2$ except for north or south pole. Draw the line through $P$ and the $z$-axis which is parallel to the plane $\{z=0\}$. This line intersects the cylinder in 2 points. Denote by $P'$ the intersection point which is closest to $P$.](/images/archimedes.png){#fig-archimedes width=80%}



![Stereographic projection of the Earth. Image from [Wikipedia](https://en.wikipedia.org/wiki/Stereographic_projection)](/images/stereographic_2.png){#fig-stereographic-1 width=75%}

![Stereographic projection is a conformal map: Angles and shapes are preserved. However areas are magnified away from the North pole.](/images/stereographic_3.png){#fig-stereographic-2 width=75%}





![Mercator projection of the Earth. This is the most known Earth map.](/images/mercator_2.png){width=75%}

![Mercator projection: Angles and shapes are preserved. However areas are magnified away from the Equator.](/images/mercator_3.png){width=75%}

The Mercator projection is a conformal map. As such it preseves angles and shapes. However areas are distorted. Images from [Britannica](https://www.britannica.com/science/Mercator-projection) and [Wikipedia](https://en.wikipedia.org/wiki/Mercator_projection).

:::


::: Example
### Mercator projection

The Mercator projection is a type of cylindrical projection.  Intuitively, it is obtained by blowing up the sphere inside the cylinder, letting the sides of the sphere stick to the cylinder when it comes into contact with it. The main feature of this projection is that parallels and meridians on the Earth become horizontal and vertical lines on the map. This is ideal for navigation. A derivation of the Mercator projection using only elementary geometry is quite involved, see for example this [link](https://personal.math.ubc.ca/~israel/m103/mercator/mercator.html). We can however motivate it as follows, using differential geometry. We parametrize the sphere in spherical coordinates 
$$
\sss(\theta,\f)  = 
$$
for $\theta \in (-\pi,\pi)$, $\f \in \left(-\frac{pi}{2},\frac{\pi}{2}\right)$. 

:::



![Lambert cylindrical projection map. First project on a cylinder from the axis passing through North pole and South pole. Then unroll the cylinder.](/images/lambert_1.png){width=75%}


![Lambert cylindrical projection of the Earth.](/images/lambert_2.png){width=75%}

![Lambert cylindrical projection: Areas are preserved. Angles and shapes are distorted.](/images/lambert_3.png){width=75%}

The Lambert cylindrical projection is an equi-areal map. As such it preseves areas. However angles and shapes are distorted. Images from [Wikipedia](https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection).













## Second fudamental form



The first fundamental form allows to measure distances on a surface. However it does not give any information on how curved a surface is: For example, we saw that a plane and a cylinder have the 
same first fundamental form
$$
\mathscr{F}_1 = du^2 + dv^2 \,.
$$
However the plane is flat, while the cylinder curves. We would like to find a measure of curvature 
which allows us to tell these two surfaces apart.




We can now start our discussion about curvature of surfaces. We can make a similar argument to the one
we made for curves: If $\g$ is a unit speed curve, the curvature of $\g$ is defined as
$$
\kappa (t) = \norm{\ddg(t)} \,.
$$
The quantity $\kappa(t)$ gave us a measure of how much $\g$ is deviating from a straight line. Similarly, we would like
to quantify how much a surface $\SSS$ is deviating from the tangent plane $T_{\pp} \SSS$. Recall
that 
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u , \sss_v \} \,,
$$
where $\sss$ is a regular chart of $\SSS$ at $\pp$. The standard unit normal of $\sss$ is
$$
\NN = \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v } } \,,
$$
which is orthogonal to $T_{\pp} \SSS$. Let $(u_0,v_0) \in \R^2$ be the point such that
$$
\sss(u_0,v_0) = \pp \,.
$$
As the scalar quantities $\Delta u$ and $\Delta v$ vary, the point
$$
\sss ( u_0 + \Delta u , v_0 + \Delta v ) \in \SSS
$$
deviates from the tangent plane $T_{\pp} \SSS$. Since $\NN$ is orthogonal to $T_{\pp} \SSS$, the deviation is given by
$$
\delta := \left[  \sss(  u_0 + \Delta u , v_0 + \Delta v  ) - \sss (u_0,v_0)    \right] \cdot \NN \,,
$$
as shown in @fig-sff-sketch. 

![The point $\sss(u_0 + \Delta u, v_0 + \Delta v)$ on $\SSS$ deviates from $T_{\pp}\SSS$ by a quantity $\delta$.](/images/sff_sketch.png){#fig-sff-sketch width=70%}

Using Taylor's formula we get
\begin{align*}
\sss(u_0 + \Delta u , v_0 + \Delta v)  & = \sss(u_0,v_0) +  \sss_u (u_0,v_0) \, \Delta u + 
                                          \sss_v (u_0,v_0) \, \Delta v  \\
                                       & \,\, +  \frac12 \left(  \sss_{uu}(u_0,v_0) (\Delta u)^2 +  2 \sss_{uv}(u_0,v_0) \Delta u \Delta v  +{\sss}_{vv}(u_0,v_0) (\Delta v)^2    \right) \\ 
                                       &  \,\, + R(\Delta u , \Delta v) \,,
\end{align*}
where $R(\Delta u , \Delta v)$ is a remainder such that
$$
\lim_{\Delta \to 0} \, \frac{R(\Delta u , \Delta v) }{\Delta }  =  0 \,, \quad \Delta := (\Delta u)^2 + (\Delta v)^2 \,. 
$$
Since $\NN$ is orthogonal to $\sss_u$ and $\sss_v$, if we multiply the above Taylor expansion by $\NN$, and ignore the remainder, we obtain
$$
\delta =  \frac12 \left(  L  (\Delta u)^2 +  2 M \Delta u \Delta v  + N (\Delta v)^2    \right) \,,
$$
where we set 
$$
L := \sss_{uu}  \cdot \NN \,, \quad 
M := \sss_{uv}  \cdot \NN \,, \quad 
N := \sss_{vv}  \cdot \NN \,.
$$
The expression
$$
\mathscr{F}_2 :=  L \, du^2 +  2 M  \,du dv  + N \, dv^2 
$$
is called the **second fundamental form** of $\SSS$. Therefore $\mathscr{F}_2$ measures how much the surface $\SSS$ deviates from being a plane. Let us make this definition precise.


::: Definition
### Second fundamental form of a chart

Let $\sss \colon U \to \R^3$ be a regular chart of $\SSS$. Denote the standard unit normal of $\sss$ by
$$
\NN \colon U \to \R^3 \,, \quad \NN = \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v } } \,.
$$
Define the functions
$$
L , M , N \colon U \to \R 
$$
by setting
$$
L := \sss_{uu} \cdot \NN  \,, \quad  M := \sss_{uv} \cdot \NN \,, \quad 
N := \sss_{vv} \cdot \NN \,.
$$
Let $\pp \in \sss(U)$ and denote by $(u_0,v_0) \in U$ the point such that
$$
\sss(u_0,v_0) = \pp \,.
$$
The **second fundamental form** of $\sss$ at $\pp$ is the quadratic form
$$
\mathscr{F}_2 \colon T_{\pp} \SSS \to \R
$$
defined by
$$
\mathscr{F}_2 (\vv) := L \, du^2(\vv) + 2M \, du(\vv) \, dv (\vv)+ N \, dv^2 (\vv) \,,
$${#eq-sff-chart}
for all $\vv \in T_{\pp} \SSS$. Here $L,M,N$ are evaluated at $(u_0,v_0)$, and 
$du$, $dv$ are the coordinate functions as in Definition \ref{definition-coordinate-functions}.

:::


::: Notation 

With a little abuse of notation, we also denote by $\mathscr{F}_2$ the $2 \times 2$ matrix
$$
\mathscr{F}_2 = 
\left(
\begin{array}{cc}
L & M \\
M & N 
\end{array}
\right) \,.
$$

:::



::: Remark
### Second fundamental form and reparametrizations  

The second fundamental form
$$
\mathscr{F}_2 = L \, du^2 + 2M \, du dv + N \, dv^2
$$
depends on the choice of chart $\sss \colon U \to \R^3$. Indeed, let us adopt the same notations 
as Remark \ref{remark-fff-reparametrization}. Suppose that $\widetilde{\sss} \colon \widetilde{U} \to \R^3$ is a reparametrization of $\sss$ with 
$$
\widetilde{\sss} = \sss \circ \Phi \,,
$$
where $\Phi \colon \widetilde{U} \to U$ is a diffeomorphism. Denote the second fundamental form of $\widetilde{\sss}$ by
$$
\widetilde{\mathscr{F}}_2 = \widetilde{L} \, d\tilde{u}^2 + 2 \widetilde{M} \, d\tilde{u} d\tilde{v} + \widetilde{N} \, d\tilde{v}^2 \,.
$$
The matrices of $\mathscr{F}_2$ and $\widetilde{\mathscr{F}}_2$ are related by
$$
\left(
\begin{array}{cc}
\widetilde{L} & \widetilde{M} \\
\widetilde{M} & \widetilde{N}
\end{array}
\right)  
= 
\pm (J \Phi)^T \,
\left(
\begin{array}{cc}
L & M \\
M & N
\end{array}
\right)
\, 
J \Phi  \,,
$${#eq-sff-repar}
where (@eq-sff-repar) holds with $+$ if $\det J\Phi > 0$ and $-$ if
$\det J\Phi < 0$. 

> Formula (@eq-sff-repar) holds by a change of variable argument. The sign depends on the sign of  $\det J\Phi$ because
$$
\widetilde{\NN} = \frac{ \widetilde{\sss}_{\tilde{u}} \times \widetilde{\sss}_{\tilde{v}} }{\norm{\widetilde{\sss}_{\tilde{u}} \times \widetilde{\sss}_{\tilde{v}}}} = \frac{\det J\Phi}{|\det J\Phi|} \frac{\sss_u \times \sss_v}{\norm{\sss_u \times \sss_v}} = \pm \NN \,,
$$
as shown in Remark \ref{remark-normal-chart}.

:::


Let us show that a plane and a cylinder have different second fundamental forms.



::: Example
### Plane   {#example-sff-plane}

Let $\mathbf{a}, \pp, \mathbf{q} \in \R^3$. Suppose that $\pp$ and $\mathbf{q}$ are orthonormal vectors, that is,
$$
\norm{\pp} = \norm{\mathbf{q}} = 1 \,, \quad \pp \cdot \mathbf{q} = 0 \,. 
$$
Consider the plane with chart
$$
\sss(u,v) = \mathbf{a} + u \pp + v \mathbf{q} \,, \quad (u,v) \in \R^2 \,.
$$
Prove that the second fundamental form of $\sss$ is
$$
\mathscr{F}_2 = 0 \,.
$$
This reflects the intuition that a plane is flat, and therefore there is no *curvature*. 

> We have
$$
\sss_u = \pp \,, \quad \sss_v = \mathbf{q} \,.
$$
The principal unit normal is
$$
\NN = \frac{\pp \times \mathbf{q}}{\norm{ \pp \times \mathbf{q} }   } \,,
$$
while the second derivatives are
$$
\sss_{\uu} = \sss_{\uu} = \sss_{\uu} = \zero \,.
$$
Therefore
\begin{align*}
L & = \sss_{uu} \cdot \NN = 0 \\
M & = \sss_{uv} \cdot \NN = 0 \\
N & = \sss_{vv} \cdot \NN = 0 \\
\end{align*}
and the second fundamental form is
$$
\mathscr{F}_2 = L \, du^2 + 2 M\, du \, dv + N \, dv^2 = 0 \,.  
$$

:::




::: Example
### Unit cylinder  {#example-cylinder-sff}

Consider the unit cylinder with chart
$$
\sss(u,v) = (\cos(u), \sin(u),  v)  \,, \quad (u,v) \in (0,2\pi) \times \R \,.
$$
Prove that the second fundamental form of $\sss$ is
$$
\mathscr{F}_2 = -  du^2 \,.
$$
This reflects the intuition that the cylinder curves only when moving in the $v$-direction.
In such direction we are moving on a circle of radius $1$, therefore we expect the curvature 
to be $-1$.

> We have
$$
\sss_u = (-\sin(u),\cos(u), 0 )  \,, \quad \sss_v = (0,0,1) \,, 
$$
and also
$$
\sss_{uu}  = (-\cos(u), - \sin(u), 0 ) \,, \quad \sss_{uv} = \sss_{vv} = \zero \,.
$$
We have also 
$$
\sss_u \times \sss_v  =
\left|  
\begin{array}{ccc}
\ii & \jj & \kk \\
-\sin(u) & \cos(u) & 0 \\
0 & 0 & 1
\end{array}
\right|
 = (\cos(u), \sin(u),0)
$$
so that 
$$
\norm{ \sss_u \times \sss_v } = \sqrt{ \cos^2(u) + \sin^2(u)  } = 1 \,. 
$$
The principal unit normal is
$$
\NN = \frac{\sss_u \times \sss_v}{ \norm{\sss_u \times \sss_v} } = (\cos(u), \sin(u),0) \,.
$$
We finally compute
\begin{align*}
L & = \sss_{uu} \cdot \NN \\
  & = (-\cos(u), - \sin(u), 0 ) \cdot (\cos(u), \sin(u),0) \\
  & = - \cos^2(u) - \sin^2(u) = - 1 \\
M & = \sss_{uv} \cdot \NN = 0 \\
N & = \sss_{vv} \cdot \NN = 0 \\
\end{align*}
The second fundamental form is
$$
\mathscr{F}_2 = L \, du^2 + 2 M\, du \, dv + N \, dv^2 = - du^2  \,.  
$$

:::


::: Remark

We have seen that a plane and the unit cylinder have the same first fundamental form 
$$
\mathscr{F}_1 = \widetilde{\mathscr{F}}_1 = du^2 + dv^2 \,,
$$
while their second fundamental forms differ: we have
$$
\mathscr{F}_2 = 0 \,, \quad \widetilde{\mathscr{F}}_2 = - du^2   \,,
$$
respectively.
:::








### Gauss and Weingarten maps


Another way to quantify how much a surface $\SSS$ is curving is by 
examining the behavior of standard unit normal $\NN$. If 
$\SSS$ is a plane spanned by vectors $\pp$ and $\mathbf{q}$, then its standard unit normal is
$$
\NN = \frac{\pp \times \mathbf{q}}{ \norm{\pp \times \mathbf{q}} } \,,
$$
which is constant across $\SSS$. If $\SSS$ is a general surface, measuring the variation of $\NN$ will tell us how much $\SSS$ is deviating from being a plane. This
is the idea behind the definition of the **Gauss** and **Weingarten** maps.


::: Remark 

Let $\SSS$ be oriented and $\NN \colon \SSS \to \R^3$ be the standard unit normal. In particular $\NN$ is a smooth map and 
$$
\NN(\pp) \perp T_{\pp} \SSS \,, \quad \| \NN(\pp) \| = 1 \,, \quad \forall  \, \pp \in \SSS \,. 
$$
Since $T_{\pp} \SSS$ passes through the origin and $\NN$ has norm $1$, it follows that
$$
\NN (\pp) \in 
\sphere^2 := \{ \xx \in \R^3 \, \colon \, \| \xx \| = 1 \}  \,,
$$
where $\sphere^2$ is the unit sphere in $\R^3$. Thus $\NN \colon \SSS \to \sphere^2$.

:::




::: Definition
### Gauss map

Let $\SSS$ be an oriented surface and $\NN$ the standard unit normal to $\SSS$. The **Gauss map** of 
$\SSS$ is the map 
$$
{\mathcal{G}}_{\SSS} \colon \SSS  \to \sphere^2 \,, \quad 
{\mathcal{G}}_{\SSS} (\pp):= \NN(\pp) \,.
$$

:::

![The Gauss map ${\mathcal{G}}_{\SSS}$ of $\SSS$ is defined as ${\mathcal{G}}_{\SSS}(\pp):= \NN(\pp)$. Note that ${\mathcal{G}}_{\SSS}(\pp) \in \sphere^2$.](/images/sff_gauss_map.png){width=70%}



::: {.Remark #remark-gauss-coordinates}

The Gauss map of $\SSS$ is just the standard unit normal of $\SSS$. By definition
of standard unit normal to $\SSS$ we obtain that 
$$
\mathcal{G}_{\SSS} \circ \sss = \NN
$$
for all charts $\sss \colon U \to \R^3$, where $\NN = \NN_{\sss}$ is the standard unit normal to $\sss$,
that is, 
$$
\NN \colon U \to \R^3 \,, \quad 
\NN := \frac{ \sss_u \times \sss_v }{ \norm{ \sss_u \times \sss_v } } \,.
$$


:::


::: Example

1. Suppose $\SSS$ is the unit sphere $\sphere^2$. Then 
${\mathcal{G}}_{\SSS} \colon \SSS \to \sphere^2$ is the identity, see @fig-gauss-sphere.

2. Let $\mathbf{a} , \vv ,\ww \in \R^3$ with $\vv$ and $\ww$ linearly independent.
Let $\SSS$ be the plane 
$$
\sss (u,v):= \mathbf{a} + \vv u + \mathbf{\ww} v \,, \quad \forall \, (u,v) \in \R^2 \,.
$$
The Gauss map of $\SSS$ is constant:
$$
\mathcal{G}_{\SSS} (\pp) = \frac{ \vv \times \ww  }{ \| \vv \times \ww \| } \,,
$$
for all $\pp \in \SSS$, see @fig-gauss-plane.

3. Let $\SSS$ be the unit cylinder
$$
\sss(u,v) = (\cos(u), \sin(u),  v)  \,, \quad (u,v) \in (0,2\pi) \times \R \,.
$$
Then
$$
\sss_u = (-\sin(u),\cos(u), 0 )  \,, \quad \sss_v = (0,0,1) \,,
$$
and
$$
\sss_u \times \sss_v = 
\left|
\begin{array}{ccc}
\ii & \jj & \kk \\
-\sin(u) & \cos(u) & 0 \\
0  &  0 &  1 
\end{array}
\right|
= (\cos(u), \sin(u), 0) \,.
$$
Therefore 
$$
\norm{ \sss_u \times \sss_v } = 1 \,,
$$
and 
$$
\NN = \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v } } = (\cos(u), \sin(u), 0) \,.
$$
The Gauss map of $\SSS$ is
$$
\mathcal{G}_{\SSS} (\pp) = (\cos(u_0), \sin(u_0), 0) \,,
$$
where $(u_0,v_0)$ is such that $\sss(u_0,v_0)=\pp$. 
Note that $\mathcal{G}_{\SSS}$ maps $\SSS$ into the equator of $\sphere^2$, see @fig-gauss-cylinder.


:::


![The Gauss map ${\mathcal{G}}_{\SSS}$ of a sphere is the identity.](/images/sff_gauss_sphere.png){#fig-gauss-sphere width=70%}


![The Gauss map ${\mathcal{G}}_{\SSS}$ of a plane is constant.](/images/sff_gauss_plane.png){#fig-gauss-plane width=70%}


![If $\SSS$ is the unit cylinder, the Gauss map ${\mathcal{G}}_{\SSS}$ maps $\SSS$ into the equator of $\sphere^2$.](/images/sff_gauss_cylinder.png){#fig-gauss-cylinder width=70%}




::: Remark

By definition, the Gauss map is a smooth function between surfaces. Therefore the differential of 
$\mathcal{G}_{\SSS}$ is well defined, and
$$
d_{\pp} {\mathcal{G}}_{\SSS} \colon T_{\pp} \SSS \to T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2 \,,
$$
for all $\pp \in \SSS$. We have that
$$
T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2 = T_{\pp} \SSS \,,
$${#eq-gauss-identification}
see @fig-weingarten. Therefore
$$
d_{\pp} {\mathcal{G}}_{\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS \,.
$$

> *Proof.* The tangent plane $T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2$ passes through the origin and
$$
\mathcal{G}(\pp) \perp T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2 \,.
$$
By definition $\mathcal{G}(\pp) = \NN(\pp)$, and thus
$$
\NN(\pp) \perp T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2 \,.
$$
Since by definition
$$
\NN(\pp) \perp T_{\pp} \SSS \,,
$$
we infer (@eq-gauss-identification).

::: 



![We ca identify $T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2$ with $T_{\pp} \SSS$. This is because $\mathcal{G}(\pp) \perp T_{{\mathcal{G}}_{\SSS}(\pp)} \sphere^2$ and $\mathcal{G}(\pp) = \NN(\pp)$.](/images/sff_weingarten.png){#fig-weingarten width=70%}




::: Definition
### Weingarten map

Let $\SSS$ be an orientable surface and $\mathcal{G} \colon \SSS \to \sphere^2$ its Gauss map. 
The **Weingarten map** $\WW_{\pp, \SSS}$ of $\SSS$ at $\pp$ is the negative differential of the 
Gauss map at $\pp$, that is,
$$
\WW_{\pp,\SSS} \colon T_{\pp}\SSS  \to T_{\pp} \SSS \,, \quad  \WW_{\pp,\SSS}(\vv) := -d_{\pp} \mathcal{G} (\vv) \,,
$$
for all $\vv \in T_{\pp} \SSS$.

:::


::: Important

The Gauss map encodes information on the standard unit normal $\NN$ to $\SSS$. Hence its derivative, the Weingarten map, detects the rate of change of $\NN$.

:::

::: Remark

The minus sign in the definition of $\WW_{\pp,\SSS}$ is a convention, just like we defined the torsion
to be the scalar $\tau$ such that
$$
\dot{\bb} = - \tau \nn \,.
$$

:::

The Weingarten map allows us to define a bilnear form on $T_{\pp} \SSS$. We call such bilinear form the **second fundamental form** of $\SSS$. 


::: Definition
### Second fundamental form of a surface


Let $\SSS$ be an orientable surface and denote by 
$$
\WW_{\pp,\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS 
$$
its Weingarten map at $\pp$. The **second fundamental form** of $\SSS$ at $\pp$ is the map
$$
II_{\pp} \colon T_{\pp} \SSS \times T_{\pp} \SSS \to \R
$$ 
defined by
$$
II_{\pp}(\vv,\ww) := \WW_{\pp, \SSS}(\vv) \cdot \ww \,, \quad \forall \, \vv , \ww \in T_{\pp} \SSS \,.
$$

:::

::: Remark

The second fudamental form $II_{\pp}$ of $\SSS$ is bilinear. 

> Indeed, $\WW_{\pp,\SSS}$ is linear, being the differential of a smooth map. Hence $II_{\pp}$ is bilinear, given that the scalar product is bilinear.

:::


::: Remark 
### Matrix of the second fundamental form


Let $\sss$ be a chart at $\pp \in \SSS$. Since $II_{\pp}$ is a bilinear form on 
$T_{\pp} \SSS$, it can be represented by the $2 \times 2$ matrix 
$$
A = 
\left( 
\begin{array}{cc}
II_{\pp} (\sss_u, \sss_u) & II_{\pp} (\sss_u , \sss_v) \\
II_{\pp} (\sss_v, \sss_u) & II_{\pp} (\sss_v , \sss_v) 
\end{array}
\right)  \,,
$$
given that $\{ \sss_u, \sss_v\}$ is a basis for $T_{\pp} \SSS$. In a not so shocking turn of events, it happens that
$$
A = \mathscr{F}_2 = 
\left( 
\begin{array}{cc}
L & M \\
M & N 
\end{array}
\right) 
$$
where
$$
L = \sss_{uu} \cdot \NN \,, \quad 
M = \sss_{uv} \cdot \NN \,, \quad 
N = \sss_{vv} \cdot \NN \,.
$$
Therefore, the second fundamental form $II_{\pp}$ coincides with the second fundamental form $\mathscr{F}_{2}$ of the chart $\sss$. We prove this statement in the next theorem.

:::


::: {.Theorem #theorem-sff-chart }

Let $\SSS$ be an orientable surface and $\sss \colon U \to \R^3$ be a regular chart.
Let $\pp \in \sss(U)$. 

1. The second funamental form $II_{\pp}$ is a symmetric bilinear map.

2. It holds
$$
II_{\pp} (\vv,\ww) = (du (\vv), dv(\vv) )  \, 
\left( 
\begin{array}{cc}
L & M \\
M & N 
\end{array}
\right) \, (du(\ww) , dv(\ww))^T \,,
$$
for all $\vv,\ww \in T_{\pp} \SSS$, where
$$
L = \sss_{uu} \cdot \NN \,, \quad 
M = \sss_{uv} \cdot \NN \,, \quad 
N = \sss_{vv} \cdot \NN \,.
$$

3. $\mathscr{F}_2$ is the quadratic form associated to $II_{\pp}$, that is,
$$
\mathscr{F}_2 (\vv) = {II}_{\pp} (\vv,\vv) \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$$


:::


To prove Theorem \ref{theorem-sff-chart} we use the following two Lemmas.


::: {.Lemma  #lemma-normal-derivatives}

Let $\sss \colon U \to \R^3$ be a regular chart with standard unit normal $\NN \colon U \to \R^3$. 
Then
\begin{align*}
\NN_{u} \cdot \sss_u & = - L \,,\\
\NN_{u} \cdot \sss_v & = \NN_{v} \cdot \sss_u = - M \,, \\
\NN_{v} \cdot \sss_v & = - N \,.
\end{align*}

:::


::: Proof

The vectors $\sss_u$ and $\sss_v$ form a basis for $T_{\pp} \SSS$. Since $\NN$ is orthogonal to 
$T_{\pp} \SSS$ by definition, it follows that
$$
\NN \cdot \sss_u = 0 \,, \quad 
\NN \cdot \sss_v = 0 \,.
$$
Differentiating the above with respect to $u$ and $v$ yields the thesis. For example, we have
$$
\frac{\partial}{\partial u} (\NN \cdot \sss_u) = 0 \,.
$$
On the other hand, by chain rule,
$$
\frac{\partial}{\partial u} (\NN \cdot \sss_u) = \NN_u \cdot \sss_u + \NN \cdot \sss_{uu} = 
\NN_u \cdot \sss_u + L \,,
$$
from which we infer
$$
\NN_u \cdot \sss_u = - L \,.
$$
The rest of the proof follows similarly.

:::


::: {.Lemma  #lemma-weingarten}

Let $\SSS$ be an orientable surface and $\WW_{\pp,\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS$ be 
its Weingarten map at $\pp$. Let $\sss$ be a regular chart at $\pp$, with $\sss(u_0,v_0) = \pp$. Then
$$
\WW_{\pp,\SSS} (\sss_u) = - \NN_u \,, \quad 
\WW_{\pp,\SSS} (\sss_v) = - \NN_v \,,
$$
where $\sss_u,\sss_v,\NN_u,\NN_v$ are evaluated at $(u_0,v_0)$.

:::


::: Proof

Since $\WW_{\pp,\SSS}$ is defined as $- d_{\pp} \mathcal{G}_{\SSS}$, we can compute 
$\WW_{\pp,\SSS} (\sss_u)$ and $\WW_{\pp,\SSS} (\sss_v)$ by using the definition of differential of
a smooth function. To this end, consider the curve
$$
\g (t) := \sss ( u_0 + t , v_0 ) \,.
$$
We have that $\g$ is a smooth curve in $\SSS$ and
$$
\dg(t) =  \sss_u( u_0 + t, v_0 ) \,.
$$
Therefore
$$
\g(0) = \sss(u_0,v_0) = \pp \,, \quad \dg(0) = \sss_u (u_0,v_0) \,.
$$
Define
$$
\tg(t) := (\mathcal{G}_{\SSS} \circ \g )(t) \,.
$$
By Remark \ref{remark-gauss-coordinates}
$$
\tg(t) = \mathcal{G}_{\SSS} (\g(t)) = \mathcal{G}_{\SSS} (\sss(u_0 + t , v_0)) = \NN (u_0 + t , v_0) \,.
$$
Thus
$$
\dtg(t) = \NN_u (u_0 + t , v_0) \,, \quad \dtg(0) = \NN_u (u_0 , v_0) \,.
$$
By definition of differential, we have
$$
\WW_{\pp,\SSS} (\sss_u)  = - d_{\pp} \mathcal{G}_{\SSS} (\sss_u) 
                         = - \dtg (0) 
                         = - \NN_u (u_0,v_0) \,,
$$
as we wanted to prove. To show that
$$
\WW_{\pp,\SSS} (\sss_v) = - \NN_v (u_0,v_0) \,,
$$
it is sufficient to consider the curve
$$
\g (t) := \sss ( u_0 , v_0 + t ) \,,
$$
and argue similarly. This is left as an exercise.


:::


We can now prove Theorem \ref{theorem-sff-chart}


::: Proof
### Proof of Theorem \ref{theorem-sff-chart}

By Theorem \ref{theorem-tangent-plane} we have
$$
T_{\pp} \SSS = \operatorname{span} \{ \sss_u, \sss_v \} \,.
$$
Therefore, for $\vv,\ww \in T_{\pp} \SSS$, there exist $\lambda_1,\lambda_2,\mu_1,\mu_2 \in \R$ such that 
$$
\vv = \lambda_1 \sss_u + \mu_1 \sss_v \,, \quad 
\ww = \lambda_2 \sss_u + \mu_2 \sss_v \,.
$$
By bilinearity of $II_{\pp}$ we infer
\begin{align*}
{II}_{\pp} (\vv,\ww) & = \lambda_1 \lambda_2 \, II_{\pp}(\sss_u , \sss_u)  +  \lambda_1 \mu_2 \,  II_{\pp}(\sss_u , \sss_v) \\ 
& \,\,\,\, + \lambda_2 \mu_1  \,  II_{\pp}(\sss_v , \sss_u)  + \mu_1 \mu_2 \,  II_{\pp}(\sss_v , \sss_v) \\
& = du(\vv) du(\ww) \, II_{\pp}(\sss_u , \sss_u)  +  du(\vv) dv(\ww) \,  II_{\pp}(\sss_u , \sss_v) \\ 
& \,\,\,\, + dv(\vv) du(\vv)  \,  II_{\pp}(\sss_v , \sss_u)  + dv(\vv) dv(\ww) \,  II_{\pp}(\sss_v , \sss_v) \\
& = (du (\vv), dv(\vv) )  \, 
\left( 
\begin{array}{cc}
II_{\pp}(\sss_u , \sss_u) & II_{\pp}(\sss_u , \sss_v) \\
II_{\pp}(\sss_v , \sss_u) & II_{\pp}(\sss_v , \sss_v) 
\end{array}
\right) \, (du(\ww) , dv(\ww))^T \,.
\end{align*}
By Lemma \ref{lemma-weingarten} and Lemma \ref{lemma-normal-derivatives} we have
$$
\WW_{\pp, \SSS} (\sss_u) = - \NN_u \,, \quad L = - \NN_u \cdot \sss_u \,.
$$
Therefore, using the above and the definition of $II_{\pp}$, we get
$$
II_{\pp} (\sss_u,\sss_u) = \WW_{\pp,\SSS} (\sss_u) \cdot \sss_u = - \NN_u \cdot \sss_u = L \,.
$$
With similar calculations we obtain 
$$
II_{\pp} (\sss_u,\sss_v) = II_{\pp} (\sss_v,\sss_u) = M \,, \quad
II_{\pp} (\sss_v,\sss_v) = N \,,
$$
concluding the proof of point 2. In particular this also proves that $II_{\pp}$ is symmetric, which is Point 1 of the statement. The fact that 
$$
II_{\pp}(\vv,\vv) = \mathscr{F}_2(\vv)
$$ 
follows from Point 2 and definition of $\mathscr{F}_2$.

:::




### Matrix of Weingarten map


The Weingarten map is a linear map
$$
\WW_{\pp,\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS \,.
$$
We would like to find a formula to compute $\WW_{\pp,\SSS}$. This is easily done: Given a chart $\sss$ at $\pp$, we have that $\{\sss_u,\sss_v\}$ is a basis 
for the vector space $T_{\pp} \SSS$. Therefore there exists a $2 \times 2$ matrix $A$
which represents $\WW_{\pp,\SSS}$, that is, 
$$
\WW_{\pp,\SSS}(\vv) = A \vv \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$$
It turns out that
$$
A = \mathscr{F}_1^{-1} \mathscr{F}_2 \,,
$$
where we recall that
$$
\mathscr{F}_1 =
\left(
\begin{array}{cc}
E & F \\
F & G
\end{array}
\right)\,, \quad 
\mathscr{F}_2 =
\left(
\begin{array}{cc}
L & M \\
M & N
\end{array}
\right) \,,
$$
where
\begin{align*}
E & = \sss_u \cdot \sss_u \,, & F & =  \sss_u \cdot \sss_v \, , & G & =  \sss_v \cdot \sss_v \,,  \\
L & = \sss_{uu} \cdot \NN \, ,  & M & =  \sss_{uv} \cdot \NN \,, & N & =  \sss_{vv} \cdot \NN \,, 
\end{align*}
and
$$
\NN = \frac{ \sss_u \times \sss_v }{ \norm{ \sss_u \times \sss_v } } \,.
$$
Let us prove this claim.


::: Theorem
### Matrix of Weingarten map  {#theorem-weingarten}

Let $\SSS$ be an orientable surface and $\WW_{\pp,\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS$ be 
its Weingarten map at $\pp$. Let $\sss$ be a regular chart at $\pp$, with $\sss(u_0,v_0) = \pp$. Then
$$
\WW_{\pp,\SSS} (\vv) = \mathscr{F}_1^{-1} \mathscr{F}_2   \left(
\begin{array}{c}
\lambda \\
\mu
\end{array}
\right)\,, \quad \forall \, v \in T_{\pp} \SSS \,,
$$
where 
$$
\vv = \lambda \sss_u + \mu \sss_v \,,
$$
with $\sss_u$ and $\sss_v$ evaluated at $(u_0,v_0)$.

:::

::: Proof

By Theorem \ref{theorem-tangent-plane} we know that $\{\sss_u,\sss_v\}$ is a basis of 
$T_{\pp} \SSS$. Since $\WW_{\pp,\SSS} \colon T_{\pp} \SSS \to T_{\pp} \SSS$ is linear, by standard linear algebra results there exist coefficients $a,b,c,d \in \R$ such that
$$
\WW_{\pp,\SSS} (\vv) = 
\left(
\begin{array}{cc} 
a & b \\
c & d
\end{array}
\right) 
\left(
\begin{array}{c}
\lambda \\
\mu
\end{array}
\right)\, \quad \forall \, \vv \in T_{\pp} \SSS \,,
$$
where
$$
\vv = \lambda \sss_u + \mu \sss_v \,.
$$
The coefficients $a,b,c,d \in \R$ can be compute by solving the linear system
\begin{align*}
\WW_{\pp,\SSS} (\sss_u) & = a \sss_u + b \sss_v \\
\WW_{\pp,\SSS} (\sss_v) & = c \sss_u + d \sss_v \,.
\end{align*}
By Lemma \ref{lemma-weingarten} we have
$$
\WW_{\pp,\SSS} (\sss_u) = - \NN_u \,, \quad 
\WW_{\pp,\SSS} (\sss_v) = - \NN_v \,,
$$
so that we obtain
\begin{align*}
- \NN_u & = a \sss_u + b \sss_v \\
- \NN_v & = c \sss_u + d \sss_v \,.
\end{align*}
Taking the scalar product of the above equations with $\sss_u$ and $\sss_v$ we get
\begin{align*}
- \NN_u \cdot \sss_u & = a (\sss_u \cdot \sss_u) + b (\sss_v \cdot \sss_u) \\
- \NN_u \cdot \sss_v & = a (\sss_u \cdot \sss_v) + b (\sss_v \cdot \sss_v) \\
- \NN_v \cdot \sss_u & = c (\sss_u \cdot \sss_u) + d (\sss_v \cdot \sss_u) \\
- \NN_v \cdot \sss_v & = c (\sss_u \cdot \sss_v) + d (\sss_v \cdot \sss_v) 
\end{align*}
By Lemma \ref{lemma-normal-derivatives} we have
\begin{align*}
\NN_u \cdot \sss_u & = - L \,,  & \NN_u \cdot \sss_v & = - M \,, \\
\NN_v \cdot \sss_u & = - M \,,  & \NN_v \cdot \sss_v & = - N \,. \\
\end{align*}
If in addition we recall the definition of $E,F,G$, we obtain
\begin{align*}
L & = a E + b F \\
M & = a F + b G \\
M & = c E + d F \\
N & = c F + d G 
\end{align*}
The above equations are equivalent to the matrix multiplication
$$
\left(
\begin{array}{cc} 
L & M \\
M & N
\end{array}
\right)
=
\left(
\begin{array}{cc} 
a & b \\
c & d
\end{array}
\right)
\left(
\begin{array}{cc} 
E & F \\
F & G
\end{array}
\right) \,,
$$
which reads
$$
\mathscr{F}_1 A = \mathscr{F}_2 \,.
$$
Now, notice that 
$$
\det \mathscr{F}_1 > 0 \,.
$$

> Indeed, recall Cauchy-Schwarz inequality:
$$
\vv \cdot \vv \leq \| \vv \| \| \ww \| \,, \quad \forall \, \vv , \ww \in 
\R^3 \,,
$$
where the inequality is strict if and only if $\vv$ and $\ww$ are linearly independent. Since $\SSS$ is regular, we have that 
$\sss_u$ and $\sss_v$ are linearly independent. Therefore by Cauchy-Schwarz 
we have 
$$
\sss_u \cdot \sss_v  < \norm{ \sss_u } \norm{\sss_v} \,,
$$
and so, squaring both sides,
$$
\left( \sss_u \cdot \sss_v \right)^2 < \norm{ \sss_u }^2 \norm{\sss_v}^2 \,.
$$
Hence
\begin{align*}
\det (\mathscr{F}_1) & = EG-F^2 \\
                     & =  \left(\sss_u \cdot \sss_u  \right) \left(\sss_v \cdot \sss_v  \right)  -  \left(\sss_u \cdot \sss_v \right)^2  \\
                     & = \norm{ \sss_u }^2 \norm{\sss_v}^2 - \left(\sss_u \cdot \sss_v \right)^2 > 0 \,.
\end{align*}


In particular the matrix $\mathscr{F}_1$ is invertible and thus
$$
A = \mathscr{F}_1^{-1} \mathscr{F}_2 \,,
$$
concluding the proof.

:::


::: Important

A matrix $A \in \R^{n \times n}$ is invertible if and only if $\det (A) \neq 0$. In such case
the inverse $A^{-1}$ is computed via the formula
$$
A^{-1} = \frac{1}{\det (A)} \, \operatorname{cof}(A)^T \,,
$$
where $\operatorname{cof}(A)$ is the cofactor matrix of $A$. For $n=2$ the above formula
reads:
$$
\left(
\begin{array}{cc}
a & b \\
c & d 
\end{array}
\right)^{-1}
=
\frac{1}{ad - bc}  \,
\left(
\begin{array}{cc}
d & -b \\
-c & a 
\end{array}
\right) \,.
$$
If the matrix is diagonal, then 
$$
\left(
\begin{array}{cc}
\lambda & 0 \\
0 & \mu 
\end{array}
\right) 
=
\left(
\begin{array}{cc}
1/\lambda & 0 \\
0 & 1/\mu 
\end{array}
\right) \,.
$$


:::



::: Notation

In the following we denote the matrix of $\WW_{\pp,\SSS}$ by the symbol $\WW$.

:::



::: Example
### Helicoid

The Helicoid is charted by
$$
\sss (u,v) = (u \cos (v), u \sin(v) , \lambda v) \,, \quad u \in [0,1] \,, \, v \in [0,4\pi) \,,
$$
where $\lambda>0$ is a constant, see @fig-helicoid. Prove that the matrix of the Weingarten map is
$$
\WW = 
\left(
\begin{array}{cc}
0 & - \dfrac{\lambda}{(u^2 + \lambda^2)^{1/2}} \\
\dfrac{\lambda}{(u^2 + \lambda^2)^{3/2}} & 0 
\end{array}
\right) \,.
$$


*Solution.* We compute
\begin{align*}
\sss_u & = ( \cos(v), \sin(v), 0  )  \\
\sss_v & = ( - u \sin(v), u \cos(v), \lambda  )  \\
\sss_{uu} & = ( 0, 0, 0  )  \\
\sss_{uv} & = (- \sin(v), \cos(v), 0 ) \\
\sss_{vv} & = ( - u \cos(v), - u \sin(v), 0 ) \\
\end{align*}
from which
\begin{align*}
E & = \sss_u \cdot \sss_u = 1 \\
F & = \sss_u \cdot \sss_v = 0 \\
G & = \sss_v \cdot \sss_v = u^2 + \lambda^2 \,, 
\end{align*}
so that the first fundamental form is
$$
\mathscr{F}_1 = 
\left(
\begin{array}{cc}
E & F \\
F & G 
\end{array}
\right)
=
\left(
\begin{array}{cc}
1 & 0 \\
0 & u^2 + \lambda^2 
\end{array}
\right) \,.
$$
Since $\mathscr{F}_1$ is diagonal, the inverse is immediately computed
$$
\mathscr{F}_1^{-1}
=
\left(
\begin{array}{cc}
1 & 0 \\
0 & \dfrac{1}{u^2 + \lambda^2}
\end{array}
\right) \,.
$$
Moreover
\begin{align*}
\sss_u \times \sss_v & = 
\left|
\begin{array}{ccc}
\ii & \jj & \kk \\
\cos(v)  &  \sin(v)  &  0 \\
-u \sin(v) & u \cos(v) & \lambda 
\end{array}
\right| \\
& =
(\lambda \sin (v), - \lambda \cos(v), u)
\end{align*}
and so
$$
\norm{\sss_u \times \sss_v} = \sqrt{u^2 + \lambda^2} \,.
$$
The standard unit normal to $\sss$ is 
$$
\NN  = \frac{ \sss_u \times \sss_v }{ \norm{\sss_u \times \sss_v} } = 
\frac{1}{\sqrt{u^2 + \lambda^2}} \, (\lambda \sin(v), -\lambda \cos(v), u) \,.
$$
Hence
\begin{align*}
L & = \sss_{uu} \cdot \NN = 0 \\
M & = \sss_{uv} \cdot \NN = - \frac{\lambda}{\sqrt{u^2 + \lambda^2}} \\
N & = \sss_{vv} \cdot \NN = 0 \\
\end{align*}
and the second funamental form $\mathscr{F}_2$ is
$$
\mathscr{F}_2 = 
\left(
\begin{array}{cc}
L & M \\
M & N 
\end{array}
\right)
=
\left(
\begin{array}{cc}
0 & - \dfrac{\lambda}{\sqrt{u^2 + \lambda^2}} \\
- \dfrac{\lambda}{\sqrt{u^2 + \lambda^2}} & 0
\end{array}
\right) \,.
$$
Finally
\begin{align*}
\WW & = \mathscr{F}_1^{-1} \mathscr{F}_2 \\
    & =
\left( 
\begin{array}{cc}
1 & 0 \\
0 & \dfrac{1}{u^2 + \lambda^2}
\end{array}
\right)    
\left(
\begin{array}{cc}
0 & - \dfrac{\lambda}{\sqrt{u^2 + \lambda^2}} \\
- \dfrac{\lambda}{\sqrt{u^2 + \lambda^2}} & 0
\end{array}
\right) \\
& = 
\left(
\begin{array}{cc}
0 & - \dfrac{\lambda}{(u^2 + \lambda^2)^{1/2}} \\
\dfrac{\lambda}{(u^2 + \lambda^2)^{3/2}} & 0 
\end{array}
\right) \,.
\end{align*}

:::



```{python}
#| echo: false
#| fig-cap: "Plot of Helicoid."
#| label: fig-helicoid

# Importing numpy, matplotlib and mplot3d
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d

# Generates figure object of size 4 x 4
fig = plt.figure(figsize = (4,4))

# Generates 3D axes
ax = plt.axes(projection = '3d')

# Shows axes grid
ax.grid(True)

# Generates coordinates u and v by dividing
# the intervals (0,1) and (0,2pi) in 100 parts
u = np.linspace(0, 1, 100)
v = np.linspace(0, 4*np.pi, 100)

# Generates grid [U,V] from the coordinates u, v
U, V = np.meshgrid(u, v)

# Computes the surface on grid [U,V]
x = U * np.cos(V) 
y = U * np.sin(V)
z = V

# Plots the cone
ax.plot_surface(x, y, z, rstride = 5, cstride = 5, color = 'dimgray', edgecolors = 'snow')




# Setting axes labels
ax.set_xlabel('x', labelpad=10)
ax.set_ylabel('y', labelpad=10)
ax.set_zlabel('z', labelpad=10)

# Setting viewing angle
ax.view_init(elev = 26, azim = 35)

# Showing the plot
plt.show()
```







::: {.Example #example-weingarten-2}

Find the Weingarten matrix of the following surface chart
$$
\sss (u, v) = \left(u-v, u+v, u^{2}+v^{2}\right) \,.
$$

*Solution*. Start by computing the first fundamental form:
\begin{align*}
\sss_{u} & =(1,1,2u) \\
\sss_{v} & =(-1,1,2v) \\  
E & = \sss_{u} \cdot \sss_u  = 2 (1+2u^2) \\
F & = \sss_{u} \cdot \sss_v  = 4uv \\
G & = \sss_{v} \cdot \sss_v  = 2 (1+2v^2) 
\end{align*}
so that
$$
\mathscr{F}_{1}=
\left(
  \begin{array}{ll}
E & F \\
F & G
\end{array}
\right)
=
\left(\begin{array}{ll}
2(1 + 2u^2) & 4uv \\
4uv & 2(1 + 2v^2)
\end{array}\right)
$$
The determinant of $\mathscr{F}_1$ is
$$
\det (\mathscr{F}_1) = 4 (1+2u^2 + 2v^2)
$$
and therefore
\begin{align*}
\mathscr{F}_{1}^{-1} & = \frac{1}{\det (\mathscr{F}_1)} 
\left(
  \begin{array}{ll}
G & -F \\
-F & E
\end{array}
\right) \\
& = \frac{1}{2(1 + 2u^2 + 2v^2)}
\,\left(\begin{array}{ll}
1 + 2v^2 & -2uv \\
- 2uv & 1 + 2u^2
\end{array}\right) \,.
\end{align*}
We now need to compute the second fundamental form
\begin{align*}
\sss_{u u} & =(0,0,2) \\
\sss_{u v} & =(0,0,0) \\
\sss_{v v} & =(0,0,2) \\
\sss_{u} \times \sss_{v} & =\left|\begin{array}{ccc}
\ii & \jj & \kk \\
1 & 1 & 2 u \\
-1 & 1 & 2 v
\end{array}\right| \\
& =2(v-u,-u-v, 1) \\
\left\|\sss_{u} \times \sss_{v}\right\| & =2\left( 1 + 2u^2 + 2v^2\right)^{\frac{1}{2}} \\
\NN & =\frac{(v-u,-u-v, 1)}{ \left( 1 + 2 u^2 + 2 v^2 \right)^{\frac{1}{2}}} \\
L & = \sss_{uu} \cdot \NN =\frac{2}{\left( 1 + 2u^{2}+ 2v^{2}\right)^{\frac{1}{2}}} \\
M & = \sss_{uv} \cdot \NN = 0 \\
N & = \sss_{vv} \cdot \NN = \frac{2}{\left(1 + 2u^{2}+ 2v^{2}\right)^{\frac{1}{2}}}
\end{align*}
so that
\begin{align*}
\mathscr{F}_{2} & =
\left(\begin{array}{ll}
L & M \\
M & N
\end{array}\right) \\
& =
\frac{2}{\left( 1 + 2u^{2}+ 2v^{2}\right)^{\frac{1}{2}}} \, \left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right) \,.
\end{align*}
The matrix of the Weingarten map is
\begin{align*}
\WW & = \mathscr{F}_1^{-1} \mathscr{F}_2 \\
& = 
\frac{1}{(1 + 2u^2 + 2v^2)^{\frac32}}
\,\left(\begin{array}{ll}
1 + 2v^2 & -2uv \\
- 2uv & 1 + 2u^2
\end{array}\right) \,.
\end{align*}

:::






## Curvatures


Curvatures of a surface $\SSS$ are scalars associated to the Weingarten 
map $\WW_{\pp,\SSS}$. We will define:

- Gaussian curvature
- Mean curvature
- Principal curvatures
- Normal curvature
- Geodesic curvature



### Gaussian and mean curvature


The Weingarten map of $\SSS$ encodes the rate of change of the standard unit normal
$\NN$. We use this map to produce scalar values, which we call **curvatures**. The
first two curvatures that we consider are called **Gaussian** and **mean** curvatures.



::: Definition
### Gaussian and mean curvature

Let $\SSS$ be an orientable surface and let $\WW$ denote the matrix of
the Weingarten map $\WW_{\pp,\SSS}$ of $\SSS$ at $\pp$. We define:

- The **Gaussian curvature** of $\SSS$ at $\pp$ as
$$
K := \det (\WW) \,,
$$

- The **mean curvature** of $\SSS$ at $\pp$ as
$$
H := \frac12 \, \operatorname{trace} (\WW) \,,
$$

:::


::: Notation
### Trace of a $2 \times 2$ matrix

We recall that the **trace** of a $2 \times 2$ matrix $A$ is defined as the sum of the diagonal
entries, that is,
$$
\operatorname{trace} A = a + d \,, \quad
A = 
\left(
\begin{array}{cc}
a & b \\
c & d
\end{array}
\right) \,.
$$

:::


::: Remark

The Gaussian curvature and mean curvature do not depend on the choice of basis of $T_{\pp} \SSS$. Indeed, if $\widetilde{\WW}$ is the 
matrix of the Weingarten map with respect to the basis $\{\widetilde{\sss}_u,\widetilde{\sss}_v\}$ of $T_{\pp} \SSS$, then 
$$
\det (\WW) = \det (\widetilde{\WW}) \,, \quad 
\operatorname{trace} (\WW) = \operatorname{trace} (\widetilde{\WW}) \,.
$$

> The above is true by a general linear algebra result: The determinant and trace of a matrix are invariant under change of basis.

:::


Since we have shown that the matrix of the Weingarten map is
$$
\WW = \mathscr{F}_1^{-1} \mathscr{F}_2 \,,
$$
we can express $K$ and $H$ in terms of the first and second fundamental forms.


::: Proposition

Let $\SSS$ be an orientable surface and $\sss$ a regular chart at $\pp$. Then
$$
K =
\frac{ LN-M^2 }{ EG - F^2 } \,, \quad 
H = 
\frac{LG - 2MF - NE}{2 (EG - F^2)} \,.
$$

:::


::: Proof

By Theorem \ref{theorem-weingarten} the matrix of the Weingarten map $\WW_{\pp,\SSS}$ of $\SSS$ at $\pp$ is given by
$$
\WW = \mathscr{F}_1^{-1} \mathscr{F}_2 \,.
$$
We have
\begin{align*}
\det (\mathscr{F}_1) & = 
 \left|
\begin{array}{cc}
E & F \\
F & G
\end{array}
\right| = EF - G^2 \,, \\
\det (\mathscr{F}_2) & = 
 \left|
\begin{array}{cc}
L & M \\
M & N
\end{array}
\right| = LN - M^2 \,.
\end{align*}
By the properties of determinant we get
$$
\det (\mathscr{F}_1^{-1}) = \frac{1}{\det (\mathscr{F}_1)} = \frac{1}{EF - G^2} \,,
$$
and therefore
\begin{align*}
K & = \det (\WW)  = \det \left( \mathscr{F}_1^{-1} \mathscr{F}_2 \right) \\
  & =  \det (\mathscr{F}_1^{-1})  \det (\mathscr{F}_2)
= \frac{ LN-M^2 }{ EG - F^2 } \, .
\end{align*}
To compute $H$ we need to find the diagonal entries of $\WW$. Since 
$$
\mathscr{F}_1^{-1} = 
\frac{1}{EG - F^2} 
\left(
\begin{array}{cc}
G & -F \\
-F & E
\end{array}
\right) 
$$
we have
$$
\WW = \frac{1}{EG - F^2} 
\left(
\begin{array}{cc}
G & -F \\
-F & E
\end{array}
\right) 
\left(
\begin{array}{cc}
L & M \\
M & N
\end{array}
\right) \,.
$$
From the above we compute
\begin{align*}
w_{11} & = \frac{1}{EG - F^2} \left( LG - MF  \right) \\
w_{22} & = \frac{1}{EG - F^2} \left( -MF + EN  \right) \\
\end{align*}
Therefore
\begin{align*}
H & = \frac12 \operatorname{trace} \WW \\
  & = \frac12 \left (w_{11} + w_{22} \right) \\
  & = \frac{LG - 2MF + EN}{2 (EG - F^2)}  \,.
\end{align*}

:::





::: Example
### Plane

Consider the plane charted by
$$
\sss (u,v) = \mathbf{a} + \pp u + \mathbf{q} v \,, \quad u \in (0,2\pi)\,, \, u, v \in \R \,.
$$
We have already computed in Example \ref{example-fff-plane} and Example \ref{example-sff-plane} that the first and second
fundamental forms of $\sss$ are
$$
\mathscr{F}_1 =
\left(
\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right) \,, \quad 
\mathscr{F}_2 =
\left(
\begin{array}{cc}
0 & 0 \\
0 & 0
\end{array}
\right) \,.
$$
Therefore the matrix of the Weingarten map is
$$
\WW  = \mathscr{F}_1^{-1} \mathscr{F}_2 
= 
\left(
\begin{array}{cc}
0 & 0 \\
0 & 0
\end{array}
\right)  \,.
$$
Hence the Gaussian curvature is
$$
K = \det (\WW) = 0 \,,
$$
while the mean curvature is
$$
H = \frac12 \, \operatorname{trace} \WW =  0 \,.
$$



:::



::: Example
### Unit cylinder  {#example-cylinder-curvatures}

Consider the unit cylinder charted by
$$
\sss (u,v) = (\cos(u), \sin(u), v) \,, \quad u \in (0,2\pi)\,, \, v \in \R \,.
$$
We have already computed in Example \ref{example-cylinder-fff} and Example \ref{example-cylinder-sff}  that the first and second
fundamental forms of $\sss$ are
$$
\mathscr{F}_1 =
\left(
\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right) \,, \quad 
\mathscr{F}_2 =
\left(
\begin{array}{cc}
-1 & 0 \\
0 & 0
\end{array}
\right) \,.
$$
Therefore the matrix of the Weingarten map is
\begin{align*}
\WW & = \mathscr{F}_1^{-1} \mathscr{F}_2 \\
& =
\left(
\begin{array}{cc}
1 & 0 \\
0 & 1
\end{array}
\right) 
\left(
\begin{array}{cc}
-1 & 0 \\
0 & 0
\end{array}
\right)  \\
& =
\left(
\begin{array}{cc}
-1 & 0 \\
0 & 0
\end{array}
\right)  \,.
\end{align*}
Therefore the Gaussian curvature is
$$
K = \det (\WW) = 0 \,,
$$
while the mean curvature is
$$
H = \frac12 \, \operatorname{trace} \WW =  - \frac12 \,.
$$



:::




### Principal curvatures

Let $V$ be a two-dimensional vector space.
For a linear map $L \colon V \to V$ we say that $\lambda \in \R$ is an **eigenvalue** of $L$ with **eigenvector** $\vv \in V$ if
$$
L(\vv)  = \lambda \vv \,, \quad \vv \neq 0 \,.
$$
Suppose $A \in \R^{2 \times 2}$ is the matrix of $L$ with respect to a basis $\{\vv_1,\vv_2\}$
of $V$. Denote by 
$$
\xx= (\lambda,\mu) \,, \quad 
\vv = \lambda \ww_1 + \mu \ww_2 \,.
$$ 
the vector of coordinates of $\vv$. Then
$$
A\vv = \lambda \vv \,,
$$
meaning that $\lambda$ is an eigenvalue of $A$ with eigenvector $\xx$.
The eigenvalues of $A$ can be computed by solving the **characteristic equation**
$$
P(\lambda) = 0 \,, \quad P(\lambda) := \det \left(  A - \lambda I  \right)  \,,
$$
where $P$ is the **characteristic polynomial** of $A$. Finally, we recall that $A \in \R^{2 \times 2}$ is **diagonalizable** if there exists a 
diagonal matrix $D$ and an invertible matrix $P$ such that
$$
A = P^{-1} D P \,.
$$



::: {.Theorem  #theorem-weingarten-diagonal}

Let $\SSS$ be an orientable surface and let $\WW_{\pp,\SSS}$ be the 
Weingarten map at $\pp$. There exist scalars $\kappa_1, \kappa_2 \in \R$ and an orthonormal basis 
$\{\mathbf{t}_1,\mathbf{t}_2\}$ of $T_{\pp} \SSS$ such that 
$$
\WW_{\pp,\SSS} (\mathbf{t}_1) = \kappa_1 \mathbf{t}_1 \,, 
\quad \WW_{\pp,\SSS} (\mathbf{t}_2) = \kappa_2 \mathbf{t}_2 \,.
$$


:::




::: Proof

Let $\sss$ be a chart for $\SSS$ at $\pp$. Then $\{\sss_u,\sss_v\}$ is a basis of $T_{\pp} \SSS$. Let $\WW$ be 
the matrix of $\WW_{\pp,\SSS}$ with respect to such basis.
By Theorem \ref{theorem-weingarten} we have
$$
\WW = \mathscr{F}_1^{-1} \mathscr{F}_2 \,. 
$$
Recall that
$$
\mathscr{F}_1^{-1} = \frac{1}{EG - F^2 }
\left( 
\begin{array}{cc}
G & - F\\
-F & E
\end{array}
\right)  \,.
$$
Thus $\mathcal{F}_1^{-1}$ is symmetric. Since $\mathcal{F}_2$ is symmetric, and the product
of symmetric matrices is symmetric, we conclude that $\WW$ is symmetric. 
Therefore $\WW_{\pp,\SSS}$ is self-adjoint, see Remark \ref{remark-self-adoint}. The thesis now follows from the Spectral Theorem, see Theorem \ref{theorem-spectral}.

:::


The matrix version of Theorem \ref{theorem-weingarten-diagonal} is given in the following Corollary.


::: {.Corollary #corollary-weingarten-diagonal}

Let $\SSS$ be orientable, and let $\WW$ the matrix of the Weingarten map $\WW_{\pp,\SSS}$
with respect to the basis $\{\sss_u,\sss_v\}$ of $T_{\pp}\SSS$, where $\sss$ is a regular chart at $\pp$. Let $\kappa_1,\kappa_2,\mathbf{t}_1,\mathbf{t}_2$ be as in Theorem \ref{theorem-weingarten-diagonal}.
Let $\lambda_1, \lambda_2, \mu_1, \mu_2 \in \R$ be such that
$$
\mathbf{t}_1 = \lambda_1 \sss_u + \mu_1 \sss_v \,, \quad 
\mathbf{t}_2 = \lambda_2 \sss_u + \mu_2 \sss_v \,.
$$
and denote 
$$
\xx_1 = (\lambda_1,\mu_1) \,, \quad 
\xx_2 = (\lambda_2,\mu_2) \,.
$$
They hold:

- The scalars $\kappa_1,\kappa_2$ are eingenvalues of $\WW$ of eigenvectors
$\xx_1$ and $\xx_2$, that is,
$$
\WW \xx_1 = \kappa_1 \xx_1 \,, \quad 
\WW \xx_2 = \kappa_2 \xx_2 \,.
$$

- The matrix $\WW$ is diagonalizable, with 
$$
\WW = P^{-1} D P \,, \quad 
D = 
\left(
\begin{array}{cc}
\kappa_1 & 0 \\
0   & \kappa_2
\end{array}
\right) \,, \quad 
P = 
\left(
\begin{array}{cc}
\lambda_1 & \lambda_2 \\
\mu_1 & \mu_2
\end{array}
\right) \,.
$$


:::


::: Proof

Recall that $\WW$ is the matrix of $\WW_{\pp,\SSS}$ with respect to the basis
$\{\sss_u,\sss_v\}$ of $T_{\pp} \SSS$. Therefore, by definition of $\xx_1$, $\xx_2$ we get
$$
\WW_{\pp,\SSS} (\mathbf{t}_1) = \WW \xx_1 \,, \quad
\WW_{\pp,\SSS} (\mathbf{t}_2) = \WW \xx_2 \,.
$$
The thesis follows by Theorem \ref{theorem-weingarten-diagonal} and the
Spectral Theorem for matrices, see Theorem \ref{theorem-spectral-matrix}.

:::



The eigenvalues and eigenvectors of the weingarten map have a name.


::: Definition
### Principal curvatures and vectors

Let $\SSS$ be an orientable surface and $\WW_{\pp,\SSS}$ be the Weingarten map of $\SSS$ at $\pp$. We define:

- The **principal curvatures** of $\SSS$ at $\pp$ are the eigenvalues $\kappa_1, \kappa_2$
of $\WW_{\pp,\SSS}$.

- The **principal vectors** corresponding to $\kappa_1$ and $\kappa_2$ are the eigenvectors $\mathbf{t_1}, \mathbf{t}_2$.

:::


::: Remark
### Computing principal curvatures and vectors

Corollary \ref{corollary-weingarten-diagonal} gives an explicit way
to compute the principal curvatures and vectors:

1. Compute the eigenvalues of $\WW$. This is done by solving for $\kappa$ the equation
$$
\det(\WW - \kappa I) = 0 \,.
$$
This gives one of the principal curvatures 
$$
\kappa_i = \kappa
$$

2. Compute the eigenvector(s) related to the eigenvalue $\kappa$. This is 
done by finding scalars $\lambda$, $\mu$ which solve the linear system
$$
(\WW - \kappa_i I) 
\left( 
\begin{array}{c}
\lambda \\
\mu
\end{array}
\right) = 0 
$$
This gives the eigenvector of $\WW$
$$
\xx_i = (\lambda,\mu)
$$

3. The principal vector associated to $\kappa_i$ is  
$$
\mathbf{t}_i = \lambda \sss_u + \mu \sss_v 
$$


:::


::: Remark
### Computing principal curvatures and vectors

If the matrix of the Weingarten map has the form
$$
\WW = 
\left(
\begin{array}{cc}
\kappa_1 & 0 \\
0        & \kappa_2
\end{array}
\right)
$$
then $\WW$ is already diagonal. The eigenvalues of $\WW$ are $\kappa_1$ and $\kappa_2$, with eigenvectors
$$
\xx_1 = (1,0) \,, \quad 
\xx_2 = (0,1) \,. 
$$
Therefore $\kappa_1,\kappa_2$ are the principal curvatures, with 
principal vectors given by
$$
\mathbf{t}_1 = \sss_u \,, \quad \mathbf{t}_2 = \sss_v \,.
$$

:::




The principal curvatures are related to the Gaussian and mean curvatures.


::: Proposition

Let $\SSS$ be an orientable surface. Then
$$
K = \kappa_1 \kappa_2 \,, \quad H = \frac{\kappa_1 + \kappa_2}{2} \,.
$$

:::


::: Proof

By Corollary \ref{corollary-weingarten-diagonal} we have
$$
\WW = P^{-1} D P \,, \quad 
D = 
\left( 
\begin{array}{cc}
\kappa_1 & 0 \\
0        & \kappa_2
\end{array}
\right) \,.
$$
By the properties of determinant
$$
\det \left(  A B \right) = \det (A) \det (B) \,, \quad \forall \, A,B \in \R^{2 \times 2} \,.
$$
By definition of Gaussian curvature and the above formula we infer
\begin{align*}
K & = \det ( \WW ) \\
  & = \det \left( P^{-1} D P  \right) \\
  & = \det (P^{-1}) \det (D) \det (P) \\
  & = \det (D) \\
  & = \kappa_1 \kappa_2 \,,
\end{align*}
where we also used that 
$$
\det(P^{-1}) = \frac{1}{\det(P)}  \,.
$$
The trace satisfies
$$
\operatorname{trace} \left(  A B \right) = \operatorname{trace} \left( BA \right) \,, \quad \forall \, A,B \in \R^{2 \times 2} \,.
$$
By definition of mean curvature and the above formula we get
\begin{align*}
H & = \frac12 \operatorname{trace} (\WW ) \\
  & = \frac12 \operatorname{trace} \left( P^{-1} D P  \right) \\
  & = \frac12 \operatorname{trace} \left( P P^{-1} D  \right) \\
  & = \frac12 \operatorname{trace} \left( D  \right) \\
  & = \frac{1}{2} \left( \kappa_1  + \kappa_2 \right) \,,
\end{align*}
concluding the proof.

:::


::: Important

In general $\kappa_1$ and $\kappa_2$ are hard to compute, as they require solving a second order
equation. Instead $K$ and $H$ are easier to compute, as they are directly expressed in terms of
the first and second fundamental form coefficients.

:::



::: Example
### Unit Cylinder


Consider the unit cylinder charted by
$$
\sss (u,v) = (\cos(u), \sin(u), v) \,, \quad u \in (0,2\pi)\,, \, v \in \R \,.
$$
We have already computed in Example \ref{example-cylinder-curvatures} that the matrix of the Weingarten map is
$$
\WW =
\left(
\begin{array}{cc}
-1 & 0 \\
0 & 0
\end{array}
\right)  \,.
$$
Since $\WW$ is diagonal, the eigenvalues are the diagonal entries of $\WW$ and
eigenvectors are 
$$
\xx_1 = (1,0), \quad \xx_2 = (0,1) \,.
$$
Therefore the principal curvatures are 
$$
\kappa_1 = - 1 \,, \quad \kappa_2 = 0
$$
and the principal vectors are
\begin{align*}
\mathbf{t}_1 & = \sss_u = (-\sin(u),\cos(v),0) \,,\\
\mathbf{t}_2 & = \sss_v = (0,0,1)\,,
\end{align*}
as shown in @fig-cylinder-principal.

:::



![Principal vectors of the unit cylinder.](/images/sff_principal_cylinder.png){#fig-cylinder-principal width=70%}




::: Example
### Sphere  {#example-sphere-principal}

Consider the chart for the sphere
$$
\sss(u, v)=(\cos (u) \sin (v), \sin (u) \sin (v), \cos (v))
$$
Prove that 
$$
\mathcal{F}_1 =
\mathcal{F}_2 = 
\left( 
\begin{array}{cc}
\sin^2(v) & 0 \\
0         & 1 
\end{array}
\right) \,, \quad 
\WW = 
\left( 
\begin{array}{cc}
1 & 0 \\
0 & 1 
\end{array}
\right) \,,
$$
and
$$
K = H = \kappa_1 = \kappa_2 =1 \,, \quad \mathbf{t}_1 = \sss_u \,, \quad
\mathbf{t}_2 = \sss_v \,.
$$ 


*Solution.* We compute
\begin{align*}
\sss_u & = (-\sin(u)\sin(v), \cos(u)\sin(v),0) \\
\sss_v & = (\cos(u)\cos(v), \sin(u)\cos(v), - \sin(v)) \\
E & = \sss_u \cdot \sss_u = \sin^2(v) \\
F & = \sss_u \cdot \sss_v = 0\\
G & = \sss_v \cdot \sss_v = 1
\end{align*}
and therefore the first fundamental form is
$$
\mathcal{F}_1 = 
\left( 
\begin{array}{cc}
\sin^2(v) & 0 \\
0         & 1 
\end{array}
\right) \,.
$$
Moreover 
\begin{align*}
\sss_u \times \sss_v & = 
\left| 
\begin{array}{ccc}
\ii & \jj & \kk \\
-\sin(u)\sin(v)  & \cos(u)\sin(v) & 0 \\
\cos(u)\cos(v) & \sin(u)\cos(v) & - \sin(v)
\end{array}
\right| \\
& = (-\cos(u)\sin^2(v), 
-\sin(u) \sin^2(v),
- \cos(v)\sin(v)) \\
\| \sss_u \times \sss_v \| & = |\sin(v)| \\
\NN & = (- \cos(u) \sin(v), -\sin(u)\sin(v), -\cos(v) ) \\
\sss_{uu} & = (-\cos(u)\sin(v), -\sin(u)\sin(v), 0 ) \\ 
\sss_{uv} & = (-\sin(u)\cos(v), \cos(u)\cos(v), 0 ) \\
\sss_{vv} & = (-\cos(u)\sin(v), -\sin(u)\sin(v), -\cos(v) ) \\ 
L & = \sss_{uu} \cdot \NN = \sin^{2}(v) \\
M & =\sss_{uv} \cdot \NN  = 0 \\
N & = \sss_{vv} \cdot \NN  = 1 
\end{align*}
so that the second fundamental form is 
$$
\mathcal{F}_2 = 
\left( 
\begin{array}{cc}
\sin^2(v) & 0 \\
0         & 1 
\end{array}
\right) \,.
$$
In particular the matrix of the Weingarten map is
$$
\WW = \mathcal{F}_1^{-1}\mathcal{F}_2 = \left( 
\begin{array}{cc}
1 & 0 \\
0 & 1 
\end{array}
\right)
$$
Since $\WW$ is diagonal, the principal curvatures are
$$
\kappa_1 = \kappa_2 = 1
$$
and the principal vectors
$$
\mathbf{t}_1 = \sss_u \,, \quad 
\mathbf{t}_2 = \sss_v \,.
$$
Finally, we have that
$$
H = \frac{\kappa_1 + \kappa_2}{2} = 1 \,, \quad
K= \kappa_1 \kappa_2 = 1 \,.
$$


:::



::: Example
### Torus

Consider a circle $\mathcal{C}$ contained in the $xz$-plane, with center 
at distance $b>0$ from the $z$-axis and radius $a$, with $0<a<b$. 
The torus is obtained by rotating $\mathcal{C}$ around the $z$-axis. 
This surface is charted by 
$$
\sss (\theta,\f) = \left( \left(a+b \cos(\theta) \right) \cos(\f), \left(a+b \cos(\theta) \right) \sin(\f), b\sin(\theta) \right) \,,
$$
where $\theta \in (-\pi/2,\pi/2)$ and $\f \in (0,2\pi)$.
One can compute that the first and second fundamental forms are
\begin{align*}
\mathscr{F}_1 & =
\left(   
\begin{array}{cc}
b^2  &    0   \\
0   & \left(a+b \cos(\theta) \right)^2 
\end{array}
\right)  \\
\mathscr{F}_2 & =
\left(   
\begin{array}{cc}
b  &    0   \\
0   & \left(a+b \cos(\theta) \right) \cos(\theta)
\end{array}
\right) \,.
\end{align*}
Therefore the matrix of the Weingarten map is
$$
\WW = \mathscr{F}_1^{-1} \mathscr{F}_2 =
\left(   
\begin{array}{cc}
\dfrac{1}{b}  &    0   \\
0   & \dfrac{\cos(\theta)}{ a + b \cos(\theta)}
\end{array}
\right) \,.
$$
Since $\WW$ is diagonal, the principal curvatures are
$$
\kappa_1 = \frac{1}{b} \,, \quad 
\kappa_2 = \dfrac{\cos(\theta)}{ a + b \cos(\theta)} \,,
$$
and the principal vectors
$$
\mathbf{t}_1 = \sss_u \,, \quad 
\mathbf{t}_2 = \sss_v \,.
$$
The Gaussian and mean curvature are
\begin{align*}
K & = \kappa_1 \kappa_2 = \dfrac{\cos(\theta)}{ b  \left(a + b \cos(\theta)\right)}  \\
H & = \frac{\kappa_1 + \kappa_2}{2} =
\dfrac{a + 2b \cos(\theta)}{2 b \left(a + b \cos(\theta)\right)}  
\end{align*}

:::





### Normal and geodesic curvatures


Let $\SSS$ be a regular surface and consider all the curves $\g$ on $\SSS$ 
passing through the point $\pp \in \SSS$. 

::: Question

Which curves through $\pp$ have greatest or lowest curvature?

:::

We start our analysis with the following proposition.


::: {.Proposition #proposition-surface-frame}

Let $\SSS$ be a regular surface and $\g \colon (a,b) \to \SSS$ be a unit speed curve. Then 
$$
\{ \dg , \NN , \NN \times \dg  \}
$$
is an orthornormal basis of $\R^3$ for all $t \in (a,b)$, where $\NN$ is the standard unit normal to $\SSS$ evaluated at $\pp = \g(t)$.

:::

::: Proof

By definition 
$$
\dg(t) \in T_{\pp} \SSS \,, \quad \pp := \g(t) \,,
$$
for all $t \in (a,b)$. This means $\dg$ is tangent to $\SSS$. Thus
$$
\dg \cdot \NN = 0 \,.
$$
We have $\norm{\dg} = 1$ since $\g$ is unit speed. 
Moreover $\norm{\NN}=1$ by definition. 
Since $\dg$ and $\NN$ are orthogonal, we also obtain
$$
\norm{\NN \times \dg} = \norm{\NN} \norm{\dg} = 1 \,,
$$ 
by the properties of vector product. Finally 
$$
 (\NN \times \dg ) \cdot \NN  = 0 \,, \quad 
 (\NN \times \dg ) \cdot \dg  = 0 \,, \quad 
$$
by the properties of vector product.

:::



::: Important

Notice that the basis
$$
\{ \dg , \NN , \NN \times \dg  \}
$$
does not coincide with the Frenet frame of $\g$ in general.

:::



::: Proposition

Let $\SSS$ be a regular surface and $\g \colon (a,b) \to \SSS$ be a 
unit speed curve. Then
$$
\ddg = \kappa_n \NN + \kappa_g \, \left( \NN \times \dg \right) \,,
$${#eq-surface-curve-curvature}
where $\NN$ is evaluated at $\pp:=\g(t)$ and $\kappa_n,\kappa_g$ are
scalars depedent on $\pp$. Moreover
$$
\kappa_n = \ddg \cdot \NN \,, \quad \kappa_g = \ddg \cdot \left( \NN \times \dg \right)  \,,
$${#eq-surface-curve-curvature-1}
$$
\kappa^2 = \kappa_n^2 + \kappa_g^2 \,,
$${#eq-surface-curve-curvature-2}
$$
\kappa_n = \kappa \cos (\phi) \,, \quad  \kappa_g = \pm \kappa \sin(\phi) \,,
$${#eq-surface-curve-curvature-3}
where $\kappa$ is the curvature of $\g$ and $\phi$ is the angle between 
$\NN$ and $\nn$, the principal unit normal of $\g$.

:::


::: Proof


*Part 1.* By Proposition \ref{proposition-surface-frame} we know that
$$
\{ \dg , \NN , \NN \times \dg  \}
$$
is an orthornormal basis of $\R^3$. Hence 
$$
\ddg = a \dg + b \NN + c \left( \NN \times \dg \right) \,,
$$
for some coefficients $a,b,c \in \R$. Since $\g$ is unit speed, 
we have that
$$
\dg \cdot \ddg = 0 \,.
$$
On the other hand, 
$$
\dg \cdot \ddg = a  (\dg \cdot \dg ) + b ( \dg \cdot \NN ) + 
c \dg \cdot \left( \NN \times \dg \right) = a \,,
$$
since $\dg$ is orthogonal to $\NN$ and $\NN \times \dg$, and 
$$
\dg \cdot \dg  = \norm{\dg}^2 = 1 \,.
$$
Therefore $a = 0$ and 
$$
\ddg = b \NN + c \left( \NN \times \dg \right) \,.
$$
Setting $\kappa_n := b$ and $\kappa_g := c$ we conclude (@eq-surface-curve-curvature).

*Part 2.* Taking the scalar product of (@eq-surface-curve-curvature) with $\NN$ yields
$$
\ddg \cdot \NN = \kappa_n \norm{\NN}^2 + \kappa_g \left( \NN \times \dg  \right) \cdot \NN = \kappa_n \,,
$$
where we used that $\NN$ and $\NN \times \dg$ are orthonormal vectors. 
Similarly, taking the scalar product of (@eq-surface-curve-curvature) with $\NN \times \dg$ yields the second equation in (@eq-surface-curve-curvature-1).

*Part 3.* By (@eq-surface-curve-curvature) we infer
\begin{align*}
\norm{\ddg}^2 & = \kappa_n^2 \norm{\NN}^2 + 2 \kappa_n \kappa_g \NN \cdot 
\left(\NN \times \dg \right) + \kappa_g^2  \norm{\NN \times \dg}^2 \\
              & = \kappa_n^2 + \kappa_g^2 \,,
\end{align*}
where we used that $\NN$ and $\NN \times \dg$ are orthonormal. Since 
$\kappa(t) = \norm{\ddg(t)}$, we get (@eq-surface-curve-curvature-2).

*Part 4.* Recalling that 
$$
\ddg = \kappa \nn \,,
$$
from the first equation in (@eq-surface-curve-curvature-1) we obtain
\begin{align*}
\kappa_n & = \ddg \cdot \NN \\
         & = \kappa \nn \cdot \NN \\
         & = \kappa \| \nn \|^2 \| \NN \|^2 \cos(\phi) \\
         & = \kappa \cos(\phi) \,,
\end{align*}
where we used that $\nn$ and $\NN$ have unit norm. Hence the first 
equation in (@eq-surface-curve-curvature-3) is established. By 
(@eq-surface-curve-curvature-2) we get
\begin{align*}
\kappa_g^2 & = \kappa^2 - \kappa_n^2 \\
           & = \kappa^2 \cos^2(\phi) -  \kappa_n^2 \\
           & = \kappa^2 (\cos^2(\phi) - 1 ) \\
           & = \kappa^2 \sin^2(\phi) \,,
\end{align*}
from which we obtain the second equation in (@eq-surface-curve-curvature-3).

:::


The quantities $\kappa_n$ and $\kappa_g$ are the normal and geodesic 
curvatures of $\g$.


::: Definition 
### Normal and geodesic curvature

Let $\SSS$ be regular and $\g \colon (a,b) \to \SSS$ a unit speed curve. By (@eq-surface-curve-curvature) we have
$$
\ddg = \kappa_{n} \NN + \kappa_{g} (\NN \times \dg )
$$
for $\NN$ the standard unit normal to $\SSS$ and scalars 
$\kappa_n , \kappa_g \in \R$. We call

- $\kappa_{n}$ the **normal curvature** of $\g$,
- $\kappa_{g}$ the **geodesic curvature** of $\g$.

:::



The normal curvature $\kappa_n$ can be computed via the second 
fundamental form, as shown in the theorem below.


::: {.Theorem #theorem-normal-curvature}

Let $\SSS$ be a regular surface and $\g \colon (a,b) \to \SSS$ a 
unit speed curve. Denote $\pp := \g(t)$. We have:

1. The normal curvature $\kappa_n$ satisfies
$$
\kappa_n = {II}_{\pp} (\dg, \dg) \,.
$$

2. Let $\sss$ be a chart for $\SSS$ at $\pp$. Then 
$$
\g(t)=\sss(u(t), v(t))
$$ 
for some smooth functions $u,v \colon (a,b) \to \R$, and 
$$
\kappa_{n}=L \dot{u}^{2}+2 M \dot{u} \dot{v}+N \dot{v}^{2} \,.
$$

:::


::: Proof

*Part 1.* By definition we have
$$
\dg (t) \in T_{\pp} \SSS 
$$
when $\pp = \g(t)$. Set
$$
\tg(t) := \NN( \g(t)) \,.
$${#eq-theorem-normal-curvature-1}
By definition of differential we have 
$$
d_{\pp} \NN (\dg(t)) = \dtg(t)  \,.
$${#eq-theorem-normal-curvature-2}
Note that
$$
\tg(t) \cdot \dg(t) = 0 \,,
$$
since $\NN$ is normal to $\SSS$ at $\pp$ and $\dg(t) \in T_{\pp}(\SSS)$.
Differentiating the above expression we get
\begin{align*}
0 & = \frac{d}{dt} \left( \tg(t) \cdot \dg(t) \right) \\
  & = \tg(t) \cdot \ddg(t)  + \dtg(t) \cdot \dg(t)   \\
  & = \NN (\g(t)) \cdot \ddg(t)  + d_{\pp} \NN (\dg(t)) \cdot \dg(t)  
\end{align*}
where in the last equation we used (@eq-theorem-normal-curvature-1) and
(@eq-theorem-normal-curvature-2). Hence
$$
- d_{\pp} \NN (\dg(t)) \cdot \dg(t)  = 
\NN (\g(t))  \cdot  \ddg(t)   \,.
$${#eq-theorem-normal-curvature-3}
By definition of Weingarten and Gauss map we get
$$
\WW_{\pp,\SSS} (\dg(t)) = - d_{\pp} \mathcal{G} (\dg(t)) =  
- d_{\pp} \NN (\dg(t)) \,.
$${#eq-theorem-normal-curvature-4}
Therefore, using (@eq-theorem-normal-curvature-3) and (@eq-theorem-normal-curvature-4), we infer
\begin{align*}
II_{\pp} (\dg(t) , \dg(t) ) & = \WW_{\pp,\SSS} (\dg(t)) \cdot \dg(t) \\
                            & = - d_{\pp} \NN (\dg(t)) \cdot \dg(t) \\
                            & = \NN (\g(t))  \cdot  \ddg(t) \\
                            & = \kappa_n \,,
\end{align*}
where in the last equality we used (@eq-surface-curve-curvature-1).


*Part 2.* Let $\sss$ be a chart at $\pp$ and 
$$
\g(t) = \sss(u(t),v(t)) \,.
$$
Differentiating the above expression we get
$$
\dg(t) = \dot{u} \sss_u + \dot{v} \sss_v \,.
$$
By definition of $du$ and $dv$, see Definition \ref{definition-coordinate-functions}, we have
$$
du(\dg(t)) = \dot{u}(t) \,, \quad 
dv(\dg(t)) = \dot{v}(t) \,.
$$
Therefore, using Part 1 and Theorem \ref{theorem-sff-chart}, we obtain
\begin{align*}
\kappa_n & = II_{\pp} (\dg(t) , \dg(t) ) \\
         & = L du(\dg(t))^2 + 2M du(\dg(t)) dv(\dg(t)) + N dv(\dg(t))^2 \\ 
         & = L \dot{u}^{2}+2 M \dot{u} \dot{v}+N \dot{v}^{2} \,.
\end{align*}

:::


::: Example
### Curves on the sphere  {#example-curves-on-sphere}

Consider the chart for the sphere
$$
\sss(u, v)=(\cos (u) \sin (v), \sin (u) \sin (v), \cos (v))
$$
Show that 
$$
\kappa_{n}(t)=1
$$ 
for all unit speed curves on the sphere.

*Solution.* 
We have computed in Example \ref{example-sphere-principal} that the 
second fundamental form of $\sss$ is
$$
\mathcal{F}_2 = \sin^{2}(v) du^2 + dv^2 
$$
Let $\g$ be a unit speed curve on the sphere, that is,
$$
\g(t)=\sigma(u(t), v(t)) \,.
$${#eq-sphere-normal-curvature} 
By Theorem \ref{theorem-normal-curvature} the normal
curvature of $\g$ is
$$
\kappa_{n}=\sin^{2}(v) \dot{u}^{2}+\dot{v}^{2} \,.
$$
Differentiating (@eq-sphere-normal-curvature) we get
\begin{align*}
\dg(t) & = \frac{d}{dt} ( \cos(u(t)) \sin(v(t)), \sin(u(t)) \sin(v(t)), \cos(v(t)) ) \\
       & = (-\dot{u} \sin (u) \sin (v)+\dot{v} \cos (u) \cos (v), \dot{u} \cos (u) \sin (v)+ \\
  & \qquad \dot{v} \sin (u) \cos (v),-\dot{v} \sin (v))
\end{align*}
so that 
$$
\| \dg(t) \|^2 =  \sin^{2}(v) \dot{u}^{2}+\dot{v}^{2} \,.
$$
Since $\g$ is unit speed, we also get
$$ 
\|\dg\|^{2} = 1 \,,
$$ 
showing that 
$$
\kappa_{n}=\sin^{2}(v) \dot{u}^{2}+\dot{v}^{2} = 1 \,,
$$
as required.


:::



The normal curvature $\kappa_n$ is related to the principal 
curvatures $\kappa_1$ and $\kappa_2$.



::: Theorem
### Euler's Theorem {#theorem-euler-thm}

Let $\SSS$ be a regular surface and denote by $\kappa_1, \kappa_2$ the
principal curvatures with principal vectors $\mathbf{t}_1,\mathbf{t}_2$.
Let $\g$ be a unit speed curve on $\SSS$. The normal curvature of $\g$ is given by
$$
\kappa_n = \kappa_1 \cos^2(\theta) + \kappa_2 \sin^2(\theta) \,,
$$
where $\theta$ is the angle between $\dg$ and $\mathbf{t}_1$.

:::


::: Proof

Let $\g$ be a unit speed curve on $\SSS$ and set
$$
\pp := \g(t) \,.
$$
By Theorem \ref{theorem-weingarten-diagonal} the principal vectors 
$\{ \mathbf{t}_1, \mathbf{t}_2 \}$ form an orthonormal basis of 
$T_{\pp} \SSS$. Since by definition
$$ 
\dg(t) \in T_{\pp} \SSS \,,
$$
there exist scalars $\lambda,\mu \in \R$ such that
$$
\dg(t) = \lambda \mathbf{t}_1 + \mu \mathbf{t}_2 \,.
$$
As $\g$ is unit speed and $\mathbf{t}_1, \mathbf{t}_2$ orthonormal, we infer
$$
1 = \norm{\dg(t)}^2 = \dg \cdot \dg = \lambda^2 + \mu^2 \,.
$$
Therefore there exists $\theta \in [0,2\pi]$ such that 
$$
\lambda = \cos(\theta), \quad 
\mu = \sin(\theta) \,.
$$
Hence 
$$
\dg(t) = \cos(\theta) \mathbf{t}_1 + \sin(\theta) \mathbf{t}_2 \,.
$${#eq-euler-thm-proof}
In particular, we can take the scalar product of (@eq-euler-thm-proof) with
$\mathbf{t}_1$ to get
$$
\cos(\theta) = \lambda = \dg(t) \cdot \mathbf{t}_1 \,.
$$
Since $\dg$ and $\mathbf{t}_1$ are unit vectors, from the above equation we conclude that 
$\theta$ is the angle between $\dg$ and $\mathbf{t}_1$. In addition, recall
that
$$
\WW_{\pp,\SSS} (\mathbf{t}_1) = \kappa_1 \mathbf{t}_1 \,, \quad 
\WW_{\pp,\SSS} (\mathbf{t}_2) = \kappa_2 \mathbf{t}_2 \,, 
$$
and $\mathbf{t}_1$, $\mathbf{t}_2$ are orthonormal. Thus
\begin{align*}
II_{\pp}(\mathbf{t}_1 , \mathbf{t}_1) & = \WW_{\pp,\SSS} (\mathbf{t}_1) \cdot \mathbf{t}_1 = \kappa_1 \norm{\mathbf{t}_1}^2 = \kappa_1 \\
II_{\pp}(\mathbf{t}_1 , \mathbf{t}_2) & = \WW_{\pp,\SSS} (\mathbf{t}_1) \cdot \mathbf{t}_2 = \kappa_1  \mathbf{t}_1 \cdot \mathbf{t}_2 = 0 \\
II_{\pp}(\mathbf{t}_2 , \mathbf{t}_1) & = \WW_{\pp,\SSS} (\mathbf{t}_2) \cdot \mathbf{t}_1 = \kappa_2  \mathbf{t}_2 \cdot \mathbf{t}_1 = 0 \\
II_{\pp}(\mathbf{t}_2 , \mathbf{t}_2) & = \WW_{\pp,\SSS} (\mathbf{t}_2) \cdot \mathbf{t}_2 = \kappa_2 \norm{\mathbf{t}_2}^2 = \kappa_2 \\
\end{align*}
By Theorem \ref{theorem-normal-curvature}, equation (@eq-euler-thm-proof), and bilinearity of $II_{\pp}$, we get
\begin{align*}
\kappa_n & = {II}_{\pp} (\dg,\dg) \\
& = \cos^2(\theta) \, II_{\pp}(\mathbf{t}_1 , \mathbf{t}_1)  +  \cos(\theta) \sin(\theta) \,  II_{\pp}(\mathbf{t}_1 , \mathbf{t}_2) \\ 
& \,\,\,\, + \sin(\theta)\cos(\theta)  \,  II_{\pp}(\mathbf{t}_2 , \mathbf{t}_1)  + \sin^2(\theta)  \,  II_{\pp}(\mathbf{t}_2 , \mathbf{t}_2)  \\
& = \cos^2(\theta) \kappa_1 + \sin^2(\theta) \kappa_2 
\end{align*}
ending the proof. 

:::


As an immediate corollary of the Euler's Theorem we get the next
statement.


::: {.Corollary #corollary-euler-thm}

Let $\SSS$ be a regular surface and $\kappa_1, \kappa_2$ its
principal curvatures at $\pp$ with principal vectors $\mathbf{t}_1,\mathbf{t}_2$. Then:

- $\kappa_{1}$ and $\kappa_{2}$ are the minimum and maximum values of $\kappa_{n}$, for all unit speed curves on $\SSS$ passing through $\pp$.

- The directions of lowest and highest curvature on $\SSS$ are given by $\mathbf{t}_1$ and $\mathbf{t}_2$.

:::


In Example \ref{example-curves-on-sphere} we have shown with a direct 
argument that 
$$
\kappa_n = 1
$$
for all unit speed curves on the sphere. Thanks to Euler's Theorem we 
can obtain an immediate proof of this fact.


::: Example 
### Curves on the sphere

Let us consider again the chart for the sphere
$$
\sss(u, v)=(\cos (u) \sin (v), \sin (u) \sin (v), \cos (v))
$$
as seen in Example \ref{example-curves-on-sphere}. By Example \ref{example-sphere-principal}, the principal curvatures of
$\sss$ are
$$
\kappa_1 = \kappa_2 =  1 \,.
$$
By Euler's Theorem, for any curve $\g$ on the sphere we have
$$
\kappa_n = \kappa_1 \cos^2(\theta) + \kappa_2 \sin^2(\theta) = 1 \,.
$$

:::





## Local shape of a surface



The principal curvatures $\kappa_1$ and $\kappa_2$ determine
the maximum and minimum curvature of a surface $\SSS$, see
Corollary \ref{corollary-euler-thm}. Hence we can study the local
shape of $\SSS$ in function of $\kappa_1$ and $\kappa_2$. 




::: Theorem
### Local structure of surfaces {#theorem-local-surface}

Let $\SSS$ be a regular surface and $\pp \in \SSS$. In the vicinity of $\pp$ 
the surface $\SSS$ is approximated by the quadric surface of equation
$$
z = \frac12 \left( x^2 \kappa_1 (\pp) + y^2 \kappa_2(\pp) \right) \,,
$${#eq-local-structure}
where $\kappa_1 (\pp),\kappa_2 (\pp)$ are the principal curvatures of
$\SSS$ at $\pp$.

:::


::: Proof

By Theorem \ref{theorem-weingarten-diagonal} the principal vectors 
$\{ \mathbf{t}_1, \mathbf{t}_2 \}$ are an orthonormal basis of 
$T_{\pp} \SSS$. Therefore the standard unit normal $\NN$ at $\pp$ is 
orthogonal to both 
$\mathbf{t}_1$ and $\mathbf{t}_2$. Up to rotations and translations, 
we can assume WLOG that $\pp = \zero$ and
$$
\mathbf{t}_1 = (1,0,0) \,, \quad 
\mathbf{t}_2 = (0,1,0) \,, \quad 
\NN = (0,0,1) \,.
$${#eq-theorem-local-surface}
Let $\sss$ be a chart for $\SSS$ at $\pp$. Up to reparametrizing, 
we can assume that
$$
\sss(0,0)  = \pp = \zero \,.
$$
As $\NN = (0,0,1)$, it follows that $T_{\pp} \SSS$ is the $xy$-plane
$$
T_{\pp} \SSS = \R^2 = \{ (x,y,0) \divider x, y \in \R \} \, .
$$
Since $\{\sss_u ,\sss_v\}$ is a basis for $T_{\pp} \SSS$, we have that 
for each $(x,y) \in \R^2$ there exist $(s,t) \in \R^2$ such that
$$
(x,y,0) = s \sss_u + t \sss_v \,,
$${#eq-theorem-local-surface-1}
where $\sss_u$ and $\sss_v$ are evaluated at $(0,0)$. The Taylor 
approximation of $\sss$ at $(0,0)$ is
\begin{align*}
\sss(s,t) & = \sss(0,0) + s \sss_u + t \sss_v \\
          & \qquad + \frac12 \left(  s^2 \sss_{uu} + 2st \sss_{uv} + t^2 \sss_{vv}   \right) + R \,, \\
          & = (x,y,0) + \frac12 \left(  s^2 \sss_{uu} + 2st \sss_{uv} + t^2 \sss_{vv}   \right) + R
\end{align*}
where $R$ is a remainder and the derivatives of $\sss$ are evaluated
at $(0,0)$. Hence, if $x,y$ are small (and thus $s,t$ are small), we have
that
$$
\sss(s,t) \approx  (x,y,z)
$$
where
\begin{align*} 
z & := \frac12 \left(  s^2 \sss_{uu} + 2st \sss_{uv} + t^2 \sss_{vv}   \right) \cdot \NN  \\
  & = \frac12 \left( L s^2  + 2M st + N t^2   \right) \,,
\end{align*}
with $L,M,N$ coefficients of the second fundamental form of $\sss$ at
$(0,0)$. Set 
$$
\vv :=  s \sss_u + t \sss_v  \,.
$$
By Theorem \ref{theorem-sff-chart} we have
$$
 L s^2  + 2M st + N t^2  = II_{\pp} (\vv,\vv) = \WW_{\pp,\SSS} (\vv) \cdot \vv \,.
$$
On the other hand, using (@eq-theorem-local-surface) and
(@eq-theorem-local-surface-1) we get
$$
\vv = s \sss_u + t \sss_v  = (x,y,0) = x \mathbf{t}_1 + y \mathbf{t}_2 \,.
$$
Since the Weingarten map is linear we get
\begin{align*}
 \WW_{\pp,\SSS} (\vv) & = x  \WW_{\pp,\SSS} (\mathbf{t}_1) + y  \WW_{\pp,\SSS} (\mathbf{t}_2) \\
    & = x \kappa_1 \mathbf{t}_1 + y \kappa_2 \mathbf{t}_2 \,, 
\end{align*}
where we used that $\mathbf{t}_1$ and $\mathbf{t}_2$ are eigenvectors of 
$\WW_{\pp,\SSS}$ with eigenvalues $\kappa_1$ and $\kappa_2$. Hence
\begin{align*}
 \WW_{\pp,\SSS} (\vv) \cdot \vv & =  x \kappa_1 \mathbf{t}_1 + y \kappa_2 \mathbf{t}_2 \cdot ( x \mathbf{t}_1 + y  \mathbf{t}_2) \\
                               & = x^2 \kappa_1 + y^2 \kappa_2  
\end{align*}
Therefore
\begin{align*}
z & = \frac12 \left( L s^2  + 2M st + N t^2   \right) \\
  & = \frac12 \WW_{\pp,\SSS} (\vv) \cdot \vv \\
  & = \frac12 \left( x^2 \kappa_1 + y^2 \kappa_2  \right) \,,
\end{align*}
showing that 
$$
\sss(t,s) \approx \left(x,y, \frac12 \left( x^2 \kappa_1 + y^2 \kappa_2  \right)  \right) \,.
$$

:::



Thanks to Theorem \ref{theorem-local-surface}
we can distinguish between $4$ approximating shapes.




::: Definition
### Local shape types

Let $\SSS$ be a regular surface and denote by $\kappa_1(\pp)$ and 
$\kappa_2(\pp)$ its principal curvatures at $\pp$. The point $\pp$ is


- **Elliptic** if 
$$
\kappa_1(\pp) > 0 \,, \, \kappa_2(\pp) > 0 \quad \mbox{ or } \quad  \kappa_1(\pp) < 0 \,, \, \kappa_2(\pp) < 0 
$$
Then (@eq-local-structure) is the equation of an **elliptic paraboloid**.

- **Hyperbolic** if 
$$
\kappa_{1}(\mathbf{p})<0<\kappa_{2}(\mathbf{p})  \quad \mbox{ or } \quad  \kappa_{2}(\mathbf{p})<0< \kappa_{1}(\mathbf{p})
$$
Then (@eq-local-structure) is the equation of a **hyperbolic paraboloid**.

- **Parabolic** if 
$$
\kappa_{1}(\mathbf{p})=0 \, , \, \kappa_{2}(\mathbf{p}) \neq 0 \quad \mbox{ or } \quad \kappa_{2}(\mathbf{p}) \neq 0, \, \kappa_{1}(\mathbf{p})=0
$$
Then (@eq-local-structure) is the equation of a **parabolic cylinder**.

- **Planar** if 
$$
\kappa_{1}(\mathbf{p})=\kappa_{2}(\mathbf{p}) = 0
$$
Then (@eq-local-structure) is the equation of a **plane**.


:::



::: {#fig-elephants layout-nrow=2}

![](/images/surfaces_local_shape_1.png){width=70%}

![](/images/surfaces_local_shape_2.png){width=70%}

A surface $\SSS$ is locally approximated by one of the above quadrics, depending on the values of principal curvatures at $\pp$.

:::



::: Example

Consider the surface chart
$$
\sss (u, v) = \left(u-v, u+v, u^{2}+v^{2}\right) \,.
$$
Show that $\pp = \sss(1,0)$ is an elliptic point. Therefore $\sss$ is approximated by an *elliptic paraboiloid* in the vicinity of $\pp$.

*Solution.* In Example \ref{example-weingarten-2} we have shown that the Weingarten matrix of $\sss$ is
$$
\WW 
 = 
\frac{1}{(1 + 2u^2 + 2v^2)^{\frac32}}
\,\left(\begin{array}{ll}
1 + 2v^2 & -2uv \\
- 2uv & 1 + 2u^2
\end{array}\right) \,.
$$
For $u=1$ and $v=1$ we obtain
$$
\WW 
 = 
\frac{1}{3^{\frac32}}
\,\left(\begin{array}{ll}
1  & 0 \\
0 &  3
\end{array}\right)
=
\left(\begin{array}{ll}
3^{-\frac32}  & 0 \\
0 &  3^{- \frac12}
\end{array}\right) \,.
$$
Therefore the principal curvatures at $\pp$ are
$$
\kappa_1(\pp) = 3^{-\frac32} \,, \quad
\kappa_2(\pp) = 3^{-\frac12} \,. \quad
$$
Since $\kappa_1(\pp) > 0$ and $\kappa_2(\pp) > 0$ we have that $\pp$ is an elliptic point.

:::





### Umbilical points


::: Definition
### Umbilical point

Let $\SSS$ be a regular surface and denote by $\kappa_1(\pp)$ and 
$\kappa_2(\pp)$ its principal curvatures at $\pp$. We say that $\pp$ is an **umbilic** if 
$$
\kappa_{1}(\mathbf{p})=\kappa_{2}(\mathbf{p}) \,.
$$

:::


::: Remark

Umbilical points might be **planar** or **elliptic**.

:::


Suppose that $\pp$ is an umbilic, that is, 
$$
\kappa_1=\kappa_2 
$$
at $\pp$. Let $\kappa_n$ be the normal curvature of a unit speed
curve $\g$ passing through $\pp$. By Theorem \ref{theorem-euler-thm}
we have
$$
\kappa_n = \kappa_1 \cos^2(\theta) + \kappa_2 \sin^2(\theta) = \kappa_1 \,.
$$
Therefore $\kappa_n$ does not depend on $\g$. Intuitively, this 
can only happen if in the vicinity of $\pp$ the surface looks like
a sphere or a plane. Indeed, the following theorem holds.


::: Theorem

Let $\SSS$ be a regular surface such that every point $\pp \in \SSS$ is
umbilic. Then $\SSS$ is an open subset of plane or a sphere.

:::


::: Proof

By assumption we have
$$
\kappa_1 (\pp) = \kappa_2 (\pp) = \kappa (\pp) \,, \quad \forall \, \pp \in \SSS \,.
$${#eq-theorem-umbilic}


*Step 1. $\kappa$ is constant.*

By Theorem \ref{theorem-weingarten-diagonal} the principal vectors
$\{\mathbf{t}_1,\mathbf{t}_2\}$ are an orthonormal basis of
$T_{\pp} \SSS$. Hence, for each $\vv \in T_{\pp} \SSS$ there exist
$\lambda,\mu \in \R$ such that
$$
\vv = \lambda \mathbf{t}_1 + \mu \mathbf{t}_2 \,.
$$
Using the linearity of $\WW_{\pp,\SSS}$ and (@eq-theorem-umbilic)
we obtain
\begin{align*}
\WW_{\pp,\SSS} (\vv) & = \lambda \WW_{\pp,\SSS} ( \mathbf{t}_1) + \mu  \WW_{\pp,\SSS} (\mathbf{t}_2) \\
                     & = \lambda \kappa \mathbf{t}_1 + \mu \kappa \mathbf{t}_2 \\
                     & = \kappa \vv \,,
\end{align*}
showing that
$$
\WW_{\pp,\SSS} (\vv) = \kappa \vv \,, \quad \forall \, \vv \in T_{\pp} \SSS \,.
$${#eq-theorem-umbilic-1}
Let $\sss \colon U \to \R^3$ be a chart of $\SSS$. Up to restricting $\sss$, we can
assume that $U$ is connected. By Lemma \ref{lemma-weingarten} we have
$$
\WW_{\pp,\SSS} (\sss_u) = - \NN_{u} \,, \quad 
\WW_{\pp,\SSS} (\sss_v) = - \NN_{v} \,.
$$
On the other hand, by (@eq-theorem-umbilic-1) we infer
$$
\WW_{\pp,\SSS} (\sss_u) = \kappa \sss_u \,, \quad 
\WW_{\pp,\SSS} (\sss_v) = \kappa \sss_v \,,
$$
from which 
$$
\NN_{u} = - \kappa \sss_u \,, \quad 
\NN_{v} = - \kappa \sss_v \,.
$${#eq-theorem-umbilic-2}
Thus
$$
\left( \kappa \sss_u \right)_v = - \left( \NN_u \right)_v = 
- \left( \NN_v \right)_u = \left( \kappa \sss_v \right)_u \,.
$$
Moreover
\begin{align*}
\left( \kappa \sss_u \right)_v & = \kappa_v \sss_u + \kappa \sss_{uv} \\
\left( \kappa \sss_v \right)_u & = \kappa_u \sss_v + \kappa \sss_{uv} \,,
\end{align*}
so that 
$$
\kappa_v \sss_u = \kappa_u \sss_v \,.
$${#eq-theorem-umbilic-3}
Recall that $\sss_u$ and $\sss_v$ are linearly independent, being $\SSS$ regular. Hence the linear combination at (@eq-theorem-umbilic-3) must be trivial, implying
$$
\kappa_u = \kappa_v = 0 \,.
$$
Since $U$ is connected, the above implies that $\kappa$ is constant.


*Step 2.* We have the two cases $\kappa = 0$ and $\kappa \neq 0$.

- Assume $\kappa = 0$. By (@eq-theorem-umbilic-2) we get that
$$
\NN_u = \NN_v = \zero \,,
$$
which implies $\NN$ is constant. Therefore 
$$
\left( \NN \cdot \sss  \right)_u = \NN_u \cdot \sss + \NN \cdot \sss_u = 0  
$$
since $\NN_u = \zero$ and $\NN \cdot \sss_u = 0$ because $\NN$ is orthogonal to $T_{\pp} \SSS$.
Similarly we get
$$
\left( \NN \cdot \sss  \right)_v = 0 \,,
$$
showing that $\NN \cdot \sss$ is constant. Hence there exists $c \in \R$ such that
$$
\NN \cdot \sss(u,v) = c \,, \quad \forall \, (u,v) \in U \,.
$$
This shows $\sss(U)$ is contained in the plane
$$
\pi = \{ \xx \in \R^3 \divider  \NN \cdot \xx = c \} \,.
$$

- Assume $\kappa \neq 0$. Condition (@eq-theorem-umbilic-2) implies 
$$
\NN = -\kappa \sss + \mathbf{a}
$$
for some $\mathbf{a} \in \R^3$ constant vector. Thus
$$
\left\|  \sss - \frac{1}{\kappa} \mathbf{a}  \right\|^2 = 
\left\| - \frac{1}{\kappa}  \NN  \right\|^2 = \frac{1}{\kappa^2} \,,
$$
given that $\| \NN \| = 1$. Therefore $\sss(U)$ is contained in the sphere of center 
$\mathbf{a}/\kappa$ and radius $1/\kappa$.


:::






